[["index.html", "Analysing seed germination and emergence data with R: a tutorial Section 1 Introduction 1.1 The R package 1.2 Our purpose", " Analysing seed germination and emergence data with R: a tutorial Andrea Onofri Update: v. 0.551 (2022-10-20), compil. 2022-10-20 Section 1 Introduction Germination/emergence assays are relatively easy to perform, by following standardised procedures, as described, e.g., by the International Seed Testing Association (see here ). In short, we take a sample of seeds and we put them in an appropriate container. We put the container in the right environmental conditions (e.g., relating to humidity content and temperature) and we inspect the seeds according to a regular schedule (e.g., daily). At each inspection, we count the number of germinated/emerged seeds and remove them from the containers; inspections are performed until no new germinations/emergences are observed for a sufficient amount of time. We see that these assays are rather simple, but, in spite of such simplicity, the process of data analysis still presents several grey areas. How should we quantify the germination/emergence process? How should we compare the germination/emergence of different seed lots? A brief survey of literature shows that a plethora of methods is used, which is certainly encouraged by the wide availability of computer packages. Some of these methods have been around for quite a while (e.g., the use of germination indices or nonlinear regression), some others are relatively new (e.g., methods from survival analysis). It is clear that not all these methods are efficient or reliable, especially when they are used with little concern about the basic assumptions that each method makes. Furthermore, the use of a lot of different methods of data analysis by different research groups may serve the purpose of creativity, but are we really sure that it also serves the purpose of advancing science? Wouldn’t it be better if we could use the same reliable methods of data analysis, so that we could better understand each other, compare our results and pool them together? Therefore, together with some collegues, we decided to start defining a framework for the analysis of germination and emergence data, which might help the readers to select efficient and reliable methods and, lately, improve comparisons and communication of results within the scientific community. We decided to structure this framework as the combination of: a step-by-step procedure the methods to accomplish it a user friendly software interface, based on a new R package. 1.1 The R package As we anticipated, the analyses we propose for seed germination/emergence assays can be performed by using our new R package, namely drcte. This package is heavily based on the ‘drc’ package (Ritz et al., 2015) that is a very flexible software for general model fitting purposes. Although drc contains, already, several basic functions for time-to-event analyses, we felt that, in order to meet the specific needs of agricultural research, it would be useful to make some further customisation and develop some additional functions, which we implemented in the ‘drcte’ package. Furthermore, we also created the drcSeedGerm package, that contains specific functions for seed germination/emergence assays. Both the drcte and drcSeedGerm packages can be downloaded and installed from gitHub, by using the code proposed in the box below. It requires the ‘devtools’ package, that needs to be as well installed, if it is not already included in the system. Please, make sure you always have the latest version of both packages. install.packages(&quot;devtools&quot;) library(devtools) install_github(&quot;OnofriAndreaPG/drcte&quot;) install_github(&quot;OnofriAndreaPG/drcSeedGerm&quot;) Once you are ready with the above packages, you can proceed to work with the rest of this tutorial. 1.2 Our purpose We have already presented the procedure and the R package in a recent paper in the Journal Weed Science (Onofri et al., 2022; if you are interested please follow this link to the paper). The purpose of this tutorial is to expand on that manuscript and present several realistic examples, relating to seed germination/emergence assays. We would like to emphasize that these methods can be as well useful for other types of time-to-event or censored data in agriculture. Building this site is still (and will always be…) an ongoing task, so, please forgive us if you do not find what you are looking for. In the meantime, you can take a look at the published papers from my group and at my blog, at this page. We look forward to your comments to improve our approach. Please, drop your notes to me: Prof. Andrea Onofri Department of Agricultural, Food and Environmental Sciences University of Perugia (Italy) andrea.onofri@unipg.it If you want to be updated, you can follow me at: Follow "],["what-is-time-to-event-data.html", "Section 2 What is time-to-event data? 2.1 Time-to-event data are censored data 2.2 Motivating example: a simulated dataset 2.3 Neglecting censoring 2.4 Accounting for censoring 2.5 Neglecting or accounting for censoring? 2.6 Take-home message", " Section 2 What is time-to-event data? In general, time-to-event data describe the amount of time elapsed before an event of interest occurs. In medicine, such an event is, e.g., the death, or the remission from a disease; in agriculture we are more often interested in other types of events, such as germination, emergence or flowering. Regardless the discipline, studying the time to en event of interest requires periodical inspections on a population of individuals (people, animals, seeds, plants…) to record, for each individual, the date when the event is achieved. The data resulting from such a series of periodical inspections is usually called time-to-event data. Please, note that we have been talking about periodical inspections; in some cases, germination/emergence assays are performed with only one inspection at a pre-defined time. With this type of assays we can only record the proportion of germinated seeds (in general: the proportion of individuals with the event) at a given time point, while we cannot record the event time for all individuals. Therefore, this type of data are NOT time-to-event data and they will not be the object of this tutorial. 2.1 Time-to-event data are censored data You may wonder: what’s the matter with time-to-event data? Do they have anything special that needs our attention? The answer is, definitely, yes! Indeed, with very few exceptions, time-to-event data are affected by a peculiar form of uncertainty, which takes the name of censoring. It relates to the fact that, due to the typical monitoring schedule, the exact time-to-event may not always be determined. Think about a germination assay, where we put, e.g., 100 seeds in a Petri dish and make daily inspections. At each inspection, we count the number of germinated seeds. In the end, what have we learnt about the germination time of each seed? It is easy to note that we do not have exact values, we only have a set of intervals. Let’s consider three possible situations. If we found a germinated seed at the first inspection time, we only know that germination took place before the inspection (left-censoring). If we find a germinated seed at the second (or later) inspection time, we only know that germination took place somewhere between the previous and the present inspection (interval-censoring). If we find an ungerminated seed at the end of the experiment, we only know that its germination time, if any, is higher than the duration of the experiment (right-censoring). Censoring implies a lot of uncertainty, which is additional to other more common sources of uncertainty, such as the individual-to-individual variability or random errors in the manipulation process. The problem of censoring has been widely recognised in other disciplines, such as medicine, in relation to survival data (time-to-death data). In order to address that problem, a vast body of methods has developed, which goes under the name of ‘survival analysis’. In principle, time-to-germination and time-to-emergence data are totally similar to time-to-death data, apart from the fact that we usually deal with different (and less sad) events. Unfortunately, such a connection has been largely overlooked by plant biologists and, as the consequence, the problem of censoring has been most often neglected. This is not an unfortunate practice and it is important that we become aware about the possible consequences of neglecting censoring during the data analysis step. 2.2 Motivating example: a simulated dataset It may be useful to think about a possible mechanism by which time-to-event data arise. Let’s imagine that we have a population with 85% of germinable seeds (the other ones are dormant and, therefore, they are not immediately able to germinate). The germinable fraction is composed by seeds with variables germination times, as dictated by their genotypes and environmental conditions. Let’s assume that such a variability can be described by using a log-logistic distribution, with a median germination time \\(e = 4.5\\) days and a shape parameter \\(b = 1.6\\). If we sample 100 seeds from that population, the sample will not necessarily reflect the characteristics of the whole population. We can do this sampling in R, by using a three-steps approach. 2.2.1 Step 1: the ungerminated fraction First, let’s simulate the number of germinated seeds, assuming a binomial distribution with a proportion of successes equal to 0.85. We use the random number generator rbinom(): #Monte Carlo simulation - Step 1 d &lt;- 0.85 set.seed(1234) nGerm &lt;- rbinom(1, 100, d) nGerm ## [1] 89 We see that, in this instance, 89 seeds germinated out of 100, which is not the expected 85%. This may be regarded as an expression of the typical random sampling variability. 2.2.2 Step 2: germination times for the germinated fraction Second, let’s simulate the germination times for these 89 germinable seeds, by drawing from a log-logistic distribution with \\(b = 1.6\\) and \\(e = 4.5\\). To this aim, we use the rllogis() function in the actuar package (Dutang et al., 2008): #Monte Carlo simulation - Step 2 library(actuar) b &lt;- 1.6; e &lt;- 4.5 Gtimes &lt;- rllogis(nGerm, shape = b, scale = e) Gtimes &lt;- c(Gtimes, rep(NA, 100 - nGerm)) Gtimes ## [1] 3.2936708 3.4089762 3.2842199 1.4401630 3.1381457 ## [6] 82.1611955 9.4906364 2.9226745 4.3424551 2.7006042 ## [11] 4.0202158 8.0519663 0.9492013 7.8199588 1.6163588 ## [16] 7.9661485 8.4641154 11.2879041 9.5014360 7.2786264 ## [21] 7.5809838 12.7421713 32.7999661 9.9691944 1.8137333 ## [26] 4.2197542 1.0218849 1.6604417 30.0352308 5.0235265 ## [31] 8.5085067 7.5367739 4.4185382 11.5555259 2.1919263 ## [36] 10.6509339 8.6857151 0.2185902 1.8377033 3.9362727 ## [41] 3.0864702 7.3804164 3.2978782 7.0100360 4.4775843 ## [46] 2.8328842 4.6721090 9.1258796 2.1485568 21.8749808 ## [51] 7.4265984 2.5148724 4.4491466 13.1132301 4.4559642 ## [56] 4.5684584 2.2556488 11.8783556 1.5338755 1.4106592 ## [61] 31.8419420 7.2666641 65.0154287 9.2798476 2.5988399 ## [66] 7.4612907 4.4048509 27.7439121 3.8257187 15.4967751 ## [71] 1.1960785 62.5152642 2.0169970 19.1134899 4.2891084 ## [76] 6.0420938 22.6521417 7.1946293 2.9028993 0.9241876 ## [81] 4.8277336 13.8068124 4.0273655 10.8651761 1.1509735 ## [86] 5.9593534 7.4009589 12.6839405 1.1698335 NA ## [91] NA NA NA NA NA ## [96] NA NA NA NA NA Now, we have a vector hosting 100 germination times (‘Gtimes’). Please, note that I also added 11 NA values, to represent non-germinable seeds. 2.2.3 Step 3: counts of germinated seeds Unfortunately, due to the monitoring schedule, we cannot observe the exact germination time for each single seed in the sample; we can only count the seeds which have germinated between two assessment times. Therefore, as the third step, we simulate the observed counts, by assuming daily monitoring for 40 days; what we do, is a sort of ‘binning’ process, where we assign each seed to the time interval during which it germinated. obsT &lt;- seq(1, 40, by=1) #Observation schedule count &lt;- table( cut(Gtimes, breaks = c(0, obsT)) ) count ## ## (0,1] (1,2] (2,3] (3,4] (4,5] (5,6] (6,7] (7,8] ## 3 11 10 8 13 2 1 12 ## (8,9] (9,10] (10,11] (11,12] (12,13] (13,14] (14,15] (15,16] ## 4 5 2 3 2 2 0 1 ## (16,17] (17,18] (18,19] (19,20] (20,21] (21,22] (22,23] (23,24] ## 0 0 0 1 0 1 1 0 ## (24,25] (25,26] (26,27] (27,28] (28,29] (29,30] (30,31] (31,32] ## 0 0 0 1 0 0 1 1 ## (32,33] (33,34] (34,35] (35,36] (36,37] (37,38] (38,39] (39,40] ## 1 0 0 0 0 0 0 0 We can see that, e.g., 11 germinated seeds were counted at day 2; therefore they germinated between day 1 and day 2 and their real germination time is unknown, but included in the range between 1 and 2 (left-open and right-closed). This is a typical example of interval-censoring (see above). We can also see that, in total, we counted 86 germinated seeds and, therefore, 14 seeds were still ungerminated at the end of the assay. For this simulation exercise, we know that 11 seeds were non-germinable and three seeds were germinable, but they were not allowed enough time to germinate (look at the table above: there are 3 seeds with germination times higher than 40). In real life, this is another source of uncertainty: we might be able to ascertain whether these 14 seeds are viable or not (e.g. by using a tetrazolium test), but, if they are viable, we would never be able to tell whether they are dormant or their germination time is simply longer than the duration of the assay. In real life, we can only reach an uncertain conclusion: the germination time of the 14 ungerminated seeds is comprised between 40 days to infinity; this is an example of right-censoring. The above uncertainty affects our capability of describing the germination time-course from the observed data. We can try to picture the situation in the graph below. What is the real germination time-course? The red one? The blue one? Something in between? We cannot really say this from our dataset, we are uncertain. The grey areas represent the uncertainty due to censoring. Do you think that we can reasonably neglect it? 2.3 Neglecting censoring For a moment, let’s forget about those grey uncertainty areas. Let’s forget about censoring; this is what it is often done in literature for germination data: we associate the observed proportion of germinated seeds to the exact time when it was observed. It is, indeed, an abuse, as the observed data tell us a different story: the observed proportion of germinated seeds might have been attained before the moment of inspection (and not necessarily at the moment of inspection). But we disregard this and fit a nonlinear regression model, i.e. a log-logistic function: \\[ G(t) = \\frac{d}{ 1 + exp \\left\\{ - b \\right[ \\log(t) - \\log(e) \\left] \\right\\}} \\] where \\(G\\) is the fraction of germinated seeds at time \\(t\\), \\(d\\) is the germinable fraction, \\(e\\) is the median germination time for the germinable fraction and \\(b\\) is the slope around the inflection point. The above model is sygmoidally shaped and it is symmetric on a log-time scale. The three parameters are biologically relevant, as they describe the three main features of seed germination, i.e. capability (\\(d\\)), speed (\\(e\\)) and uniformity (\\(b\\)). In order to fit a nonlinear regression model, we need to transform the observed data, as follows: counts &lt;- as.numeric( table( cut(Gtimes, breaks = c(0, obsT)) ) ) propCum &lt;- cumsum(counts)/100 df &lt;- data.frame(time = obsT, counts = counts, propCum = propCum) df ## time counts propCum ## 1 1 3 0.03 ## 2 2 11 0.14 ## 3 3 10 0.24 ## 4 4 8 0.32 ## 5 5 13 0.45 ## 6 6 2 0.47 ## 7 7 1 0.48 ## 8 8 12 0.60 ## 9 9 4 0.64 ## 10 10 5 0.69 ## 11 11 2 0.71 ## 12 12 3 0.74 ## 13 13 2 0.76 ## 14 14 2 0.78 ## 15 15 0 0.78 ## 16 16 1 0.79 ## 17 17 0 0.79 ## 18 18 0 0.79 ## 19 19 0 0.79 ## 20 20 1 0.80 ## 21 21 0 0.80 ## 22 22 1 0.81 ## 23 23 1 0.82 ## 24 24 0 0.82 ## 25 25 0 0.82 ## 26 26 0 0.82 ## 27 27 0 0.82 ## 28 28 1 0.83 ## 29 29 0 0.83 ## 30 30 0 0.83 ## 31 31 1 0.84 ## 32 32 1 0.85 ## 33 33 1 0.86 ## 34 34 0 0.86 ## 35 35 0 0.86 ## 36 36 0 0.86 ## 37 37 0 0.86 ## 38 38 0 0.86 ## 39 39 0 0.86 ## 40 40 0 0.86 In practice, we determine the cumulative proportion (or percentage) of germinated seeds (‘propCum’), which is used as the response variable, while the observation time (‘time’) is used as the independent variable. Then, we fit the log-logistic function by non-linear least squares regression. I’ll say this again: you can clearly see that, by doing so, we totally neglect the grey areas in the figure above, we only look at the observed points. Let’s use the ‘drm’ function, in the ‘drc’ package (Ritz et al., 2015). The argument ‘fct’ is used to set the fitted function to log-logistic with three parameters (the equation above). The plot() and summary() methods can be used to plot a graph and to retrieve the estimated parameters. library(drc) mod &lt;- drm(propCum ~ time, data = df, fct = LL.3() ) plot(mod, log = &quot;&quot;, xlab = &quot;Time (days)&quot;, ylab = &quot;Proportion of germinated seeds&quot;) summary(mod) ## ## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms) ## ## Parameter estimates: ## ## Estimate Std. Error t-value p-value ## b:(Intercept) -1.8497771 0.0702626 -26.327 &lt; 2.2e-16 *** ## d:(Intercept) 0.8768793 0.0070126 125.044 &lt; 2.2e-16 *** ## e:(Intercept) 5.2691575 0.1020457 51.635 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: ## ## 0.01762168 (37 degrees of freedom) We see that our estimates are very close to the real values (\\(b\\) = 1.85 vs. 1.6; \\(e\\) = 5.27 vs. 4.5; \\(d\\) = 0.88 vs. 0.86) and we also see that standard errors are rather small (the coefficient of variability goes from 1 to 4%). There is a difference in sign for \\(b\\), which relates to the fact that the LL.3() function in ‘drc’ removes the minus sign in the equation above. Please, disregard this aspect, which stems from the fact that the ‘drc’ package is rooted in pesticide bioassays. Do you think that this analysis is not that bad? Wait a moment. Let’s see what happens if we account for censoring. 2.4 Accounting for censoring How can we account for censoring? The answer is simple: we should use fitting methods which are specifically devised to incorporate the uncertainty due to censoring. We said that, in medicine, the body of these methods goes under the name of survival analysis and, from this framework, we can borrow a parametric survival model. However, I will not use the name ‘survival model’ as we are not dealing with a survival process. Instead, I will use the name parametric time-to-event model. My colleagues and I have extensively talked about parametric time-to-event models in two of our recent papers and related appendices (Onofri et al., 2019; Onofri et al., 2018). Therefore, I will not go into detail, now. I will just say that time-to-event models directly consider the observed counts as the response variable. As the independent variable, they consider the extremes of each time interval (‘timeBef’ and ‘timeAf’; see below). We immediately see two differences with nonlinear regression: (1) we do not need to transform the observed counts into cumulative proportions, and (2) by using an interval as the independent variable, we inject into the model the uncertainty due to censoring (the grey areas in the figure above). Let’s reshape the dataset as shown below. df &lt;- data.frame(timeBef = c(0, obsT), timeAf = c(obsT, Inf), counts = c(as.numeric(counts), 100 - sum(counts)) ) df ## timeBef timeAf counts ## 1 0 1 3 ## 2 1 2 11 ## 3 2 3 10 ## 4 3 4 8 ## 5 4 5 13 ## 6 5 6 2 ## 7 6 7 1 ## 8 7 8 12 ## 9 8 9 4 ## 10 9 10 5 ## 11 10 11 2 ## 12 11 12 3 ## 13 12 13 2 ## 14 13 14 2 ## 15 14 15 0 ## 16 15 16 1 ## 17 16 17 0 ## 18 17 18 0 ## 19 18 19 0 ## 20 19 20 1 ## 21 20 21 0 ## 22 21 22 1 ## 23 22 23 1 ## 24 23 24 0 ## 25 24 25 0 ## 26 25 26 0 ## 27 26 27 0 ## 28 27 28 1 ## 29 28 29 0 ## 30 29 30 0 ## 31 30 31 1 ## 32 31 32 1 ## 33 32 33 1 ## 34 33 34 0 ## 35 34 35 0 ## 36 35 36 0 ## 37 36 37 0 ## 38 37 38 0 ## 39 38 39 0 ## 40 39 40 0 ## 41 40 Inf 14 Can you see the difference? Please, note that we also added the ungerminated seeds at the end, with an uncertainty interval going from 40 days to infinity. Time-to-event models can be easily fitted by using the drm() function in the ‘drc’ package, although we should specify that we want to use a time-to-event method, by setting the type = \"event\" argument. More simply, we can use the drmte() function in the ‘drcte’ package, that is a specific package for time-to-event methods. Both the functions use the same syntax and, with respect to nonlinear regression, there are some important differences in the model call. In particular, a nonlinear regression model is defined as: CumulativeProportion ~ timeAf On the other hand, a time-to-event model is defined as: Count ~ timeBef + timeAf The full model call is shown below, both with drm() and with drmte() #Time-to-event model library(drcte) # modTE &lt;- drm(counts ~ timeBef + timeAf, data = df, # fct = LL.3(), type = &quot;event&quot;) modTE &lt;- drmte(counts ~ timeBef + timeAf, data = df, fct = LL.3()) summary(modTE) ## ## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 ## ## Robust estimation: no ## ## Parameter estimates: ## ## Estimate Std. Error t-value p-value ## b:(Intercept) -1.826006 0.194579 -9.3844 &lt; 2.2e-16 *** ## d:(Intercept) 0.881476 0.036928 23.8701 &lt; 2.2e-16 *** ## e:(Intercept) 5.302109 0.565273 9.3797 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 With respect to the nonlinear regression fit, the estimates from a time-to-event fit are very similar, but the standard errors are much higher (the coefficient of variability now goes from 4 to 11%). That was expected: we have added the uncertainty due to censoring. 2.5 Neglecting or accounting for censoring? You may wonder which of the two analysis is right and which is wrong. We cannot say this from just one dataset. However, we can repeat the Monte Carlo simulation above to extract 1000 samples, fit the model by using the two methods and retrieve parameter estimates and standard errors for each sample and method. We do this by using the code below (please, be patient… it may take some time). GermSampling &lt;- function(nSeeds, timeLast, stepOss, e, b, d){ #Draw a sample as above nGerm &lt;- rbinom(1, nSeeds, d) Gtimes &lt;- rllogis(nGerm, shape = b, scale = e) Gtimes &lt;- c(Gtimes, rep(Inf, 100 - nGerm)) #Generate the observed data obsT &lt;- seq(1, timeLast, by=stepOss) counts &lt;- as.numeric( table( cut(Gtimes, breaks = c(0, obsT)) ) ) propCum &lt;- cumsum(counts)/nSeeds timeBef &lt;- c(0, obsT) timeAf &lt;- c(obsT, Inf) counts &lt;- c(counts, nSeeds - sum(counts)) #Calculate the T50 with two methods mod &lt;- drm(propCum ~ obsT, fct = LL.3() ) modTE &lt;- drm(counts ~ timeBef + timeAf, fct = LL.3(), type = &quot;event&quot;) c(b1 = summary(mod)[[3]][1,1], ESb1 = summary(mod)[[3]][1,2], b2 = summary(modTE)[[3]][1,1], ESb2 = summary(modTE)[[3]][1,2], d1 = summary(mod)[[3]][2,1], ESd1 = summary(mod)[[3]][2,2], d2 = summary(modTE)[[3]][2,1], ESd2 = summary(modTE)[[3]][2,2], e1 = summary(mod)[[3]][3,1], ESe1 = summary(mod)[[3]][3,2], e2 = summary(modTE)[[3]][3,1], ESe2 = summary(modTE)[[3]][3,2] ) } set.seed(1234) result &lt;- data.frame() for (i in 1:1000) { res &lt;- GermSampling(100, 40, 1, 4.5, 1.6, 0.85) result &lt;- rbind(result, res) } names(result) &lt;- c(&quot;b1&quot;, &quot;ESb1&quot;, &quot;b2&quot;, &quot;ESb2&quot;, &quot;d1&quot;, &quot;ESd1&quot;, &quot;d2&quot;, &quot;ESd2&quot;, &quot;e1&quot;, &quot;ESe1&quot;, &quot;e2&quot;, &quot;ESe2&quot;) result &lt;- result[result$d2 &gt; 0,] We have stored our results in the data frame ‘result’. The means of estimates obtained for both methods should be equal to the real values that we used for the simulation, which will ensure that estimators are unbiased. The means of standard errors (in brackets, below) should represent the real sample-to-sample variability, which may be obtained from the Monte Carlo standard deviation, i.e. from the standard deviation of the 1000 estimates for each parameter and method. \\(b\\) \\(d\\) \\(e\\) Nonlinear regression 1.63 (0.051) 0.85 (0.006) 4.55 (0.086) Time-to-event method 1.62 (0.187) 0.85 (0.041) 4.55 (0.579) Real values 1.60 (0.188) 0.85 (0.041) 4.55 (0.593) We clearly see that both nonlinear regression and the time-to-event method lead to unbiased estimates of model parameters. However, standard errors from nonlinear regression are severely biased and underestimated. On the contrary, standard errors from time-to-event method are unbiased. 2.6 Take-home message Censoring is peculiar to germination assays and other time-to-event studies. It may have a strong impact on the reliability of our standard errors and, consequently, on hypotheses testing. Therefore, censoring should never be neglected and time-to-event methods should necessarily be used for data analyses. The body of time-to-event methods often goes under the name of ‘survival analysis’, which creates a direct connection between survival data and germination/emergence data. "],["reshaping-time-to-event-data.html", "Section 3 Reshaping time-to-event data 3.1 Motivating example 3.2 Transforming from WIDE to LONG GROUPED 3.3 Transforming from WIDE to LONG UNGROUPED 3.4 From LONG GROUPED to LONG UNGROUPED (and vice-versa) 3.5 From NONLINEAR REGRESSION to LONG GROUPED", " Section 3 Reshaping time-to-event data Let’s now open a parenthesis about the structure of germination/emergence data. To our experience, seed scientists are used to storing their datasets in several formats, that may not be immediately usable with the ‘drcte’ and ‘drc’ packages, which this tutorial is built upon. The figure below shows some of the possible formats that I have often encountered in my consulting work. Possible data structures for seed germination/emergence data Both the ‘drcte’ and ‘drc’ packages require that the data is stored in LONG GROUPED format, as shown in the figure above (panel A, top left). We have already mentioned in the previous section that each row represents a time interval, the columns ‘timeBef’ and ‘timeAf’ represent the beginning and ending of the interval, while the column ‘count’ represents the seeds that germinated/emerged during that interval of time. Other columns may be needed, to represent, e.g., the randomisation unit (e.g., Petri dish) within which the count was made and the experimental treatment level that was allocated to that unit. Apart from the LONG GROUPED format, other time-to-event packages, such as ‘survival’ (Therneau, 2021) or ‘interval’ (Fay and Shaw, 2010) require a different data format, which could be named as LONG UNGROUPED (Figure above, panel B, top right). In this format, each row represents a seed, while the columns ‘timeBef’ and ‘timeAf’ represent the beginning and ending of the interval during which that seed germinated/emerged. The column ‘count’ is not necessary, while other columns may be necessary, as for the LONG GROUPED format. Apart from the above mentioned ‘survival’ and ‘interval’ packages, this format is also compatible with the ‘drcte’ package. Both the GROUPED and UNGROUPED formats have two basic advantages: (i) they can be used with all types of time-to-event data and (ii) they obey to the principles of tidy data (Wickham, 2016). However, to my experience, seed scientists often use other formats, such as the WIDE format (Figure above, panel C, bottom left) or the NONLINEAR REGRESSION format (Figure above, panel D, bottom right), which need to be preliminary transformed into one of the LONG GROUPED or LONG UNGROUPED formats. In order to ease the transition from traditional methods of data analysis to time-to-event methods, we decided to develop a couple of service functions that can be used to reshape the data to a format that is more suitable for time-to-event analyses. Let’s see how to do this by using a ‘real-life’ example. 3.1 Motivating example Seeds of L. ornithopodioides were collected from natural populations, at three different maturation stages, i.e. at 27 Days After Anthesis (DAA), when seeds were still green (Stage A), at 35 DAA, when seeds were brown and soft (Stage B) and at 41 DAA, when seeds were brown and moderately hard (Stage C). Germination assays were performed by placing four replicates of 25 seeds on filter paper (Whatman no. 3) in 9-cm diameter Petri dishes, in the dark and at a constant temperature of 20°C. The filter paper was initially moistened with 5 mL of distilled water and replenished as needed during the assay. Germinated seeds were counted daily over 15 days and removed from the Petri dishes. This dataset is a subset of a bigger dataset, aimed at assessing the time when the hard coat imposes dormancy in seeds of different legume species (Gresta et al., 2011). The authors of the above study sent me the above dataset in WIDE format, where the rows represented each Petri dish and the columns represented all information about each dish, including the counts of germinated seeds, which were listed in different columns. The dataset is shown in the table below and it is available as the ‘lotusOr’ dataframe in the ‘drcte’ package. ## Stage Dish 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## A 1 0 0 0 0 0 1 2 1 1 1 3 1 1 4 2 ## A 2 0 0 0 0 0 1 1 1 1 2 1 2 3 1 1 ## A 3 0 0 0 0 0 3 4 4 3 1 2 1 1 0 1 ## A 4 0 0 0 0 0 1 3 1 2 1 2 1 3 1 1 ## B 5 0 0 0 4 1 2 1 1 0 1 2 2 3 2 1 ## B 6 0 0 0 4 2 2 1 0 1 1 3 4 3 4 0 ## B 7 0 0 0 4 0 4 1 2 1 1 3 3 2 2 0 ## B 8 0 0 0 4 3 2 2 3 1 1 1 1 1 0 0 ## C 9 1 10 1 2 1 2 3 2 0 0 0 0 1 0 0 ## C 10 1 10 4 1 4 0 1 1 0 0 0 0 1 0 1 ## C 11 1 11 5 1 2 2 1 0 1 0 0 1 0 0 0 ## C 12 0 16 1 2 2 1 1 0 0 1 0 0 0 1 0 The WIDE format is handy for swift calculations with a spreadsheet, but, in general, it is not ok, as: (1) it does not obey to the principle of tidy data (Wickham, 2016); (2) it is not generally efficient and it cannot be used with a set of germination assays with different monitoring schedules. Therefore, facing a dataset in the WIDE format, we need to reshape it into a LONG format. 3.2 Transforming from WIDE to LONG GROUPED For such a reshaping, we could use one of the available R functions, such us pivot_longer() in the ‘tidyverse’ or melt() in the ‘reshape’ package. However, when reshaping the data, it is also useful to make e few transformations, such as producing cumulative counts and proportions, that might be useful to plot graphs, or for other purposes. Therefore, we developed the melt_te() function; let’s look at its usage, in the box below. datasetG &lt;- melt_te(lotusOr, count_cols = 3:17, treat = Stage, monitimes = 1:15, n.subjects = rep(25,12)) head(datasetG, 16) ## Stage Units timeBef timeAf count nCum propCum ## 1 A 1 0 1 0 0 0.00 ## 2 A 1 1 2 0 0 0.00 ## 3 A 1 2 3 0 0 0.00 ## 4 A 1 3 4 0 0 0.00 ## 5 A 1 4 5 0 0 0.00 ## 6 A 1 5 6 1 1 0.04 ## 7 A 1 6 7 2 3 0.12 ## 8 A 1 7 8 1 4 0.16 ## 9 A 1 8 9 1 5 0.20 ## 10 A 1 9 10 1 6 0.24 ## 11 A 1 10 11 3 9 0.36 ## 12 A 1 11 12 1 10 0.40 ## 13 A 1 12 13 1 11 0.44 ## 14 A 1 13 14 4 15 0.60 ## 15 A 1 14 15 2 17 0.68 ## 16 A 1 15 Inf 8 NA NA The melt_te() function requires the following arguments: data: the original dataframe count_cols: the positions of the columns in ‘data’, listing, for each dish, the counts of germinated seeds at each assessment time (columns) treat: the columns in ‘data’, listing, for each dish, the levels of each experimental treatment monitimes: a vector of monitoring times that needs to be of the same length as the argument ‘count_cols’ subjects: a vector with the number of viable seeds per dish, at the beginning of the assay. If this argument is omitted, the function assumes that such a number is equal to the total count of germinated seeds in each dish The functions outputs a dataframe in LONG format, where the initial columns code for the experimental treatments, the column ‘Units’ represents the original rows (Petri dishes), ‘timeAf’ represents the time at which the observation was made, ‘timeBef’ represents the time at which the previous observation was made, ‘count’ represents the number of seeds that germinated between ‘timeBef’ and ‘timeAf’, ‘nCum’ is the cumulative count and ‘propCum’ is the cumulative proportion of germinated seeds. An extra row is added for the ungerminated seeds at the end of the assay, with ‘timeBef’ equal to the final assessment time and ‘timeAf’ equal to \\(\\infty\\). 3.3 Transforming from WIDE to LONG UNGROUPED The LONG GROUPED format is good for the packages ‘drc’ and ‘drcte’. However, we might be interested in performing data analyses within the framework of survival analysis, e.g. with the ‘survival’ or ‘interval’ packages, that require the LONG UNGROUPED format. In order to reshape the original dataset into the LONG UNGROUPED format, we can use the same melt_te() function, by setting the argument grouped = FALSE. An example is given in the box below. datasetU &lt;- melt_te(lotusOr, count_cols = 3:17, treat = 1, monitimes = 1:15, n.subjects = rep(25,12), grouped = F) head(datasetU, 16) ## Stage Units timeBef timeAf ## 1 A 1 5 6 ## 2 A 1 6 7 ## 3 A 1 6 7 ## 4 A 1 7 8 ## 5 A 1 8 9 ## 6 A 1 9 10 ## 7 A 1 10 11 ## 8 A 1 10 11 ## 9 A 1 10 11 ## 10 A 1 11 12 ## 11 A 1 12 13 ## 12 A 1 13 14 ## 13 A 1 13 14 ## 14 A 1 13 14 ## 15 A 1 13 14 ## 16 A 1 14 15 3.4 From LONG GROUPED to LONG UNGROUPED (and vice-versa) If necessary, we can easily reshape back and forth from the GROUPED and UNGROUPED formats, by using the funtions ungroup_te and group_te(). See the sample code below. # From LONG GROUPED to LONG UNGROUPED datasetU2 &lt;- ungroup_te(datasetG, count)[,-c(5, 6)] head(datasetU2, 16) ## Stage Units timeBef timeAf ## 1 A 1 5 6 ## 2 A 1 6 7 ## 3 A 1 6 7 ## 4 A 1 7 8 ## 5 A 1 8 9 ## 6 A 1 9 10 ## 7 A 1 10 11 ## 8 A 1 10 11 ## 9 A 1 10 11 ## 10 A 1 11 12 ## 11 A 1 12 13 ## 12 A 1 13 14 ## 13 A 1 13 14 ## 14 A 1 13 14 ## 15 A 1 13 14 ## 16 A 1 14 15 # From LONG UNGROUPED to LONG GROUPED datasetG2 &lt;- group_te(datasetU) head(datasetG2, 16) ## Stage Units timeBef timeAf count ## 1 A 1 5 6 1 ## 2 A 1 6 7 2 ## 3 A 1 7 8 1 ## 4 A 1 8 9 1 ## 5 A 1 9 10 1 ## 6 A 1 10 11 3 ## 7 A 1 11 12 1 ## 8 A 1 12 13 1 ## 9 A 1 13 14 4 ## 10 A 1 14 15 2 ## 11 A 1 15 Inf 8 ## 12 A 2 5 6 1 ## 13 A 2 6 7 1 ## 14 A 2 7 8 1 ## 15 A 2 8 9 1 ## 16 A 2 9 10 2 3.5 From NONLINEAR REGRESSION to LONG GROUPED In other instances, it may happen that the dataset was prepared as required by nonlinear regression analysis, i.e. listing the cumulative number of germinated seeds at each inspection time. The following Table shows an example for the first Petri dish, as available in the ‘lotusCum’ dataframe in the ‘drcte’ package. ## Stage Dish Time nCum ## A 1 1 0 ## A 1 2 0 ## A 1 3 0 ## A 1 4 0 ## A 1 5 0 ## A 1 6 1 ## A 1 7 3 ## A 1 8 4 ## A 1 9 5 ## A 1 10 6 ## A 1 11 9 ## A 1 12 10 ## A 1 13 11 ## A 1 14 15 ## A 1 15 17 In this situation, we need to ‘decumulate’ the counts and add the beginning of each inspection interval (e.g., ‘timeBef’). We can easily do this by using the decumulate_te() function in ‘drcte’. An example is given in the box below. dataset_sd &lt;- decumulate_te(lotusCum, resp = nCum, treat = Stage, monitimes = Time, units = Dish, n.subjects = rep(25, 12), type = &quot;count&quot;) dataset_sd &lt;- decumulate_te(lotusCum, resp = Prop, treat = Stage, monitimes = Time, units = Dish, n.subjects = rep(25, 12), type = &quot;proportion&quot;) The decumulate_te() function requires the following arguments: resp: the column containing the counts/proportions of germinated seeds treat: the columns listing, for each row of data, the corresponding level of experimental factors (one factor per column) monitimes: the column listing monitoring times units: the column listing the randomisation units subjects: a vector listing the number of viable seeds, at the beginning of the assay, for each randomisation unit. type: a value specifying if ‘resp’ contains ‘counts’ or ‘proportions’ We do hope that, with these functions, we can menage to ease your transition from traditional methods of data analysis to time-to-event methods, for seed germination/emergence assays. "],["time-to-event-models-for-seed-germinationemergence.html", "Section 4 Time-to-event models for seed germination/emergence 4.1 Parametric time-to-event models 4.2 Nonparametric time-to-event models 4.3 Kernel density estimators 4.4 ML, NPMLE or KDE?", " Section 4 Time-to-event models for seed germination/emergence The individual seeds within a population do not germinate/emerge altogether at the same moment; this is an undisputed fact, resulting from seed-to-seed variability in germination/emergence time. Accordingly, the primary reason why we organise germination assays is to describe the progress to germination for the whole population, by using some appropriate time-to-event model. What is a time-to-event model? It is a model that describes the probability that the event (germination/emergence, in our case) occurs at any time \\(t\\) or before that time: \\[ P(t) = \\Phi(T \\le t)\\] In practice, it may be easier to think that \\(P(t)\\) is the proportion of germinated/emerged seeds at time \\(t\\). In statistical terms, \\(\\Phi\\) is a Cumulative Distribution Function (CDF), with the following characteristics: the time \\(t\\) is constrained from 0 to +\\(\\infty\\) the response \\(P(t)\\) is constrained from 0 to 1 the response \\(P(t)\\) is monotonically increasing due to the possible presence of a final fraction of individuals without the event (e.g., ungerminated seeds), \\(P(t)\\) may not necessarily reach 1. The first task to fit a time-to-event model is to select a form for \\(\\Phi\\). In general, we have three possibilities: a parametric maximum likelihood model (ML) a non-parametric maximum likelihood model (NPMLE) a kernel density estimator (KDE) Let’s have a closer look at those three options. 4.1 Parametric time-to-event models The CDF for parametric time-to-event models is characterised by a pre-defined, usually sigmoidal, shape. Right-skewed CDFs have proven useful, such as the log-normal, log-logistic or Weibull, which are only defined for \\(t &gt; 0\\) (see #1 above). These CDFs contain a location (\\(e\\)) and a scale (\\(b\\)) parameter: the former is a measure of central tendency (e.g., the median for the log-logistic and log-normal CDFs) while the latter is a measure of how fast the curve grows during time. For seed germination/emergence, most often, a third parameter is necessary, to describe the fraction of dormant or nonviable seeds (\\(0 &lt; d \\leq 1\\)). As an example, we show a log-logistic CDF, that is also used in ecotoxicology, for dose-response studies: \\[P(t) = \\frac{d}{1 + exp\\left\\{ b \\right[ \\log(t) - log(e)\\left] \\right\\}}\\] Fitting the above parametric model implies that, based on the observed data, we need to assign a specific value to the parameters \\(b\\), \\(d\\) and \\(e\\), so that an appropriate likelihood function is maximised (Maximum Likelihood estimation). Relating to the estimation process, we should necessarily take into account that germination/emergence data are censored data; neglecting this fact has some important consequences, as I have described in this post. In practice, parametric time-to-event models can be fitted by the drmte() function in the ‘drcte’ package. As an example, let’s consider a factitious dataset relating to an assay where the germinations of 30 seeds were counted daily for 15 days. A log-logistic time-to-event model can be easily fit as follows: dataset &lt;- read.csv(&quot;https://www.casaonofri.it/_datasets/oneFlush.csv&quot;) head(dataset) ## timeBef timeAf counts ## 1 0 1 3 ## 2 1 2 2 ## 3 2 3 3 ## 4 3 4 4 ## 5 4 5 3 ## 6 5 6 2 library(drcte) te.mod &lt;- drmte(counts ~ timeBef + timeAf, fct = LL.3(), data = dataset) # Alternative # te.mod &lt;- drm(counts ~ timeBef + timeAf, fct = LL.3(), # data = dataset, type = &quot;event&quot;) We can see that we have directly considered the observed counts as the response variable, with no preliminary transformation. Furthermore, we have two predictors that represent the extremes of each time interval (‘timeBef’ and ‘timeAf’), by which we associate each count to the whole uncertainty interval during which germinations took place and not to a precise time instant. In other words, we fully respect our censored data. The very same model can be fitted by using the drm() function in the ‘drc’ package, although we should add the argument type = \"event\", as this latter package is not specific to time-to-event methods. The usual coef(), summary(), print() and plot() methods can be used for ‘drcte’ objects as for any other model object in R. summary(te.mod) ## ## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 ## ## Robust estimation: no ## ## Parameter estimates: ## ## Estimate Std. Error t-value p-value ## b:(Intercept) -1.52553 0.44166 -3.4541 0.0005521 *** ## d:(Intercept) 0.97842 0.16027 6.1048 1.03e-09 *** ## e:(Intercept) 4.91400 1.68058 2.9240 0.0034558 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 plot(te.mod, ylim = c(0, 1), xlim = c(0, 15), xlab = &quot;Time&quot;, ylab = &quot;Cumulative proportion of germinated seeds&quot;) 4.2 Nonparametric time-to-event models In some cases we are not willing to assume that the germination curve has a certain predefined shape, but we need an extra degree of flexibility. For example, emergences may proceed in successive flushes that are not easily described by using a sigmoidal curve. In these cases, we can fit a non-parametric model, whose shape is not pre-defined, but it is built by closely following the observed data. In survival analyses, time-to-event curves for interval censored data are estimated by using Nonparametric Maximum Likelihood Estimators (NPMLE), that are potentially interesting also for plant science. For example, we can consider another factitious dataset, where the germination took place in two distinct flushes; a non-parametric maximum likelihood model can be fit by using the NPMLE() function, as shown in the box below. dataset &lt;- read.csv(&quot;https://www.casaonofri.it/_datasets/twoFlushes.csv&quot;) head(dataset) ## timeBef timeAf nEmerg ## 1 0 2 0 ## 2 2 4 1 ## 3 4 6 10 ## 4 6 8 9 ## 5 8 10 4 ## 6 10 12 0 te.npmle &lt;- drmte(nEmerg ~ timeBef + timeAf, fct = NPMLE(), data = dataset) summary(te.npmle) ## ## Model fitted: NPML estimator for time-to-event data ## ## Robust estimation: no ## ## Turnbull&#39;s intervals and masses: ## ## count pdf cdf Naive.SE ## 1.(2,4] 1.00 0.02 0.02 0.0198 ## 1.(4,6] 10.00 0.20 0.22 0.0586 ## 1.(6,8] 9.00 0.18 0.40 0.0693 ## 1.(8,10] 4.00 0.08 0.48 0.0707 ## 1.(14,16] 1.00 0.02 0.50 0.0707 ## 1.(18,20] 1.00 0.02 0.52 0.0707 ## 1.(20,22] 1.00 0.02 0.54 0.0705 ## 1.(22,24] 4.00 0.08 0.62 0.0686 ## 1.(24,26] 7.00 0.14 0.76 0.0604 ## 1.(26,28] 6.00 0.12 0.88 0.0460 ## 1.(28,30] 3.00 0.06 0.94 0.0336 ## 1.(32,Inf) 3.00 0.06 1.00 0.0000 par(mfrow = c(1,2)) plot(te.npmle, ylim = c(0, 1), xlab = &quot;Time&quot;, ylab = &quot;Cumulative proportion of germinated seeds&quot;, main = &quot;Interpolation method&quot;, npmle.points = T) plot(te.npmle, ylim = c(0, 1), xlab = &quot;Time&quot;, ylab = &quot;Cumulative proportion of germinated seeds&quot;, npmle.type = &quot;midpoint&quot;, shading = F, main = &quot;Midpoint imputation&quot;) With NPMLE, the time-to-event curve is only defined at the end of each time interval, while it is undefined elsewhere and it is (optionally) represented by a shaded area (Figure above, left). This shaded area reflects the uncertainty due to censoring. Although we cannot know at what moment the nonparametric curve went up within the grey interval, we can make some reasonable assumptions. For example, we could assume that events are evenly spread within the interval, which is the approach taken in the ‘interval’ package (Figure above, left panel). In the ‘survival’ package and, most commonly, in survival analysis, it is assumed that the curve goes up in the middle of the interval (midpoint imputation; Figure above, right panel). 4.3 Kernel density estimators NPMLEs are very flexible and they can be used to describe the progress to germination/emergence with, virtually, every type of datasets, also when the events took place in distinct flushes. However, we may be reluctant to accept a time-to-event curve with a stairstep shape, especially for prediction purposes. A further possibility to describe the time to event curve with a smooth and flexible model is to use a so-called Kernel Density Estimator (KDE). A KDE is built by considering the observed data, a Kernel function (usually gaussian) and a bandwith value, that controls the degree of smoothing; a nice post to see how Kernel density estimation works in practice can be found at this link here. In the box below we show that a KDE can be fitted to the observed data (same example as above) by using the drmte() function and setting the ‘fct’ argument to KDE(). Please, note that this type of KDE is specifically modified to comply with censoring. te.kde &lt;- drmte(nEmerg ~ timeBef + timeAf, fct = KDE(), data = dataset) summary(te.kde) ## ## Model fitted: Kernel estimator for the distribution function ## ## Robust estimation: no ## ## Bandwidth estimates: ## ## Estimate ## h:(bandwidth) 1.7871 plot(te.kde, ylim = c(0, 1), xlab = &quot;Time&quot;, ylab = &quot;Cumulative proportion of germinated seeds&quot;) paf &lt;- KDE.fun(seq(1,35, 1), dataset$timeBef, dataset$timeAf, dataset$nEmerg, h = 0.5) lines(paf ~ seq(1,35, 1), col = &quot;red&quot;) paf &lt;- KDE.fun(seq(1,35, 1), dataset$timeBef, dataset$timeAf, dataset$nEmerg, h = 3.0) lines(paf ~ seq(1,35, 1), col = &quot;blue&quot;) We have augmented the above graph with three estimators: the blue one has a bandwidth \\(h = 3\\), the red one has \\(b = 0.5\\) and the black one has \\(b = 1.7871\\). Our aim was to show the effect of bandwidth selection on the resulting time-to-event curve, although it is usually necessary to apply an appropriate algorithm for the selection. The function drmte(), by default, uses the AMISE method and, unless you know what you are doing, we recommend that you stick to such an algorithm. 4.4 ML, NPMLE or KDE? There is no rule to select the type of time-to-event model for seed germination/emergence and you will have to make your own choice and defend it at the publication stage. As a swift suggestion, I would say that a parametric model is to be preferred, unless it shows some visible signs of lack of fit. Whatever model you select, fitting a time-to-event model may be the most unambiguous way to describe the progress to germination/emergence. In a future post, we will see that we can also compare time-to-event models for different experimental treatments and or environmental conditions, which is, most often, the central step in our process of data analyses, for seed germination/emergence assays. "],["comparing-germinationemergence-for-several-seed-lots.html", "Section 5 Comparing germination/emergence for several seed lots 5.1 A motivating example 5.2 Fitting several time-to-event curves 5.3 Comparing non-parametric curves", " Section 5 Comparing germination/emergence for several seed lots Very often, seed scientists need to compare the germination behavior of different seed populations, e.g., different plant species, or one single plant species submitted to different temperatures, light conditions, priming treatments and so on. How should such a comparison be performed? For example, if we have submitted several seed samples to different environmental conditions, how do we decide whether the germinative response is affected by those environmental conditions? If the case that we have replicates for all experimental treatments, e.g. several Petri dishes, one possible line of attack is to take a summary measure for each dish and use that for further analyses, in a two-steps fashion. For example, we could take the total number of germinated seeds (Pmax) in each dish and use the resulting values to parameterise some sort of ANOVA-like model and test the significance of all effects. This method of data analysis is known as ‘response feature analysis’ and it may be regarded as ‘very traditional’, in the sense that it is often found in literature; although it is not wrong, it is, undoubtedly, sub-optimal. Indeed, two seed lots submitted to different treatments may show the same total number of germinated seeds, but a different velocity or uniformity of germination. In other words, if we only consider, e.g., the Pmax, we can answer the question: “do the seed lots differ for their germination capability?”, but not the more general question: “are the seed lots different?”. In order to answer this latter question, we should consider the entire time-course of germination and not only one single summary statistic. In other words, we need a method to fit and compare several time-to-event curves. 5.1 A motivating example Let’s take a practical approach and start from an example: a few years ago, some colleagues of mine studied the germination behavior of a plant species (Verbascum arcturus), in different conditions. In detail, they considered the factorial combination of two storage periods (LONG and SHORT storage) and two temperature regimes (FIX: constant daily temperature of 20°C; ALT: alternating daily temperature regime, with 25°C during daytime and 15°C during night time, with a 12:12h photoperiod). If you are a seed scientist and are interested in this experiment, you’ll find detail in Catara et al. (2016). If you are not a seed scientist, you may wonder why my colleagues made such an assay; well, there is evidence that, for some plant species, the germination ability improves over time, after seed maturation. Therefore, if we take seeds and store them for different periods of time, there might be an effect on their germination traits. Likewise, there is also evidence that germinations may be hindered if seed is not submitted to daily temperature fluctuations. For seed scientists, all these mechanisms are very important, as they permit to trigger the germinations when the environmental conditions are favorable for seedling survival. Let’s go back to our assay: the experimental design consisted of four experimental ‘combinations’ (LONG-FIX, LONG-ALT, SHORT-FIX and SHORT-ALT) and four replicates for each combination. One replicate consisted of a Petri dish, that is a small plastic box containing humid blotting paper, with 25 seeds of V. arcturus. In all, there were 16 Petri dishes, which were put in climatic chambers with the appropriate conditions. During the assay, my colleagues made daily inspections: germinated seeds were counted and removed from the dishes. Inspections were made for 15 days, until no more germinations could be observed. The original dataset is available from a gitHub repository: let’s load and have a look at it. rm(list = ls()) datasetOr &lt;- read.csv(&quot;https://raw.githubusercontent.com/OnofriAndreaPG/agroBioData/master/TempStorage.csv&quot;, header = T, check.names = F) head(datasetOr) ## Dish Storage Temp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 ## 1 1 Low Fix 0 0 0 0 0 0 0 0 3 4 6 0 1 0 3 ## 2 2 Low Fix 0 0 0 0 1 0 0 0 2 7 2 3 0 5 1 ## 3 3 Low Fix 0 0 0 0 1 0 0 1 3 5 2 4 0 1 3 ## 4 4 Low Fix 0 0 0 0 1 0 3 0 0 3 1 1 0 4 4 ## 5 5 High Fix 0 0 0 0 0 0 0 0 1 2 5 4 2 3 0 ## 6 6 High Fix 0 0 0 0 0 0 0 0 2 2 7 8 1 2 1 We have one row per Petri dish; the first three columns show, respectively, the dish number, storage and temperature conditions. The next 15 columns represent the inspection times (from 1 to 15) and contain the counts of germinated seeds. The research question is: Is germination behavior affected by storage and temperature conditions? 5.2 Fitting several time-to-event curves The original dataset for our example is in a WIDE format and, as we have shown earlier in this tutorial, it is necessary to reshape it in LONG GROUPED format, by using the melt_te() function in the ‘drcte’ package. The melt_te() function needs to receive the columns storing the counts (‘count_cols = 4:18’), the columns storing the factor variables (‘treat_cols = c(“Dish”, “Storage”, “Temp”)’), a vector of monitoring times (‘monitimes = 1:15’) and a vector with the total number of seeds in each Petri dish (‘n.subjects = rep(25,16)’). library(drcte) dataset &lt;- melt_te(datasetOr, count_cols = 4:18, treat_cols = c(&quot;Dish&quot;, &quot;Storage&quot;, &quot;Temp&quot;), monitimes = 1:15, n.subjects = rep(25, 16)) head(dataset, 16) ## Dish Storage Temp Units timeBef timeAf count nCum propCum ## 1 1 Low Fix 1 0 1 0 0 0.00 ## 2 1 Low Fix 1 1 2 0 0 0.00 ## 3 1 Low Fix 1 2 3 0 0 0.00 ## 4 1 Low Fix 1 3 4 0 0 0.00 ## 5 1 Low Fix 1 4 5 0 0 0.00 ## 6 1 Low Fix 1 5 6 0 0 0.00 ## 7 1 Low Fix 1 6 7 0 0 0.00 ## 8 1 Low Fix 1 7 8 0 0 0.00 ## 9 1 Low Fix 1 8 9 3 3 0.12 ## 10 1 Low Fix 1 9 10 4 7 0.28 ## 11 1 Low Fix 1 10 11 6 13 0.52 ## 12 1 Low Fix 1 11 12 0 13 0.52 ## 13 1 Low Fix 1 12 13 1 14 0.56 ## 14 1 Low Fix 1 13 14 0 14 0.56 ## 15 1 Low Fix 1 14 15 3 17 0.68 ## 16 1 Low Fix 1 15 Inf 8 NA NA In the resulting data frame, the column ‘timeAf’ contains the time when the inspection was made and the column ‘count’ contains the number of germinated seeds (e.g. 9 seeds were counted at day 9). These seeds did not germinate exactly at day 9; they germinated within the interval between two inspections, that is between day 8 and day 9. The beginning of the interval is given as the variable ‘timeBef’. Apart from these three columns, we have the columns for the blocking factor (‘Dish’ and ‘Units’; this latter column is added by the R function, but it is not useful in this case) and for the treatment factors (‘Storage’ and ‘Temp’) plus two other additional columns (‘nCum’ and ‘propCum’), which we are not going to use for our analyses. In this case, we have reasons to believe that the germination time-course can be described by using a parametric log-logistic time-to-event model, which can be estimated by using either the drm() function in the ‘drc’ package (Ritz et al., 2019) or the drmte() function in the ‘drcte’ package (Onofri et al., 2022). In both cases, we have to include the experimental factor (‘curveid’ argument), to specify that we want to fit a different curve for each combination of storage and temperature. library(tidyverse) ## ── Attaching packages ───────────────────────────── tidyverse 1.3.1 ── ## ✔ ggplot2 3.3.6 ✔ purrr 0.3.4 ## ✔ tibble 3.1.7 ✔ dplyr 1.0.9 ## ✔ tidyr 1.2.0 ✔ stringr 1.4.0 ## ✔ readr 2.1.2 ✔ forcats 0.5.1 ## ── Conflicts ──────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ✖ dplyr::select() masks MASS::select() library(drcte) dataset &lt;- dataset %&gt;% mutate(across(1:3, .fns = factor)) mod1 &lt;- drmte(count ~ timeBef + timeAf, fct = loglogistic(), data = dataset, curveid = Temp:Storage) summary(mod1) ## ## Model fitted: Log-logistic distribution of event times ## ## Robust estimation: no ## ## Parameter estimates: ## ## Estimate Std. Error t-value p-value ## b:Fix:Low 4.974317 0.819632 6.0690 1.287e-09 *** ## b:Fix:High 11.476618 1.254439 9.1488 &lt; 2.2e-16 *** ## b:Alt:Low 7.854558 5.239825 1.4990 0.1339 ## b:Alt:High 10.600439 1.014061 10.4534 &lt; 2.2e-16 *** ## d:Fix:Low 0.998474 0.150189 6.6481 2.968e-11 *** ## d:Fix:High 0.861711 0.038987 22.1027 &lt; 2.2e-16 *** ## d:Alt:Low 1.405930 5.607576 0.2507 0.8020 ## d:Alt:High 0.948113 0.024298 39.0208 &lt; 2.2e-16 *** ## e:Fix:Low 12.009974 0.987039 12.1677 &lt; 2.2e-16 *** ## e:Fix:High 10.906963 0.190532 57.2447 &lt; 2.2e-16 *** ## e:Alt:Low 17.014976 13.214513 1.2876 0.1979 ## e:Alt:High 9.585255 0.166937 57.4183 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 In a previous post I have described a log-logistic time-to-event model (see here), which has a sygmoidal shape, with the three parameters \\(b\\), \\(d\\) and \\(e\\). These parameters represent, respectively, the slope at inflection point, the higher asymptote (i.e. the maximum proportion of germinated seeds) and the median germination time. As we have four curves, we have a number of 12 estimated parameters. We see that the optimization routines returns an unreasonable value for the higher asymptote for one of the curves (\\(d\\) = 1.40 with Alt:Low); it is unreasonable because the maximum proportion of germinated seeds may not exceed 1. Therefore, we should refit the model by adding a constraint (\\(d \\le 1\\)) for all the four curves. We can do so by setting the ‘upperl’ argument to 1 for the 5th through 8th estimands. mod1 &lt;- drmte(count ~ timeBef + timeAf, fct = loglogistic(), data = dataset, curveid = Temp:Storage, upperl = c(NA, NA, NA, NA, 1, 1, 1, 1, NA, NA, NA, NA)) summary(mod1) ## ## Model fitted: Log-logistic distribution of event times ## ## Robust estimation: no ## ## Parameter estimates: ## ## Estimate Std. Error t-value p-value ## b:Fix:Low 4.979665 0.818414 6.0845 1.168e-09 *** ## b:Fix:High 11.471625 1.254025 9.1478 &lt; 2.2e-16 *** ## b:Alt:Low 8.408186 2.232712 3.7659 0.0001659 *** ## b:Alt:High 10.605807 1.014523 10.4540 &lt; 2.2e-16 *** ## d:Fix:Low 0.997284 0.149235 6.6826 2.347e-11 *** ## d:Fix:High 0.861709 0.038999 22.0955 &lt; 2.2e-16 *** ## d:Alt:Low 1.000000 0.881644 1.1342 0.2566920 ## d:Alt:High 0.948132 0.024282 39.0468 &lt; 2.2e-16 *** ## e:Fix:Low 12.004534 0.981279 12.2336 &lt; 2.2e-16 *** ## e:Fix:High 10.907108 0.190613 57.2213 &lt; 2.2e-16 *** ## e:Alt:Low 15.903079 2.872327 5.5367 3.083e-08 *** ## e:Alt:High 9.585297 0.166873 57.4406 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 plot(mod1, log = &quot;&quot;, legendPos = c(6, 1)) From the graph we see that there are visible differences between the fitted curves (the legend considers the curves in alphabetical order, i.e. 1: Fix-Low, 2: Fix-High, 3: Alt-Low and 4: Alt-High). Now, the question is: could we say that those differences are only due to chance (null hypothesis)? In order to make such a test, we could compare the logarithm of the likelihood for the fitted model with the logarithm of the likelihood for a ‘reduced’ model, where all curves have been pooled into one common curve for all treatment levels. The higher the log-likelihood difference, the lowest the probability that the null is true (Likelihood Ratio Test; LRT). A LRT for parametric models can be done with the compCDF() function in the ‘drcte’ package, as shown in the box below. compCDF(mod1) ## ## ## Likelihood ratio test ## NULL: time-to-event curves are equal ## ## Observed LR value: 202.8052 ## Degrees of freedom: 9 ## P-value: 8.551556e-39 We see that the LR value, that relates to the difference between the two log-likelihoods, is rather high and equal to 202; when the null is true, this LR value has an approximate Chi-square distribution; accordingly, we see that the P-level is very low and, thus, the null should be rejected. It general, the results of LRTs should be taken with care, particularly when the observed data are not independent from one another. Unfortunately, the lack of independence is an intrinsic characteristic of germination/emergence assays, where seeds are, most often, clustered within Petri dishes or other types of containers. In this example, we got a very low p-level, which leaves us rather confident that the difference between time-to-event curves is significant. More generally, instead of relying on a chi-square approximation, we should better use a grouped-permutation approach. This technique is based on the idea that, when the difference between curves is not significant, we should be able to freely permute the labels (treatment level) among Petri dishes (clustering units) and, consequently, build an empirical distribution for the LR statistic under the null (permutation distribution). The p-level is related to the proportion of LR values in the permutation distribution that are higher than the observed value (i.e.: 202.8) In the code below, we show how we can do this. The code is rather slow and, therefore, we should not use a very high number of permutation; the default is 199, that gives us a minimum p-value of 0.005. We see that we can confirm that the difference between curves is highly significant. compCDF(mod1, type = &quot;permutation&quot;, units = dataset$Dishes) ## ## ## Likelihood ratio test (permutation based) ## NULL: time-to-event curves are equal ## ## Observed LR value: 202.8052 ## Degrees of freedom: 9 ## Naive P-value: 8.551556e-39 ## Permutation P-value (B = 199): 0.005 5.3 Comparing non-parametric curves In the above example, we have decided to fit a parametric time-to-event model. However, in other situations, we might be interested in fitting a non-parametric time-to-event model (NPMLE; see here) and compare the curves for different treatment levels. In practice, nothing changes with respect to the approach I have shown above: first of all, we fit the NPMLEs with the following code: modNP &lt;- drmte(count ~ timeBef + timeAf, fct = NPMLE(), data = dataset, curveid = Temp:Storage) plot(modNP, log = &quot;&quot;, legendPos = c(6, 1)) Next, we compare the non-parametric curves, in the very same fashion as above: compCDF(modNP, units = dataset$Units) ## Exact Wilcoxon test (permutation form) ## NULL: time-to-event curves are equal ## ## level n Scores ## 1 Fix:Low 100 2.5350 ## 2 Fix:High 100 6.4600 ## 3 Alt:Low 100 -51.2275 ## 4 Alt:High 100 42.2325 ## ## Observed T value: 44.56 ## Permutation P-value (B = 199): 0.005 Obviously, with NPMLEs, a different test statistic is used in the background; the default one is the Wilcoxon rank sum score, although two types of log-rank scores are also implemented (Sun’s scores and Finkelstein’s scores; see Fay and Shaw 2010). Permutation based P-values are calculated and reported. The approach is exactly the same with Kernel Density Estimators (KDE; see here). First we fit the four curves curves, by including the experimental factor as the ‘curveid’ argument: modKD &lt;- drmte(count ~ timeBef + timeAf, fct = KDE(), data = dataset, curveid = Temp:Storage) plot(modKD, log = &quot;&quot;, legendPos = c(6, 1)) Second, we compare those curves, by using the compCDF() function: compCDF(modKD, units = dataset$Units) ## Permuting groups ## ....................................................................................................................................................................................................... ## ## Permutation test based on a Cramer-von-Mises type distance (Barreiro-Ures et al., 2019) ## NULL HYPOTHESIS: time-to-event curves are equal ## ## level n D ## 1 Fix:Low 100 0.0579661 ## 2 Fix:High 100 0.1347005 ## 3 Alt:Low 100 4.1378209 ## 4 Alt:High 100 3.8581487 ## ## Observed D value = 2.0472 ## P value = 0.005 In this case, a Cramér‐von Mises type distance among curves is used (Barreiro-Ures et al., 2019), which, roughly speaking, is based on the integrated distance between the KDEs for the different groups and the pooled KDE for all groups. Permutation based P-values are also calculated and reported. "],["fitting-time-to-event-models-with-environmental-covariates.html", "Section 6 Fitting time-to-event models with environmental covariates 6.1 Hydro-time-to-event models 6.2 A better modelling approach 6.3 Another modelling approach 6.4 Further detail", " Section 6 Fitting time-to-event models with environmental covariates We have seen that time-to-event curves (e.g., germination or emergence curves) can be used to describe the time course of germinations/emergences for a seed lot and we have also seen that the effects of experimental factors on seed germination can be accounted for by coding a different time-to-event curve for each factor level. In some cases, we might be interested in considering environmental variables, that are, perhaps, the most important factors to trigger germination/emergence. For example, let’s consider either humidity content in the substrate, or temperature, or oxygen availability; it is clear that these variables play a fundamental role in determining germination extent and velocity and, therefore, they are very much studied by seed scientists. In principle, germination assays with environmental variables are straightforward to set up: several Petri dishes are submitted to different environmental conditions and germinations are inspected over time. What is the best method to analyse the resulting data and retrieve some important parameters, such as threshold temperatures (base, optimal or ceiling temperature) or base water potential? It is important to anticipate that most environmental variables can be expressed on a quantitative scale; obviously when we make an experiment we are forced into selecting a subset of all possible, e.g., temperatures, such as 15, 20, 30°C, but that does not mean that we are not interested to what happens at, e.g., 18 or 22°C. From this point of view, quantitative variables are very different from qualitative variables, such as the different plant species that we have compared in previous sections of this tutorial. In this post we will see an example of how we can account for the effects of water content in the substrate and include it in our time-to-event models. Of course, the same approach can be followed also with other types of environmental variables and, more generally, quantitative variables. 6.1 Hydro-time-to-event models Let’s consider the following example: the germination of rapeseed (Brassica napus L. var. oleifera, cv. Excalibur) was tested at fourteen different water potential levels (0, -0.03, -0.15, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9, -1, -1.1, -1.2, -1.5 MPa), which were created by using a polyethylene glycol solution (PEG 6000). For each water potential level, three replicated Petri dishes with 50 seeds each were incubated at 20°C. Germinated seeds were counted every 2-3 days for 14 days and they were removed from the dishes after germination. The dataset was published by Pace et al. (2012) and it is available as rape in the drcSeedGerm package, which needs to be installed from github (see below). Furthermore, the package drcte is necessary to fit time-to-event models and it should also be installed from gitHub. The following code loads the necessary packages, loads the dataset rape and shows the first six lines. # library(devtools) # install_github(&quot;OnofriAndreaPG/drcSeedGerm&quot;) # install_github(&quot;OnofriAndreaPG/drcte&quot;) library(drcSeedGerm) library(drcte) library(ggplot2) data(rape) head(rape) ## Psi Dish timeBef timeAf nSeeds nCum propCum ## 1 0 1 0 3 49 49 0.98 ## 2 0 1 3 4 0 49 0.98 ## 3 0 1 4 5 0 49 0.98 ## 4 0 1 5 7 0 49 0.98 ## 5 0 1 7 10 0 49 0.98 ## 6 0 1 10 14 0 49 0.98 In the above data.frame, ‘timeAf’ represents the moment when germinated seeds were counted, while ’timeBef’ represents the previous inspection time (or the beginning of the assay). The column ’nSeeds’ is the number of seeds that germinated during the time interval between ‘timeBef’ and ‘timeAf. The ’propCum’ column contains the cumulative proportions of germinated seeds and it is not necessary for time-to-event model fitting, although we can use it for plotting purposes. ggplot(rape, aes(timeAf, propCum)) + geom_point() + facet_wrap(~Psi) + scale_x_continuous(name = &quot;Time (d)&quot;) + scale_y_continuous(name = &quot;Cumulative proportion of germinated seeds&quot;) The germination time-course is strongly affected by the water potential in the substrate, as this determines the ability of seeds to absorb water and, consequently, trigger the germination and emergence processes. Therefore, our obvious interest is to understand how the environmental factor affects the time-course of germination. We have shown that a parametric time-to-event curve is defined as a cumulative probability function (\\(\\Phi\\)), with three parameters: \\[P(t) = \\Phi \\left( b, d, e \\right)\\] Considering our previous post, the most obvious extension of the above model is to allow for different \\(b\\), \\(d\\) and \\(e\\) value for each water potential level: \\[P(t, \\Psi_i) = \\Phi \\left( b_i, d_i, e_i \\right)\\] The first problem is that, for some water potential levels, germination did not occur and, for other levels, it occurred very quickly, so that no time-course of events could be observed (e.g., see the graph at 0 or -0.03 MPa). We say that we have ‘degenerated’ time-to-event curves. If we fit those curves by using the ‘curveid’ argument, we are forced into fitting the same time-to-event model to all water potential levels (as shown in our previous post), and, therefore, the presence of degenerated curves provokes an error. # Not run # mod0 &lt;- drmte(nSeeds ~ timeBef + timeAf, data = rape, # curveid = Psi, fct = loglogistic()) This problem can be circumvented by using the separate = TRUE argument; in this case, the different curves are fitted independent of one another and we are not tied to fitting the same model for all water potential levels. Errors are raised when trying to fit parametric time-to-event models, but they do not stop the execution in R. mod1 &lt;- drmte(nSeeds ~ timeBef + timeAf, data = rape, curveid = Psi, fct = loglogistic(), separate = TRUE) ## Error in optim(startVec, opfct, hessian = TRUE, method = optMethod, control = list(maxit = maxIt, : ## non-finite finite-difference value [3] ## Error in optim(startVec, opfct, hessian = TRUE, method = optMethod, control = list(maxit = maxIt, : ## non-finite value supplied by optim ## Error in optim(startVec, opfct, hessian = TRUE, method = optMethod, control = list(maxit = maxIt, : ## non-finite value supplied by optim ## Error in optim(startVec, opfct, hessian = TRUE, method = optMethod, control = list(maxit = maxIt, : ## non-finite value supplied by optim coef(mod1) ## b:-1 d:-1 e:-1 b:-0.9 d:-0.9 ## 6.439202e+01 4.666194e-02 8.364749e+00 5.832909e+00 5.501028e-01 ## e:-0.9 b:-0.8 d:-0.8 e:-0.8 b:-0.7 ## 5.870221e+00 3.732950e+00 8.788932e-01 4.471057e+00 3.599409e+00 ## d:-0.7 e:-0.7 b:-0.6 d:-0.6 e:-0.6 ## 9.359289e-01 2.730251e+00 -1.439224e+00 -2.343929e+03 7.160646e-01 ## b:-0.5 d:-0.5 e:-0.5 b:-0.15 d:-0.15 ## -6.019417e-01 -1.486343e+03 6.107110e-02 -5.594961e-01 -2.775981e+03 ## e:-0.15 ## 2.952136e-02 In particular, for the cases where a time-course of events cannot be estimated, the drmte() function resorts to fitting a simpler model, where only the \\(d\\) parameter is estimated (that is the maximum fraction of germinated seeds). In the box above, we can see the estimated parameters but no standard errors, which can be obtained by using the summary() method, although there are some statistical issues that we will consider in a following post. 6.2 A better modelling approach The previous approach is clearly sub-optimal. First of all, the different water potential levels are assumed as independent, with no ordering and distances. In other words, we have a time-to-event curve for, e.g. -0.9 MPa and -0.8 MPa, but we have no information about the time-to-event curve for any water potential levels in between. Furthermore, we have no estimates of some relevant hydro-time parameters, such as the base water potential, that is fundamental to predict the germination/emergence in field conditions. In order to account for the very nature of the water potential variable, we could code a time-to-event model where the three parameters are continuous functions of \\(\\Psi\\): \\[P(t, \\Psi) = \\Phi \\left( b(\\Psi), d(\\Psi), e(\\Psi) \\right)\\] We followed such an approach in a relatively recent publication (Onofri et al., 2018) and we also spoke about this in a recent post. In detail, we considered a log-logistic cumulative distribution function: \\[P(t) = \\frac{ d }{1 + \\exp \\left\\{ b \\left[ \\log(t) - \\log( e ) \\right] \\right\\} }\\] where \\(e\\) is the median germination time, \\(b\\) is the slope at the inflection point and \\(d\\) is the maximum germinated proportion. Considering that the germination rate is the inverse of germination time, we replaced \\(e = 1/GR_{50}\\) and wrote the three parameters as functions of \\(\\Psi\\): \\[P(t, \\Psi) = \\frac{ d(\\Psi) }{1 + \\exp \\left\\{ b(\\Psi) \\left[ \\log(t) - \\log(1 / \\left[ GR_{50}(\\Psi) \\right] ) \\right] \\right\\} }\\] where: \\[{\\begin{array}{l} GR_{50}(\\Psi) = \\textrm{max} \\left( \\frac{\\Psi - \\Psi_{b}}{\\theta_H}; 0 \\right)\\\\ d(\\Psi ) = \\textrm{max} \\left\\{ G \\, \\left[ 1 - \\exp \\left( \\frac{ \\Psi - \\Psi_b }{\\sigma_{\\Psi_b}} \\right) \\right]; 0 \\right\\}\\\\ b(\\Psi) = b \\end{array}}\\] The parameters are: \\(\\Psi_{b}\\), that is the median base water potential in the seed lot (in MPa), \\(\\theta_H\\), that is the hydro-time constant (in MPa day or MPa hour) \\(\\sigma_{\\Psi_b}\\), that represents the variability of \\(\\Psi_b\\) within the population, \\(G\\), that is the germinable fraction, accounting for the fact that \\(d\\) may not reach 1, regardless of time and water potential. \\(b\\) (slope parameter) that is assumed to be constant and independent on \\(\\Psi\\). In the end, our hydro-time model is composed by four sub-models: a cumulative probability function (log-logistic, in our example), based on the three parameters \\(d\\), \\(b\\) and \\(e = 1/GR50\\); a sub-model expressing \\(d\\) as a function of \\(\\Psi\\); a sub-model expressing \\(GR50\\) as a function of \\(\\Psi\\); a sub-model expressing \\(b\\) as a function of \\(\\Psi\\), although, this was indeed a simple identity model \\(b(\\Psi) = b\\). This hydro-time-to-event model was implemented in R as the HTE1() function, and it is available within the drcSeedGerm package, together with the appropriate self-starting routine. It can be fitted by using the drmte() function in the drcte package and the coef() function can be used to retrieve the parameter estimates. modHTE &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTE1()) coef(modHTE) ## G:(Intercept) Psib:(Intercept) sigmaPsib:(Intercept) ## 0.9577918 -1.0397239 0.1108891 ## thetaH:(Intercept) b:(Intercept) ## 0.9061385 4.0273963 As we said before, we are also interested in standard errors for model parameters; we will address this issue in another post. It is important to note that this model gives us the ability of predicting germination at any water potential levels and it is not restrained to the values that we included in the experimental design. Furthermore, we have reliable estimates of \\(\\Psi_{b}\\) and \\(\\theta_H\\), which we can use for prediction purposes in field conditions. 6.3 Another modelling approach Another type of hydro-time model was proposed by Bradford (2002) and later extended by Mesgaran et al., (2013). These authors, instead of modifying a traditional log-logistic distribution to include the environmental covariate, wrote a totally new cumulative distribution function, based on theoretical underpinnings relating to the distribution of base water potential within a seed population. Their model is: \\[ P(t, \\Psi) = \\Phi \\left\\{ \\frac{\\Psi - (\\theta_H / t) -\\Psi_b }{\\sigma_{\\Psi_b}} \\right\\}\\] where \\(\\Phi\\) is a gaussian cumulative distribution function for base water potential. More information on how this model can be obtained from the original papers; it is, however, important to highlight that it is assumed that base water potential changes from seed to seeds within the population, according to a gaussian distribution function. The cumulative distribution function of event times is indirectly modelled, but it is not, in itself, gaussian (you see that \\(t\\) is at the denominator). Mesgaran et al (2013) suggested that \\(\\Phi\\) may not be gaussian and proposed several alternatives, so that, in all, we have six possible hydro-time-to-event models, which we have implemented within the drcSeedGerm package: gaussian (function HTnorm()) logistic (function HTL()) Gumbel (function HTG()) log-logistic (function HTLL()) Weibull (Type I) (function HTW1()) Weibull (Type II) (function HTW2()) These equations are given at the end of this post. The code to fit those models is given below: mod1 &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTnorm()) mod2 &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTL()) mod3 &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTG()) mod4 &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTLL()) mod5 &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTW1()) mod6 &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTW2()) What is the best model for this dataset? Let’s use the Akaike’s Information Criterion (AIC: the lowest, the best) to decide; we see that modHTE was the best fitting one, followed by mod4. AIC(mod1, mod2, mod3, mod4, mod5, mod6, modHTE) ## df AIC ## mod1 291 3516.914 ## mod2 291 3300.824 ## mod3 291 3097.775 ## mod4 290 2886.608 ## mod5 290 2889.306 ## mod6 290 3009.023 ## modHTE 289 2832.481 It is important not to neglect a graphical inspection of model fit. The plot() method does not work with time-to-event curves with additional covariates (apart from time). However, we can retrieve the fitted data by using the plotData() function and use those predictions within the ggplot() function. The box below shows the appropriate coding. library(ggplot2) tab &lt;- plotData(modHTE) ggplot() + geom_point(data = rape, mapping = aes(x = timeAf, y = propCum), col = &quot;red&quot;) + geom_line(data = tab$plotFits, mapping = aes(x = timeAf, y = CDF)) + facet_wrap(~ Psi) + scale_x_continuous(name = &quot;Time (d)&quot;) + scale_y_continuous(name = &quot;Cumulative proportion of germinated seeds&quot;) ## Warning: Removed 42 rows containing missing values (geom_point). 6.4 Further detail Let us conclude this section by giving some detail on all other models in Mesgaran et al (2913; slightly reparameterised). In same cases \\(\\Psi_b\\) has been replaced by \\(\\mu\\), that is the location parameter of the cumulative distribution function of base water potential, but it is not the median value. On the other hand, \\(\\delta\\) is the shifting parameter for all logarithm based distributions; indeed, logarithm based distribution are only defined for strictly positive variables, while we know that water potential usually assumes negative values. The shifting parameters is used to shift the cumulative distribution function to the right, so that negative values are allowed. 6.4.1 HTL() \\[ G(t, \\Psi) = \\frac{1}{1 + exp \\left[ - \\frac{ \\Psi - \\left( \\theta _H/t \\right) - \\Psi_{b} } {\\sigma} \\right] }\\] 6.4.2 HTG() \\[ G(t, \\Psi) = \\exp \\left\\{ { - \\exp \\left[ { - \\left( {\\frac{{\\Psi - (\\theta _H / t ) - \\mu }}{\\sigma }} \\right)} \\right]} \\right\\} \\] 6.4.3 HTLL() \\[ G(t, \\Psi) = \\frac{1}{1 + \\exp \\left\\{ \\frac{ \\log \\left[ \\Psi - \\left( \\frac{\\theta _H}{t} \\right) + \\delta \\right] - \\log(\\Psi_{b} + \\delta) }{\\sigma}\\right\\} }\\] 6.4.4 HTW1() \\[ G(t, \\Psi) = exp \\left\\{ - \\exp \\left[ - \\frac{ \\log \\left[ \\Psi - \\left( \\frac{\\theta _H}{t} \\right) + \\delta \\right] - \\log(\\Psi_{b} + \\delta) }{\\sigma}\\right] \\right\\}\\] 6.4.5 HTW2() \\[ G(t, \\Psi) = 1 - exp \\left\\{ - \\exp \\left[ \\frac{ \\log \\left[ \\Psi - \\left( \\frac{\\theta _H}{t} \\right) + \\delta \\right] - \\log(\\Psi_{b} + \\delta) }{\\sigma}\\right] \\right\\}\\] "],["exploring-the-results-of-a-time-to-event-fit-model-parameters.html", "Section 7 Exploring the results of a time-to-event fit: model parameters", " Section 7 Exploring the results of a time-to-event fit: model parameters Once we have fit a time-to-event model, we are usually interested in exploring the results, to get all possible information from the fitted model. If we have fitted a parametric model, the value of the estimated parameters is usually of extreme interest, as it gives information on the main traits of germination/emergence (e.g., capability, speed and uniformity). For example, let’s consider the hydro-time model we have fitted in our previous post at this link: \\[ P(t, \\Psi) = \\Phi \\left\\{ \\frac{\\Psi - (\\theta_H / t) -\\Psi_b }{\\sigma_{\\Psi_b}} \\right\\}\\] where \\(P\\) is the cumulative proportion of germinated seeds at time \\(t\\) and water potential \\(\\Psi\\), \\(\\Phi\\) is a gaussian cumulative distribution function for base water potential, \\(\\Psi_{b}\\) is the median base water potential in the seed lot (in MPa), \\(\\theta_H\\) is the hydro-time constant (in MPa day or MPa hour) and \\(\\sigma_{\\Psi_b}\\) represents the variability of \\(\\Psi_b\\) within the population. Clearly, these parameters have a clear biological meaning and getting to know about their value represents the reason why we have fitted such a model. The box below shows the code we used in our previous post: library(drcSeedGerm) library(drcte) data(rape) modHTE &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTnorm()) coef(modHTE) ## ThetaH:(Intercept) Psib50:(Intercept) sigmaPsib:(Intercept) ## 0.7510691 -0.9069810 0.2369954 Indeed, we got parameter estimates, but we are not happy with this. We also need standard errors, to present along with estimates in our papers. The easiest way to obtain parameters and their standard errors altogether is to use the summary() method for ‘drcte’ objects: summary(modHTE) ## ## Model fitted: Hydrotime model with normal distribution of Psib (Bradford et al., 2002) ## ## Robust estimation: no ## ## Parameter estimates: ## ## Estimate Std. Error t-value p-value ## ThetaH:(Intercept) 0.7510691 0.0394604 19.034 &lt; 2.2e-16 *** ## Psib50:(Intercept) -0.9069810 0.0118081 -76.810 &lt; 2.2e-16 *** ## sigmaPsib:(Intercept) 0.2369954 0.0071406 33.190 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Unfortunately, the above standard errors are not correct: indeed, they are obtained assuming that the observational units (i.e., the seeds) are independent, while they are clustered within randomisation units (Petri dishes, in this case). Consequently, seeds in the same Petri dish are more similar than seeds in different Petri dishes (there is intra-class correlation, we say). How can we obtain standard errors that account for such lack of independence? If we look at the literature about survival analysis (that is where we borrowed our methods from), we can see that cluster robust sandwich estimators of standard errors have proven useful and reliable (Yu and Peng, 2008). Therefore, we have implemented them in ‘drcte’; the ‘units’ argument in the summary() method can be used to provide a variable for the Petri dishes and calculate cluster-robust SEs, by way of the facilities provided in the ‘sandwich’ package (Zeileis et al. 2020). summary(modHTE, robust = T, units = Dish) ## ## Model fitted: Hydrotime model with normal distribution of Psib (Bradford et al., 2002) ## ## Robust estimation: Cluster robust sandwich SEs ## ## Parameter estimates: ## ## Estimate Std. Error t value Pr(&gt;|t|) ## ThetaH:(Intercept) 0.751069 0.131968 5.6913 3.075e-08 *** ## Psib50:(Intercept) -0.906981 0.039530 -22.9444 &lt; 2.2e-16 *** ## sigmaPsib:(Intercept) 0.236995 0.031309 7.5696 4.974e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We see that the difference between ‘naive’ and cluster robust SEs is remarkable. There might be other methods to obtain cluster robust standard errors (e.g., jackknife and bootstrap methods) and we are looking for ways to implement them in a reliable way. So far, we recommend that you make sure that your standard errors for model parameters do not neglect the clustering of seeds within randomisation units (petri dishes, pots, boxes or plots). "],["predictions-from-time-to-event-models.html", "Section 8 Predictions from time-to-event models 8.1 Parametric time-to-event model 8.2 Non-parametric time-to-event models 8.3 Predictions from a time-to-event model from literature", " Section 8 Predictions from time-to-event models 8.1 Parametric time-to-event model Another key aspect is to use a fitted model to make predictions: what fraction of germinated/emerged seeds will we find in, e.g., one/two weeks? And in one month? For example, let’s consider the hydro-time model we have fitted in some previous posts (the first one is at this link): \\[ P(t, \\Psi) = \\Phi \\left\\{ \\frac{\\Psi - (\\theta_H / t) -\\Psi_b }{\\sigma_{\\Psi_b}} \\right\\}\\] In the above model, \\(P\\) is the cumulative proportion of germinated seeds at time \\(t\\) and water potential \\(\\Psi\\), \\(\\Phi\\) is a gaussian cumulative distribution function for base water potential, \\(\\Psi_{b}\\) is the median base water potential in the seed lot (in MPa), \\(\\theta_H\\) is the hydro-time constant (in MPa day or MPa hour) and \\(\\sigma_{\\Psi_b}\\) represents the variability of \\(\\Psi_b\\) within the population. The code below can be used to fit the above model to the ‘rape’ dataset in the ‘drcSeedGerm’ package and retreive the estimated parameters, with robust standard errors: library(drcSeedGerm) library(drcte) data(rape) modHTE &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTnorm()) summary(modHTE, units = Dish) ## ## Model fitted: Hydrotime model with normal distribution of Psib (Bradford et al., 2002) ## ## Robust estimation: Cluster robust sandwich SEs ## ## Parameter estimates: ## ## Estimate Std. Error t value Pr(&gt;|t|) ## ThetaH:(Intercept) 0.751069 0.131968 5.6913 3.075e-08 *** ## Psib50:(Intercept) -0.906981 0.039530 -22.9444 &lt; 2.2e-16 *** ## sigmaPsib:(Intercept) 0.236995 0.031309 7.5696 4.974e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Now, we may wonder: if we have a seed lot with the above characteristics (\\(\\theta = 0.751\\) MPa d, \\(\\Psi_{b_{50}} = -0.907\\) MPa and \\(\\sigma_{\\Psi_b} = 0.237\\)), what will the proportion of germinated seeds be, e.g., at 1, 3, 5, 7 days after water imbibition, when the base water potential in the substrate is, e.g., 0, -0.25 and -0.5 MPa? To predict this from the model object we can build a data frame with the values of predictors (see below the use of the expand.grid() function) and use it as the ‘newdata’ argument to the predict() method. newd &lt;- expand.grid(time = c(1, 3, 5, 7), psi = c(0, -0.25, -0.5)) predict(modHTE, newdata = newd) ## time psi Prediction ## 1 1 0.00 0.74468884 ## 2 3 0.00 0.99720253 ## 3 5 0.00 0.99929640 ## 4 7 0.00 0.99962993 ## 5 1 -0.25 0.34568239 ## 6 3 -0.25 0.95689600 ## 7 5 -0.25 0.98375378 ## 8 7 -0.25 0.98981312 ## 9 1 -0.50 0.07326801 ## 10 3 -0.50 0.74565419 ## 11 5 -0.50 0.86069050 ## 12 7 -0.50 0.89697826 With time-to-event models, the ‘newdata’ argument takes a data frame, where the first column is always time and the succeeding columns, wherever needed, represent the environmental covariates, in the same order as they appear in the model definition. If several models have been simultaneously fitted by using the ‘curveid’ argument (not in this case, though), predictions are made for all models, always using the same ‘newdata’. We can also obtain standard errors and confidence intervals for the predictions, by adding the se.fit = TRUE and interval = TRUE arguments. We also recommend to add the robust = T argument, so that we obtain robust standard errors, accounting for the clustering of seeds within Petri dishes (lack of independence). With parametric time-to-event models, robust standard errors are obtained by using a cluster-robust sandwich variance-covariance matrix (Zeileis et al. 2020); in this case, a clustering variable needs to be provided with the units argument. # Naive standard errors and confidence intervals predict(modHTE, newdata = newd, se.fit = T, interval = T) ## time psi Prediction SE Lower Upper ## 1 1 0.00 0.74468884 0.0452433821 0.65601344 0.8333642 ## 2 3 0.00 0.99720253 0.0008053309 0.99562411 0.9987809 ## 3 5 0.00 0.99929640 0.0002384085 0.99882913 0.9997637 ## 4 7 0.00 0.99962993 0.0001358778 0.99936362 0.9998963 ## 5 1 -0.25 0.34568239 0.0488012921 0.25003362 0.4413312 ## 6 3 -0.25 0.95689600 0.0060636345 0.94501149 0.9687805 ## 7 5 -0.25 0.98375378 0.0027953655 0.97827496 0.9892326 ## 8 7 -0.25 0.98981312 0.0019555787 0.98598025 0.9936460 ## 9 1 -0.50 0.07326801 0.0182524957 0.03749378 0.1090422 ## 10 3 -0.50 0.74565419 0.0143630866 0.71750306 0.7738053 ## 11 5 -0.50 0.86069050 0.0098002073 0.84148245 0.8798986 ## 12 7 -0.50 0.89697826 0.0084761895 0.88036524 0.9135913 # Cluster robust standard errors and confidence intervals predict(modHTE, newdata = newd, se.fit = T, interval = T, robust = T, units = Dish) ## time psi Prediction SE Lower Upper ## 1 1 0.00 0.74468884 0.1450176755 0.46045941 1.0289183 ## 2 3 0.00 0.99720253 0.0035012373 0.99034023 1.0040648 ## 3 5 0.00 0.99929640 0.0011070141 0.99712670 1.0014661 ## 4 7 0.00 0.99962993 0.0006427237 0.99837022 1.0008897 ## 5 1 -0.25 0.34568239 0.1576339911 0.03672545 0.6546393 ## 6 3 -0.25 0.95689600 0.0251911861 0.90752218 1.0062698 ## 7 5 -0.25 0.98375378 0.0129567170 0.95835908 1.0091485 ## 8 7 -0.25 0.98981312 0.0093141326 0.97155775 1.0080685 ## 9 1 -0.50 0.07326801 0.0622953823 0.00000000 0.1953647 ## 10 3 -0.50 0.74565419 0.0498559815 0.64793826 0.8433701 ## 11 5 -0.50 0.86069050 0.0424570614 0.77747619 0.9439048 ## 12 7 -0.50 0.89697826 0.0388178876 0.82089660 0.9730599 We are currently studying a way to avoid that confidence intervals return unrealistic predictions (see above some values that are higher than 1). We may note that cluster robust standard errors are higher than naive standard errors: the seed in the same Petri dish are correlated and, thus, they do not contribute full information. 8.2 Non-parametric time-to-event models The predict() method can also be used to make predictions from NPMLE and KDE fits. In this case, no environmental covariates are admissible and, therefore, we can provide ‘newdata’ as a vector of times to make predictions. In the code below we fit the NPMLE of a time-to-event model to four species of the genus Verbascum, for which the data are available as the ‘verbascum’ data frame. We also make predictions relating to the proportion of germinated seeds at 1, 3, 5, and 7 days from water imbibition. data(verbascum) mod &lt;- drmte(nSeeds ~ timeBef + timeAf, fct = NPMLE(), curveid = Species, data = verbascum) # Define the values for predictions newd &lt;- c(1, 3, 5, 7) predict(mod, newdata = newd, se.fit = T, interval = T, robust = T, units = Dish) ## Species newdata Prediction SE Lower Upper ## 1 arcturus 1 0.00 0.00000000 0.000000 0.00 ## 2 arcturus 3 0.00 0.00000000 0.000000 0.00 ## 3 arcturus 5 0.00 0.00000000 0.000000 0.00 ## 4 arcturus 7 0.00 0.00000000 0.000000 0.00 ## 5 blattaria 1 0.00 0.00000000 0.000000 0.00 ## 6 blattaria 3 0.09 0.05594901 0.010000 0.24 ## 7 blattaria 5 0.73 0.06893809 0.600000 0.86 ## 8 blattaria 7 0.80 0.06154616 0.690000 0.91 ## 9 creticum 1 0.00 0.00000000 0.000000 0.00 ## 10 creticum 3 0.33 0.08076917 0.167625 0.48 ## 11 creticum 5 0.97 0.02382806 0.910000 1.00 ## 12 creticum 7 0.97 0.02382806 0.910000 1.00 Standard errors are estimated by using a resampling (bootstrap) approach, that is performed at the group level, whenever a grouping variable is provided, by way of the ‘units’ argument (Davison and Hinkley, 1997). For KDE models, we can make predictions in the very same way, although we are still unsure about the most reliable way to obtain standard errors. For this reason, the use of the ‘predict’ method with this type of non-parametric models does not yet provide standard errors and confidence intervals. 8.3 Predictions from a time-to-event model from literature In some cases, we do not have a fitted model, but we have some literature information. For example, we have seen a manuscript where the authors say that, for a certain species, emergences appeared to follow a log-logistic time-course with the following parameters: ‘b’ (the slope at inflection point) equal to -1, ‘d’ (maximum germinated proportion) equal to 0.83 and ‘e’ (median germination time for the germinated fraction) equal to 12.3. Considering that a log-logistic time-to-event model is represented as LL.3(), we can make predictions by using the following code: predict(LL.3(), coefs = c(-1, 0.83, 12.3), newdata = c(1, 3, 5, 7, 10)) ## newdata prediction ## 1 1 0.06240602 ## 2 3 0.16274510 ## 3 5 0.23988439 ## 4 7 0.30103627 ## 5 10 0.37219731 "],["quantiles-from-time-to-event-models.html", "Section 9 Quantiles from time-to-event models 9.1 Peculiarities of seed science data 9.2 Getting the quantiles with ‘drcte’ 9.3 Quantiles and Effective Doses (ED)", " Section 9 Quantiles from time-to-event models A time-to-event model is, indeed, a cumulative probability function for germination time and, therefore, we might be interested in finding the quantiles. But, what are the ‘quantiles’? It is a set of ‘cut-points’ that divide the distribution of event-times into a set of \\(q\\) intervals with equal probability. For example the 100-quantiles, also named as the percentiles, divide the distribution of event-times into \\(q = 100\\) groups. Some of these cut-off points may be particularly relevant: for example the 50-th percentile corresponds to the time required to reach 50% germination (T50) and it is regarded as a good measure of germination velocity. Other common percentiles are the T10, or the T30, which are used to express the germination velocity for the quickest seeds in the lot. Extracting some relevant percentiles from the time-to-event curve is regarded as an important task, to sintetically describe the germination/emergence velocity of seed populations. To this aim, we have included the quantile() method in the drcte package, that addresses most of the peculiarities of seed germination/emergence data. In this post, we will show the usage of this function. 9.1 Peculiarities of seed science data I know that you are looking forward to getting the quantiles for your time-to-event curve. Please, hang on for a while… we need to become aware of a couple of issues, that are specific to germination/emergence data and are not covered in literature for other types of time-to-event data (e.g., survival data). 9.1.1 Quantiles and ‘restricted’ quantiles Due to the presence of the ungerminated/unemerged fraction, quantiles suffer from the intrinsic ambiguity that we could calculate them either for the whole sample, or for the germinated fraction. For example, let’s think that we have a seed lot where the maximum percentage of germination is 60% and thus 40% of seeds are dormant. How do we define the 50th percentile? In general, we should consider the whole population, including the ungerminated fraction, where the event is not observed; accordingly, the, e.g., 50th percentile (T50) should be defined as the time to 50% germination. Obviously, with such a definition the, e.g., T50 cannot be estimated when the maximum germinated fraction is lower than 50%. On the other hand, for certain applications, it might be ok to remove the ungerminated fraction prior to estimating the quantiles; in this case, for our example where the maximum germinated fracion is 60%, the T50 would be defined as the time to 30% germination, that is 50% of the maximum germinated fraction. Due to such an ambiguity, we should talk about quantiles and ‘restricted’ quantiles. The graph below should help clarify such a difference. As a general suggestion, we should never use restricted quantiles for seed germination/emergence studies, especially when the purpose is to make comparisons across treatment groups (Bradford, 2002; Keshtkar et al. 2021). 9.1.2 Germination/emergence rates The quantiles of germination times (e.g., T10, T30 or T50) are very common measures of germination velocity, although they may be rather counterintuitive, because a high germination time implies low velocity. Another common measure of velocity is the Germination Rate, that is the inverse of germination time (e.g., GR10 = 1/T10). The quantiles of germination rates (e.g., GR10, GR30, GR50…) represents the daily progress to germination for a given subpopulation and they are used as the basis for hydro-thermal-time modelling. Therefore, their determination for a seed lot is also very relevant. 9.2 Getting the quantiles with ‘drcte’ 9.2.1 Parametric models In a previous post we have used the code below to fit a log-logistic time-to-event model to the germination data for three species of the Verbascum genus: library(drcte) library(drcSeedGerm) data(verbascum) mod1 &lt;- drmte(nSeeds ~ timeBef + timeAf, fct = LL.3(), curveid = Species, data = verbascum) summary(mod1, units = Dish) ## ## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 ## ## Robust estimation: Cluster robust sandwich SEs ## ## Parameter estimates: ## ## Estimate Std. Error t value Pr(&gt;|t|) ## b:arcturus -9.930005 1.111135 -8.9368 4.286e-16 *** ## b:blattaria -7.198025 0.578038 -12.4525 &lt; 2.2e-16 *** ## b:creticum -11.033749 0.943374 -11.6961 &lt; 2.2e-16 *** ## d:arcturus 0.356648 0.047915 7.4433 3.715e-12 *** ## d:blattaria 0.840064 0.025593 32.8242 &lt; 2.2e-16 *** ## d:creticum 0.969990 0.017290 56.1015 &lt; 2.2e-16 *** ## e:arcturus 12.059189 0.486010 24.8126 &lt; 2.2e-16 *** ## e:blattaria 4.031763 0.199741 20.1850 &lt; 2.2e-16 *** ## e:creticum 3.200655 0.103161 31.0259 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 It may be useful to rank the species in terms of their germination velocity and, to that purpose, we could estimate the times to 30% and 50% germination (T30 and T50), that are the 30th and 50th percentiles of the time-to-event distribution. We can use the quantile() method, where the probability levels are passed in as the vector ‘probs’: quantile(mod1, probs = c(0.3, 0.5)) ## ## Estimated quantiles ## ## Estimate Std. Error ## arcturus:30% 14.2634 0.992685 ## arcturus:50% NaN NaN ## blattaria:30% 3.7156 0.106630 ## blattaria:50% 4.2536 0.118066 ## creticum:30% 2.9759 0.058279 ## creticum:50% 3.2187 0.059480 We may note that the T50 is not estimable with Verbascum arcturus, as the maximum germinated proportion (d parameter for the time-to-event model above) is 0.36. Standard errors are obtained by using the delta method and they are invalid whenever the experimental units (seeds) are clustered within containers, such as the Petri dishes. For all these cases, we should prefer cluster-robust standard errors (Zeileis et al. 2020), which can be obtained by setting the extra argument ‘robust = TRUE’ and providing a clustering variable as the units argument. By setting ‘interval = TRUE’ we can also obtain confidence intervals for the desired probability level (0.95, by default). quantile(mod1, probs = c(0.3, 0.5), robust = T, units = Dish, interval = T) ## ## Estimated quantiles ## ## Estimate Std. Error Lower Upper ## arcturus:30% 14.2634 0.755294 12.7830 15.7437 ## arcturus:50% NaN NaN NaN NaN ## blattaria:30% 3.7156 0.188941 3.3452 4.0859 ## blattaria:50% 4.2536 0.209027 3.8439 4.6632 ## creticum:30% 2.9759 0.085151 2.8090 3.1428 ## creticum:50% 3.2187 0.104743 3.0134 3.4240 We may note that cluster robust standard errors are higher than naive standard errors: the seed in the same Petri dish are correlated and, thus, they do not contribute full information. If we are interested in the germination rates G30 and G50, we can set the argument ‘rate = T’, as shown in the box below. quantile(mod1, probs = c(0.3, 0.5), robust = T, units = Dish, interval = T, rate = T) ## ## Estimated quantiles ## ## Estimate SE Lower Upper ## arcturus:30% 0.07011 0.0037126 0.062833 0.077386 ## arcturus:50% 0.00000 0.0000000 0.000000 0.000000 ## blattaria:30% 0.26914 0.0136861 0.242315 0.295963 ## blattaria:50% 0.23510 0.0115531 0.212454 0.257741 ## creticum:30% 0.33604 0.0096153 0.317191 0.354882 ## creticum:50% 0.31069 0.0101106 0.290872 0.330505 9.2.2 Parametric models with environmental covariates If we have fitted a hydro-thermal time model or other models with an environmental covariate, we can also use the quantile() method, and pass a value for that covariate, as shown in the code below. # Parametric model with environmental covariate data(rape) modTE &lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, data = rape, fct = HTLL()) quantile(modTE, Psi = 0, probs = c(0.05, 0.10, 0.15, 0.21), restricted = F, rate = T, robust = T, interval = T) ## ## Estimated quantiles ## ## Estimate SE Lower Upper ## 1:5% 1.6630 0.29134 1.0919 2.2340 ## 1:10% 1.6581 0.28523 1.0990 2.2171 ## 1:15% 1.6546 0.28115 1.1036 2.2056 ## 1:21% 1.6513 0.27745 1.1075 2.1951 The environmental covariate only accepts a single value; in order to vectorise, we need to use the lapply() function, as shown below. # This is to vectorise on Psi psiList &lt;- seq(-1, 0, 0.25) names(psiList) &lt;- as.character(psiList) lapply(psiList, function(x) quantile(modTE, Psi = x, probs = c(0.05, 0.10, 0.15, 0.21), restricted = F, rate = T, interval = &quot;delta&quot;, units = rape$Dish, display = F)) ## $`-1` ## Estimate SE Lower Upper ## 1:5% 0.1854204 0.1316218 -0.07255364 0.4433945 ## 1:10% 0.1805588 0.1246436 -0.06373812 0.4248557 ## 1:15% 0.1770742 0.1199609 -0.05804492 0.4121932 ## 1:21% 0.1737531 0.1157066 -0.05302779 0.4005339 ## ## $`-0.75` ## Estimate SE Lower Upper ## 1:5% 0.5548033 0.1603098 0.2406019 0.8690047 ## 1:10% 0.5499417 0.1532949 0.2494893 0.8503941 ## 1:15% 0.5464571 0.1485831 0.2552394 0.8376747 ## 1:21% 0.5431360 0.1442990 0.2603152 0.8259567 ## ## $`-0.5` ## Estimate SE Lower Upper ## 1:5% 0.9241862 0.1932594 0.5454048 1.302968 ## 1:10% 0.9193246 0.1863806 0.5540254 1.284624 ## 1:15% 0.9158400 0.1817648 0.5595875 1.272092 ## 1:21% 0.9125189 0.1775713 0.5644855 1.260552 ## ## $`-0.25` ## Estimate SE Lower Upper ## 1:5% 1.293569 0.2286380 0.8454469 1.741691 ## 1:10% 1.288708 0.2219286 0.8537354 1.723680 ## 1:15% 1.285223 0.2174308 0.8590664 1.711379 ## 1:21% 1.281902 0.2133475 0.8637483 1.700055 ## ## $`0` ## Estimate SE Lower Upper ## 1:5% 1.662952 0.2654765 1.142628 2.183276 ## 1:10% 1.658090 0.2589271 1.150603 2.165578 ## 1:15% 1.654606 0.2545391 1.155718 2.153493 ## 1:21% 1.651285 0.2505575 1.160201 2.142368 9.2.3 Non-parametric (NPMLE) models The quantile() method can also be used to make predictions from NPMLE fits. This method works by assuming that the events are evenly scattered within each inspection interval (‘interpolation method’). Inferences need to be explicitly requested by using setting ‘interval = T’; in this case, standard errors are estimated by using a resampling approach, that is performed at the group level, whenever a grouping variable is provided, by way of the ‘units’ argument (Davison and Hinkley, 1997). mod2 &lt;- drmte(nSeeds ~ timeBef + timeAf, fct = NPMLE(), curveid = Species, data = verbascum) quantile(mod2, probs = c(0.3, 0.5), robust = T, units = Dish, interval = T, rate = T) ## ## ## ## ## Estimated quantiles ## (cluster robust bootstrap-based inference) ## ## n Mean Median SE Lower Upper ## arcturus.30% 999 0.04215854 0.067385 0.0367409 0.00000 0.085837 ## arcturus.50% 999 0.00047593 0.000000 0.0056696 0.00000 0.000000 ## blattaria.30% 999 0.26933051 0.268456 0.0180207 0.23961 0.308415 ## blattaria.50% 999 0.23279718 0.230530 0.0131552 0.21341 0.263740 ## creticum.30% 999 0.34397841 0.343750 0.0195091 0.31087 0.379032 ## creticum.50% 999 0.30314443 0.302198 0.0117692 0.28139 0.326935 For KDE models, quantiles are calculated from the time-to-event curve by using a bisection method. However, we are still unsure about the most reliable way to obtain standard errors and, for this reason, inferences are not provided with this type of non-parametric models. 9.3 Quantiles and Effective Doses (ED) Quantiles for time-to-event data resamble Effective Doses (ED) for dose-response data, although we discourage the use of this latter term, as the time-to-event curve is a cumulative probability function based on time, that is not a ‘dose’ in strict terms. However, the concept is similar: we need to find the stimulus (time) that permits to obtain a certain response (germination/emergence). Considering such similarity, we decided to define the ED() method for ‘drcte’ objects, that is compatible with the ED() method for ‘drc’ objects. However, for seed germination/emergence data, we strongly favor the use of the quantile() method. "],["references.html", "Section 10 References", " Section 10 References Barreiro-Ures D, Francisco-Fernández M, Cao R, Fraguela BB, Doallo R, González-Andújar JL, Reyes M (2019) Analysis of interval-grouped data in weed science: The binnednp Rcpp package. Ecol Evol 9:10903–10915 Bradford KJ (2002) Applications of hydrothermal time to quantifying and modeling seed germination and dormancy. Weed Sci 50:248–260 Brown, RF, DG Mayer (1988a) Representing Cumulative Germination. 1. A Critical Analysis of Single-value Germination Indices. Annals of Botany 61:117–125 Brown, RF, DG Mayer (1988b) Representing Cumulative Germination.: 2. The Use of the Weibull Function and Other Empirically Derived Curves. Annals of Botany 61:127–138 Catara, S., Cristaudo, A., Gualtieri, A., Galesi, R., Impelluso, C., Onofri, A. (2016). Threshold temperatures for seed germination in nine species of Verbascum (Scrophulariaceae). Seed Science Research 26, 30–46. Davison, A.C., Hinkley, D.V. (1997). Bootstrap methods and their application. Cambridge University Press, UK. Dutang, C, Goulet V and M. Pigeon (2008). actuar: An R Package for Actuarial Science. Journal of Statistical Software, vol. 25, no. 7, 1-37. Fay, MP, PA Shaw (2010) Exact and Asymptotic Weighted Logrank Tests for Interval Censored Data: The interval R Package. Journal of Statistical Software 36:1–34 Gresta, F, G Avola, A Onofri, U Anastasi, A Cristaudo (2011) When Does Hard Coat Impose Dormancy in Legume Seeds? Lotus and Scorpiurus Case Study. Crop Science 51:1739–1747 Keshtkar E, Kudsk P, Mesgaran MB (2021) Perspective: Common errors in dose–response analysis and how to avoid them. Pest Manag Sci 77:2599–2608 Mesgaran, M.B., Mashhadi, H.R., Alizadeh, H., Hunt, J., Young, K.R., Cousens, R.D., 2013. Importance of distribution function selection for hydrothermal time models of seed germination. Weed Research 53, 89–101. https://doi.org/10.1111/wre.12008 Michael P. Fay, Pamela A. Shaw (2010). Exact and Asymptotic Weighted Logrank Tests for Interval Censored Data: The interval R Package. Journal of Statistical Software, 36(2), 1-34. URL https://www.jstatsoft.org/v36/i02/. Onofri, A, F Gresta, F Tei (2010) A new method for the analysis of germination and emergence data of weed species. Weed Research 50:187–198 Onofri, A, MB Mesgaran, F Tei, RD Cousens (2011) The cure model: an improved way to describe seed germination? Weed Research 51:516–524 Onofri, A, MB Mesgaran, P Neve, RD Cousens (2014) Experimental design and parameter estimation for threshold models in seed germination. Weed Research 54:425–435 Onofri, A., Benincasa, P., Mesgaran, M.B., Ritz, C. (2018). Hydrothermal-time-to-event models for seed germination. European Journal of Agronomy 101, 129–139. Onofri, A., Mesgaran, M., &amp; Ritz, C. (2022). A unified framework for the analysis of germination, emergence, and other time-to-event data in weed science. Weed Science, 1-13. doi:10.1017/wsc.2022.8 Onofri, Andrea, Hans Peter Piepho, and Marcin Kozak (2019). Analysing Censored Data in Agricultural Research: A Review with Examples and Software Tips. Annals of Applied Biology, 174, 3-13. Onofri, Andrea, Paolo Benincasa, M B Mesgaran, and Christian Ritz (2018). Hydrothermal-Time-to-Event Models for Seed Germination. European Journal of Agronomy 101: 129–39. Pace, R., Benincasa, P., Ghanem, M.E., Quinet, M., Lutts, S. (2012). Germination of untreated and primed seeds in rapeseed (brassica napus var oleifera del.) under salinity and low matric potential. Experimental Agriculture 48, 238–251. Ritz C, Jensen SM, Gerhard D, Streibig JC (2019). Dose-response analysis using R CRC Press. USA Ritz, C., Baty, F., Streibig, J. C., Gerhard, D. (2015). Dose-Response Analysis Using R PLOS ONE, 10(12) Therneau T (2021). A Package for Survival Analysis in R. R package version 3.2-11, &lt;URL: https://CRAN.R-project.org/package=survival&gt;. Wickham, H, G Grolemund (2016) R for data science: import, tidy, transform, visualize, and model data. First edition. Sebastopol, CA: O’Reilly. 492 pp. Yu, B., Peng, Y. (2008). Mixture cure models for multivariate survival data. Computational Statistics and Data Analysis 52, 1524–1532. Zeileis, A., Köll, S., Graham, N. (2020). Various Versatile Variances: An Object-Oriented Implementation of Clustered Covariances in R. J. Stat. Soft. 95. https://doi.org/10.18637/jss.v095.i01 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
