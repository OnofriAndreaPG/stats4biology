<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Metodologia statistica per le scienze agrarie</title>
  <meta name="description" content="Appunti dai corsi S.I.A.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Metodologia statistica per le scienze agrarie" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Appunti dai corsi S.I.A." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Metodologia statistica per le scienze agrarie" />
  
  <meta name="twitter:description" content="Appunti dai corsi S.I.A." />
  

<meta name="author" content="Andrea Onofri e Dario Sacco">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="dalla-popolazione-al-campione-i-modelli-stocastici.html">
<link rel="next" href="breve-introduzione-al-test-dipotesi.html">
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global Site Tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131792052-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-131792052-1');
  </script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduzione</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#organizzazione-del-testo"><i class="fa fa-check"></i><b>1.1</b> Organizzazione del testo</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#gli-autori"><i class="fa fa-check"></i><b>1.2</b> Gli autori</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><i class="fa fa-check"></i><b>2</b> Il metodo sperimentale: quando la scienza è scienza</a><ul>
<li class="chapter" data-level="2.1" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#introduzione-1"><i class="fa fa-check"></i><b>2.1</b> Introduzione</a><ul>
<li class="chapter" data-level="2.1.1" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#cosa-e-quindi-una-prova-scientifica"><i class="fa fa-check"></i><b>2.1.1</b> Cosa è quindi una prova scientifica?</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#esperimenti-buoni-e-cattivi"><i class="fa fa-check"></i><b>2.2</b> Esperimenti buoni e cattivi!</a><ul>
<li class="chapter" data-level="2.2.1" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#lerrore-sperimentale"><i class="fa fa-check"></i><b>2.2.1</b> L’errore sperimentale</a></li>
<li class="chapter" data-level="2.2.2" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#il-campionamento"><i class="fa fa-check"></i><b>2.2.2</b> Il campionamento</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#scienza-metodo"><i class="fa fa-check"></i><b>2.3</b> Scienza = metodo</a></li>
<li class="chapter" data-level="2.4" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#chi-valuta-se-un-esperimento-e-attendibile"><i class="fa fa-check"></i><b>2.4</b> Chi valuta se un esperimento è attendibile?</a></li>
<li class="chapter" data-level="2.5" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#il-metodo-sperimentale"><i class="fa fa-check"></i><b>2.5</b> Il metodo sperimentale</a></li>
<li class="chapter" data-level="2.6" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#metodi-sperimentali-validi-ed-invalidi"><i class="fa fa-check"></i><b>2.6</b> Metodi sperimentali validi ed invalidi</a><ul>
<li class="chapter" data-level="2.6.1" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#primo-esperimento"><i class="fa fa-check"></i><b>2.6.1</b> Primo esperimento</a></li>
<li class="chapter" data-level="2.6.2" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#secondo-esperimento"><i class="fa fa-check"></i><b>2.6.2</b> Secondo esperimento</a></li>
<li class="chapter" data-level="2.6.3" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#terzo-esperimento"><i class="fa fa-check"></i><b>2.6.3</b> Terzo esperimento</a></li>
<li class="chapter" data-level="2.6.4" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#quarto-esperimento-quello-buono"><i class="fa fa-check"></i><b>2.6.4</b> Quarto esperimento: quello buono</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#incertezza-residua"><i class="fa fa-check"></i><b>2.7</b> Incertezza residua</a></li>
<li class="chapter" data-level="2.8" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#il-ruolo-della-statistica"><i class="fa fa-check"></i><b>2.8</b> Il ruolo della statistica</a></li>
<li class="chapter" data-level="2.9" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#conclusioni"><i class="fa fa-check"></i><b>2.9</b> Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html"><i class="fa fa-check"></i><b>3</b> Introduzione al disegno sperimentale</a><ul>
<li class="chapter" data-level="3.1" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#definizioni"><i class="fa fa-check"></i><b>3.1</b> Definizioni</a></li>
<li class="chapter" data-level="3.2" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#elementi-fondamentali-del-disegno-sperimentale"><i class="fa fa-check"></i><b>3.2</b> Elementi fondamentali del disegno sperimentale</a><ul>
<li class="chapter" data-level="3.2.1" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#controllo-degli-errori"><i class="fa fa-check"></i><b>3.2.1</b> Controllo degli errori</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#replicazione"><i class="fa fa-check"></i><b>3.2.2</b> Replicazione</a></li>
<li class="chapter" data-level="3.2.3" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#randomizzazione"><i class="fa fa-check"></i><b>3.2.3</b> Randomizzazione</a></li>
<li class="chapter" data-level="3.2.4" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#esperimenti-non-validi"><i class="fa fa-check"></i><b>3.2.4</b> Esperimenti non validi</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#progettazione-di-un-esperimento-protocollo"><i class="fa fa-check"></i><b>3.3</b> Progettazione di un esperimento (protocollo)</a><ul>
<li class="chapter" data-level="3.3.1" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#ipotesi-scientifica-rightarrow-obiettivo-dellesperimento"><i class="fa fa-check"></i><b>3.3.1</b> Ipotesi scientifica <span class="math inline">\(\rightarrow\)</span> obiettivo dell’esperimento</a></li>
<li class="chapter" data-level="3.3.2" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#casi-di-studio---1"><i class="fa fa-check"></i><b>3.3.2</b> Casi di studio - 1</a></li>
<li class="chapter" data-level="3.3.3" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#identificazione-dei-fattori-sperimentali"><i class="fa fa-check"></i><b>3.3.3</b> Identificazione dei fattori sperimentali</a></li>
<li class="chapter" data-level="3.3.4" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#esperimenti-multifattoriali"><i class="fa fa-check"></i><b>3.3.4</b> Esperimenti (multi)fattoriali</a></li>
<li class="chapter" data-level="3.3.5" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#aggiungere-un-controllo"><i class="fa fa-check"></i><b>3.3.5</b> Aggiungere un controllo?</a></li>
<li class="chapter" data-level="3.3.6" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#fattori-sperimentali-di-trattamento-e-di-blocco"><i class="fa fa-check"></i><b>3.3.6</b> Fattori sperimentali di trattamento e di blocco</a></li>
<li class="chapter" data-level="3.3.7" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#casi-di-studio---2"><i class="fa fa-check"></i><b>3.3.7</b> Casi di studio - 2</a></li>
<li class="chapter" data-level="3.3.8" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#identificazione-delle-unita-sperimentali-e-delle-repliche"><i class="fa fa-check"></i><b>3.3.8</b> Identificazione delle unità sperimentali e delle repliche</a></li>
<li class="chapter" data-level="3.3.9" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#scelta-delle-variabili-da-rilevare"><i class="fa fa-check"></i><b>3.3.9</b> Scelta delle variabili da rilevare</a></li>
<li class="chapter" data-level="3.3.10" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#casi-di-studio---3"><i class="fa fa-check"></i><b>3.3.10</b> Casi di studio - 3</a></li>
<li class="chapter" data-level="3.3.11" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#allocazione-dei-trattamenti"><i class="fa fa-check"></i><b>3.3.11</b> Allocazione dei trattamenti</a></li>
<li class="chapter" data-level="3.3.12" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#casi-di-studio---4"><i class="fa fa-check"></i><b>3.3.12</b> Casi di studio - 4</a></li>
<li class="chapter" data-level="3.3.13" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#impianto-delle-prove"><i class="fa fa-check"></i><b>3.3.13</b> Impianto delle prove</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#come-scrivere-un-progetto-di-ricerca-o-un-report-di-ricerca"><i class="fa fa-check"></i><b>3.4</b> Come scrivere un progetto di ricerca o un report di ricerca</a></li>
<li class="chapter" data-level="3.5" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#per-approfondimenti"><i class="fa fa-check"></i><b>3.5</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html"><i class="fa fa-check"></i><b>4</b> Per iniziare: introduzione ad R</a><ul>
<li class="chapter" data-level="4.1" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#cosa-e-r"><i class="fa fa-check"></i><b>4.1</b> Cosa è R?</a></li>
<li class="chapter" data-level="4.2" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#oggetti-e-assegnazioni"><i class="fa fa-check"></i><b>4.2</b> Oggetti e assegnazioni</a></li>
<li class="chapter" data-level="4.3" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#costanti-e-vettori"><i class="fa fa-check"></i><b>4.3</b> Costanti e vettori</a></li>
<li class="chapter" data-level="4.4" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#matrici"><i class="fa fa-check"></i><b>4.4</b> Matrici</a></li>
<li class="chapter" data-level="4.5" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#operazioni-ed-operatori"><i class="fa fa-check"></i><b>4.5</b> Operazioni ed operatori</a></li>
<li class="chapter" data-level="4.6" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#funzioni-ed-argomenti"><i class="fa fa-check"></i><b>4.6</b> Funzioni ed argomenti</a></li>
<li class="chapter" data-level="4.7" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#dataframe"><i class="fa fa-check"></i><b>4.7</b> Dataframe</a></li>
<li class="chapter" data-level="4.8" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#quale-oggetto-sto-utilizzando"><i class="fa fa-check"></i><b>4.8</b> Quale oggetto sto utilizzando?</a></li>
<li class="chapter" data-level="4.9" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#consigli-per-limmissione-di-dati-sperimentali"><i class="fa fa-check"></i><b>4.9</b> Consigli per l’immissione di dati sperimentali</a><ul>
<li class="chapter" data-level="4.9.1" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#immissione-manuale-di-dati"><i class="fa fa-check"></i><b>4.9.1</b> Immissione manuale di dati</a></li>
<li class="chapter" data-level="4.9.2" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#immissione-di-numeri-progressivi"><i class="fa fa-check"></i><b>4.9.2</b> Immissione di numeri progressivi</a></li>
<li class="chapter" data-level="4.9.3" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#immissione-dei-codici-delle-tesi-e-dei-blocchi"><i class="fa fa-check"></i><b>4.9.3</b> Immissione dei codici delle tesi e dei blocchi</a></li>
<li class="chapter" data-level="4.9.4" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#leggere-e-salvare-dati-esterni"><i class="fa fa-check"></i><b>4.9.4</b> Leggere e salvare dati esterni</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#alcune-operazioni-comuni-sul-dataset"><i class="fa fa-check"></i><b>4.10</b> Alcune operazioni comuni sul dataset</a><ul>
<li class="chapter" data-level="4.10.1" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#selezionare-un-subset-di-dati"><i class="fa fa-check"></i><b>4.10.1</b> Selezionare un subset di dati</a></li>
<li class="chapter" data-level="4.10.2" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#ordinare-un-vettore-o-un-dataframe"><i class="fa fa-check"></i><b>4.10.2</b> Ordinare un vettore o un dataframe</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#workspace"><i class="fa fa-check"></i><b>4.11</b> Workspace</a></li>
<li class="chapter" data-level="4.12" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#script-o-programmi"><i class="fa fa-check"></i><b>4.12</b> Script o programmi</a></li>
<li class="chapter" data-level="4.13" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#interrogazione-di-oggetti"><i class="fa fa-check"></i><b>4.13</b> Interrogazione di oggetti</a></li>
<li class="chapter" data-level="4.14" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#altre-funzioni-matriciali"><i class="fa fa-check"></i><b>4.14</b> Altre funzioni matriciali</a></li>
<li class="chapter" data-level="4.15" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#cenni-sulle-funzionalita-grafiche-in-r"><i class="fa fa-check"></i><b>4.15</b> Cenni sulle funzionalità grafiche in R</a></li>
<li class="chapter" data-level="4.16" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#per-approfondimenti-1"><i class="fa fa-check"></i><b>4.16</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html"><i class="fa fa-check"></i><b>5</b> Primo passo: la descrizione dei dati raccolti</a><ul>
<li class="chapter" data-level="5.1" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#le-variabili-quantitative-analisi-chimiche-e-altre-misurazioni-fondamentali"><i class="fa fa-check"></i><b>5.1</b> Le variabili quantitative: analisi chimiche e altre misurazioni fondamentali</a><ul>
<li class="chapter" data-level="5.1.1" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#indicatori-di-tendenza-centrale"><i class="fa fa-check"></i><b>5.1.1</b> Indicatori di tendenza centrale</a></li>
<li class="chapter" data-level="5.1.2" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#indicatori-di-variabilita"><i class="fa fa-check"></i><b>5.1.2</b> Indicatori di variabilità</a></li>
<li class="chapter" data-level="5.1.3" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#arrotondamenti"><i class="fa fa-check"></i><b>5.1.3</b> Arrotondamenti</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#descrizione-dei-sottogruppi"><i class="fa fa-check"></i><b>5.2</b> Descrizione dei sottogruppi</a></li>
<li class="chapter" data-level="5.3" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#distribuzioni-di-frequenza-e-classamento"><i class="fa fa-check"></i><b>5.3</b> Distribuzioni di frequenza e classamento</a></li>
<li class="chapter" data-level="5.4" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#statistiche-descrittive-per-le-distribuzioni-di-frequenza"><i class="fa fa-check"></i><b>5.4</b> Statistiche descrittive per le distribuzioni di frequenza</a></li>
<li class="chapter" data-level="5.5" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#distribuzioni-di-frequenza-bivariate-le-tabelle-di-contingenza"><i class="fa fa-check"></i><b>5.5</b> Distribuzioni di frequenza bivariate: le tabelle di contingenza</a></li>
<li class="chapter" data-level="5.6" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#connessione"><i class="fa fa-check"></i><b>5.6</b> Connessione</a></li>
<li class="chapter" data-level="5.7" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#correlazione"><i class="fa fa-check"></i><b>5.7</b> Correlazione</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html"><i class="fa fa-check"></i><b>6</b> Dalla popolazione al campione. I modelli stocastici</a><ul>
<li class="chapter" data-level="6.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#introduzione-2"><i class="fa fa-check"></i><b>6.1</b> Introduzione</a></li>
<li class="chapter" data-level="6.2" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#popolazione-di-soggetti-e-popolazione-di-misure"><i class="fa fa-check"></i><b>6.2</b> Popolazione di soggetti e popolazione di misure</a></li>
<li class="chapter" data-level="6.3" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#la-scienza-del-caso"><i class="fa fa-check"></i><b>6.3</b> La scienza del caso</a></li>
<li class="chapter" data-level="6.4" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#modelli-probabilistici-stocastici"><i class="fa fa-check"></i><b>6.4</b> Modelli probabilistici (stocastici)</a><ul>
<li class="chapter" data-level="6.4.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#funzioni-di-probabilita"><i class="fa fa-check"></i><b>6.4.1</b> Funzioni di probabilità</a></li>
<li class="chapter" data-level="6.4.2" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#funzioni-di-densita"><i class="fa fa-check"></i><b>6.4.2</b> Funzioni di densità</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#la-distribuzione-normale-curva-di-gauss"><i class="fa fa-check"></i><b>6.5</b> La distribuzione normale (curva di Gauss)</a><ul>
<li class="chapter" data-level="6.5.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-1"><i class="fa fa-check"></i><b>6.5.1</b> ESERCIZIO 1</a></li>
<li class="chapter" data-level="6.5.2" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-2"><i class="fa fa-check"></i><b>6.5.2</b> ESERCIZIO 2</a></li>
<li class="chapter" data-level="6.5.3" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-3"><i class="fa fa-check"></i><b>6.5.3</b> ESERCIZIO 3</a></li>
<li class="chapter" data-level="6.5.4" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-4"><i class="fa fa-check"></i><b>6.5.4</b> ESERCIZIO 4</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#la-distribuzione-t-di-student"><i class="fa fa-check"></i><b>6.6</b> La distribuzione t di Student</a><ul>
<li class="chapter" data-level="6.6.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-5"><i class="fa fa-check"></i><b>6.6.1</b> ESERCIZIO 5</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#la-distribuzione-f-di-fisher"><i class="fa fa-check"></i><b>6.7</b> La distribuzione F di Fisher</a><ul>
<li class="chapter" data-level="6.7.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-6"><i class="fa fa-check"></i><b>6.7.1</b> ESERCIZIO 6</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#modelli-stocastici-per-eventi-discreti-la-distribuzione-binomiale"><i class="fa fa-check"></i><b>6.8</b> Modelli stocastici per eventi discreti: la distribuzione binomiale</a><ul>
<li class="chapter" data-level="6.8.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-7"><i class="fa fa-check"></i><b>6.8.1</b> ESERCIZIO 7</a></li>
<li class="chapter" data-level="6.8.2" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-8"><i class="fa fa-check"></i><b>6.8.2</b> ESERCIZIO 8</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#altri-modelli-stocastici-di-interesse-per-lo-sperimentatore"><i class="fa fa-check"></i><b>6.9</b> Altri modelli stocastici di interesse per lo sperimentatore</a></li>
<li class="chapter" data-level="6.10" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#e-allora"><i class="fa fa-check"></i><b>6.10</b> E allora?</a></li>
<li class="chapter" data-level="6.11" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#le-simulazioni-monte-carlo"><i class="fa fa-check"></i><b>6.11</b> Le simulazioni Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><i class="fa fa-check"></i><b>7</b> Modellizzare l’errore sperimentale: introduzione all’inferenza statistica</a><ul>
<li class="chapter" data-level="7.1" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#introduzione-3"><i class="fa fa-check"></i><b>7.1</b> Introduzione</a></li>
<li class="chapter" data-level="7.2" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#lanalisi-dei-dati-gli-ingredienti-fondamentali"><i class="fa fa-check"></i><b>7.2</b> L’analisi dei dati: gli ’ingredienti’ fondamentali</a></li>
<li class="chapter" data-level="7.3" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#modello-della-realta-e-sampling-space"><i class="fa fa-check"></i><b>7.3</b> Modello della realtà e ’sampling space’</a></li>
<li class="chapter" data-level="7.4" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#esempio-1-2"><i class="fa fa-check"></i><b>7.4</b> Esempio 1</a><ul>
<li class="chapter" data-level="7.4.1" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#sampling-distribution"><i class="fa fa-check"></i><b>7.4.1</b> Sampling distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#esempio-2-2"><i class="fa fa-check"></i><b>7.5</b> Esempio 2</a><ul>
<li class="chapter" data-level="7.5.1" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#definire-la-sampling-distribution-per-lesempio-2"><i class="fa fa-check"></i><b>7.5.1</b> Definire la ’sampling distribution’ per l’esempio 2</a></li>
<li class="chapter" data-level="7.5.2" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#le-simulazioni-monte-carlo-con-excel"><i class="fa fa-check"></i><b>7.5.2</b> Le simulazioni Monte Carlo con Excel</a></li>
<li class="chapter" data-level="7.5.3" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#la-distribuzione-delle-medie-campionarie-lerrore-standard"><i class="fa fa-check"></i><b>7.5.3</b> La distribuzione delle medie campionarie: l’errore standard</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#riepilogo-1-caratterizzare-lincertezza-di-un-esperimento"><i class="fa fa-check"></i><b>7.6</b> Riepilogo 1: Caratterizzare l’incertezza di un esperimento</a></li>
<li class="chapter" data-level="7.7" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#gli-intervalli-di-confidenza"><i class="fa fa-check"></i><b>7.7</b> Gli intervalli di confidenza</a></li>
<li class="chapter" data-level="7.8" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#gli-intervalli-di-confidenza-con-excel"><i class="fa fa-check"></i><b>7.8</b> Gli intervalli di confidenza con Excel</a></li>
<li class="chapter" data-level="7.9" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#qual-e-il-senso-dellintervallo-di-confidenza"><i class="fa fa-check"></i><b>7.9</b> Qual è il senso dell’intervallo di confidenza?</a></li>
<li class="chapter" data-level="7.10" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#analisi-statistica-dei-dati-riassunto-del-percorso-logico"><i class="fa fa-check"></i><b>7.10</b> Analisi statistica dei dati: riassunto del percorso logico</a></li>
<li class="chapter" data-level="7.11" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#presentazione-dei-risultati-degli-esperimenti"><i class="fa fa-check"></i><b>7.11</b> Presentazione dei risultati degli esperimenti</a></li>
<li class="chapter" data-level="7.12" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#da-ricordare"><i class="fa fa-check"></i><b>7.12</b> Da ricordare</a></li>
<li class="chapter" data-level="7.13" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#esercizi"><i class="fa fa-check"></i><b>7.13</b> Esercizi</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html"><i class="fa fa-check"></i><b>8</b> Breve introduzione al test d’ipotesi</a><ul>
<li class="chapter" data-level="8.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-una-media-osservata-e-una-media-teorica"><i class="fa fa-check"></i><b>8.1</b> Confronto tra una media osservata e una media teorica</a><ul>
<li class="chapter" data-level="8.1.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#esempio-1-3"><i class="fa fa-check"></i><b>8.1.1</b> ESEMPIO 1</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#simulazione-monte-carlo"><i class="fa fa-check"></i><b>8.2</b> Simulazione Monte Carlo</a></li>
<li class="chapter" data-level="8.3" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#soluzione-formale"><i class="fa fa-check"></i><b>8.3</b> Soluzione formale</a></li>
<li class="chapter" data-level="8.4" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#interpretazione-del-p-level"><i class="fa fa-check"></i><b>8.4</b> Interpretazione del P-level</a></li>
<li class="chapter" data-level="8.5" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-medie-il-test-t-di-student"><i class="fa fa-check"></i><b>8.5</b> Confronto tra due medie: il test t di Student</a><ul>
<li class="chapter" data-level="8.5.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#esempio-2-3"><i class="fa fa-check"></i><b>8.5.1</b> ESEMPIO 2</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#approfondimento-tipologie-alternative-di-test-t"><i class="fa fa-check"></i><b>8.6</b> Approfondimento: tipologie alternative di test t</a></li>
<li class="chapter" data-level="8.7" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-proporzioni"><i class="fa fa-check"></i><b>8.7</b> Confronto tra due proporzioni</a><ul>
<li class="chapter" data-level="8.7.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#esempio-3-2"><i class="fa fa-check"></i><b>8.7.1</b> ESEMPIO 3</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#conclusioni-1"><i class="fa fa-check"></i><b>8.8</b> Conclusioni</a></li>
<li class="chapter" data-level="8.9" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#riepilogo"><i class="fa fa-check"></i><b>8.9</b> Riepilogo</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="modelli-matamatici-descrittivi-breve-introduzione.html"><a href="modelli-matamatici-descrittivi-breve-introduzione.html"><i class="fa fa-check"></i><b>9</b> Modelli matamatici descrittivi: breve introduzione</a><ul>
<li class="chapter" data-level="9.1" data-path="modelli-matamatici-descrittivi-breve-introduzione.html"><a href="modelli-matamatici-descrittivi-breve-introduzione.html#che-centra-la-matematica"><i class="fa fa-check"></i><b>9.1</b> Che c’entra la matematica?</a></li>
<li class="chapter" data-level="9.2" data-path="modelli-matamatici-descrittivi-breve-introduzione.html"><a href="modelli-matamatici-descrittivi-breve-introduzione.html#mettiamo-alcuni-paletti"><i class="fa fa-check"></i><b>9.2</b> Mettiamo alcuni paletti</a></li>
<li class="chapter" data-level="9.3" data-path="modelli-matamatici-descrittivi-breve-introduzione.html"><a href="modelli-matamatici-descrittivi-breve-introduzione.html#metodo-di-lavoro"><i class="fa fa-check"></i><b>9.3</b> Metodo di lavoro</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html"><i class="fa fa-check"></i><b>10</b> Una variabile indipendente categorica: ANOVA ad una via</a><ul>
<li class="chapter" data-level="10.1" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#la-situazione-sperimentale"><i class="fa fa-check"></i><b>10.1</b> La situazione sperimentale</a></li>
<li class="chapter" data-level="10.2" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#la-verita-vera-la-popolazione"><i class="fa fa-check"></i><b>10.2</b> La verità ‘vera’ (la popolazione)</a></li>
<li class="chapter" data-level="10.3" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#esecuzione-dellesperimento"><i class="fa fa-check"></i><b>10.3</b> Esecuzione dell’esperimento</a></li>
<li class="chapter" data-level="10.4" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#analisi-dei-dati-1"><i class="fa fa-check"></i><b>10.4</b> Analisi dei dati</a><ul>
<li class="chapter" data-level="10.4.1" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#statistiche-descrittive"><i class="fa fa-check"></i><b>10.4.1</b> Statistiche descrittive</a></li>
<li class="chapter" data-level="10.4.2" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#stima-dei-parametri-1"><i class="fa fa-check"></i><b>10.4.2</b> Stima dei parametri</a></li>
<li class="chapter" data-level="10.4.3" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#stima-della-varianza"><i class="fa fa-check"></i><b>10.4.3</b> Stima della varianza</a></li>
<li class="chapter" data-level="10.4.4" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#effetto-del-trattamento"><i class="fa fa-check"></i><b>10.4.4</b> Effetto del trattamento</a></li>
<li class="chapter" data-level="10.4.5" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#test-dipotesi"><i class="fa fa-check"></i><b>10.4.5</b> Test d’ipotesi</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#per-approfondimenti-2"><i class="fa fa-check"></i><b>10.5</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><i class="fa fa-check"></i><b>11</b> La verifica delle assunzioni di base: metodi diagnostici</a><ul>
<li class="chapter" data-level="11.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#introduzione-4"><i class="fa fa-check"></i><b>11.1</b> Introduzione</a></li>
<li class="chapter" data-level="11.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#procedure-diagnostiche"><i class="fa fa-check"></i><b>11.2</b> Procedure diagnostiche</a></li>
<li class="chapter" data-level="11.3" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#analisi-grafica-dei-residui"><i class="fa fa-check"></i><b>11.3</b> Analisi grafica dei residui</a><ul>
<li class="chapter" data-level="11.3.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#grafico-dei-residui-contro-i-valori-attesi"><i class="fa fa-check"></i><b>11.3.1</b> Grafico dei residui contro i valori attesi</a></li>
<li class="chapter" data-level="11.3.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#qq-plot"><i class="fa fa-check"></i><b>11.3.2</b> QQ-plot</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#altri-strumenti-diagnostici"><i class="fa fa-check"></i><b>11.4</b> Altri strumenti diagnostici</a></li>
<li class="chapter" data-level="11.5" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#risultati-contraddittori"><i class="fa fa-check"></i><b>11.5</b> Risultati contraddittori</a></li>
<li class="chapter" data-level="11.6" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#terapia"><i class="fa fa-check"></i><b>11.6</b> ‘Terapia’</a><ul>
<li class="chapter" data-level="11.6.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#correzionerimozione-degli-outliers"><i class="fa fa-check"></i><b>11.6.1</b> Correzione/Rimozione degli outliers</a></li>
<li class="chapter" data-level="11.6.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#correzione-del-modello"><i class="fa fa-check"></i><b>11.6.2</b> Correzione del modello</a></li>
<li class="chapter" data-level="11.6.3" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#non-normalita-dei-residui-ed-eterogeneita-delle-varianze"><i class="fa fa-check"></i><b>11.6.3</b> Non-normalità dei residui ed eterogeneità delle varianze</a></li>
<li class="chapter" data-level="11.6.4" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#la-procedura-di-box-e-cox"><i class="fa fa-check"></i><b>11.6.4</b> La procedura di Box e Cox</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#referenze-bibliografiche-per-approfondimenti"><i class="fa fa-check"></i><b>11.7</b> Referenze bibliografiche per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html"><i class="fa fa-check"></i><b>12</b> Contrasti e confronti multipli con R</a><ul>
<li class="chapter" data-level="12.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#introduzione-5"><i class="fa fa-check"></i><b>12.1</b> Introduzione</a></li>
<li class="chapter" data-level="12.2" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#esempio"><i class="fa fa-check"></i><b>12.2</b> Esempio</a></li>
<li class="chapter" data-level="12.3" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-contrasti"><i class="fa fa-check"></i><b>12.3</b> I contrasti</a><ul>
<li class="chapter" data-level="12.3.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#varianza-del-contrasto-e-intervalli-di-confidenza"><i class="fa fa-check"></i><b>12.3.1</b> Varianza del contrasto e intervalli di confidenza</a></li>
<li class="chapter" data-level="12.3.2" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#significativita-del-contrasto-e-intervalli-di-confidenza"><i class="fa fa-check"></i><b>12.3.2</b> Significatività del contrasto e intervalli di confidenza</a></li>
<li class="chapter" data-level="12.3.3" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-contrasti-con-r"><i class="fa fa-check"></i><b>12.3.3</b> I contrasti con R</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-confronti-multipli-a-coppie-pairwise-comparisons"><i class="fa fa-check"></i><b>12.4</b> I confronti multipli a coppie (pairwise comparisons)</a></li>
<li class="chapter" data-level="12.5" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#display-a-lettere"><i class="fa fa-check"></i><b>12.5</b> Display a lettere</a></li>
<li class="chapter" data-level="12.6" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#problemi-di-molteplicita-tassi-di-errore-per-confronto-e-per-esperimento"><i class="fa fa-check"></i><b>12.6</b> Problemi di molteplicità: tassi di errore per confronto e per esperimento</a><ul>
<li class="chapter" data-level="12.6.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#correzione-per-la-molteplicita"><i class="fa fa-check"></i><b>12.6.1</b> Correzione per la molteplicità</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#intervalli-di-confidenza-simultanei"><i class="fa fa-check"></i><b>12.7</b> Intervalli di confidenza simultanei</a></li>
<li class="chapter" data-level="12.8" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#e-le-classiche-procedure-di-confronto-multiplo"><i class="fa fa-check"></i><b>12.8</b> E le classiche procedure di confronto multiplo?</a></li>
<li class="chapter" data-level="12.9" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#consigli-pratici"><i class="fa fa-check"></i><b>12.9</b> Consigli pratici</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="referenze-bibliografiche.html"><a href="referenze-bibliografiche.html"><i class="fa fa-check"></i><b>13</b> Referenze bibliografiche</a></li>
<li class="chapter" data-level="14" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html"><i class="fa fa-check"></i><b>14</b> La regressione lineare semplice</a><ul>
<li class="chapter" data-level="14.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#introduzione-6"><i class="fa fa-check"></i><b>14.1</b> Introduzione</a></li>
<li class="chapter" data-level="14.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#esempio-6"><i class="fa fa-check"></i><b>14.2</b> Esempio</a></li>
<li class="chapter" data-level="14.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#stima-dei-parametri-2"><i class="fa fa-check"></i><b>14.3</b> Stima dei parametri</a></li>
<li class="chapter" data-level="14.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-della-bonta-del-modello"><i class="fa fa-check"></i><b>14.4</b> Valutazione della bontà del modello</a><ul>
<li class="chapter" data-level="14.4.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-grafica"><i class="fa fa-check"></i><b>14.4.1</b> Valutazione grafica</a></li>
<li class="chapter" data-level="14.4.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#errori-standard-dei-parametri"><i class="fa fa-check"></i><b>14.4.2</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="14.4.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-mancanza-dadattamento"><i class="fa fa-check"></i><b>14.4.3</b> Test F per la mancanza d’adattamento</a></li>
<li class="chapter" data-level="14.4.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-bonta-di-adattamento-e-coefficiente-di-determinazione"><i class="fa fa-check"></i><b>14.4.4</b> Test F per la bontà di adattamento e coefficiente di determinazione</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#previsioni"><i class="fa fa-check"></i><b>14.5</b> Previsioni</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html"><i class="fa fa-check"></i><b>15</b> La regressione non-lineare</a><ul>
<li class="chapter" data-level="15.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#introduzione-7"><i class="fa fa-check"></i><b>15.1</b> Introduzione</a></li>
<li class="chapter" data-level="15.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-1-4"><i class="fa fa-check"></i><b>15.2</b> Esempio 1</a><ul>
<li class="chapter" data-level="15.2.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#scelta-della-funzione"><i class="fa fa-check"></i><b>15.2.1</b> Scelta della funzione</a></li>
<li class="chapter" data-level="15.2.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#stima-dei-parametri-3"><i class="fa fa-check"></i><b>15.2.2</b> Stima dei parametri</a></li>
<li class="chapter" data-level="15.2.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#la-regressione-non-lineare-con-r"><i class="fa fa-check"></i><b>15.2.3</b> La regressione non-lineare con R</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#riparametrizzazione-delle-funzioni"><i class="fa fa-check"></i><b>15.3</b> Riparametrizzazione delle funzioni</a><ul>
<li class="chapter" data-level="15.3.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-2-4"><i class="fa fa-check"></i><b>15.3.1</b> Esempio 2</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#inferenze-statistiche-e-verifiche-delle-assunzioni-di-base"><i class="fa fa-check"></i><b>15.4</b> Inferenze statistiche e verifiche delle assunzioni di base</a><ul>
<li class="chapter" data-level="15.4.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#analisi-grafica-dei-residui-1"><i class="fa fa-check"></i><b>15.4.1</b> Analisi grafica dei residui</a></li>
<li class="chapter" data-level="15.4.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#test-f-per-la-mancanza-di-adattamento-approssimato"><i class="fa fa-check"></i><b>15.4.2</b> Test F per la mancanza di adattamento (approssimato)</a></li>
<li class="chapter" data-level="15.4.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#errori-standard-dei-parametri-1"><i class="fa fa-check"></i><b>15.4.3</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="15.4.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#coefficiente-di-determinazione"><i class="fa fa-check"></i><b>15.4.4</b> Coefficiente di determinazione</a></li>
<li class="chapter" data-level="15.4.5" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#coefficiente-di-determinazione-aggiustato"><i class="fa fa-check"></i><b>15.4.5</b> Coefficiente di determinazione aggiustato</a></li>
<li class="chapter" data-level="15.4.6" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#altre-statistiche"><i class="fa fa-check"></i><b>15.4.6</b> Altre statistiche</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#gestione-delle-situazioni-patologiche"><i class="fa fa-check"></i><b>15.5</b> Gestione delle situazioni ‘patologiche’</a><ul>
<li class="chapter" data-level="15.5.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-del-modello"><i class="fa fa-check"></i><b>15.5.1</b> Trasformazione del modello</a></li>
<li class="chapter" data-level="15.5.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-dei-dati"><i class="fa fa-check"></i><b>15.5.2</b> Trasformazione dei dati</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#funzioni-lineari-e-nonlineari-dei-parametri"><i class="fa fa-check"></i><b>15.6</b> Funzioni lineari e nonlineari dei parametri</a></li>
<li class="chapter" data-level="15.7" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#modelli-ancova"><i class="fa fa-check"></i><b>15.7</b> Modelli ANCOVA</a><ul>
<li class="chapter" data-level="15.7.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-3-3"><i class="fa fa-check"></i><b>15.7.1</b> Esempio 3</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#confronto-tra-modelli-alternativi"><i class="fa fa-check"></i><b>15.8</b> Confronto tra modelli alternativi</a><ul>
<li class="chapter" data-level="15.8.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#confronto-tra-modelli-non-nested"><i class="fa fa-check"></i><b>15.8.1</b> Confronto tra modelli non-nested</a></li>
</ul></li>
<li class="chapter" data-level="15.9" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#il-package-drc"><i class="fa fa-check"></i><b>15.9</b> Il package ‘drc’</a></li>
<li class="chapter" data-level="15.10" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#previsioni-1"><i class="fa fa-check"></i><b>15.10</b> Previsioni</a></li>
<li class="chapter" data-level="15.11" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#bibliografia"><i class="fa fa-check"></i><b>15.11</b> Bibliografia</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Metodologia statistica per le scienze agrarie</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica" class="section level1">
<h1><span class="header-section-number">Capitolo 7</span> Modellizzare l’errore sperimentale: introduzione all’inferenza statistica</h1>
<div id="introduzione-3" class="section level2">
<h2><span class="header-section-number">7.1</span> Introduzione</h2>
<p>L’attività sperimentale in ambito scientifico/sociale e, in generale, nelle scienze della vita è condizionata dalla presenza di una componente stocastica, imprevedibile, che va sotto il nome generico di ’errore sperimentale’. Uno dei più influenziali scienziati che si sono confrontati con questo problema è Ronald Fisher (1890-1962), che nel suo famoso testo “Il disegno degli esperimenti” (1935, con seconda edizione nel 1937) ha posto le basi per una corretta metodica sperimentale, volta a minimizzare l’errore sperimentale e, soprattutto, ad impedire che gli effetti da esso prodotti potessero confondersi con gli effetti dei fenomeni scientifici in studio.</p>
<p>Era tuttavia evidente, già in quel testo, come un accurato disegno sperimentale è un presupposto necessario, ma non sufficiente per ottenere prove scientifiche attendibili. Infatti, i fenomeni scientifici sono sempre estremamente complessi e sfaccettati e manifestano i loro effetti su un universo di soggetti e situazioni sperimentali altamente variabili, che possono essere studiate solo attraverso un processo di campionamento. In questo modo, dall’universo di varianti possibili, posso ottenere un campione di dimensione sufficientemente piccola da poter essere studiato agevolmente. Anche se il campione è effettivamente rappresentativo, rimane il fatto che esso rappresenta il risultato di uno solo degli infiniti sforzi di campionamento possibili, con l’importante conseguenza che la ripetizione di un esperimento porta sempre a risultati più o meno diversi, perché diversi sono i soggetti e, spesso, anche le condizioni in cui l’esperimento viene eseguito.</p>
<p>Insomma, abbiamo studiato un campione di soggetti sperimentali, ma il nostro interesse è fondamentalmente rivolto verso la popolazione che ha generato il campione. Ci si deve allora chiedere quale sia la relazione tra l’esperimento da noi eseguito e la realtà scientifica o meglio quale sia la relazione tra le caratteristiche del campione e quelle della popolazione da cui esso è estratto. Questo processo logico prende il nome di <em>inferenza statistica</em> e può essere condotto secondo le teorie di Karl Pearson (1857-1936), Egon Pearson (suo figlio: 1895-1980) e Jarzy Neyman (1894-1981), oltre a Ronald Fisher.</p>
</div>
<div id="lanalisi-dei-dati-gli-ingredienti-fondamentali" class="section level2">
<h2><span class="header-section-number">7.2</span> L’analisi dei dati: gli ’ingredienti’ fondamentali</h2>
<p>Nell’analisi dei dati si segue in genere un percorso logico che può essere così sintetizzato:</p>
<ol style="list-style-type: decimal">
<li>PRESUPPOSTO: I fenomeni biologici seguono una legge di natura (verità ’vera’), che ne costituisce il meccanismo fondamentale.</li>
<li>Quando si organizza un esperimento, i soggetti sperimentali obbediscono a questo meccanismo di fondo, al quale tuttavia si sovrappongono molto altri elementi di ’confusione’, altamente incontrollabili, che vanno sotto il nome di errore sperimentale.</li>
<li>L’osservazione sperimentale è quindi un’immagine confusa della verità vera e, soprattutto, l’osservazione sperimentale tende ad essere diversa per ogni sforzo di campionamento.</li>
<li>Compito del ricercatore è quello di separare l’informazione (che rappresenta la verità ’vera’) dal ’rumore di fondo’ provocato dall’errore sperimentale.</li>
</ol>
<p>Questo dualismo tra verità ’vera’ (inconoscibile) e verità sperimentale (esplorabile tramite un esperimento opportunamente pianificato) è l’aspetto centrale di tutta la biometria ed è schematizzato nella figura seguente.</p>
<div class="figure">
<img src="https://zzeula.db.files.1drv.com/y4mw-F9fZ7hIurd-zQxPAaVX94ykHfQwD9nCRLUwOdkxcFD1gn0Yceof02SO7qy6Pl57YEMoJubYH08risr0SMJiOdnuZzW3BZ41us4TcAfqslJ16vwDYM7O3ZfXO5s_n-HKNRaRgs-PK__DLBJ8maRIMtHYsmxengDFZinI5wSYaxXwop-OXWMpA0Az41qLxhol16BnBGTL7XjBSvM2ylsrA?width=720&amp;height=540&amp;cropmode=none" alt="Osservazioni sperimentali e meccanismi perturbativi" />
<p class="caption">Osservazioni sperimentali e meccanismi perturbativi</p>
</div>
<div class="figure">
<img src="_images/InferenceProcess.jpeg" alt="Osservazioni sperimentali e meccanismi perturbativi" />
<p class="caption">Osservazioni sperimentali e meccanismi perturbativi</p>
</div>
<p>In semplici termini algebrici, la questione può essere illustrata in questo modo:</p>
<p><span class="math display">\[Y_t = f(X)\]</span></p>
<p>La verità ’vera’ (<span class="math inline">\(Y_T\)</span>) segue un modello deterministico (relazione causa-effetto), per il quale essa è funzione dello stimolo. Quando impostiamo un esperimento per investigare questa relazione causale, l’errore sperimentale non permette di osservare esattamente <span class="math inline">\(Y_T\)</span>, ma ci fornisce invece <span class="math inline">\(Y_o\)</span>, il cui valore cambia quando ripetiamo l’esperimento. Di conseguenza possiamo utilizzare un modello stocastico <span class="math inline">\(\Phi\)</span> per assegnare valori di probabilità ad ogni ’outcome’ <span class="math inline">\(Y_o\)</span>:</p>
<p><span class="math display">\[Y_o \sim \Phi(Y_T)\]</span></p>
<p>A questo punto <span class="math inline">\(Y_T\)</span> diviene il valore atteso del modello stocastico, cioè l’output che tende a realizzarsi nel lungo periodo.</p>
</div>
<div id="modello-della-realta-e-sampling-space" class="section level2">
<h2><span class="header-section-number">7.3</span> Modello della realtà e ’sampling space’</h2>
<p>Nel percorso logico precedentemente indicato ci sono due aspetti fondamentali che debbono essere attentamente valutati:</p>
<ol style="list-style-type: decimal">
<li>modello di generazione dei dati sperimentali;</li>
<li>sampling distribution (o sample space).</li>
</ol>
<p>Chiariamo i due concetti con un esempio.</p>
</div>
<div id="esempio-1-2" class="section level2">
<h2><span class="header-section-number">7.4</span> Esempio 1</h2>
<div id="background" class="section level4">
<h4><span class="header-section-number">7.4.0.1</span> Background</h4>
<p>Immaginiamo di avere 4’000’000 di semi ben mischiati (in modo che non ci siano raggruppamenti non casuali di qualche tipo), che costituiscono la nostra popolazione di partenza.</p>
</div>
<div id="obiettivo" class="section level4">
<h4><span class="header-section-number">7.4.0.2</span> Obiettivo</h4>
<p>Vogliamo appurare la frequenza relativa (p) dei semi dormienti. Questa informazione, nella realtà, esiste (<span class="math inline">\(\pi\)</span> = 0.25), ma non è nota.</p>
</div>
<div id="materiali-e-metodi" class="section level4">
<h4><span class="header-section-number">7.4.0.3</span> Materiali e metodi</h4>
<p>Dato l’elevato numero di ’soggetti’, non possiamo saggiare la germinabilità di tutti i semi, ma dobbiamo necessariamente prelevare un campione casuale di 40 soggetti; ogni seme viene saggiato e, dato che la popolazione è molto numerosa, l’estrazione di un seme non modifica sensibilmente la proporzione di quelli dormienti nella popolazione (esperimenti indipendenti).</p>
</div>
<div id="risultati" class="section level4">
<h4><span class="header-section-number">7.4.0.4</span> Risultati</h4>
<p>Il risultato dell’esperimento è: nove semi dormienti su 40 (9 successi su 40 estrazioni).</p>
</div>
<div id="analisi-dei-dati" class="section level4">
<h4><span class="header-section-number">7.4.0.5</span> Analisi dei dati</h4>
<p>Dopo aver descritto la popolazione e l’esperimento, ci chiediamo quale sia il modello matematico che genera i nostri dati (numero di successi su 40 semi estratti). Il disegno sperimentale ci assicura che ogni estrazione è totalmente indipendente dalla precedente e dalla successiva ed ha due soli risultati possibili, cioè successo (seme dormiente), o insuccesso (seme germinabile). Di conseguenza, ogni singola estrazione si configura come un esperimento Bernoulliano, con probabilità di successo pari a <span class="math inline">\(\pi\)</span>, il cui valore ’vero’ esiste, è fisso, pre-determinato (esiste ancor prima di organizzare l’esperimento), anche se incognito e inconoscibile, a meno di non voler/poter esaminare tutti i semi disponibili. L’insieme delle 40 estrazioni (40 esperimenti Bernoulliani) può produrre un ventaglio di risultati possibili, da 40 successi a 40 insuccessi, per un totale di 41 possibili ’outcomes’.</p>
<p>E’ evidente che i 41 possibili risultati non sono ugualmente probabili e si può dimostrare che la probabilità di ottenere <em>k</em> successi (con <em>k</em> che va da 0 ad <em>n</em>; <em>n</em> è al numero delle estrazioni) dipende da <span class="math inline">\(\pi\)</span> ed è descrivibile matematicamente con la distribuzione binomiale <span class="math inline">\(\phi\)</span>:</p>
<p><span class="math display">\[\phi(k, n, p) = \frac{n!}{(n-k)!k!} p^k (1 - p)^{(n-k)}\]</span></p>
<p>Abbiamo quindi definito il modello matematico che descrive la probabilità di tutti i possibili risultati del nostro esperimento e quindi può in qualche modo essere considerato il ’meccanismo’ che ’genera’ i dati sperimentali osservati. Si tratta di un meccanismo puramente ’stocastico’ nel quale è solo il caso che, attraverso il campionamento, determina il risultato dell’esperimento.</p>
</div>
<div id="stima-dei-parametri" class="section level4">
<h4><span class="header-section-number">7.4.0.6</span> Stima dei parametri</h4>
<p>Dovendo stimare la quantità <span class="math inline">\(\pi\)</span>, la statistica tradizionale trascura totalmente le nostre aspettative sul fenomeno e utilizza soltanto i risultati dell’esperimento. Chiamiamo <em>p</em> la quantità stimata e, dato che abbiamo contato nove semi dormienti, concludiamo che p = 0.225, in quanto questa è la cosa più verosimile (maximum likelihood). Infatti, la probabilità di ottenere 9 successi su 40 estrazioni partendo da una distribuzione binomiale con p = 0.225 è pari a 0.1496, mentre, ad esempio, le probabilità di ottenere sempre 9 successi a partire da popolazioni binomiali rispettivamente con p=0.235 o p=0.215 sono più basse, come è possibile verificare utilizzando il software statistico R (R Core Team, 2015) e la funzione dbinom(k, n, p).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">9</span>, <span class="dv">40</span>, <span class="fl">0.225</span>)</code></pre></div>
<pre><code>## [1] 0.1495739</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">9</span>, <span class="dv">40</span>, <span class="fl">0.235</span>)</code></pre></div>
<pre><code>## [1] 0.1479025</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">9</span>, <span class="dv">40</span>, <span class="fl">0.215</span>)</code></pre></div>
<pre><code>## [1] 0.1478311</code></pre>
<p>Si osserva una chiara discrasia tra la verità ’vera’ e l’osservazione sperimentale (tra <span class="math inline">\(\pi\)</span> e <span class="math inline">\(p\)</span>), nel senso che il risultato dell’esperimento non riflette esattamente la realtà. Anche se questa discrasia non è normalmente evidente (perché la verità vera è ignota), non può in nessun modo essere trascurata o meglio, non ci si può mai comportare come se essa non esistesse!</p>
<p><strong>INSOMMA: l’incertezza è un componente inerente della scienza!</strong></p>
</div>
<div id="sampling-distribution" class="section level3">
<h3><span class="header-section-number">7.4.1</span> Sampling distribution</h3>
<p>Abbiamo individuato il modello che ha generato le osservazioni (9 successi su 40 estrazioni), ma è evidente che la natura stocastica di questo modello fa si che l’eventuale ripetizione dell’esperimento potrebbe portare ad ottenere un valore di p diverso. Infatti, se <span class="math inline">\(\pi\)</span> è uguale a 0.25, trovare 10 successi su 40 è la situazione più probabile, ma sono possibili anche altri risultati, seppur meno probabili, come indicato nella figura seguente.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Distribuzione binomiale</span>
<span class="kw">barplot</span>(<span class="kw">dbinom</span>(<span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">40</span>, <span class="dt">by=</span><span class="dv">1</span>), <span class="dt">size=</span><span class="dv">40</span>, <span class="dt">prob=</span><span class="fl">0.25</span>),
        <span class="dt">main=</span><span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Distribuzione binomiale per &quot;</span>,
                              pi, <span class="st">&quot; = 0.25&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;&quot;</span>)),
        <span class="dt">xlab=</span><span class="st">&quot;Successi&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Probabilità&quot;</span>,
        <span class="dt">names.arg=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">40</span>))</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
<p>La ripetizione dell’esperimento può essere simulata (simulazione Monte Carlo) ricorrendo ad un generatore di numeri casuali da una distribuzione binomiale con n = 40 e <span class="math inline">\(\pi\)</span> = 0.25 (in R si usa la funzione rbinom(numeroDatiCasuali, n, p)):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="kw">rbinom</span>(<span class="dv">1</span>, <span class="dv">40</span>, <span class="fl">0.25</span>)</code></pre></div>
<pre><code>## [1] 11</code></pre>
<p>In questo caso il generatore casuale ha prodotto 7 successi, ma ripetendo ancora otteniamo risultati diversi. Trattandosi di un esperimento Monte Carlo, non ci sono problemi a ripeterlo un numero molto alto di volte (es. 10’000’000), ottenendo così una ’popolazione’ di stime <em>p</em>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
result &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">10000000</span>, <span class="dv">40</span>, <span class="fl">0.25</span>)</code></pre></div>
<p>A questo punto possiamo esplorare i risultati ottenuti.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result_p &lt;-<span class="st"> </span>result<span class="op">/</span><span class="dv">40</span>
<span class="kw">mean</span>(result_p)</code></pre></div>
<pre><code>## [1] 0.2500129</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(result_p)</code></pre></div>
<pre><code>## [1] 0.0684611</code></pre>
<p>Osserviamo subito che, anche se i singoli esperimenti portano a stime diverse da <span class="math inline">\(\pi\)</span>, la media di <span class="math inline">\(p\)</span> tende ad essere uguale a <span class="math inline">\(\pi\)</span>. Abbiamo però una variabilità intorno a questo valore, quantificabile con una deviazione stndard di 0.068.</p>
<p>Possiamo utilizzare i 10’000’000 di valori p ottenuti per costruire una distribuzione empirica di frequenze, che viene detta ’sampling distribution’. La deviazione standard della ’sampling distribution’ (0.0685, in questo caso) si chiama <strong>errore standard</strong>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">breaks &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">0.7</span>, <span class="dt">by=</span><span class="fl">0.025</span>)
freqAss &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( <span class="kw">table</span>(<span class="kw">cut</span>(result_p, breaks) ) ) 
freqRel &lt;-<span class="st"> </span>freqAss<span class="op">/</span><span class="kw">length</span>(result_p)
density &lt;-<span class="st"> </span>freqRel<span class="op">/</span><span class="fl">0.025</span>
p_oss &lt;-<span class="st"> </span>breaks[<span class="dv">2</span><span class="op">:</span><span class="kw">length</span>(breaks)]

<span class="kw">plot</span>(density <span class="op">~</span><span class="st"> </span>p_oss, <span class="dt">type =</span> <span class="st">&quot;h&quot;</span>,
     <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">bar</span>(p))),
     <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, 
    <span class="dt">main=</span><span class="st">&quot;Sampling distribution per p&quot;</span>, 
    <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.6</span>) )

<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="fl">0.25</span>, <span class="fl">0.0685</span>), <span class="dt">add=</span>T, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<p>La sampling distribution può essere approssimata con una distribuzione normale, con media pari a 0.025 e deviazione standard pari a 0.0685. Lo percepiamo chiaramente dal grafico soprastante.</p>
<p>In effetti vi è una spiegazione scientifica per questo, basata sul <strong>TEOREMA DEL LIMITE CENTRALE</strong>:</p>
<ol style="list-style-type: decimal">
<li>La sampling distribution di una statistica ottenuta da campioni casuali e indipendenti è approssimativamente normale, indipendentemente dalla distribuzione della popolazione da cui i campioni sono stati estratti.</li>
<li>La media della sampling distribution è uguale al valore della statistica calcolata sulla popolazione originale, la deviazione standard della sampling distribution (errore standard) è pari alla deviazione standard della popolazione originale divisa per la radice quadrata della numerosità di un campione.</li>
</ol>
<p>In questo caso la statistica calcolata sulla popolazione originale è <span class="math inline">\(\pi\)</span> = 0.25 e quindi la media della sampling distribution è pari a <span class="math inline">\(\pi\)</span> = 0.25. La deviazione standard della popolazione originale (che è binomiale) è pari a <span class="math inline">\(\sqrt{p \times (1 - p)}\)</span> e la deviazione standard della sampling distribution è pari a <span class="math inline">\(\sqrt{p \times (1 - p) / 40}\)</span> = <span class="math inline">\(\sqrt{0.25 \times 0.75 / 40} = 0.0685\)</span>. La bontà di questa approssimazione è evidente in figura, anche se non si tratta di campioni di numerosità molto alta.</p>
<p>Per concludere questa parte osserviamo che abbiamo finora lavorato con due oggetti, o meglio due distribuzioni di probabilità:</p>
<ol style="list-style-type: decimal">
<li>La distribuzione di probabilità che descrive come saranno i risultati del nostro esperimento (campionamento). In questo caso si tratta di una distribuzione binomiale, che costituisce un vero e proprio ’meccanismo generativo’ delle nostre osservazioni sperimentali.</li>
<li>La sampling distribution, che descrive la variabilità delle stime tra un esperimento e l’altro. Si tratta di una distribuzione diversa dalla precedente anche se ad essa legata, per il tramite del teorema del limite centrale.</li>
</ol>
<p>La sampling distribution caratterizza la riproducibilità di un esperimento e la variabilità stocastica dei suoi risultati, in quanto rappresenta i risultati di tutti gli infiniti esperimenti che avremmo dovuto fare, ma non abbiamo fatto. Rappresenta quindi una proiezione sul futuro e può quindi essere utilizzata per trarre conclusioni in modo ’oggettivo’, per testare ipotesi e per costruire intervalli di incertezza, come vedremo in seguito.</p>
<div class="figure">
<img src="https://zzevla.db.files.1drv.com/y4mTg0HEcKv1xC7wRnRAKhSCI7txTJzY-S2eFugdLgFmI-SpWVK6lPfplEdgDyaOr3AhkF7xELZBaLwhWiD9F38H_Tgl3zcFsuxe-NZG6IojXX130175C-rp21ByURMdjsR-GOFbJIy58cOctubkvDVITz2rIaBcw00e1hxBr2geYrmmwbY6HbgjhonCTqTP7ZzulT06Iwr-1hQWCGvlAxctA?width=693&amp;height=350&amp;cropmode=none" alt="I due ’ingredienti fondamentali’ della biostatistica" />
<p class="caption">I due ’ingredienti fondamentali’ della biostatistica</p>
</div>
</div>
</div>
<div id="esempio-2-2" class="section level2">
<h2><span class="header-section-number">7.5</span> Esempio 2</h2>
<p>Immaginiamo a questo punto una situazione diversa e più vicina alla pratica sperimentale reale</p>
<ol style="list-style-type: decimal">
<li>VERITA’ VERA: abbiamo una soluzione erbicida a concentrazione pari a 120 <span class="math inline">\(mg/l\)</span>, che viene misurata tramite un gascromatografo.</li>
<li>MECCANISMI DI CONFUSIONE: Lo strumento di misura, unitamente a tutte le altre fonti ignote di errore, produce un coefficiente di variabilità del 10% (corrispondete ad una deviazione standard pari a 12 <span class="math inline">\(mg/l\)</span>).</li>
<li>VERITA’ SPERIMENTALE: i risultati di analisi chimiche ripetute saranno diversi tra di loro e probabilmente diversi dal valore vero di 120 <span class="math inline">\(mg/l\)</span>.</li>
</ol>
<p>Come abbiamo già fatto in precedenza, simuliamo l’esperimento ricorrendo ad un generatore di numeri casuali, con la seguente logica:</p>
<ol style="list-style-type: decimal">
<li>Immaginiamo che la natura operi secondo un meccanismo perfettamente gaussiano, dove gli errori positivi e negativi sono equiprobabili, con probabilità decrescente al crescere della distanza dal valore ’vero’</li>
<li>Eseguiamo l’esperimento Monte Carlo, considerando che la concentrazione vera <span class="math inline">\(\mu\)</span> sia pari a 120 e <span class="math inline">\(\sigma\)</span> sia pari a 12.</li>
<li>Otteniamo i tre valori 109.28, 132.29 e 130.85 (ovviamente, ripetendo l’estrazione i valori cambiano!!!)</li>
<li>Questo è il risultato dell’esperimento, per creare il quale ci siamo sostituiti alla natura, riproducendo i suoi meccanismi di confusione.</li>
</ol>
<p>Il valore ’vero’ di <span class="math inline">\(\mu\)</span> in pratica è ignoto, anche se in questo caso lo conosciamo, trattandosi di una simulazione.</p>
<p>Traiamo le seguenti conclusioni:</p>
<ol style="list-style-type: decimal">
<li>In base alle osservazioni in nostro possesso, concludiamo che la concentrazione erbicida è pari a m = 124.14 <span class="math inline">\(mg/l\)</span>, con una deviazione standard pari a s = 12.89 <span class="math inline">\(mg/l\)</span>.</li>
<li>La verità sperimentale non coincide con la verità ’vera’ (<span class="math inline">\(m \ne \mu\)</span>, ma non siamo molto distanti, compatibilmente con il 10% di variabilità dello strumento di analisi.</li>
<li>Lo scopo dell’esperimento però non è fornire informazioni sulla verità sperimentale, ma su quella ’vera’.</li>
<li>E’ quindi giustificato un atteggiamento prudenziale da parte nostra.</li>
<li>Che cosa succederebbe se ripetessimo l’esperimento molte altre volte?</li>
</ol>
<p>La statistica ’frequentista’ (così chiamata per distinguerla da quella bayesiana) assume che la verità vera è fissa e la variabilità di osservazione è misurabile attraverso un ipotetico meccanismo di ripetizione degli esperimenti.</p>
<div id="definire-la-sampling-distribution-per-lesempio-2" class="section level3">
<h3><span class="header-section-number">7.5.1</span> Definire la ’sampling distribution’ per l’esempio 2</h3>
<p>In questo caso l’esperimento è solo ’elettronico’ e possiamo quindi ripeterlo un numero anche molto elevato di volte, seguendo questa procedura:</p>
<ol style="list-style-type: decimal">
<li>Ripetiamo l’estrazione precedente per 10000 volte (ripetiamo l’analisi chimica per 10000 volte, sempre con tre repliche)</li>
<li>Otteniamo 10000 medie, la cui media è pari a 120.03 e la cui deviazione standard è pari 6.94</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Simulazione MONTE CARLO - Esempio 2</span>
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  result[i] &lt;-<span class="st"> </span><span class="kw">mean</span>(sample)
}
<span class="kw">mean</span>(result)</code></pre></div>
<pre><code>## [1] 119.9882</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(result)</code></pre></div>
<pre><code>## [1] 6.924185</code></pre>
<p>In sostanza, la simulazione MONTE CARLO ci consente di fare quello che dovremmo sempre fare (ripetere l’esperimento un numero di volte molto elevato, anche se non infinito), ma che, nella realtà, non possiamo fare. A questo punto abbiamo in mano una popolazione di medie, che viene detta ’sampling distribution’, un ’oggetto’ abbastanza ’teorico’, ma fondamentale per la statistica frequentista, perché caratterizza la variabilità dei risultati di un esperimento, e quindi la sua riproducibilità.</p>
<p>Notiamo empiricamente che:</p>
<ol style="list-style-type: decimal">
<li>La media delle medie è ora praticamente coincidente con <span class="math inline">\(\mu\)</span>, la verità ’vera’. Ciò conferma che l’unico modo di ottenere risultati totalmente precisi è ripetere infinite volte l’esperimento;simExcel</li>
<li>La deviazione standard delle medie è pari a circa <span class="math inline">\(12/\sqrt(3)\)</span> = 6.928, cioè l’errore standard della media (SEM)</li>
</ol>
</div>
<div id="le-simulazioni-monte-carlo-con-excel" class="section level3">
<h3><span class="header-section-number">7.5.2</span> Le simulazioni Monte Carlo con Excel</h3>
<p>Finora abbiamo eseguito le nostre simulazioni utilizzando R, cioè un software statistico avanzato. Tuttavia, anche in Excel esiste uno strumento analogo per la generazione di numeri casuali. Assicurarsi di avere installato ed abilitato gli strumenti di analisi dei dati (in Excel 2003 Strumenti/Componenti aggiuntivi/Strumenti di analisi; in Excel 2010: File/Opzioni/Componenti aggiuntivi/Strumenti di analisi/Vai..). Scegliere ’analisi dei dati’ dal menù dati e selezionare lo strumento di generazione dei numeri casuali normali. Immettere le informazioni richieste.</p>
<div class="figure">
<img src="https://zzesla.db.files.1drv.com/y4mMWyplAMgR70MozHfTpZCtenuBONCMTxMgDMxpJkqvgW7bpn9BzIhEXfXBbdItoFAcfzESK1yYvBK-4eQ6VVJpc1dnPx0Ba57Gb_OhgBtTQUIMnjuORGAv6DwLFIk4gE1wql3vlW27vg1ggYGMzm1kfKf2vsymezNApUItyg8Y7kiWPDTnyQnjcEBBAH5tCvveyTQuQa7VnkWPpGJco6T6Q?width=500&amp;height=299&amp;cropmode=none" alt="Impiego dello strumento di generazione dei dati in Excel" />
<p class="caption">Impiego dello strumento di generazione dei dati in Excel</p>
</div>
<p>Ricordare che i numeri generati sono disposti in più righe e in più colonne, che possiamo specificare immettendo informazioni nei primi due campio della finestra di immissione, cioè numero di variabili (che corrisponde alle colonne) e numero di numeri casuali (che corrisponde alle righe. Nel campo generatore possiamo immettere il ’seed’ cioè il valore di partenza per la generazione di numeri casuali. A partire dal valore prefissato, si ottengono serie di numeri casuali uguali (si tratta in realtà di numeri pseudo-casuali), in modo che le simulazioni possono essere replicate utilizzando lo stesso generatore.</p>
</div>
<div id="la-distribuzione-delle-medie-campionarie-lerrore-standard" class="section level3">
<h3><span class="header-section-number">7.5.3</span> La distribuzione delle medie campionarie: l’errore standard</h3>
<p>Se vogliamo affrontare il tema in un modo un po’ più formale, il problema allora è: esiste una distribuzione di frequenze che descrive la variabilità delle medie di tutti gli infiniti campioni estraibili dalla popolazione anzidetta?</p>
<div id="la-propagazione-degli-errori" class="section level4">
<h4><span class="header-section-number">7.5.3.1</span> La propagazione degli errori</h4>
<p>Questo problema si può risolvere considerando che quando prelevo un individuo da una popolazione, da un collettivo ottengo un risultato variabile, a seconda di chi prelevo. Ogni soggetto quindi porta con sé una sua componente di incertezza, che egli ‘eredita’ dalla popolazione di cui fa parte. In questo caso, la popolazione ha una varianza pari a <span class="math inline">\(12^2 = 144\)</span> e quindi ogni osservazione ha tale varianza. Quando calcolo la media di tre osservazioni, in prima battuta io le sommo. A questo punto posso chiedermi: nota che sia la varianza di tre osservazioni, qual è la varianza della loro somma?</p>
<p>Dato che si tratta di osservazioni indipendenti, lapropagazione degli errori ci dice che la varianza della somma è uguale alla somma delle varianze. Quindi è pari a <span class="math inline">\(144 \times 3 = 432\)</span>.</p>
<p>Dopo aver sommato, il calcolo della media richiede che il risultato venga diviso per tre. Ci chiediamo ancora: qual è la varianza del quoziente? Anche questa risposta arriva attraverso il teorema di propagazione degli errori: Se divido per tre, la varianza viene divisa per <span class="math inline">\(3^2 = 9\)</span>. Insomma la varianza della media è <span class="math inline">\(432/9 = 48\)</span>. Quindi la deviazione standard della media è <span class="math inline">\(\sqrt{48} = 6.933\)</span>. E’ facile vedere che questo valore è pari a <span class="math inline">\(12/\sqrt{3}\)</span>. In generale:</p>
<p><span class="math display">\[\sigma_m  = \frac{\sigma }{\sqrt n }\]</span></p>
<p>dove <em>n</em> è la dimensione del campione.</p>
<p>Questa quantità si dice ERRORE STANDARD della media, e rappresenta la deviazione standard della sampling distribution, che, in questo modo, è totalmente caratterizzata ed è in grado di descrivere perfettamente l’incertezza associata alla stima della media.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">b &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">90</span>, <span class="dv">160</span>, <span class="dt">by=</span><span class="fl">2.5</span>)
<span class="kw">hist</span>(result, <span class="dt">breaks =</span> b, <span class="dt">freq=</span>F, <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(m)), <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">120</span>, <span class="dv">12</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>)), <span class="dt">add=</span>T, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="riepilogo-1-caratterizzare-lincertezza-di-un-esperimento" class="section level2">
<h2><span class="header-section-number">7.6</span> Riepilogo 1: Caratterizzare l’incertezza di un esperimento</h2>
<p>A questo punto possiamo aggiornare le nostre conclusioni precedenti, aggiornandole alla realtà dei fatti.</p>
<ol style="list-style-type: decimal">
<li>Abbiamo fatto un esperimento con tre repliche campionando da una distribuzione normale incognita.</li>
<li>Abbiamo ottenuto i tre valori 109.28, 132.29 e 130.85.</li>
<li>In base alle osservazioni in nostro possesso, concludiamo che la concentrazione erbicida è pari a m = 124.14 <span class="math inline">\(mg/l\)</span>, con una deviazione standard pari a 12.89 <span class="math inline">\(mg/l\)</span>.</li>
<li>Dobbiamo adottare un atteggiamento prudenziale in relazione alla media, dato che non sappiamo il valore vero di <span class="math inline">\(\mu\)</span>.</li>
<li>Immaginiamo di conoscere la sampling distribution, che avrà una deviazione standard pari a 12.89/<span class="math inline">\(\sqrt{3}\)</span> = 7.44</li>
<li>Concludiamo quindi che <span class="math inline">\(\mu\)</span> è pari a 124.14 <span class="math inline">\(\pm\)</span> 7.44</li>
</ol>
</div>
<div id="gli-intervalli-di-confidenza" class="section level2">
<h2><span class="header-section-number">7.7</span> Gli intervalli di confidenza</h2>
<p>Finora abbiamo in mano una stima associata alla sua incertezza, ma sarebbe interessante poter rispondere a questa domanda: ”qual è la proporzione di medie (cioè di ipotetici risultati del mio esperimento) che si trova all’interno della fascia di incertezza data?” Un passo in avanti in questo senso è stato fatto da Neyman (1941) che ha proposto di calcolare gli ’intervalli di confidenza’ prendendo due valori dalla sampling distribution tali da comprendere al loro interno il 95% dei valori di m, lasciando all’esterno solo il 5% di quelli meno probabili (2.5% per ognuna delle due code). Questo problema di calcolo di probabilità può essere risolto partendo dalla formula seguente (utilizzando la notazione R, per comodità):</p>
<p><span class="math display">\[P(\textrm{qnorm}(0.025,\mu,\sigma/\sqrt(n)) \leq m \leq \textrm{qnorm}(0.975,\mu,\sigma/\sqrt(n))) = 0.95\]</span></p>
<p>dove si formalizza il fatto che esiste una probabilità pari a 0.95 che m è compreso tra qnorm(0.025, <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma/\sqrt(n)\)</span>) e qnorm(0.975, <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma/\sqrt(n)\)</span>), cioè tra il 2.5-esimo e il 97.5-esimo percentile di una distribuzione normale con media <span class="math inline">\(\mu\)</span> e deviazione standard <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma/\sqrt(n)\)</span>.</p>
<p>Questa espressione è solo un punto di partenza, ma è inutile, in pratica, per calcolare gli intervalli di confidenza della media, in quanto <span class="math inline">\(\mu\)</span> e <span class="math inline">\(\sigma\)</span> non sono normalmente noti. Dobbiamo quindi trovarci una statistica che sia più facilmente gestibile. Neyman ha proposto di operare la standardizzazione della sampling distribution, tramite la seguente statistica:</p>
<p><span class="math display">\[T = \frac{m - \mu}{s_m}\]</span></p>
<p>Considerando quanto detto più sopra, ci aspetteremmo che la sampling distribution di T sia costituita da una distribuzione normale standardizzata, con media 0 e deviazione standard 1.</p>
<p>Verifichiamo la nostra aspettativa con una nuova simulazione Monte Carlo. Questa volta facciamo la seguente operazione:</p>
<ol style="list-style-type: decimal">
<li>campioniamo tre individui</li>
<li>Calcoliamo il valore di T con la statistica precedente e lo salviamo</li>
<li>Con un po’ di pazienza, ripetiamo il tutto 100’000 volte.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#SIMULAZIONE MONTE CARLO - t di Student</span>
<span class="kw">set.seed</span>(<span class="dv">435</span>)
result &lt;-<span class="st"> </span><span class="kw">c</span>()
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample3 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  T &lt;-<span class="st"> </span>(<span class="kw">mean</span>(sample3) <span class="op">-</span><span class="st"> </span><span class="dv">120</span>) <span class="op">/</span><span class="st"> </span>(<span class="kw">sd</span>(sample3)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>))
  result[i] &lt;-<span class="st"> </span>T
  }</code></pre></div>
<p>Se riportiamo i valori ottenuti su una distribuzione di frequenze otteniamo il grafico sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Plot sampling distribution</span>
b &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">600</span>, <span class="dv">600</span>, <span class="dt">by=</span><span class="fl">0.2</span>)
<span class="kw">hist</span>(result, <span class="dt">breaks =</span> b, <span class="dt">freq=</span>F, <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(m)), <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.4</span>), <span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">2</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-82-1.png" width="672" /></p>
<p>In sostanza, la distribuzione normale (blue) è un’approssimazione alla vera distribuzione di T, che diviene accettabile solo quando <span class="math inline">\(n\)</span> è molto grande (non certamente ora). Il motivo di questo è legato al fatto che, oltre a non conoscere <span class="math inline">\(\mu\)</span>, non conosciamo neanche <span class="math inline">\(\sigma\)</span>, il che crea un ulteriore elemento di incertezza. Infatti, vediamo che la distribuzione reale è più ’dispersa’ di quella normale, con un maggior numero di valori sulle code.</p>
<p>In pratica, bisogna quindi fare riferimento ad una nuova distribuzione di probabilità, quella di t di Student (in rosso). In realtà, esiste una famiglia infinita di distribuzioni di t di Student, una per ogni numero di gradi di libertà. La distribuzione t di Student con infiniti gradi di libertà coincide con quella normale. In questo caso avremo 2 gradi di libertà.</p>
<p>Possiamo quindi scrivere che il 95% dei valori di T è contenuto nell’intervallo sottostante:</p>
<p><span class="math display">\[P \left[ qt(0.025,n - 1) \le \frac{m - \mu }{s_m} \le qt(0.975, n - 1) \right] = 0.95\]</span></p>
<p>dove <span class="math inline">\(qt(0.025,n - 1)\)</span> e <span class="math inline">\(qt(0.975,n - 1)\)</span> sono rispettivamente il 2.5-esimo e il 97.5-esimo percentile della distribuzione t di Student, con n-1 gradi di libertà. Da questa espressione possiamo facilmente ottenere la seguente:</p>
<p><span class="math display">\[P \left( m + qt(0.025,n - 1) \cdot s_m \le \mu  \le m + qt(0.975,n - 1) \cdot s_m \right) = 0.95\]</span></p>
<p>che dimostra come nel 95% dei casi la media <span class="math inline">\(\mu\)</span> della popolazione è contenuta nell’intervallo che va da <span class="math inline">\(m + qt(0.025,n - 1) \cdot s_m\)</span> <span class="math inline">\(m + qt(0.975,n - 1) \cdot s_m\)</span>.</p>
<p>I valori della distribuzione t di Student che lasciano al loro esterno il 5% delle varianti (2.5% per coda) sono:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] -4.302653</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>)</code></pre></div>
<pre><code>## [1] 4.302653</code></pre>
<p>Gli intervalli di confidenza sono pertanto:</p>
<p><span class="math display">\[124.14 - 4.3027 \cdot 7.44 \le \mu  \le m + 4.3027 \cdot 7.44\]</span></p>
</div>
<div id="gli-intervalli-di-confidenza-con-excel" class="section level2">
<h2><span class="header-section-number">7.8</span> Gli intervalli di confidenza con Excel</h2>
<p>Se vogliamo calcolare gli intervalli di confidenza con Excel, dobbiamo utilizzare la funzione inversa della distribuzione t di Student. Sfortunatamente, le versioni di Excel non sono completamente coerenti a questo proposito e funzionano in modo diverso in Windows e Mac Os X. Infatti, nel sistema operativo di Microsoft, le funzioni INV.T (da Excel 2007) e INV.T.2T sono ’a due code’ e quindi è sufficiente inserire un livello di probabilità pari a 0.05 per ottenere il valore che, assieme al suo reciproco, definisce l’intervallo che lascia al suo esterno il 5% delle varianti (2.5% per coda). Ad esempio:</p>
<p>=INV.T(0.05, 2) = 4.3027</p>
<p>per cui i valori da inserire nella formula precedente sono -4.3027 e 4.3027.</p>
<p>Al contrario, su EXCEL per Mac Os x, la funzione ”INV.T” è a ’una coda’ (quella sinistra) ; pertanto, vanno usate in questo modo:</p>
<p>=INV.T(0.025, 2) = -4.3027</p>
<p>e</p>
<p>=INV.T(0.975, 2) = 4.3027</p>
</div>
<div id="qual-e-il-senso-dellintervallo-di-confidenza" class="section level2">
<h2><span class="header-section-number">7.9</span> Qual è il senso dell’intervallo di confidenza?</h2>
<p>E’utile ricordare il nostro punto di partenza e il nostro punto di arrivo:</p>
<ol style="list-style-type: decimal">
<li>PUNTO DI PARTENZA: una distribuzione normale con <span class="math inline">\(\mu\)</span> = 120 e <span class="math inline">\(\sigma\)</span> = 12. Nella realtà assumiamo che la distribuzione di partenza sia normale, mentre i suoi parametri sono totalmente ignoti.</li>
<li>PUNTO DI ARRIVO: una stima di 124.14 ed un intervallo da 92.13 a 156.15</li>
</ol>
<p>Qual è il reale valore di questo intervallo? Esso fornisce:</p>
<ol style="list-style-type: decimal">
<li>una misura di precisione: più piccolo è l’intervallo, maggiore è la precisione;</li>
<li>la confidenza che, se ripetessimo l’esperimento, nel 95% dei casi l’intervallo calcolato conterrebbe <span class="math inline">\(\mu\)</span>.</li>
</ol>
<p>Questa seconda affermazione può essere dimostrata abbastanza facilmente: in R, dobbiamo estrarre un numero elevato di campioni composti da tre soggetti da una distribuzione normale con media 120 e deviazione standard 12 calcolare gli intervalli di confidenza ogni volta e memorizzare per ogni intervallo di confidenza il valore 1 o 0 a seconda che la media vera sia contenuta nell’intervallo oppure no. In questo caso eseguiamo 100000 simulazioni:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>) 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>) 
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span></code></pre></div>
<pre><code>## [1] 0.94992</code></pre>
<p>Chiaramente <strong>NON E’ VERO</strong> che:</p>
<ol style="list-style-type: decimal">
<li>c’è il 95% di probabilità che la media ’vera’ della popolazione si trovi tra 92.13 e 156.15. La media vera della popolazione è sempre fissa e pari a 120 e non cambia affatto tra un campionamento e l’altro.</li>
<li>ripetendo l’esperimento, il 95% delle stime che otteniamo cadono nell’intervallo 92.13 - 156.15. Una semplice simulazione mostra che quasi tutte le medie campionate cadono in quell’intervallo:</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  <span class="cf">if</span> (<span class="kw">mean</span>(sample) <span class="op">&lt;=</span><span class="st"> </span><span class="fl">156.15</span> <span class="op">&amp;</span><span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">&gt;=</span><span class="st"> </span><span class="fl">92.13</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span></code></pre></div>
<pre><code>## [1] 0.99996</code></pre>
<ol style="list-style-type: decimal">
<li>c’è il 95% di probabilità che l’affermazione ’la media vera è compresa tra 92.13 e 156.15’ sia vera. Nelle normali condizioni sperimentali la media vera è ignota e non sapremo mai nulla su di essa: il nostro intervallo di confidenza può catturarla o no. In questo caso, lo ha fatto,ed è tutto quello che possiamo dire.</li>
</ol>
<p>Insomma, l’intervallo di confidenza vale per la sampling distribution e non vale per ogni singolo campionamento (esperimento). Pertanto, affermazioni del tipo: ”c’è il 95% di probabilità che <span class="math inline">\(\mu\)</span> è compreso nell’intervallo di confidenza” oppure ”il valor più probabile di <span class="math inline">\(\mu\)</span> è…” non sono corrette e anzi non hanno senso nella statistica tradizionale.</p>
<p>In altre parole, l’intervallo di confidenza è una sorta di polizza assicurativa che ci garantisce che, se operiamo continuativamente con le procedure indicate, al termine della nostra carriera avremo sbagliato in non più del 5% dei casi.</p>
</div>
<div id="analisi-statistica-dei-dati-riassunto-del-percorso-logico" class="section level2">
<h2><span class="header-section-number">7.10</span> Analisi statistica dei dati: riassunto del percorso logico</h2>
<p>Considerando quanto finora detto, possiamo riassumere la logica dell’inferenza tradizionale nel modo seguente:</p>
<ol style="list-style-type: decimal">
<li>Un esperimento è solo un campione di un numero infinito di esperimenti simili che avremmo potuto/dovuto eseguire, ma che non abbiamo eseguito, per mancanza di risorse;</li>
<li>Assumiamo che i dati del nostro esperimento sono generati da un modello matematico probabilistico, che prende una certa forma algebrica e ne stimiamo i parametri utilizzando i dati osservati;</li>
<li>Costruiamo la sampling distribution per i parametri stimati o per altre statistiche rilevanti, in modo da caratterizzare i risultati delle infinite repliche del nostro esperimento, che avremmo dovuto fare, ma che non abbiamo fatto.</li>
<li>Utilizziamo la sampling distribution per l’inferenza statistica.</li>
</ol>
<div class="figure">
<img src="https://zzetla.db.files.1drv.com/y4mCYFBvU0WE-Wipao2xiy42hBFpLD7FbZnUsP_e6auyQUKFOCG_Y2Ra23Zl4L4U9kfOyJ8VIlRn8oOLd7L-_gIgdl7sXc8yhcDm32LAReB7O9RhXnyb_tkRCIWgv8b-r5G-barv1fUlTfirfiSgx1DsbxzAmdpa3HhDIYTPKb0L5uG5VBqwShJRrFhqp0Oi6C-M8vtc8hQ3sgZUuVqxcXp5A?width=720&amp;height=540&amp;cropmode=none" alt="Riassunto del percorso logico nell’inferenza statistica" />
<p class="caption">Riassunto del percorso logico nell’inferenza statistica</p>
</div>
</div>
<div id="presentazione-dei-risultati-degli-esperimenti" class="section level2">
<h2><span class="header-section-number">7.11</span> Presentazione dei risultati degli esperimenti</h2>
<p>Dovrebbe essere chiaro che la presenza dell’errore sperimentale ci obbliga a riportare sempre per ogni misurazione un indicatore di tendenza centrale ed un indicatore di variabilità. L’assenza di quest’ultimo non è, in linea di principio, accettabile. Possiamo considerare le seguenti possibilità:</p>
<ol style="list-style-type: decimal">
<li>la media associata alla deviazione standard, per descrivere la variabilità originale del fenomeno in studio;</li>
<li>la media associata all’errore standard, per descrivere l’incertezza associata alla stima della media;</li>
<li>la mediana, associata al 25th e 75th percentile, per descrivere dati e fenomeni che non sembrano seguire una distribuzione normale.</li>
</ol>
</div>
<div id="da-ricordare" class="section level2">
<h2><span class="header-section-number">7.12</span> Da ricordare</h2>
<ol style="list-style-type: decimal">
<li>La natura genera i dati</li>
<li>Noi scegliamo un modello deterministico che simula il meccanismo di generazione dei dati attuato dalla natura.</li>
<li>Stimiamo i parametri.</li>
<li>Confrontiamo le previsioni con i dati osservati. Determiniamo <span class="math inline">\(\epsilon\)</span> e la sua deviazione standard (<span class="math inline">\(\sigma\)</span>)</li>
<li>Assumiamo un modello stocastico ragionevole per spiegare <span class="math inline">\(\epsilon\)</span>, quasi sempre di tipo gaussiano, con media 0 e deviazione standard pari a <span class="math inline">\(\sigma\)</span>, indipendente dalla X (omoscedasticità)</li>
<li>Qualunque stima sperimentale deve essere associata ad un indicatore di variabilità (errore standard o intervallo di confidenza).</li>
</ol>
</div>
<div id="esercizi" class="section level2">
<h2><span class="header-section-number">7.13</span> Esercizi</h2>
<ol style="list-style-type: decimal">
<li>Un’analisi chimica è stata eseguita in triplicato, ottenendo i seguenti risultati: 125, 169 e 142 ng/g. Calcolare media, devianza, varianza, deviazione standard e coefficiente di variabilità.</li>
<li>Considerare il campione <span>[</span>140 - 170 - 155<span>]</span> proveniente da una popolazione distribuita normalmente. Calcolare la probabilità di estrarre dalla stessa popolazione un campione di tre individui con media:
<ul>
<li>maggiore di 170</li>
<li>minore di 140</li>
<li>compresa tra 170 e 140</li>
</ul></li>
<li>Dati i tre individui dell’esercizio precedente (140 - 170 - 155), stimare i limiti di confidenza della media (p = 0.05).</li>
<li>Dati i tre individui dell’esercizio precedente, immaginare che essi siano stati estratti da una distribuzione normale con sigma noto e uguale a 2. stimare i limiti di confidenza della media (p = 0.05).</li>
<li>Un campione di 400 insetti a cui è stato somministrato un certo insetticida mostra che 136 di essi sono sopravvissuti. Determinare un intervallo di confidenza con grado di fiducia del 95% per la proporzione della popolazione insensibile al trattamento.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="dalla-popolazione-al-campione-i-modelli-stocastici.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="breve-introduzione-al-test-dipotesi.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
