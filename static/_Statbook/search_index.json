[["index.html", "Metodologia sperimentale per le scienze agrarie Premessa Obiettivi Organizzazione Software statistico Gli autori Ringraziamenti e scuse Acronimi", " Metodologia sperimentale per le scienze agrarie Andrea Onofri e Dario Sacco Update: v. 0.5 (Early Draft, Anno Accademico 2025-2026; giugno), compil. 2025-11-19 Premessa In questo sito troverete l’e-book “Metodologia sperimentale per le scienze agrarie”, con il quale ci siamo posti il compito di fornirvi informazioni su come sia possibile ottenere informazioni scientificamente attendibili, partendo da un esperimento opportunamente pianificato ed organizzato. Siamo convinti che già sappiate come gli esperimenti siano l’elemento chiave del progresso scientifico; forse però non siete coscienti del fatto che non tutti gli esperimenti sono ugualmente buoni e producono dati ugualmente validi. In questo libro, cercheremo di mostrarvi come si riconosce un buon esperimento da un cattivo esperimento e, di conseguenza, come si riconosce la scienza dalla pseudoscienza. Ovviamente, un buon ricercatore non è soltanto in grado di pianificare un esperimento valido ed ottenere quindi risultati scientificamente affidabili. Un buon ricercatore deve essere anche in grado di interpretarne correttamente i risultati, attraverso l’impiego di metodiche di analisi statistica, che consentano di separare l’informazione dal rumore di fondo. Siamo perfettamente coscienti del fatto che la statistica non è una materia molto praticata nei piani di studio relativi alle scienze agrarie e, di conseguenza, in questo libro seguiremo un approccio fondamentalmente pratico, orientato al ‘problem solving’; in fin dei conti, quando impariamo a guidare un auto ci preoccupiamo di riuscire a raggiungere la nostra destinazione senza incidenti, ma non ci preoccupiamo esattamente di capire quali siano le reazioni chimiche che avvengono all’interno del motore. Secondo questo approccio, faremo grande uso di esempi, in gran parte relativi a sperimentazioni tipiche delle scienze agrarie, con le quali si confrontano tecniche colturali, genotipi innovativi, erbicidi ed altri metodi di controllo dei patogeni, degli insetti e delle piante infestanti. Siamo fermamente convinti che qualunque progresso tecnico in agricoltura debba sempre essere basata su dati attendibili ottenuti con esperimenti validi; delle opinioni, per quanto autorevoli, abbiamo da sempre imparato a dubitare… Questo libro rappresenta la versione italiana del testo “Field Research Methods in Agriculture” edito dalla Springer. Si tratta di un progetto che è partito molti anni fa in lingua italiana, insieme all’amico Dario Sacco; successivamente è stato portato in lingua inglese e perfezionato, fino a fargli assumere una struttura molto diversa da quella iniziale, il che ci ha permesso di pubblicarlo e renderlo disponibile in ambito Internazionale. Oggi lo abbiamo ritradotto in italiano e lo mettiamo a disposizione della comunità scientifica del nostro paese, in forma gratuita, seconda la licenza Creative Commons Attribution-NonCommercial-NoDerivs 3.0. È stato scritto in R, con un linguaggio favoloso, chiamato RMarkdown e utilizzando la libreria ‘bookdown’. Viene ricompilato di frequente, perché sia sempre il più aggiornato possibile, cosa che è indispensabile in quanto R è un linguaggio che si evolve molto rapidamente. Obiettivi In questo libro non cerchiamo di essere esaustivi perché la materia è molto ampia. Abbiamo cercato di adattare la lunghezza ad un corso di 6 CFU anche se, probabilmente, qualche capitolo sembrerà un po’ eccessivo. Tuttavia, abbiamo preferito aggiungerlo, in quanto ci sembrava che alcune parti, pur non essendo indispensabili per la preparazione dell’esame, potrebbero risultare utili per le applicazioni professionali. È un libro introduttivo, il primo passo in questa affascinante disciplina e dovrebbe mettervi nelle condizioni di affrontare studi più avanzati, se mai lo vorrete. Organizzazione I primi due capitoli di questo libro riguardano il disegno sperimentale; spiegano come distinguere un esperimento buono da uno cattivo. Forse vi sembrerà strano, ma non avremo mai la garanzia che i dati che abbiamo raccolto siano infallibili e quindi il nostro giudizio sulla loro attendibilità sarà solo ed esclusivamente basato sulla bontà dei metodi impiegati: se i metodi sono buoni i dati sono buoni, altrimenti no. Nel terzo capitolo vedremo come descrivere i risultati ottenuti, utilizzando semplici statistiche come la media, la mediana il valore di chi quadro e il coefficiente di correlazione di Pearson. Nel quarto capitolo vedremo come il dataset che abbiamo ottenuto possa essere immaginato come il prodotto finale di una serie di processi deterministici e stocastici, che possiamo descrivere utilizzando un modello statistico. Nei capitoli cinque e sei vedremo come il dataset che abbiamo raccolto, proprio perché prodotto in conseguenza di processi, almeno in parte, stocastici, debba essere considerato come un campione estratto da un universo di possibili risultati. Visto che vogliamo sempre ottenere informazioni generali, non saremo mai interessati solo ai risultati ottenuti, ma cercheremo di ottenere informazioni su tutto l’universo da cui i nostri data sono stati campionati. Generalizzare i risultati di un campione comporta sempre un certo grado di incertezza, che dovremo imparare ad esplicitare e presentare come una componente integrante del nostro report. Nei capitoli da sette a dodici ci occuperemo dell’ANOVA, una delle tecniche più importanti per l’analisi dei dati. Gli ultimi due capitoli si occuperanno invece dei modelli di regressione. In questi capitoli (da 7 a 14) partiremo sempre da un esempio pratico, in modo che possiate cogliere la finalità del lavoro prima di passare ad un’analisi più dettagliata. Nell’ultimo capitolo forniremo una serie di esercizi, con i quali potrete acquisire un po’ più di familiarità con gli argomenti trattati; gli esercizi sono organizzati in gruppi in modo che sappiate con esattezza a quale capitolo del libro ogni gruppo si riferisce. Software statistico In questo libro lavoreremo con il software R, all’interno dell’interfaccia grafica RStudio. Abbiamo scelto questo software per un certo numero di ragioni: in primo luogo, ci piace molto e pensiamo che sia un piacere utilizzarlo. Vi sembrerà strano, ma vi assicuriamo che alcuni studenti, dopo aver superato le iniziali difficoltà rimangono affascinati dal linguaggio. Alcuni altri, purtroppo, imparano ad odiarlo… speriamo nessuno di voi sia tra quelli! In secondo luogo, R è gratuito (freeware), cosa che è fondamentale per uno studente. Terzo, dobbiamo dire che le capacità informatiche dello studente medio si sono moltiplicate negli ultimi anni e, a livello di laurea specialistica, abbiamo notato che nessuno è ormai ad un livello così basso da non riuscire a scrivere quei semplici pezzi di codice che utilizzeremo per le nostre elaborazioni. Infine, vogliamo anche dire che la richiesta di lavorare con R è arrivata anche dai vostri colleghi più anziani, che si sono accorto che la capacità, almeno elementare, di lavorare con questo software è spesso richiesta dalle aziende che assumono laureati in agraria. R ha una struttura modulare e le sue potenzialità possono essere notevolmente estese installando librerie aggiuntive. Per semplicità, in questo libro abbiamo deciso di utilizzare l’installazione di base, evitando il più possibile l’installazione di altre librerie aggiuntive. In alcuni casi ciò non è stato possibile e quindi sarà necessario installare i componenti che vi indicheremo di volta in volta. In questo libro daremo per scontata una conoscenza, seppur limitata, di R e dell’ambiente RStudio, anche se abbiamo aggiunto un’appendice, nella quale troverete tutte le indicazioni necessarie per i principianti. Quindi, Non preoccupatevi, non daremo nulla per scontato e partiremo dall’inizio, procedendo lentamente, passo dopo passo. Gli autori Andrea è Professore Associato al Dipartimento di Scienze Agrarie, Alimentari e Ambientali dell’Università degli Studi di Perugia ed insegna Metodologia Sperimentale in Agricoltura dal 2000. Dario era Professore Associato al Dipartimento di Scienze Agrarie, Forestali e Alimentari dell’Università degli Studi di Torino e ha insegnato Metodologia Sperimentale fino al 2020, quando, troppo presto, è venuto improvvisamente a mancare. Purtroppo non ha mai visto questo libro completo… Ciao Dario! Ringraziamenti e scuse Iniziamo con le scuse. C’è una cosa che, probabilmente non piacerà a qualcuno: in questo testo abbiamo utilizzato il punto come separatore decimale. Sappiamo che questo non è del tutto corretto nella tradizione italiano, ma ci siamo resi conto che se avessimo utilizzato la virgola nel testo avremmo generato una gran confusione, in quanto non saremmo comunque riusciti ad evitare l’uso del punto decimale nel codice R e nei suoi risultati. Per quanto riguarda i ringraziamenti, siamo profondamente grati a tutto il Core Team di R per aver creato e per mantenere questo ambiente di programmazione estremamente potente e gratuito. Siamo inoltre grati a Yihui Xie e ai suoi collaboratori per la disponibilità di Rmarkdown e Bookdown, due pacchetti fondamentali per la redazione di questo testo, nelle due versioni online e a stampa. Acronimi DA TRADURRE!!!! ANOVA: Analisi della varianza (ANalysis Of VAriance) CRD: Completely Randomised Design CI: Intervallo di confidenza (Confidence Interval) DF DegreesofDreedom EDA Exploratory DataAnalyses LM LinearModel LMM LinearMixed Model RCBD RandomisedCompleteBlockDesign SD Standard Deviation SE Standard errors SEM Standard Error of aMean SED Standard Error of aDiﬀerence In this book, we will also use the term ’dataframe’ to refer to the R ’data.frame’ object,i.e.atabular data structure with rowsand columns. "],["scienza-e-pseudo-scienza.html", "Capitolo 1 Scienza e pseudo-scienza 1.1 Scienza = dati 1.2 Dati ‘buoni’ e ‘cattivi’ 1.3 Dati ‘buoni’ e metodi ‘buoni’ 1.4 Il principio di falsificazione 1.5 Falsificare un risultato 1.6 Elementi fondamentali del disegno sperimentale 1.7 Chi valuta se un esperimento è attendibile? 1.8 Conclusioni 1.9 Esercizi e domande 1.10 Altre letture", " Capitolo 1 Scienza e pseudo-scienza In una società caratterizzata dal sovraccarico cognitivo, è chiedersi (e chiedere) che cosa sia la scienza, cioè cosa distingua le informazioni scientifiche da tutto quello che invece non è altro che pura opinione, magari autorevole, ma senza il sigillo dell’oggettività. Per quanto affascinante possa sembrare l’idea del ricercatore che con un’improvviso colpo di genio elabora una stupefacente teoria, dovrebbe essere chiaro che l’intuizione, per quanto geniale ed innovativa, è solo un possibile punto di partenza, che non necessariamente prelude al progresso scientifico. In generale, almeno in ambito biologico, nessuna teoria acquisisce automaticamente valenza scientifica, ma rimane solo nell’ambito delle opinioni, indipendentemente dal fatto che nasca da un colpo di genio, oppure da un paziente e meticoloso lavoro di analisi intellettuale, che magari si concretizza in un modello matematico altamente elegante e complesso. Che cosa è che permette ad una prova scientifica di uscire dall’ambito delle opinioni legate a divergenze di cultura, percezione e/o credenze individuali, per divenire, al contrario, oggettiva e universalmente valida? Che cosa è che distingue la verità scientifica da altre verità di natura metafisica, religiosa o pseudoscientifica? A questo proposito, è utile leggere questi aforismi interessanti e significativi: Analogy cannot serve as proof (Pasteur) The interest I have in believing a thing is not a proof of the existence of that thing (Voltaire) A witty saying proves nothing (Voltaire) 1.1 Scienza = dati La base di tutta la scienza risiede nel cosiddetto ‘metodo scientifico’, che si fa comunemente risalire a Galileo Galilei (1564-1642) e che è riassunto nella Figura 1.1. Figura 1.1: Il metodo scientifico Galileiano Senza andare troppo in profondità, è importante notare due aspetti: il ruolo fondamentale dell’esperimento scientifico, che produce dati a supporto di ipotesi pre-esistenti; lo sviluppo di teorie basate sui dati, che rimangono valide fino a che non si raccolgono altri dati che le confutano, facendo nascere nuove ipotesi che possono portare allo sviluppo di nuove teorie, più affidabili o più semplici. Insomma, l’ingrediente fondamentale di una prova scientifica è quello di essere supportata dai dati sperimentali: di fatto, non esiste scienza senza dati! Resta famoso l’aforisma “In God we trust, all the others bring data”, attribuito all’ingegnere e statistico americano W. Edwards Deming (1900-1993), anche se pare che egli, in realtà, non l’abbia mai pronunciato. 1.2 Dati ‘buoni’ e ‘cattivi’ Detto che la scienza si basa sui dati, bisogna anche dire che non tutti i dati sono ugualmente ‘buoni’. Nelle scienze biologiche, così come nelle altre scienze, è importante che i dati siano in grado di cogliere gli effetti che vogliamo studiare, senza introdurre distorsioni. In agricoltura e nelle altre scienze quantitative abbiamo a che fare con fenomeni ‘misurabili’ e, di conseguenza, i nostri dati consistono di un set di misure di diverso tipo (ci torneremo nel secondo capitolo). L’aspetto più importante è che, per tutta una serie di motivi che dettaglieremo tra poco, le nostre misure non necessariamente riflettono il valore vero della caratteristica misurata nel nostro soggetto. Ciò è noto con il termine di errore sperimentale, che non significa che abbiamo necessariamente fatto qualcosa di sbagliato. Anzi, l’errore sperimentale è considerato una componente inevitabile di ogni esperimento, in grado di proiettare un alea d’incertezza su ogni risultato scientifico. Ci sono tre fondamentali fonti di errore sperimentale: Errore di misura Variabilità dei soggetti sperimentali Campionamento Gli errori di misura sono legati allo strumento e dipendono dall’errata taratura, dall’impiego di un protocollo sbagliato, da inesattezze strumentali, da errori nella trascrizione dei risultati oppure dall’irregolarità dell’oggetto da misurare. Ad esempio, pensate alla misurazione dell’altezza di una pianta di mais: è facile riscontrare difficoltà legate, ad esempio, all’individuazione del punto esatto in cui inizia il culmo e del punto esatto dove termina l’infiorescenza apicale. A parte gli errori di misura, ci sono anche altre sorgenti di errore meno evidenti e legate al fatto che, nel lavoro sperimentale, siamo di solito interessati non ad un singolo soggetto, ma ad un gruppo più o meno numeroso. Ad esempio, se dobbiamo misurare l’effetto di un erbicida, non possiamo farlo trattando una sola pianta, ma dobbiamo ripetere le misure su un gruppo di piante, il che ci porta ad avere un gruppo di misure, una diversa dall’altra. Quindi, qual è l’effetto dell’erbicida? Il fatto di avere tanti effetti diversi quante sono le piante studiate crea comunque un certo grado di variabilità che non dipende da alcun errore tecnico, ma è una caratteristica intrinseca del fenomeno biologico in studio. Di per se’, la variabilità naturale dei soggetti sperimentali non sarebbe un grosso problema, in quanto potremmo calcolarci l’effetto medio e ritenerci soddisfatti in relazione alle finalità dell’esperimento. Tuttavia sorge un nuovo problema legato al fatto che spesso i soggetti sono così numerosi che non possiamo misurarli tutti e siamo costretti a misurare un campione composto da un ridotto numero di individui. Abbiamo un nuovo elemento di incertezza: come facciamo ad essere sicuri che la media, o qualunque altra statistica, misurata nel nostro campione rifletta la media dell’intera popolazione? Anche se abbiamo fatto del tutto per scegliere un campione rappresentativo, è evidente che il campione perfetto non esiste: cosa potrebbe succedere se prendessimo un altro campione? 1.3 Dati ‘buoni’ e metodi ‘buoni’ Quindi la ricerca scientifica non è esente da ‘errori’ in senso lato (componenti di incertezza). Tuttavia, gli errori non sono tutti uguali e si dividono in sistematici ed accidentali (casuali). L’errore sistematico è provocato da difetti intrinseci dello strumento o incapacità peculiari dell’operatore e tende a ripetersi costantemente e con lo stesso segno in misure successive. Un esempio tipico è quello di una bilancia non tarata, che tende ad aggiungere 20 grammi ad ogni misura che effettuiamo. D’altra parte, l’errore accidentale, essendo di natura casuale, tende a ripresentarsi con valori e segni diversi. Di conseguenza, è ragionevole pensare che le repliche, nel lungo periodo, producano sovrastime e sottostime con uguale probabilità, in modo che la media tende a coincidere con il valore vero. È facile capire che le conseguenze degli errori sistematici e accidentali sono ben diverse. A questi proposito, dobbiamo considerare due aspetti molto importanti, cioè: precisione accuratezza Con il termine precisione intendiamo due cose: la prima è relativa al numero di decimali che ci fornisce il nostro strumento di misura. E’evidente, ad esempio, come un calibro sia più preciso di un metro da sarto. Oltre a questo significato, abbastanza intuitivo, ce n’è un altro, più specificatamente legato agli esperimenti scientifici: la precisione di un dato ottenuto attraverso un processo di misurazione non è altro che la variabilità riscontrata quando la misurazione viene ripetuta più volte. L’errore casuale produce sempre un calo di precisione. Il termine accuratezza ha invece un significato completamente diverso, riconducibile alla differenza tra la misura effettuata e il valore vero della caratteristica da misurare. Può sembrare una banalità, ma proviamo a pensare ad uno strumento non tarato, come, ad esempio, un gascromatografo, che restituisce sempre una concentrazione maggiorata del 20%. Se noi ripetessimo le analisi 100 volte, in assenza di altri errori, otterremmo sempre lo stesso risultato, molto preciso, ma totalmente inaffidabile, nel senso che non riflette la concentrazione reale della soluzione in studio. L’errore sistematico, oltre a produrre un calo di precisione, produce anche inaccuratezza. Comprendiamo bene che l’accuratezza è più importante della precisione: infatti una misura accurata, ma imprecisa, riflette bene la realtà, anche se in modo vago. Al contrario, una misura precisa, ma inaccurata, ci porta completamente fuori strada, perché non riflette la realtà. Con linguaggio tecnico, un dato non accurato si dice ‘distorto’ (biased) e, siccome la distosione dipende dagli errori sistematici, questi ultimi vanno assolutamente evitati, ad esempio con la perfetta taratura degli strumenti e l’adozione di metodi di misura rigidamente standardizzati e accettati dalla comunità scientifica mondiale. L’inaccuratezza preoccupa molto i laboratori di analisi, che spesso utilizzano standard di confronto, la cui misura è perfettamente nota e viene periodicamente confrontata con quella rilevabile dallo strumento stesso, per verificarne la taratura. Altro metodo utilizzato nelle procedure di accreditamento dei laboratori è il ring test, dove campioni reali della matrice da misurare sono inviati a più laboratori a livello nazionale, in modo da poter confrontare le misure ottenute e valutarne la variabilità. Con un ring test, un laboratorio può valutare la sua stessa affidabilità in confronto con laboratori simili, basandosi sull’eventuale differenza tra il risultato ottenuto e quelli ottenuti in tutti gli altri laboratori valutati. Sfortunatamente la possibilità di raccogliere dati inaccurati è tutt’altro che remota. Gli scienziati americani Pons e Fleischmann, il 23 Marzo del 1989, diffusero pubblicamente la notizia di essere riusciti a riprodurre la fusione nucleare fredda, causando elevatissimo interesse nella comunità scientifica (Fig. 1.2). Purtroppo le loro misure erano viziate da una serie di problemi e il loro risultato fu smentito da esperimenti successivi. Figura 1.2: Conseguenze di un esperimento sbagliato A parte questo clamoroso esempio, torniamo alla nostra domanda iniziale: come facciamo ad essere sicuri che i dati siano validi ed affidabili? La risposta è semplice: non possiamo mai essere sicuri, ma dobbiamo fare del nostro meglio per applicare metodi rigorosi, così da minimizzare la possibilità di ottenere errori sistematici. In altre parole, dati ‘buoni’ sono conseguenza di metodi ‘buoni’ e, pertanto una prova scientifica è tale non perché siamo certi che corrisponda alla realtà, ma perché siamo ragionevolmente certi che sia stata ottenuta con metodi validi!. 1.4 Il principio di falsificazione L’approccio che abbiamo indicato poco sopra ha un’importante conseguenza: anche se abbiamo utilizzato un metodo perfettamente valido non potremo mai avere la certezza di aver ottenuto un risultato corrispondente alla realtà e, quindi, ci dovremo sempre aspettare che ulteriori dati smentiscano la nostra conclusione. Questa è la base del principio di falsificazione, definito da Karl Popper (1902-1994): non potremo mai dimostrare che una nostra ipotesi è vera, ma potremo solo dimostrare che è falsa. In pratica, tornando al metodo scientifico, partiamo da un’ipotesi e organizziamo un esperimento perfettamente valido che produce, di conseguenza, dati validi. Se i nostri dati sconfermano l’ipotesi, abbiamo dimostrato che questa è falsa e dovremo quindi produrre una nuova ipotesi da sottoporre a verifica. Se invece i dati confermano la nostra ipotesi (o meglio, non la smentiscono) allora, non potremo concludere che l’ipotesi è vera, in quanto rimarrà sempre il dubbio che non abbiamo raccolto abbastanza dati. Tuttavia, in mancanza di altre informazioni, prenderemo per buona la nostra ipotesi, fino a che non sarà smentita. Una sorta di ‘assoluzione’ per insufficienza di prove, quindi… Il principio di falsificazione è piuttosto importante nel mondo scientifico ed ha alcune importanti implicazioni: Scienza non necessariamente significa ‘certezza’ o ‘verità’. Tutto quello che possiamo fare con certezza è rigettare ipotesi (provare che sono false), ma non dimostrarne la validità. Il nostro compito è quello di cercare di eliminare tutte le fonti di errore sistematico, per rendere il risultato il più accurato possibile. Eliminato l’errore sistematico, l’evantuale errore casuale residuo deve essere sempre quantificato e visualizzato insieme ai risultati. In considerazione dell’errore residuo, dobbiamo decidere se i dati raccolti consentono di rigettare la nostra ipotesi di partenza. Altrimenti, l’esperimento è inconclusivo e, pur non avendone la certezza, terremo per vera la nostra ipotesi di partenza fino a che non sarà smentita da future osservazioni. Oltre al principio di falsificazione, la scienza fa largo uso del principio del ‘rasoio di Occam’. Guglielmo di Occam (XIV secolo) era un frate francescano che, in un periodo in cui le dimostrazioni scientifiche iniziavano a divenire troppo complesse, voleva ribadire l’importanza della semplicità. Il suo principio è solitamente formulato come ‘Entia non sunt multiplicanda praeter necessitatem’ ed è noto come il ‘rasoio’ in quanto porta a respingere con nettezza (tagliare con il rasoio) le spiegazioni troppo complesse. Nella comunità scientifica, applichiamo questo principio preferendo sempre, tra due ipotesi alternative ugualmente buone, quella più semplice. 1.5 Falsificare un risultato Se un esperimento è inconclusivo e porta ad eccettare un’ipotesi, è sempre possibile eseguire un ulteriore esperimento per rigettarla. Se anche questo secondo esperimento non riesce a rigettare l’ipotesi di partenza, allora la bontà di quest’ultima è certamente rafforzata. Parliamo quindi di esperimenti confermativi che costituiscono un elemento molto importante del metodo scientifico. A questo proposito, distinguiamo: replicabilità riproducibilità Un esperimento è replicabile se, quando ripetuto in condizioni assolutamente analoghe (stessi soggetti, ambiente, strumenti…), restituisce risultati equivalenti. Per questo motivo, quando si pubblicano i risultati di un esperimento, è sempre necessario descrivere accuratamente i metodi impiegati, in modo da consentire a chiunque la verifica dei risultati. In alcuni casi, tuttavia, questa verifica indipendente è pressoché impossibile; ad esempio, nelle scienze agronomiche, le caratteristiche genetiche e pedo-climatiche giocano un ruolo molto importante e non è facile replicare un esperimento di pieno campo esattamente nelle stesse condizioni. Per questo motivo, alcuni biostatistici distinguono la replicabilità dalla riproducibilità, definita come il grado di concordanza tra esperimenti ripetuti in condizioni diverse (diversi soggetti, diverso ambiente…). Se la replicabilità di un esperimento non può essere dimostrata, bisogna avere almeno un’idea della sua riproducibilità, ripetendo l’esperimento in condizioni diverse e discutendo attentamente le eventuali differenze riscontrate nei risultati. 1.6 Elementi fondamentali del disegno sperimentale La metodica di organizzazione di un esperimento valido prende il nome di disegno sperimentale e le sue basi si fanno in genere risalire a Sir Ronald A. Fisher, vissuto in Inghilterra dal 7 Febbraio 1890 al 29 luglio 1962. Laureatosi nel 1912, lavora come statistico per il comune di Londra, fino a quando diviene socio della prestigiosa Eugenics Education Society di Cambridge, fondata nel 1909 da Francis Galton, cugino di Charles Darwin. Dopo la fine della guerra, Karl Pearson gli propone un lavoro presso il rinomato Galton Laboratory, ma egli non accetta a causa della profonda rivalità esistente tra lui e Pearson stesso. Nel 1919 viene assunto presso la Rothamsted Experimental Station, dove si occupa dell’elaborazione dei dati sperimentali e, nel corso dei successivi 7 anni, definisce le basi del disegno sperimentale ed elabora la sua teoria della “analysis of variance”. Il suo libro più importante è “The design of experiment”, del 1935. E’ sua la definizione delle tre componenti fondamentali del disegno sperimentale: controllo degli errori; replicazione; randomizzazione. 1.6.1 Controllo degli errori Controllare gli errori, o, analogamente, eseguire un esperimento controllato significa fondamentalmente due cose: adottare provvedimenti idonei ad evitare le fonti di errore, mantenendole al livello più basso possibile (alta precisione); agire in modo da isolare l’effetto in studio (accuratezza), evitando che si confonda con effetti casuali e di altra natura. Ad esempio, se dobbiamo confrontare due fitofarmaci, dobbiamo fare in modo che i soggetti inclusi nell’esperimento differiscano tra di loro solo per il fitofarmaco impiegato e non per altro. Mettere in pratica questi principi fondamentali richiede una vita di esperienza! Tuttavia, vogliamo solo sottolineare alcuni aspetti, come il rigore metodologico. È evidente che, ad esempio, se vogliamo sapere la cinetica di degradazione di un erbicida a 20 °C dovremo realizzare una prova esattamente a quella temperatura, con un erbicida uniformemente distribuito nel terreno, dentro una camera climatica capace di un controllo perfetto della temperatura. Gli strumenti dovranno essere ben tarati e sarà necessario attenersi scrupolosamente a metodi validati e largamente condivisi. Tuttavia, a proposito di rigore, non bisogna scordare il famoso aforisma, attribuito a C.F. Gauss e riferito alla della precisione nei calcoli, che può essere anche riferito al rigore nella ricerca : “Manca di mentalità matematica tanto chi non sa riconoscere rapidamente ciò che è evidente, quanto chi si attarda nei calcoli con una precisione superiore alla necessità”. In altre parole, il rigore metodologico è fondamentale, ma deve essere sempre compatibile con gli scopi della ricerca ed i livelli di precisione richiesti, per evitare un’eccessivo consumo di tempo e risorse finanziare. Oltre al rigore metodologico, è bene anche ricordare come un esperimento ben fatto passi sempre attraverso la giusta selezione dei soggetti sperimentali, che debbono essere omogenei, ma rappresentativi della popolazione alla quale intendiamo riferire i risultati ottenuti. Ad esempio, se si vuole ottenere un risultato riferito alla collina umbra, bisognerà scegliere parcelle di terreno omogenee, ma che rappresentano bene la variabilità pedo-climatica di quell’ambiente, né di più, né di meno. Per concludere, vogliamo anche ricordare le cosiddette ‘intrusioni’ cioè quegli eventi che accadono in modo inaspettato e condizionano negativamente la riuscita di un esperimento in corso. E’ evidente che, ad esempio, un’alluvione, l’attacco di insetti o patogeni, la carenza idrica hanno una pesante ricaduta sulla precisione di un esperimento e sulla sua riuscita. Per quanto possibile, controllare gli errori significa anche essere capaci di prevedere le eventuali intrusioni. In un suo famoso lavoro scientifico del 1984, lo scienziato americano Stuart Hurlbert usa il termine ‘intrusione demoniaca’ per indicare quelle intrusioni che, pur casuali, avrebbero potuto essere previste con un disegno più accurato, sottolineando in questo caso la responsabilità dello sperimentatore. Un esempio è questo: uno sperimentatore vuole studiare l’entità della predazione dovuta alle volpi e quindi usa campi senza staccionate (dove le volpi possono entrare) e campi protetti da staccionate (e quindi liberi da volpi). Se le staccionate, essendo utilizzate dai falchi come punto d’appoggio, finiscono per incrementare l’attività predatoria di questi ultimi, si viene a creare un’intrusione demoniaca, che rende l’esperimento distorto. Il demonio, in questo caso, non è il falco, che danneggia l’esperimento, ma il ricercatore stesso, che non ha saputo prevedere una possibile intrusione. 1.6.2 Replicazione In ogni esperimento, i trattamenti dovrebbe essere replicati su due o più unità sperimentali. Ciò permette di: dimostrare che i risultati sono replicabili (ma non è detto che siano riproducibili!); rassicurare che eventuali circostanze aberranti casuali non abbiano provocato risultati distorti; misurare la precisione dell’esperimento, come variabilità di risposta tra repliche trattate nello stesso modo; incrementare la precisione dell’esperimento (più sono le repliche più l’esperimento è preciso, perché si migliora la stima della caratteristica misurata, diminuendo l’incertezza). Per poter essere utili, le repliche debbono essere indipendenti, cioè debbono aver subito tutte le manipolazioni necessarie per l’allocazione del trattamento in modo totalmente indipendente l’una dall’altra. Le manipolazioni comprendono tutte le pratiche necessarie, come ad esempio la preparazione delle soluzioni, la diluizione dei prodotti, ecc.. La manipolazione indipendente è fondamentale, perché in ogni parte del processo di trattamento possono nascondersi errori più o meno grandi, che possono essere riconosciuti solo se colpiscono in modo casuale le unità sperimentali. Se la manipolazione è, anche solo in parte, comune, questi errori colpiscono tutte le repliche allo stesso modo, diventano sistematici e quindi non più riconoscibili. Di conseguenza, si inficia l’accuratezza dell’esperimento. Quando le repliche non sono indipendenti, si parla di pseudorepliche, contrapposte alle repliche vere. Il numero di repliche dipende dal tipo di esperimento: più sono e meglio è, anche se è necessario trovare un equilibrio accettabile tra precisione e costo dell’esperimento. Nella sperimentazione di campo, due repliche sono poche, tre appena sufficienti, quattro costituiscono la situazione più comune, mentre un numero maggiore di repliche è abbastanza raro, non solo per la difficoltà di seguire l’esperimento, ma anche perché aumentano la dimensione della prova e, di conseguenza, la variabilità del terreno. 1.6.3 Randomizzazione L’indipendenza di manipolazione non garantisce da sola un esperimento corretto. Infatti potrebbe accadere che le caratteristiche innate dei soggetti, o una qualche ‘intrusione’ influenzino in modo sistematico tutte le unità sperimentali trattate nello stesso modo, così da confondersi con l’effetto del trattamento. Un esempio banale è che potremmo somministrare un farmaco a quattro soggetti in modo totalmente indipendente, ma se i quattro soggetti fossero sistematicamente più alti di quelli non trattati finiremmo per confondere una caratteristica innata con l’effetto del farmaco. Oppure, se le piante di una certa varietà di sorgo si trovassero tutte più vicine alla scolina rispetto a quelle di un’altra varietà, potrebbero essere più danneggiate dal ristagno idrico, il cui effetto si confonderebbe con quello del trattamento stesso. Questi problemi sono particolarmente insidiosi e si nascondono anche dietro ai particolari apparentemente più insignificanti. La randomizzazione è l’unico sistema per evitare, o almeno rendere molto improbabile, la confusione dell’effetto del trattamento con fattori casuali e/o comunque diversi dal trattamento stesso. La randomizzazione si declina in vari modi: allocazione casuale del trattamento alle unità sperimentali. Gli esperimenti che prevedono l’allocazione del trattamento sono detti ‘manipolativi’ o ‘disegnati’. A volte l’allocazione del trattamento non è possibile o non è etica. Se volessimo studiare l’effetto delle cinture di sicurezza nell’evitare infortuni gravi, non potremmo certamente provocare incidenti deliberati. In questo caso la randomizzazione è legata alla scelta casuale di soggetti che sono ‘naturalmente’ trattati. Esperimenti di questi tipo, si dicono osservazionali. Un esempio è la valutazione dell’effetto dell’inquinamento con metalli pesanti nella salute degli animali: ovviamente non è possibile, se non su piccola scala, realizzare il livello di inquinamento desiderato e, pertanto, dovremo scegliere soggetti che sono naturalmente sottoposti a questo genere di inquinamento, magari perché vivono vicino a zone industriali. Se i soggetti sono immobili, la randomizzazione ha anche una connotazione legata alla disposizione spaziale e/o temporale casuale. L’assegnazione casuale del trattamento, o la selezione casuale dei soggetti trattati, fanno si che tutti i soggetti abbiano la stessa probabilità di ricevere qualunque trattamento oppure qualunque intrusione casuale. In questo modo, la probabilità che tutte le repliche di un trattamento abbiano qualche caratteristica innata o qualche intrusione comune che li penalizzi/avvantaggi viene minimizzata. Di conseguenza, confondere l’effetto del trattamento con variabilità casuale (‘confounding’), anche se teoricamente possibile, diviene altamente improbabile. 1.6.4 Esperimenti invalidi A questo punto, dovrebbe essere chiaro che un esperimento valido deve essere controllato, replicato e randomizzato: la mancanza anche di uno solo di questi elementi pone dubbi ragionevoli sull’affidabilità dei risultati. In particolare, gli esperimenti ‘invalidi’ sono caratterizzati da: Cattivo controllo degli errori Fondati sospetti di confounding Mancanza di repliche vere Confusione tra repliche vere e pseudo-repliche Mancanza di randomizzazione Presenza di vincoli alla randomizzazione, trascurati in fase di analisi. Le conseguenze di queste problematiche sono abbastanza diverse. 1.6.4.1 Cattivo controllo degli errori Bisogna verificare se il problema è relativo a questioni come la mancanza di scrupolosità, l’uso di soggetti poco omogenei o di un ambiente poco omogeneo, o altri aspetti che inficiano solo la precisione, ma non l’accuratezza dell’esperimento. In questo caso, l’esperimento è ancora valido (accurato), ma la bassa precisione probabilmente impedirà di trarre conclusioni forti. Quindi, un esperimento impreciso si ‘elimina’ da solo, perché sarà inconclusivo. Di questi esperimenti bisogna comunque diffidare, soprattutto quando siano pianificati per mostrare l’assenza di differenze tra due trattamenti alternativi. Mostrare l’assenza di differenze è facile: basta fare male un esperimento, in modo che vi sia un alto livello di incertezza e quindi l’evidenza scientifica sia molto debole. Diversa è la situazione in cui un cattivo controllo degli errori, ad esempio l’adozione di metodi sbagliati, porta a mancanza di accuratezza, cioè a risultati che non riflettono la realtà (campionamento sbagliato, ad esempio; oppure strumenti non tarati; impiego di metodi non validati e/o non accettabili). In questo caso venendo a mancare l’accuratezza, l’esperimento deve essere rigettato, in quanto non fornisce informazioni realistiche. 1.6.4.2 ‘Confounding’ e correlazione spuria Abbiamo appena menzionato il problema fondamentale della ricerca, cioè il confounding, vale a dire la confusione tra l’effetto del trattamento e un qualche altro effetto casuale, legato alle caratteristiche innate del soggetto o a qualche intrusione più o meno ‘demoniaca’. Abbiamo detto che non possiamo mai avere la certezza dell’assenza di confounding, ma abbiamo anche detto che l’adozione di una pratica sperimentale corretta ne minimizza la probabilità. Chiaramente, rimangono dei rischi che sono tipici di situazioni nelle quali il controllo adottato non è perfetto, come capita, ad esempio, negli esperimenti osservazionali. In questo ambito è piuttosto temuta la cosiddetta ‘correlazione spuria’, una forma di confounding casuale per cui due variabili variano congiuntamente (sono direttamente o inversamente proporzionali), ma in modo del tutto casuale. Esistono, ad esempio, dati che mostrano una chiara correlazione tra le vendite di panna acida e le morti per incidenti in motocicletta (Fig. 1.3). Chiaramente, non esistono spiegazioni scientifiche per questo effetto, che è, ovviamente, del tutto casuale. Il problema è che questa correlazione spuria non è sempre così semplice da rintracciare. Figura 1.3: Esempio di correlazione spuria A volte il confounding non è casuale, ma è legato ad una variabile esterna che si agisce all’insaputa dello sperimentatore. Ad esempio, è stato osservato che il tasso di crimini è più alto nelle città che hanno più chiese. La spiegazione di questo paradosso sta nel fatto che esiste un ‘confounder’, cioè l’ampiezza della popolazione. Nelle grandi città si riscontrano sia una maggiore incidenza criminale, sia un grande numero di chiese. In sostanza, la popolazione determina sia l’elevato numero di chiese che l’elevato numero di crimini, ma queste ultime due variabili non sono legate tra loro da una relazione causa-effetto (A implica B e A implica C, ma B non implica C). Il confounding non casuale è spesso difficile da evidenziare, soprattutto se le correlazioni misurate sono spiegabili. Inoltre, non è eliminabile con un’accurata randomizzazione, ma solo con l’esecuzione di un esperimento totalmente controllato, nel quale ci si preoccupa di rilevare tutte le variabili necessarie per spiegare gli effetti riscontrati. Di questo è importante tener conto soprattutto negli esperimenti osservazionali, dove il controllo è sempre più difficile e meno completo. 1.6.4.3 Pseudo-repliche e randomizzazione poco attenta Per evidenziare questi problemi e comprendere meglio la differenza tra un esperimento corretto e uno non corretto, è utilissima la classificazione fatta da Hurlbert (1984), che riportiamo in Figura 1.4. Figura 1.4: Indicazioni per una corretta randomizzazione (Hurlbert, 1984) Vengono mostrati 8 soggetti, sottoposti a due trattamenti (bianco e nero), con 8 disegni sperimentali diversi. Il disegno A1 è corretto, in quanto si tratta di un esperimento completamente randomizzato. Ugualmente, è valido il disegno A2, nel quale le unità sperimentali sono state divise in quattro gruppi omogenei e sono state trattate in modo randomizzato all’interno di ogni gruppo. Il disegno A3 è quantomeno ‘sospetto’: vi sono repliche vere, ma l’allocazione dei trattamenti non è randomizzata ed avviene con un processo sistematico per il quale ‘nero’ e ‘bianco’ si alternano. Cosa succederebbe se vi fosse un gradiente di fertilità decrescente da destra verso sinistra? Le unità nere sarebbero avvantaggiate rispetto alle bianche! Insomma, rimangono sospetti di confounding, a meno che non si sia assolutamente certi dell’assenza di gradienti, come capita ad esempio se all’interno dei blocchi, dobbiamo creare una sequenza spazio-temporale. Vediamo tre esempi: ho quattro piante e, per ogni pianta, voglio confrontare un ramo basso con uno alto: è evidente che i due trattamenti sono sempre ordinati in modo sistematico (basso prima di alto). Dobbiamo valutare l’effetto di fitofarmaci somministrati in due epoche diverse (accestimento e inizio-levata); anche qui non possiamo randomizzare, giacché un’epoca precede sempre l’altra. Dobbiamo confrontare la presenza di residui di un fitofarmaco a due profondità e non possiamo randomizzare, perché una profondità precede sempre l’altra nello spazio. In queste situazioni l’esperimento rimane valido, anche se la randomizzazione segue un processo sistematico e non casuale. Il disegno B1 è usualmente invalido: non vi è randomizzazione e ciò massimizza i problemi del disegno A3: la separazione delle unità sperimentali ‘bianche’ e ‘nere’ non consente una valutazione adeguata dell’effetto del trattamento, che è confuso con ogni potenziale differenza tra la parte destra e la sinistra dell’ambiente in cui la sperimentazione viene eseguita. Ovviamente, la separazione può essere non solo spaziale, ma anche temporale. Anche in questo caso diamo alcuni esempi in cui una situazione come quella descritta in B1 è valida: Vogliamo confrontare la produzione in pianura e in collina. Ovviamente dobbiamo scegliere campioni in due situazioni fisicamente separate Vogliamo confrontare la pescosità di due laghetti Vogliamo confrontare la produttività di due campi contigui. Queste situazioni sono valide, anche se con una restrizione: non siamo in grado di stabilire a chi debba essere attribuito l’effetto. Ad esempio, per la prima situazione, pianura e collina possono dare produzioni diverse per il suolo diverso, il clima diverso, la precessione colturale diversa o un qualunque altro elemento che differenzi le due località. Il disegno B2 è analogo al disegno B1, ma il problema è più grave, perché la separazione fisica è più evidente. Questo disegno è totalmente sbagliato, a meno che non siamo specificatamente interessati all’effetto località (vedi sopra). Il disegno B3 è analogo al disegno B2, ma costituisce una situazione molto frequente nella pratica scientifica. Immaginiamo infatti di voler confrontare la germinazione dei semi a due temperature diverse, utilizzando due camere climatiche e mettendo, in ognuna di esse, quattro capsule Petri identiche. In questa situazione, l’effetto temperatura è totalmente confuso con l’effetto ‘camera climatica (località)’ e risente di ogni malfunzionamento relativo ad una sola delle due camere. Inoltre, le unità sperimentali con lo stesso trattamento di temperature non sono manipolate in modo indipendente, dato che condividono la stessa camera climatica. Di conseguenza, non si può parlare di repliche vere, bensì di pseudorepliche. Altri esempi di pseudorepliche sono schematizzati con il codice B4. Ad esempio: trattare piante in vaso ed analizzare in modo indipendente i singoli individui invece che tutto il vaso; trattare una parcella di terreno e prelevare da essa più campioni, analizzandoli separatamente; trattare una capsula Petri ed analizzare separatamente i semi germinati al suo interno. Questi disegni, in assenza di repliche vere aggiuntive non sono da considerarsi validi. Ad esempio, se io ho due vasetti trattati in modo totalmente indipendente e da ciascuno di essi prelevo due piante e le analizzo separatamente, il disegno è caratterizzato da due repliche vere e due pseudorepliche per ogni replica ed è, pertanto, valido. Il disegno B5 è invece evidentemente invalido, per totale mancanza di repliche. 1.7 Chi valuta se un esperimento è attendibile? Quanto detto finora vorrebbe chiarire come il punto centrale della scienza non è la certezza delle teorie, bensì il metodo che viene utilizzato per definirle. Ognuno di noi è quindi responsabile di verificare che le informazioni in suo possesso siano ‘scientificamente’ attendibili, cioè ottenute con un metodo sperimentale adeguato. Il fatto è che non sempre siamo in grado di compiere questa verifica, perché non abbiamo strumenti ‘culturali’ adeguati, se non nel ristretto ambito delle nostre competenze professionali. Come fare allora? L’unica risposta accettabile è quella di controllare l’attendibilità delle fonti di informazione. In ambito biologico, le riviste autorevoli sono caratterizzate dal procedimento di ‘peer review’, nel quale i manoscritti scientifici, prima della pubblicazione, sono sottoposti ad un comitato editoriale ed assegnati ad un ‘editor’, il quale legge il lavoro e contemporaneamente lo invia a due o tre scienziati anonimi e particolarmente competenti in quello specifico settore scientifico (reviewers o revisori). I revisori, insieme all’editor, compiono un attento lavoro di esame e stabiliscono se l’evidenza scientifica presentata è sufficientemente ‘forte’. Le eventuali critiche vengono presentate all’autore, che è tenuto a rispondere in modo convincente, anche ripetendo gli esperimenti se necessario. Il processo richiede spesso interi mesi ed è abbastanza impegnativo per uno scenziato. E’ piuttosto significativa l’immagine presentata in scienceBlog.com, che allego qui. Figura 1.5: Il processo di peer review In sostanza il meccanismo di peer review porta a rigettare un lavoro scientifico in presenza di qualunque ragionevole dubbio metodologico. Desideriamo sottolineare che abbiamo parlato di dubbio metodologico, dato che il dubbio sul risultato non può essere allontanato completamente e i reviewer controlleranno solo che il rischio di errore sia al disotto della soglia massima arbitrariamente stabilita (di solito pari al 5%). Questo procedimento, se effettuato con competenza, dovrebbe aiutare a separare la scienza dalla pseudo-scienza e, comunque, ad eliminare la gran parte degli errori metodologici dai lavori scientifici. 1.8 Conclusioni In conclusione, possiamo ripartire dalla domanda iniziale: “Che cosa è la scienza?”, per rispondere che è scienza tutto ciò che è supportato da dati che abbiano passato il vaglio della peer review, dimostrando di essere stati ottenuti con un procedimento sperimentale privo di vizi metodologici e di essere sufficientemente affidabili in confronto alle fonti di incertezza cui sono associati. Qual è il take-home message di questo capitolo? Fidatevi solo delle riviste scientifiche attendibili, cioè quelle che adottano un serio processo di peer review prima della pubblicazione. 1.9 Esercizi e domande 1.10 Altre letture Fisher, Ronald A. (1971) [1935]. The Design of Experiments (9th ed.). Macmillan. ISBN 0-02-844690-9. Hurlbert, S., 1984. Pseudoreplication and the design of ecological experiments. Ecological Monographs, 54, 187-211 Kuehl, R. O., 2000. Design of experiments: statistical principles of research design and analysis. Duxbury Press (CHAPTER 1) "],["progettare-un-esperimento.html", "Capitolo 2 Progettare un esperimento 2.1 Gli elementi della ricerca 2.2 Ipotesi scientifica \\(\\rightarrow\\) obiettivo dell’esperimento 2.3 Identificazione dei fattori sperimentali 2.4 Le unità sperimentali 2.5 Allocazione dei trattamenti 2.6 Le variabili sperimentali 2.7 Esperimenti di campo 2.8 Altre letture 2.9 Domande ed esercizi", " Capitolo 2 Progettare un esperimento 2.1 Gli elementi della ricerca Nel capitolo precedente abbiamo visto che ogni esperimento, per essere valido, deve conformarsi a tre principi di base, cioè la replicazione, la randomizzazione e il controllo. Non è facile spiegare come si mettano in atto questi principi e, certamente, non esiste una risposta generalmente valida; l’esperienza gioca un ruolo fondamentalmente e, quando si muovono i primi passi, è sempre bene cercare l’aiuto di un collega più anziano. In questo capitolo prenderemo in esame una serie di elementi che riguardano tutti gli esperimenti scientifici, indipendentemente dalla disciplina e dalle finalità. Per la loro importanza, ognuno di questi elementi richiederà decisioni opportune in fase di pianificazione e dovrà essere accuratamente dettagliato in ogni progetto o rapporto di ricerca, per permettere la valutazione della bontà della ricerca stessa. Questi elementi sono: ipotesi ed obiettivi fattore/i sperimentale/i; soggetti sperimentali (unità sperimentali); allocazione dei trattamenti; le variabili sperimentali. 2.2 Ipotesi scientifica \\(\\rightarrow\\) obiettivo dell’esperimento Trascurando la ricerca bibliografica, che è pur fondamentale, nel metodo scientifico galileiano, il punto di partenza di un esperimento è l’ipotesi scientifica, dalla quale discende tutto il lavoro successivo. Questa ipotesi deve essere rilevante, chiaramente definita e specifica; insomma, dobbiamo aver individuato con chiarezza una connessione tra eventi che potrebbe essere spiegata da una relazione causa-effetto. Un ipotesi, solitamente si pone in forma dubitativa: “la germinazione di un lotto di semi potrebbe dipendere dall’adozione di un certo metodo di priming”; oppure: “la produttività di una coltura potrebbe migliorare con l’adozione di una maggiore fittezza d’impianto”. Dall’ipotesi, in modo consequenziale scaturiscono gli obiettivi della ricerca, cioè le domande alle quali la ricerca intende dare risposta. Questi obiettivi dovranno essere raggiungibili/realistici e temporalmente organizzati; inoltre, dovrà essere possibile capire se e quando siano stati raggiunti attraverso un qualche indicatore misurabile. Il rischio che si corre con obiettivi mal posti è quello di eseguire una ricerca dispersiva, con raccolta di dati non necessari e/o mancanza di dati fondamentali, con costi più elevati del necessario e un uso poco efficiente delle risorse. In genere, prima si definisce un obiettivo generale, poi si definiscono uno o più obiettivi specifici, proiettati su un più breve spazio temporale, anche per marcare le fasi necessarie per raggiungere l’obiettivo generale. Non è un caso se, in un lavoro scientifico, gli obiettivi della ricerca sono posti in fondo all’introduzione, appena prima dell’esposizione dei materiali e metodi. 2.3 Identificazione dei fattori sperimentali A differenza degli esperimenti osservazionali, più tipici delle scienze mediche e sociali, dove ci si limita ad osservare quanto accade in natura, gli esperimenti manipolativi sono basati appunto sulla ‘manipolazione’ dei soggetti sperimentali, che vengono sottoposti a stimoli differenti, a seconda della risposta che si vuole valutare. Dopo aver definito l’obiettivo di un esperimento, pertanto, è necessario chiarire esattamente quali saranno gli stimoli ai quali sottoporremo le unità sperimentali. Uno ‘stimolo’ sperimentale prende il nome di fattore sperimentale, che può avere più livelli, detti trattamenti (o tesi) sperimentali. Ad esempio, se l’obiettivo è quello di valutare l’effetto della temperatura sulla germinazione dei semi di quinoa, il fattore sperimentale sarà la temperatura, con tre livelli, 10, 15 e 25°C, ai quali verranno sottoposte le capsule Petri incluse in prova. 2.3.1 Esperimenti (multi-)fattoriali Talvolta gli obiettivi dell’esperimento comportano lo studio di più di un fattore sperimentale; ad esempio, oltre che alla temperatura, potremmo anche essere interessati a studiare l’effetto dell’umidità sulla germinazione dei semi. In questo caso potremmo pianificare due esperimenti separati oppure un unico esperimento, in cui prendiamo in considerazione entrambi i fattori sperimentali. Un esperimenti di questo tipo si dice fattoriale, o meglio, multi-fattoriale ed i fattori possono essere incrociati (crossed) oppure innestati. Nel primo caso includeremo in prova tutte le possibili combinazioni tra i livelli di ogni fattore. Ad esempio, se volessimo studiare il comportamento di tre varietà di girasole (A, B e C) con due tipi di concimi (pollino e urea), potremmo disegnare un esperimento con 6 trattamenti, rappresentati da tutte le possibili combinazioni di varietà e concimi, cioè A-pollina, A-urea, B-pollina, B-urea, C-pollina e C-urea. In un disegno a fattori innestati, invece, i livelli di un fattore cambiano al cambiare dei livelli dell’altro. Ad esempio, se volessimo confrontare tre varietà di frumento in due sistemi colturali (convenzionale e biologico), potremmo decidere di utilizzare varietà diverse in sistemi diversi, alla ricerca del miglior adattamento possibile per una certa specie. In questo caso avremmo comunque sei trattamenti, ma le combinazioni sarebbero: biologico-A, biologico-B, biologico-C, convenzionale-D, convenzionale-E e convenzionale-F. Il vantaggio degli esperimenti fattoriali è che permettono di valutare la presenza di ‘interazione’, un fenomeno che si produce quando le combinazioni tra alcuni dei livelli inclusi in prova per ogni fattore producono risposte inattese, particolarmente buone o cattive rispetto a quello che avremmo potuto attenderci, considerando i due fattori sperimentali uno separatamente dall’altro. Ad esempio, se considerassimo le due varietà di mais A e B, con A mediamente più produttiva di B, coltivate in due annate, ad esempio 2025 e 2026, con la seconda molto più sfavorevole, perché siccitosa, dovremmo aspettarci che la combinazione A-2025 fornisca i migliori risultati, mentre la combinazione B-2026 fornisca i peggiori. Se questo non avviene, ad esempio perché B è particolarmente adatta a resistere alla siccità, allora abbiamo un fenomeno d’interazione, che è molto importante studiare nel dettaglio, con un esperimento fattoriale. 2.3.2 Controllo o testimone In alcuni casi è necessario inserire in prova un trattamento che funga da riferimento per tutti gli altri; questo trattamento è comunemente detto controllo o testimone. Possiamo avere: controllo non trattato controllo trattato con placebo controllo trattato secondo le modalità usuali Il controllo cosiddetto ‘non trattato’ è tipico degli esperimenti in ambito fitopatologico, ad esempio quando si vogliono confrontare sostanze chimiche caratterizzate da attività biologica contro un certo organismo. In questi esperimenti, si include sempre un controllo non trattato, che ci permette di capire quale sarebbe stato lo sviluppo dell’organismo sensibile in assenza del trattamento. Nelle prove di confronto erbicida, in assenza del controllo non trattato, non saremmo in grado di stabilire l’efficacia degli erbicidi di pre-emergenza, perché non sapremmo mai se l’assenza delle piante infestanti sia dovuta all’effetto del diserbo o ad altri effetti ambientali. In alcuni casi, il soggetto è influenzabile e può reagire alla semplice idea di essere stato trattato. Ciò capita soprattutto con soggetti umani in ambito medico e, pertanto, invece che il controllo non trattato, si preferisce utilizzare un controllo trattato con placebo, cioè una preparazione che contiene tutti gli ingredienti della formulazione, meno che il principio attivo. In ambito agrario non si parla di placebo, ma talvolta si impiegano formulazioni senza principio attivo con funzioni di controllo, quando si sospetti che i co-formulanti o la soluzione impiegata per veicolare il principio attivo possano mostrare un qualche effetto biologico sul soggetto. Ad esempio, se volessimo provare un erbicida miscelato con un olio minerale, che ha di per se’ un certo effetto sulla flora infestante, dovremmo includere sia un controllo non trattato, che un controllo trattato solo con olio minerale. In altri casi, i trattamenti sperimentali non sono costituiti da trattamenti chimici e, pertanto, non possiamo parlare di controllo non trattato. Anche in questi casi, tuttavia, può sussistere la necessità di avere un riferimento, contro il quale valutare l’efficacia, per esempio, di una tecnica agronomica innovativa. In questi casi siamo soliti includere in prova una tecnica di riferimento, che di solito è quella più consolidata negli usi locali; ad esempio, in un confronto varietale, viene sempre inclusa una varietà di riferimento locale, che ci consente di capire se le prestazioni delle varietà innovative siano effettivamente interessanti oppure no. Diversamente, non saremmo in grado di capire se le produzioni osservate siano dovute al genotipo, oppure ad effetti ambientali favorevoli/sfavorevoli. Un altro esempio importante è relativo alle prove di diserbo, nelle quali, oltre al controllo non trattato, viene spesso inserito un controllo scerbato manualmente, che diviene il riferimento per valutare potenziali effetti fitotossici verso la coltura. 2.4 Le unità sperimentali L’unità sperimentale è l’entità fisica che riceve il trattamento sperimentale; può essere una pianta, un animale, un vaso, una capsula Petri o ogni altra entità di rilievo per lo studio in atto. Le unità sperimentali non vanno confuse con le unità osservazionali, perché le due entità non sempre coincidono. Ad esempio, noi potremmo allocare il trattamento erbicida ad un vaso e poi misurare l’altezza delle singole piante trattate; in questo caso il vaso è l’unità sperimentale (perché ha subito il trattamento), mentre la pianta è l’unità osservazionale. Avere chiara questa differenza è fondamentale per evitare problemi di pseudo-replicazione, come abbiamo dettagliato nel capitolo precedente. Le unità sperimentali sono sempre selezionate da una popolazione più grande, detta cornice di campionamento; ad esempio, noi selezioniamo le parcelle da un campo, gli animali da una mandria e le piante da una coltura. Comunque sia, il campione selezionato deve essere omogeneo e rappresentativo, anche se i due concetti sono spesso discordanti. Infatti, se selezioniamo soggetti molto omogenei, potremmo ottenere un campione che non rappresenta più tutte le caratteristiche della cornice di campionamento. Ad esempio, se selezioniamo solo individui maschi in buona salute, il campione non necessariamente rappresenta l’intera popolazione, se composta anche da femmine e da soggetti con patologie in atto. Campionare una popolazione d’interesse non è un procedimento banale, specie nelle scienze sociali, laddove è stato necessario definire diversi protocolli di campionamento (casuale, sistematico, stratificato, a quota …), per i quali si rimanda ai testi specializzati (ad esempio, Daniel 2011). In questo libro noi facciamo riferimento soprattutto alle prove di pieno campo e di laboratorio. Per le prime, la selezione delle unità sperimentali corrisponde fondamentalmente con la selezione dell’appezzamento di prova e l’identificazione delle parcelle, di cui parleremo tra poco. Per le prove di laboratorio, invece, la situazione può essere abbastanza diversa, in quanto le unità sperimentali sono specificatamente create per un certo esperimento (vasetti, capsule Petri ad altri preparati). Di conseguenza, non vi è un vero e proprio processo di selezione, il che, tuttavia, non significa che non ci sia campionamento. Infatti, anche le unità sperimentali preparate in laboratorio debbono comunque essere considerate come campionate da un universo più grande, costituito da tutte le altre unità sperimentali che avremmo potuto preparare. 2.5 Allocazione dei trattamenti Il problema dell’allocazione dei trattamenti non si pone con gli esperimenti osservazionali, in quanto con questi si scelgono unità sperimentali già ‘naturalmente’ trattate. Per tutti gli esperimenti manipolativi si pone invece il problema di scegliere quali soggetti trattare e come. In generale, seguendo il principio Fisheriano di randomizzazione, l’allocazione dei trattamenti dovrebbe essere effettuata scegliendo le unità sperimentali completamente a caso (esperimenti completamente randomizzati). Tuttavia vedremo che in molte circostanze è conveniente porre dei vincoli al processo di randomizzazione, il che non è sbagliato se questi vincoli sono tenuti in debita considerazione durante il processo di analisi dei dati (Analyse them as you have randomised them! R. Fisher). Questi vincoli costituiscono la base del disegno sperimentale di cui parleremo tra breve. In alcuni casi è opportuno nascondere i dettagli dell’allocazione dei trattamenti. Parliamo quindi di esperimento cieco, quando i soggetti non sono coscienti del trattamento che ricevono o doppio cieco, quando neanche i ricercatori lo sono. Un esperimento cieco o doppio cieco è necessario quando sapere quale trattamento è stato allocato può provocare effetti inconsci o indurre errori di valutazione nel ricercatore. Quest’ultimo caso è importante anche nelle scienze agrarie, dove sapere con che principio attivo è stata diserbata una parcella può indurre preconcetti in chi deve realizzare un rilievo visivo. 2.6 Le variabili sperimentali Per ogni singolo carattere, l’insieme delle modalità/valori che ognuno dei soggetti presenta prende il nome di variabile (proprio perché varia, cioè assume diversi valori, a seconda del soggetto). In questo senso è necessario precisare che non è corretto utilizzare il termine parametri, in quanto in statistica i parametri sono entità che rimangono costanti all’interno di una popolazione di soggetti. Ne parleremo meglio nei prossimi capitoli. Fondamentalmente, esistono due grandi gruppi di variabili: quelle che definiscono lo ‘stimolo’ sperimentale e quelle che misurano la risposta dei soggetti trattati. Le variabili che definiscono uno ‘stimolo’ sperimentale sono anche dette variabili ‘indipendenti’ in quanto non dipendono da nessun altro elemento interno all’esperimento, a parte la volontà dello sperimentatore. Di queste variabili abbiamo già parlato, in quanto esse sono definite all’inizio dell’esperimento e rappresentano i livelli del/dei trattamento/i sperimentali, ad esempio, le modalità di lavorazione del suolo (aratura, minima lavorazione, semina su sodo) o il valore di azoto apportato (0, 50, 100, 150 kg N ha-1). Durante e al termine dell’esperimento vengono invece rilevate le variabili ‘risposta’ che esprimono l’effetto dei trattamenti sperimentali, come, ad esempio, la produzione della coltura, il peso delle piante trattate con un diserbante, la quantità di azoto lisciviato dopo la fertilizzazione. Queste variabili vengono normalmente definite ‘dipendenti’, in quanto i valori assunti da ogni unità sperimentale dipendono, normalmente’ dallo stimolo che hanno ricevuto. Sia le variabili indipendenti che quelle dipendenti possono essere di diversi tipi, che dobbiamo saper riconoscere per scegliere che tipo di analisi statistica da eseguire. In particolare, distinguiamo: variabili nominali (categoriche); variabili ordinali; variabili quantitative discrete; variabili quantitative continue. 2.6.1 Variabili nominali (categoriche) Le variabili nominali esprimono, per ciascun soggetto, l’appartenenza ad una determinata categoria o raggruppamento ed il valore che assumono lo definiamo modalità. L’unica caratteristica delle modalità è l’esclusività, cioè un soggetto che ha una certa modalità non può averne nessun altra. Le variabili nominali sono, ad esempio, il sesso, la varietà, il tipo di diserbante impiegato, la lavorazione e così via. Le variabili categoriche permettono di raggruppare i soggetti, ma non possono essere utilizzate per fare calcoli, se non per definire le frequenze dei soggetti in ciascun gruppo. 2.6.2 Variabili ordinali Anche le variabili ordinali esprimono, per ciascun soggetto, l’appartenenza ad una determinata categoria o raggruppamento. Tuttavia, le diverse categorie sono caratterizzate, oltre che dall’esclusività, anche da una relazione di ordine, nel senso che è possibile stabilire una naturale graduatoria tra esse. Ad esempio, la risposta degli agricoltori a domande relative alla loro percezione sull’utilità di una pratica agronomica può essere espressa utilizzando una scala con sei categorie (0, 1, 2, 3, 4 e 5), in ordine crescente da 0 a 5 (scala Likert). Di conseguenza possiamo confrontare categorie diverse ed esprimere un giudizio di ordine (2 è maggiore di 1, 3 è minore di 5), ma non possiamo eseguire operazioni matematiche, tipo sottrarre dalla categoria 3 la categoria 2 e così via, dato che la distanza tra le categorie non è specificata e, soprattutto, non è necessariamente la stessa. 2.6.3 Variabili quantitative discrete Le variabili discrete sono caratterizzate dal fatto che possiedono, oltre alle proprietà dell’esclusività e dell’ordine, anche quella dell’equidistanza tra gli attributi (es., in una scala a 5 punti, la distanza – o la differenza – fra 1 e 3 è uguale a quella fra 2 e 4 e doppia di quella tra 1 e 2). Una tipica variabile discreta è il conteggio di piante infestanti all’interno di una parcella di terreno. Anche le proporzioni sono da considerare variabili discrete, in quanto non possono assumere valori nell’ambito dei numeri reali. Le variabili discrete consentono la gran parte delle operazioni matematiche e permettono di calcolare molte importanti statistiche come la media, la mediana, la varianza e la deviazione standard. 2.6.4 Variabili quantitative continue Le variabili quantitative continue possiedono tutte le proprietà precedentemente esposte (esclusività delle categorie, ordine, distanza) oltre alla continuità, almeno in un certo intervallo. Tipiche variabili continue sono l’altezza, la produzione, il tempo e la fittezza. Dato che gli strumenti di misura, nella realtà, sono caratterizzati da una risoluzione non infinita, si potrebbe arguire che le variabili continue, in pratica, non esistano. Tuttavia questo argomento è più teorico che pratico e, nella ricerca biologica, consideriamo continue tutte le variabili misurate con strumenti caratterizzati da un risoluzione sufficientemente buona rispetto alla grandezza da misurare. Insomma, se dobbiamo misurare l’altezza del mais ed utilizziamo un metro da sarto, possiamo ottenere una variabile che può essere considerata continua. Talvolta, per esigenze di rappresentazione, le variabili continue possono essere espresse su una scale qualitativa, adottando un’opportuna operazione di classamento. Il contrario, cioè trasformare in quantitativa una variabile qualitativa, non è invece possibile. 2.6.5 Rilievi visivi e sensoriali Nella pratica sperimentale è molto frequente l’adozione di metodi di rilievo basati sull’osservazione di un fenomeno attraverso uno dei sensi (più spesso, la vista, ma anche gusto e olfatto) e l’assegnazione di una valutazione su scala categorica, ordinale o, con un po’ di prudenza, quantitativa discreta o continua. Ad esempio, il ricoprimento delle piante infestanti, la percentuale di controllo di un erbicida e la sua fitotossicità vengono spesso rilevati visivamente, su scale da 0 a 100 o simili. I vantaggi di questa tecnica sono molteplici: Basso costo ed elevata velocità Possibilità di tener conto di alcuni fattori perturbativi esterni, che sono esclusi dalla valutazione, contrariamente a quello che succede con metodi oggettivi di misura non richiede strumentazione costosa A questi vantaggi fanno da contraltare alcuni svantaggi, cioè: Minor precisione (in generale) Soggettività L’osservatore può essere influenzabile Difficoltà di mantenere uniformità di giudizio Richiede esperienza specifica e allenamento I rilievi sensoriali sono ben accettati nella pratica scientifica in alcuni ambiti ben definiti, anche se richiedono attenzione nell’analisi dei dati non potendo essere assimilati tout court con le misure oggettive su scala continua. 2.6.6 Variabili di confondimento Quando si pianificano i rilievi da eseguire, oppure anche nel corso dell’esecuzione di un esperimento, bisogna tener presente non soltanto la variabile che esprime l’effetto del trattamento, ma anche tutte le variabili che misurano possibili fattori di confondimento. Ad esempio, immaginiamo di voler valutare la produttività di una specie arborea in funzione della varietà. Immaginiamo anche di sapere che, per questa specie, la produttività dipende anche dall’età. Se facciamo un esperimento possiamo utilizzare alberi della stessa età per minimizzare la variabilità dei soggetti. Tuttavia, se questo non fosse possibile, per ogni albero dobbiamo rilevare non solo la produttività, ma anche l’età, in modo da poter valutare anche l’effetto di questo fattore aggiuntivo e separarlo dall’effetto della varietà. In questo modo l’esperimento diviene molto più preciso. 2.7 Esperimenti di campo Una volta che tutti gli elementi della ricerca sono stati attentamente pianificati possiamo realizzare l’esperimento. Le tecniche che utilizzeremo saranno fortemente dipendenti dalla discipline, dagli obiettivi, dalla scala (esperimento di laboratorio, serra, campo…) e non è possibile dare indicazioni generali, a parte che ogni esperimento valido deve essere controllato, replicato e randomizzato. In questo capitolo parleremo solo di esperimenti di pieno campo, che costituiscono un elemento fondamentale della ricerca in agricoltura. Tuttavia, si può ragionevolmente ritenere che la gran parte delle informazioni che troverete sono valide anche per altri tipi di esperimenti. 2.7.1 Scegliere il campo Per quanto riguarda la sperimentazione di pieno campo, l’omogeneità dell’ambiente è fondamentale per aumentare la precisione dell’esperimento, cosa che si consegue, innanzitutto, con la scelta dell’appezzamento giusto. Questa scelta è particolarmente delicata ed è guidata soprattutto dall’esperienza, tenendo conto anche di aspetti come la facilità di accesso e la vicinanza di strutture (laboratori, capannoni…), che consentano un’accurata esecuzione degli eventuali prelievi. In genere, si cerca di non avvicinarsi troppo alle scoline, dove possono manifestarsi ristagni idrici, oppure a zone del campo che presentino evidenti segni di difformità. Oltre a scegliere correttamente l’appezzamento, è importante anche porre in atto alcune operazioni preliminari che consentano di migliorare l’omogeneità del campo o della coltura. Ad esempio, talvolta si usa far precedere la prova da una coltura come l’avena, che è molto avida di azoto e lascia nel terreno poca fertilità residua. Oppure, si può impiantare un prato di erba medica, che, grazie agli sfalci periodici, lascia il terreno libero da piante infestanti. Un’altra tecnica molto usata è quella di seminare a densità più alte del normale e poi diradare, per assicurare una migliore uniformità d’impianto. 2.7.2 Le unità sperimentali in campo Dopo aver scelto il campo dobbiamo scegliere le unità sperimentali, distinguendo: prove dimostrative prove parcellari Le prove dimostrative, di solito, costituiscono la fase finale dello sviluppo di una nuova tecnica agronomica e, pertanto, vengono condotte su scala aziendale, utilizzando i normali macchinari di un’azienda agraria e considerando tutta la variabilità tipica delle normali condizioni di coltivazione in pieno campo. Questi esperimenti, usualmente, vengono condotti su striscie di terreno (strip), usualmente di forma rettangolare e di dimensione adatta alle normali seminatrici e trebbiatrici aziendali. Di solito il numero dei trattamenti è basso, spesso pari a due: la tecnica innovativa e quella usuale, con funzioni di controllo. Questi due trattamenti sono allocati a due strisce contigue che costituiscono un ‘blocco’, ripetuto tre o quattro volte, in modo da catturare la variabilità del campo. Per semplicità, considerando l’ampia dimensione delle strisce, la randomizzazione può essere omessa, cosi che il disegno assomiglia al tipo A3 nella Figura 1.4 (capitolo precedente). Un esempio di questo lay-out è riportato in Figura 2.1, dove si vedono quattro campi con due strisce ciascuno. In un campo, i trattamenti sono allocati a ciascuna delle due strisce. Figura 2.1: Esempio di disegno sperimentale per una prova dimostrativa, con quattro campi, due strisce per campo e un diverso trattamento per striscia (giallo e bianco) Gli esperimenti dimostrativi sono spesso ripetuti nello spazio e nel tempo, per ottenere informazioni più attendibili sulla validità della tecnica innovativa. Le prove parcellari sono, invece, una via di mezzo tra le prove dimostrative e gli esperimenti di laboratorio: pur essendo in pieno campo, le parcelle di terreno sono sufficientemente piccole per consentire un elevato grado di precisione e di controllo (Figura 2.2 ). Ovviamente, questo elevato grado di controllo consente di ottenere produzioni che sono, mediamente, un 10-30% maggiori di quelle ottenibili su scala aziendale. Figura 2.2: Una prova sperimentale in campo (Foto D. Alberati) La dimensione delle parcelle viene scelta in modo da avere un numero di piante sufficientemente alto da essere rappresentativo. Per questo motivo le colture a bassa fittezza (es. mais) hanno sempre bisogno di parcelle più grandi che non quelle ad alta fittezza (es. frumento). La dimensione non deve tuttavia essere troppo elevata, in quanto si viene a determinare un incremento della variabilità del terreno e, di conseguenza, una diminuzione della precisione dell’esperimento. Per questo motivo, talvolta si preferisce diminuire la dimensione delle parcelle ed, avendo lo spazio sufficiente, aumentare il numero delle repliche. E’ poi importante tenere conto delle dimensioni delle macchine operatrici che verranno utilizzate per le pratiche colturali; in genere, la larghezza della parcella dovrebbe essere pari a un multiplo della larghezza di lavoro delle seminatrici e/o raccoglitrici e/o delle macchine per la distribuzione dei fitofarmaci. Nello stabilire la dimensione delle parcelle, dovremo tener conto del fatto che la parte più delicata è il bordo, in quanto le piante che si trovano lungo di esso risentono di condizioni diverse dalle altre piante situate al centro della parcella (effetto bordo). Questo determina variabilità all’interno della parcella, che possiamo minimizzare raccogliendo solo la parte centrale. Si viene così a distinguere la superficie totale della parcella dalla superficie di raccolta (superficie utile), che può essere anche molto minore di quella totale. Tenendo conto degli aspetti detti in precedenza, riteniamo che le colture ad elevata fittezza (frumento, cereali, erba medica…) dovrebbero avere parcelle di almeno 10-20 m2, mentre le colture a bassa fittezza (mais, girasole…) dovrebbero avere parcelle di almeno 20-40 m2, con riferimento alla superficie utile di raccolta. Per quanto riguarda la forma delle parcelle, anche se il quadrato minimizzerebbe l’effetto bordo, perché, a parità di superficie, ha un perimetro più basso, nella pratica le parcelle sono sempre rettangolari, per facilitare l’esecuzione delle operazioni meccaniche.Come già detto, la larghezza dovrebbe essere pari ad un multiplo del fronte di lavoro delle macchine operatrici da impiegare. 2.7.3 Numero di repliche Per gli esperimenti di pieno campo il numero di repliche oscilla tra tre e cinque; con meno repliche l’esperimento è inefficiente, mentre un numero più elevato di repliche può essere dannoso, in quanto aumenta la dimensione dell’esperimento e, con essa, la variabilità del campo. Inoltre, un numero alto di repliche aumenta i costi e i tempi di esecuzione dei rilievi. Il numero totale di parcella, alla fine, risulta dal prodotto tra il numero delle tesi sperimentali e il numero delle repliche. 2.7.4 La mappa di campo Il disegno di un esperimento, di solito, è pianificato su una mappa. Un esempio è riportato in Figura 2.3, relativamente ad un esperimento sistemato su un appezzamento largo 30 metri e lungo 400 metri. In questo caso abbiamo disegnato otto file di parcelle in senso trasversale (8 x 2.25 m = 18 m di larghezza), e quattro parcelle in senso longitudinale. Intorno all’esperimento abbiamo sistemato una serie di parcelle addizionali, con lo scopo di ridurre l’effetto ‘bordo’. Vediamo in figura che la mappa riporta tutte le informazioni che consentono di collocare correttamente l’esperimento nello spazio ed, inoltre, che le parcelle sono tutte chiaramente identificate con un codice numerico. Figura 2.3: Mappa di campo di un esperimento con 32 parcelle 2.7.5 Lay-out sperimentale Abbiamo già parlato di come possa essere conveniente, nella pratica sperimentale, porre dei vincoli alla randomizzazione. A seconda di come poniamo questi vincoli, distinguiamo diversi disegni sperimentali, che descriveremo nei prossimi paragrafi. 2.7.5.1 Disegni completamente randomizzati Per queste prove, le più semplici, la scelta dei soggetti da trattare è totalmente casuale, senza vincoli di sorta. Il vantaggio principale è la semplicità; lo svantaggio sta nel fatto che tutte le eventuali differenze e disomogeneità tra unità sperimentali restano non riconosciute ed entrano nella definizione della variabilità residua. Per questo, i disegno completamente randomizzati sono utilizzato soprattutto per le situazioni di buona uniformità ambientale e tra i soggetti. Come esempio, mostriamo un disegno completamente randomizzato utilizzando le parcelle della figura 2.3, alle quali abbiamo allocato 8 trattamenti (da A ad H) con quattro repliche. Come si può notare, l’allocazione è completamente casuale (figura 2.4) Figura 2.4: Esempio di uno schema sperimentale a randomizzazione completa 2.7.5.2 Disegni a blocchi randomizzati Quando le unità sperimentali non sono totalmente omogenee, ma vi è una certa variabilità per una qualche caratteristiche rilevante, potremo dividere i soggetti in base a questa caratteristica, in tanti gruppi quante sono le repliche. Ad esempio, nel caso dello schema in figura 2.4, se ammettiamo l’esistenza di un gradiente di fertilità crescente das sinistra verso destra, allora il trattamento H è stato avvantaggiato, perché tre delle quattro repliche si trovano nella parte destra, mentre il trattamento G è stato svantaggiato, per il motivo opposto. Si può ottenere un disegno più efficiente se dividendo l’esperimento in quattro blocchi perpendicolari al gradiente di fertilità. Ad esempio il blocco 1 conterrà le parcelle 1, 9, 17, 25, 2, 10, 18 e 26, cioè le prime due colonne della mappa, con un numero di parcelle esattamente uguali al numero dei trattamenti. Il blocco 2 conterrà le colonne 3 e 4 e così via. Dato che il gradiente è trasversale, le parcelle di un stesso blocco saranno più omogenee che non parcelle su blocchi diversi. Dopo aver diviso la mappa in quattro blocchi di otto parcelle, potremo allocare gli otto trattamenti a random all’interno di ogni blocco (2.5) Figura 2.5: Esempio di uno schema sperimentale a blocchi randomizzati Un disegno a blocchi randomizzati non è solo tipico della sperimentazione di campo. Ad esempio, volendo determinare la contaminazione da micotossine nelle confezioni di datteri, a seconda della modalità di confezionamento (es. carta, busta di plastica, scatola di plastica perforata), si può sospettare che il supermercato nel quale le confezioni vengono vendute potrebbe avere un certo effetto, legato alle modalità di conservazione. Per cui, invece che prelevare trenta confezioni (dieci per metodo) a caso nei supermercati di una città, scegliamo dieci supermercati e, in ognuno, prendiamo una confezione per tipo. In questo caso, il supermercato fa da blocco. Il vantaggio del disegno a blocchi randomizzati sta nel fatto che ci permetto di utilizzare soggetti sperimentali con una più bassa omogeneità iniziale, aspetto importante quando il numero di unità sperimentali richieste comincia ad essere elevato. Infatti, le differenze tra soggetti sperimentali, almeno in parte, possono essere spiegate attraverso l’appartenenza ad un determinato gruppo (blocco) e possono quindi essere scorporate dal calcolo della variabilità residua. 2.7.5.3 Disegni a quadrato latino In questo caso, le unità sperimentali presentano due ‘gradienti’, cioè vi sono differenze legate a due elementi importanti, oltre al trattamento sperimentale. La Figura 2.6 mostra un esperimento con quattro trattamenti e altrettante repliche, nel quale ogni trattamento si trova in tutte le righe e tutte le colonne, in modo da poter considerare eventuali gradienti di fertilità da destra verso sinistra e dall’alto verso il basso. La figura mostra anche perché si parli di quadrato latino: in effetti il numero di righe è uguale al numero di colonne, secondo una griglia quadrata. Qualcuno di voi riconoscerà in questo schema i principi di fondo del Sudoku. Figura 2.6: Esempio di un disegno sperimentale a quadrato latino, con quattro trattamenti (A, B, C e D) ed altrettante repliche. I colri aiutano ad identificare i quattro trattamenti e la posizione delle rispettive parcelle I disegni a quadrato latino non sono solo utili per gli esperimenti di pieno campo; ad esempio, se un certo oggetto richiede un solo operatore per essere costruito e vogliamo confrontare quattro metodi costruttivi, possiamo pianificare un esperimento dove l’unità sperimentale è il lavoratore. Volendo lavorare con quattro repliche, avremmo bisogno di sedici operatori per disegnare un esperimento completamente randomizzato. Possiamo tuttavia considerare che un operatore, in quattro turni successivi, può operare con tutti e quattro i metodi. Quindi possiamo disegnare un esperimento in cui il turno fa da unità sperimentale e l’operatore fa da blocco (esperimento a blocchi randomizzati). Tuttavia, in ogni blocco (operatore) vi è un gradiente, nel senso che i turni successivi al primo sono via via meno efficienti, perché l’operatore accumula stanchezza. Per tener conto di questo, potremmo lasciare all’operatore un congruo periodo di tempo tra un turno e l’altro. Oppure, potremmo introdurre un vincolo ulteriore, per ogni operatore, randomizzando i quattro metodi tra i turni, in modo che ogni metodo, in operatori diversi, capiti in tutti i turni. In sostanza, l’operatore fa da blocco, perché in esso sono contenuti tutti i metodi. Ma anche il turno (per tutti gli operatori) fa da blocco, in quanto in esso sono ancora contenuti tutti i metodi. Proviamo a schematizzare, nella figura seguente (2.7 ). Figura 2.7: Allocazione di quattro metodi di lavoro (A, B, C e D), tra quattro operatori, in quattro turni, seguendo uno schema a quadrato latino Il disegno a quadrato latino è utile, perché possiamo dar conto sia delle differenza tra righe (es. turni), che delle differenze tra colonne (es. operatori), in modo da ridurre al minimo possibile la variabilità inspiegabile. Lo svantaggio sta nel fatto che, dovendo avere tante repliche quanti sono i trattamenti, è utilizzabile solo per esperimenti abbastanza piccoli. 2.7.5.4 Disegni a split-plot Gli esperimenti fattoriali possono essere disegnati con uno schema a randomizzazione completa o a blocchi randomizzati, allocando alle unità sperimentali tutte le combinazioni dei fattori in studio. Per esempio, consideriamo un esperimento per confrontare tre tipi di lavorazioni del terreno (minimum tillage = MIN; aratura superficiale = SP; aratura profonda = DP) e due tipi di controllo chimico delle piante infestanti (a pieno campo = TOT; lungo la fila = PARZ). Se vogliamo fare quattro repliche, i sei trattamenti sperimentali (MIN-TOT, SP-TOT, DP-TOT, MIN-PARZ, SP-PARZ and DP-PARZ) possono essere allocati alle 24 parcelle secondo uno schema a blocchi randomizzati, come indicato in Figura 2.8. In questo caso è necessario lasciare un ampio spazio tra le parcelle, in modo da permettere la circolazione delle macchine operatrici per la lavorazione ed, inoltre, le parcelle debbono essere grandi, per consentire una buona esecuzione dell’aratura. Figura 2.8: Mappa di campo per un esperimento fattoriale con due fattori, disegnato a blocchi randomizzati Dato che il trattamento di diserbo non richiede parcelle altrettanto grosse, potremmo pensare di suddividere ogni parcella in due sub-parcelle, sulle quali allocare il trattamento di diserbo (disegno a parcella suddivisa o split-plot). Un esempio è riportato in Figura 2.9, dove possiamo osservare che le lavorazioni sono allocate su 12 parcelle principali (mainplots), secondo uno schema a blocchi randomizzati, mentre i trattamenti di diserbo sono allocati in modo randomizzato sulle due subplot in ogni mainplot. Tecnicamente, diciamo che la lavorazione è il fattore di primo ordine, mentre il diserbo chimico è il fattore di secondo ordine. Notiamo che l’esperimento diviene più piccolo e quindi più preciso. Figura 2.9: Stesso esperimento descritto nella figura precedente, ma disegnato con uno schema a split-plot. In generale, un disegno a split-plot può rendersi necessario per i seguenti motivi: un fattore sperimentale richiede parcelle più grandi dell’altro. Di conseguenza si disegna l’esperimento per il fattore che richiede parcelle più grandi, che vengono poi suddivise per accomodare l’altro fattore sperimentale. Uno dei due fattori sperimentali è più ‘difficile’ da assegnare rispetto all’altro e quindi è preferibile manipolare congiuntamente tutto il gruppo di unità sperimentali che deve riceverlo. Ad esempio, se vogliamo misurare la resistenza alla corrosione di barre d’acciaio con diversi rivestimenti e forgiate a diverse temperature, è evidente che la gestione della temperatura nella fornace è piuttosto complessa, perché richiede tempi lunghi per essere cambiata e raggiungere un nuovo equilibrio. Invece che preparare una fornace per ogni rivestimento (manipolazione indipendente delle unità sperimentali), si mettono nella stessa fornace tutte le unità sperimentali con i diversi rivestimenti. Una situazione analoga si può avere se vogliamo provare diverse miscele per torte (con vari ingredienti), e diversi tempi di cottura; dato che non è agevole preparare una miscela diversa per ogni tempo di cottura, potremmo preparare una miscela tutta insieme, per poi suddividerla tra i diversi tempi di cottura. La disponibilità di unità sperimentali è limitata, come accade con gli armadi climatici, che vengono impostati a diversa temperatura e all’interno delle quali vengono randomizzate le tesi sperimentali di secondo ordine. Un’importante conseguenza dei disegni a split-plot è che ogni mainplot funge da replica per il fattore sperimentale di secondo ordine. In effetti, se guardiamo alla Figura 2.9, possiamo osservare che ci sono quattro repliche per ogni lavorazione, ma 12 repliche per ogni tipo di diserbo chimico. Di conseguenza, l’effetto del fattore sperimentale di secondo ordine è stimato con maggior precisione. 2.7.5.5 Disegni a strip-plot In alcune circostanze, soprattutto nelle prove di diserbo chimico, potrebbe trovare applicazione un altro tipo di schema sperimentale, nel quale ogni blocco viene diviso in tante righe quanti sono i livelli di un fattore sperimentale e tante colonne quanti sono i livelli dell’altro. In questo modo, il primo trattamento sperimentale viene applicato a tutte le parcelle di una riga e l’altro trattamento a tutte le parcelle di una colonna. Ovviamente, l’allocazione alle righe e alle colonne è casuale e cambia in ogni blocco. Questo disegno è detto strip-plot ed è molto comodo perché consente di lavorare velocemente. Se consideriamo il caso studio precedente, un disegno a strip-plot potrebbe essere immaginato come in Figura 2.10. Figura 2.10: Esempio di un disegno a strip-plot per il dataset ‘beet.csv’, che prevede tre livelli di lavorazione e due livelli di diserbo chimico 2.8 Altre letture Cochran, W.G., Cox, G.M., 1950. Experimental design. John Wiley &amp; Sons, Inc., Books. LeClerg, E.L., Leonard, W.H., Clark, A.G., 1962. Field Plot Technique. Burgess Publishing Company, Books. 2.9 Domande ed esercizi 2.9.1 Domanda 1 Quali sono le caratteristiche fondamentali di un esperimento scientifico, perché possa essere ritenuto valido? 2.9.2 Domanda 2 Illustrare brevemente il metodo scientifico ‘galileiano’. 2.9.3 Domanda 3 Illustrare brevemente la differenza tra errori casuali e sistematici. In presenza di quale dei due è possibile ottenere risultati scientifici validi? 2.9.4 Domanda 4 Qual è la differenza tra repliche vere e pseudo-repliche? 2.9.5 Domanda 5 Cosa è il confounding e come può rendere distorti i risultati di un esperimento scientifico? 2.9.6 Domanda 6 Quali sono gli elementi comuni a tutti gli esperimenti scientifici? 2.9.7 Domanda 7 Quali tipi di variabili conoscete e quali sono le loro caratteristiche? 2.9.8 Domanda 8 Qual è la differenza tra un esperimento fattoriale innestato ed uno incrociato 2.9.9 Domanda 9 Quali sono le caratteristiche principali degli esperimenti a randomizzazione completa, blocchi randomizzati e quadrato latino? 2.9.10 Domanda 10 Come è fatto e quando si utilizza uno schema sperimentale a split-plot? 2.9.11 Domanda 12 Cosa è l’effetto di bordo e come si può controllare? 2.9.12 Domanda 13 Illustrare e discutere le caratteristiche fondamentali delle ‘parcelle’ (forma, dimensioni, numero …) 2.9.13 Esercizio 1 Vi è stata affidata una prova sperimentale per la taratura agronomica di un nuovo diserbante appartenente al gruppo chimico delle solfoniluree (AGRISULFURON), utilizzabile alla dose presumibile di 20 g/ha, per il diserbo di post-emergenza del mais. Gli obiettivi della prova sono: Valutare se è opportuno un certo aggiustamento della dose (incremento/diminuzione) Valutare se è opportuna l’aggiunta di un bagnante non-ionico Valutare se è opportuno splittare la dose di 20 g/ha in due distribuzioni Valutare l’efficacia del nuovo diserbante con gli opportuni controlli (testimoni) Coerentemente con questi obiettivi, scrivere un protocollo sperimentale sufficientemente dettagliato (una pagina) ed aggiungere la mappa di campo della prova. Considerare che abbiamo a disposizione un campo lungo 80 metri e largo 26 metri, in direzione Nord-Sud, lavorato nel senso della lunghezza e con un gradiente di ‘fertilità’ trasversale, nel senso della larghezza. 2.9.14 Esercizio 2 Dovete progettare una prova sperimentale per valutare i possibili effetti dell’epoca di semina (autunnale oppure primaverile) su sette varietà di favino (che etichetteremo con le lettere da A a G). Progettare un esperimento di pieno campo, decidendo il numero di repliche ed il lay-out sperimentale. Redigere la mappa di campo ed allocare i trattamenti, in base al lay-out prescelto. Aggiungere alla mappa di campo tutti i dettagli necessari (dimensioni delle parcelle, localizzazione ed orientamento dell’esperimento). Considerate che abbiamo a disposizione un campo lungo 60 metri e largo 40 metri, in direzione Est-Ovest, lavorato nel senso della lunghezza e con un gradiente di ‘fertilità’ longitudinale. 2.9.15 Esercizio 3 Illustrate il disegno sperimentale che adottereste per organizzare una prova che metta a confronto quattro concimi azotati (urea, solfato ammonico, nitrato di calcio e nitrato di sodio) e un testimone non concimato su barbabietola da zucchero. Motivate opportunamente le vostre scelte. Considerate che abbiamo a disposizione un campo lungo 50 metri e largo 30 metri, in direzione Est-Ovest, lavorato nel senso della lunghezza e con due gradienti di ‘fertilità’, longitudinale e trasversale. 2.9.16 Esercizio 4 Descrivete lo schema sperimentale che adottereste per organizzare un esperimento di confronto tra quattro dosi di un diserbate per il frumento, utilizzato con e senza un coadiuvante. Motivate opportunamente le vostre scelte. Considerate che abbiamo a disposizione un campo lungo 50 metri e largo 20 metri, in direzione Est-Ovest, lavorato nel senso della lunghezza e con due gradienti di ‘fertilità’, longitudinale e trasversale. 2.9.17 Esercizio 5 Descrivete lo schema sperimentale che utilizzereste per organizzare una prova su pomodoro da industria, per la valutazione dell’effetto di tre livelli di concimazione azotata (0, 80 e 160 kg/ha) e tre tipologie di interventi irrigui (asciutto, basso volume irriguo, alto volume irriguo). Motivate opportunamente le vostre scelte. Considerate che abbiamo a disposizione un campo lungo 100 metri e largo 25 metri, in direzione Est-Ovest, lavorato nel senso della lunghezza e con un gradiente di fertilità longitudinale. "],["richiami-di-statistica-descrittiva.html", "Capitolo 3 Richiami di statistica descrittiva 3.1 Descrizione di dati quantitativi 3.2 Statistiche descrittive con R 3.3 Altre letture 3.4 Domande ed esercizi", " Capitolo 3 Richiami di statistica descrittiva Qualunque esperimento include un processo di raccolta dati, tramite osservazioni e/o misurazioni, al termine del quale abbiamo a disposizione un collettivo di valori, di solito organizzati sotto forma di tabella (‘dataset’), dove ogni riga corrisponde ad un’unità sperimentale (soggetto) con tutti i suoi attributi, mentre ogni colonna (detta anche variabile) corrisponde ad un attributo e contiene i valori rilevati per tutte le unità sperimentali. Un esempio delle prime righe di un dataset è riportato nella Tabella 3.1. Tabella 3.1: Prime 6 righe di un dataset relativo alla qualità di alcuni genotipi di frumento. Ogni riga rappresenta un’unità sperimentale ed ogni colonna rappresenta un attributo di quella unità sperimentale (TKW: peso dei mille semi in grammi; Whectol: peso ettolitrico in kg; Yield: produzione di granella in quintali per ettaro; height: altezza in cm.) Genotype Block Height TKW Whectol Yield arcobaleno 1 90 44.5 83.2 64.40 arcobaleno 2 90 42.8 82.2 60.58 arcobaleno 3 88 42.7 83.1 59.42 baio 1 80 40.6 81.8 51.93 baio 2 75 42.7 81.3 51.34 baio 3 76 41.1 81.1 47.78 Il nostro primo compito è quello di comprendere e descrivere le caratteristiche fondamentali di ogni variabile, utilizzando statistiche descrittive opportunamente scelte, in base al tipo di dato e alle caratteristiche che si vogliono descrivere. 3.1 Descrizione di dati quantitativi Se i dati sono stati ottenuti con un processo di misurazione e rappresentano una quantità, come, ad esempio, il peso, l’altezza, la concentrazione e così via, abbiamo una variabile quantitativa, della quale dobbiamo descrivere almeno due caratteristiche fondamentali: tendenza centrale dispersione La tendenza centrale è un valore che rappresenta il ‘centro’, attorno al quale si collocano tutte le osservazioni; al contrario, la dispersione misura la distanza delle osservazioni tra di loro, cioè, in altre parole, la loro variabilità. Ovviamente, esistono anche altre importanti proprietà di una variabile quantitativa, come la simmetria e la curtosi, che, tuttavia, non verranno prese in considerazione in questo libro, rimandando alla lettura di testi più approfonditi (Sokal e Rohlf, 1981; Leti e Cerbara, 2009). Un altro aspetto che è necessario precisare è che, almeno nella sperimentazione agraria, non è infrequente rilevare, in ogni parcella, alcune variabili nominali, come la presenza di individui infetti la presenza/assenza di piante infestanti oppure alcune variabili discrete, frutto di conteggio, ad esempio il numero di piante infestanti o la fittezza della coltura e così via. Nonostante esistano metodi specifici per variabili nominali e discrete, è comune trasformare le variabili nominali in forma di frequenze relative (ad esempio, il numero di piante infette sul totale campionato) per ogni parcella, che sono poi trattate alla stregua delle variabili quantitative, così come i conteggi per parcella. 3.1.1 Indicatori di tendenza centrale L’indicatore di tendenza centrale più diffuso è la media aritmetica, che non necessita di particolari spiegazioni: si tratta della somma dei dati (\\(x\\)) divisa per il loro numero (\\(n\\)): \\[\\mu = \\frac{\\sum\\limits_{i = 1}^n x}{n}\\] Per esempio, consideriamo il seguente dataset, che elenca le altezze di quattro piante di mais \\(d = [178, 175, 158, 153]\\) Il calcolo della media è banale: \\[\\mu = \\frac{178 + 175 + 158 + 153}{4} = 166\\] La media è ‘centrale’ nel senso che la somma delle sue distanze da ogni altra osservazione è nulla. Di conseguenza, è molto sensibile ai valori estremi; se, ad esempio, supponiamo di avere i cinque valori: 1, 4, 7, 9 e 10 con media pari a 6,2 e supponiamo di sostituire il valore più alto con 100, la media aumenta di conseguenza, diventando pari a 24,2. Per questa sua sensibilità ai valori estremi, si dice che la media non è un indicatore di tendenza centrale ‘robusto’ nei confronti degli outliers, cioè delle osservazioni in qualche modo ‘aberranti’. In presenza di queste osservazioni, che potrebbero essere frutto di un errore sperimentale rilevante, la media tende a non rappresentare più la tendenza centrale del collettivo in modo affidabile. Un altro indicatore di tendenza centrale è la mediana, cioè il valore che bipartisce i dati in modo che la metà di essi siano più alti e la metà più bassi. Per calcolare la mediana, basta ordinare i soggetti in ordine crescente: se il numero di individui è dispari, la mediana è data dal valore dall’individuo che occupa il posto centrale o, se gli individui sono in numero pari, dalla media delle due osservazioni centrali. Nell’esempio precedente, i dati sono in numero pari, quindi la mediana è: \\((158 + 175)/2 = 166.5\\). La mediana è un indicatore più robusto della media: infatti, se consideriamo gli stessi cinque valori elencati in precedenza (1, 4, 7, 9 e 10), la mediana è pari a 7 e non cambia quando sostituiamo il valore più alto con 100. 3.1.2 Indicatori di dispersione Conoscere la tendenza centrale di un collettivo è importante, ma non è sufficiente. Infatti, una media pari a 100 può essere ottenuta con tre individui che misurano 99, 100 e 101, rispettivamente, o con tre individui che misurano 1, 100 e 199. E’ evidente che i due gruppi hanno la stessa tendenza centrale, ma sono molto diversi in termini di dispersione (o variabilità) rispetto alla media. Per descrivere la dispersione dei dati possiamo utilizzare il campo di variazione, che è la differenza tra la misura più bassa e la misura più alta. In realtà, questo indicatore è poco diffuso, perché considera solo i valori estremi del collettivo e non necessariamente cresce al crescere della variabilità. Altri indicatori sono più diffusi ed affidabili, come la devianza, la varianza, la deviazione standard ed il coefficiente di variabilità, tutti legati da relazioni algebriche ben definite. La devianza, generalmente nota come somma dei quadrati (abbreviata SS, da sum of squares) è data da: \\[SS = \\sum\\limits_{i = 1}^n {(x_i - \\mu)^2 }\\] Ad esempio, per le quattro altezze menzionate in precedenza, la devianza è pari a: \\[SS = \\left(178 - 166 \\right)^2 + \\left(175 - 166 \\right)^2 + \\left(158 - 166 \\right)^2 + \\left(153 - 166 \\right)^2 = 458\\] La devianza è un indicatore di dispersione molto utilizzato, soprattutto perché ha un suo preciso significato geometrico, in quanto somma delle distanze euclidee al quadrato, rispetto alla media. Tuttavia, ha due aspetti che vanno tenuti in considerazione: in primo luogo, proprio perché è una somma, il valore finale dipende dal numero di addendi e quindi non la si può utilizzare per confrontare la variabilità di collettivi con diversa numerosità. Inoltre, l’unità di misura della devianza è pari al quadrato dell’unità di misura originale dei dati; ad esempio se le osservazioni sono espresse in centimetri (come nel nostro esempio), la devianza è espressa in centimetri quadrati, il che rende più difficoltosa l’interpretazione dei risultati. Oltre dalla devianza, un indicatore molto utilizzato è la varianza campionaria (o semplicemente varianza), che è data dalla devianza divisa per il numero di dati meno uno: \\[\\sigma^2 = \\frac{SS}{n - 1}\\] Nel caso delle nostre altezze: \\[\\sigma^2 = \\frac{458}{3} = 152.67\\] La varianza è anche detta scarto quadratico medio è permette di confrontare la variabilità di collettivi diversamente numerosi, anche se permane il problema dell’unità di misura, che è sempre il quadrato di quella delle singole osservazioni. Per eliminare questo problema si ricorre alla radice quadrata della varianza, cioè la deviazione standard, che si indica con \\(\\sigma\\). La deviazione standard è espressa nella stessa unità di misura dei dati originali ed è quindi molto utilizzata per descrivere l’incertezza assoluta di misure ripetute più volte. Nel nostro caso, risulta che: \\[\\sigma = \\sqrt{152.67} = 12.36\\] e questo valore ci fa capire che, ‘mediamente’, la distanza euclidea tra ogni valore e \\(\\mu\\) è pari \\(12.36\\) centimetri. Media e deviazione standard sono spesso riportate contemporaneamente, utilizzando un intervallo \\(l\\) definito come: \\[l = \\mu \\pm \\sigma\\] Un problema della deviazione standard è che essa, in assenza della media, non riesce a dare informazioni facilmente comprensibili; infatti, se dicessimo semplicemente che un gruppo di individui ha una deviazione standard pari a \\(12.36\\), cosa potremmo concludere in relazione alla variabilità di questo collettivo? È alta o bassa? È evidente che, senza sapere la media, non riusciamo a rispondere a questa domanda: la variabilità potrebbe essere considerata molto alta se la media fosse bassa (ad esempio 16), oppure molto bassa, se la media fosse alta (esempio 1600). Per questo, se dovessimo descrivere la variabilità dei dati indipendentemente dalla media, dovremmo utilizzare il coefficiente di variabilità (CV): \\[CV = \\frac{\\sigma }{\\mu } \\times 100\\] Il CV è un numero puro e non dipende dall’unità di misura e dall’ampiezza del collettivo, sicché è molto adatto ad esprimere, ad esempio, l’errore degli strumenti di misura e delle apparecchiature di analisi (incertezza relativa). Nel nostro caso, abbiamo: \\[CV = \\frac{12.36}{166} \\times 100 = 7.45 \\%\\] Come la media, anche la devianza, la varianza e la deviazione standard sono sensibili agli outliers. Pertanto, in presenza di osservazioni aberranti, preferiamo descrivere la variabilità del collettivo utilizzando i cosiddetti percentili, che, estendendo il concetto di mediana, bipartiscono il collettivo in modo da lasciare una certa percentuale di individui alla loro sinistra. Ad esempio, il primo percentile bipartisce il collettivo in modo che l’1% dei soggetti sono più bassi e il 99% sono più alti. Allo stesso modo, l’ottantesimo percentile bipartisce il collettivo in modo che l’80% dei soggetti sono più bassi e il 20% sono più alti. Ovviamente, la mediana rappresenta il 50-esimo percentile. I percentili più utilizzati per descrivere la dispersione di un collettivo sono il 25-esimo e il 75-esimo, che individuano un intervallo all’interno del quale è compreso il 50% dei soggetti: se questo intervallo è piccolo, significa che la variabilità è bassa. Calcolare i percentili a mano non è banale e, di conseguenza, lo faremo nei paragrafi successivi, utilizzando R. 3.1.3 Incertezza delle misure derivate A volte noi misuriamo due quantità e poi le combiniamo, per ottenere una misura derivata, ad esempio la somma o la differenza. Se le due misure hanno un certo grado di incertezza, quantificabile, ad esempio, con la deviazione standard, qual è l’incertezza della loro somma o della loro differenza? La legge di propagazione degli errori dice che, in caso di misure indipendenti, la deviazione standard di una somma o di una differenza è uguale alla radice quadrata della somma dei quadrati delle deviazioni standard degli addendi. Ad esempio, se abbiamo fatto due misure indipendenti in triplicato, ottenendo le due medie \\(22\\) e \\(14\\), con deviazioni standard rispettivamente pari a \\(2\\) e \\(3\\), la somma sarà pari a \\(36\\), con deviazione standard pari \\(\\sqrt{2^2 + 3^2} = 3.6\\), mentre la differenza sarà pari ad \\(8\\) con deviazione standard comunque pari a \\(3.6\\). Ovviamente è anche possibile calcolare la deviazione standard di misure derivate con funzioni diverse dalla somma o dalla differenza, ma si tratta di una situazione meno comune, che non tratteremo in questo libro. 3.1.4 Relazioni tra variabili quantitative: correlazione Se su ogni soggetto abbiamo rilevato due caratteri quantitativi (ad esempio il peso e l’altezza, oppure la produzione e il contenuto di proteina della granella), è possibile verificare se esista una relazione tra la coppia di variabili ottenute, cioè se al variare di una cambi anche il valore dell’altra, in modo congiunto (variazione congiunta). Per questo fine, si utilizza il coefficiente di correlazione di Pearson costituito dal rapporto tra la codevianza (o somma dei prodotti) delle due variabili e la radice quadrata del prodotto delle loro devianze. Vedremo tra poco il metodo di calcolo, ma vogliamo anticipare che il coefficiente di correlazione varia tra \\(-1\\) e \\(+1\\); se è pari ad 1, abbiamo una situazione ideale di concordanza perfetta (quando aumenta una variabile, aumenta anche l’altra in modo esattamente proporzionale), mentre quando è pari a \\(-1\\), abbiamo una situazione ideale di discordanza perfetta (quando aumenta una variabile, diminuisce l’altra in modo inversamente proporzionale). Un valore pari a \\(0\\) è altrettanto ideal ed indica assenza di qualunque grado di variazione congiunta (assenza di correlazione). Nell’intervallo tra \\(-1\\) ed \\(1\\), il coefficiente indica una correlazione imperfetta, ma tanto migliore quanto più ci allontaniamo dallo zero e ci avviciniamo a \\(-1\\) o \\(1\\). Due esempi di ottima correlazione sono mostrati in Figura 3.1; si evidenzia un elevato grado di correlazione, che, tuttavia, non è perfetta, in quanto i punti non sono esattamente allineati. Figura 3.1: Esempio di correlazione positiva (destra) e negativa (sinistra) Proviamo a considerare questo esempio: il contenuto di olio di 9 lotti di acheni di girasole è stato misurato con due metodi diversi ed è riportato più sotto. A &lt;- c(45, 47, 49, 51, 44, 37, 48, 44, 53) B &lt;- c(44, 44, 49, 53, 48, 34, 47, 46, 51) Per valutare la entità della correlazione tra i risultati dei due metodi di analisi, dobbiamo eseguire alcune operazioni preliminari, cioè: calcolare i residui per A (\\(z_A\\)) calcolare i residui per B (\\(z_B\\)) calcolare devianze e codevianze In primo luogo, calcoliamo le due medie, che sono, rispettivamente, 46.44 e 46.22. Successivamente, possiamo calcolare i residui, come differenze tra ogni dato e la sua media, i loro quadrati ed i loro prodotti, come indicato in Tabella 3.2. Tabella 3.2: Calcolo manuale del coefficiente di correlazione A B \\(z_A\\) \\(z_B\\) \\(z_A \\times z_B\\) \\(z_A^2\\) \\(z_B^2\\) 45 44 -1.444 -2.222 3.210 2.086 4.938 47 44 0.556 -2.222 -1.235 0.309 4.938 49 49 2.556 2.778 7.099 6.531 7.716 51 53 4.556 6.778 30.877 20.753 45.938 44 48 -2.444 1.778 -4.346 5.975 3.160 37 34 -9.444 -12.222 115.432 89.198 149.383 48 47 1.556 0.778 1.210 2.420 0.605 44 46 -2.444 -0.222 0.543 5.975 0.049 53 51 6.556 4.778 31.321 42.975 22.827 La somma dei quadrati dei residui ci permette di calcolare le devianze di \\(A\\) e \\(B\\) (rispettivamente 176.22 e 239.56), mentre la somme dei prodotti degli residui ci permette di calcolare la codevianza (pari a 184.11). Il coefficiente di correlazione è quindi: \\[r = \\frac{184.11}{\\sqrt{176.22 \\times 239.56}} = 0.896\\] Vediamo che il coefficiente di correlazione è abbastanza vicino ad 1 e quindi possiamo concludere che i due metodi di analisi danno risultati ben concordanti. 3.2 Statistiche descrittive con R Le statistiche descrittive si calcolano facilmente con R. Per esercizio, utilizziamo il dataset ‘heights.csv’, che è disponibile in una repository online. Il box sottostante mostra come caricare il dataset, del quale utilizzeremo la colonna ‘height’ che riporta le altezze di venti piante di mais. filePath &lt;- &quot;https://www.casaonofri.it/_datasets/heights.csv&quot; dataset &lt;- read.csv(filePath, header = T) dataset$height ## [1] 172 154 150 188 162 145 157 178 175 158 153 191 174 141 165 163 ## [17] 148 152 169 185 La media si calcola con la funzione mean(), mentre la mediana si calcola con la funzione median(). mean(dataset$height) ## [1] 164 median(dataset$height) ## [1] 162.5 Per la devianza, non esiste una funzione dedicata e dobbiamo utilizzare l’equazione fornita in precedenza: sum( (dataset$height - mean(dataset$height))^2 ) ## [1] 4050 Varianza e deviazione standard sono molto facili da calcolare, grazie alle funzioni apposite, mentre il coefficiente di variabilità si può calcolare con la formula fornita in precedenza: var(dataset$height) ## [1] 213.1579 sd(dataset$height) ## [1] 14.59993 sd(dataset$height)/mean(dataset$height) * 100 ## [1] 8.902395 Per calcolare i percentili si usa la funzione quantile(), fornendo le proporzioni di soggetti da lasciare sulla sinistra con l’argomento ‘probs’. Ad esempio, per il 25-esimo percentile utilizzeremo 0.25, mentre per il 75-esimo utilizzeremo 0.75: quantile(dataset$height, probs = c(0.25, 0.75)) ## 25% 75% ## 152.75 174.25 La correlazione si calcola invece con la funzione cor(), come indicato più sotto. cor(A, B) ## [1] 0.8960795 3.2.1 Descrizione dei sottogruppi In biometria è molto comune che il gruppo di soggetti sia divisibile in più sottogruppi, corrispondenti, ad esempio, ai diversi trattamenti sperimentali. In questa comune situazione siamo soliti calcolare, per ogni gruppo, le statistiche descrittive già viste in precedenza, utilizzando la funzione tapply() in R, come mostrata più sotto. m &lt;- tapply(dataset$height, dataset$var, mean) s &lt;- tapply(dataset$height, dataset$var, sd) descript &lt;- data.frame(Media = m, SD = s) descript ## Media SD ## C 165.00 14.36431 ## N 164.00 16.19877 ## S 160.00 12.16553 ## V 165.25 19.51709 Nel codice immediatamente precedente, height è la variabile che contiene i valori da mediare, var è la variabile che contiene la codifica di gruppo, mean è la funzione che dobbiamo calcolare. Ovviamente mean può essere sostituito da qualunque altra funzione ammissibile in R, come ad esempio la deviazione standard. Nel codice precedente abbiamo utilizzato la funzione data.frame() per creare una tabella riassuntiva con le medie e le deviazioni standard dei quattro gruppi. Oltre che in una tabella, i risultati possono anche essere riportati in un grafico a barre, con l’indicazione della variabilità dei dati. Possiamo utilizzare la funzione barplot() alla quale passeremo come argomenti l’altezza delle barre, data dalle medie dei diversi gruppi, i nomi dei gruppi medesimi e, opzionalmente, la scala dell’asse delle ordinate. La funzione barplot(), oltre che creare il grafico, restituisce le ascisse del centro di ogni barra, che possiamo utilizzare per creare dei segmenti verticali corrispondenti alle deviazioni standard di ogni gruppo, attraverso la funzione arrows(). L’uso di quest’ultima funzione non è immediato; poniamo che le ascisse del centro di ogni barra siano contenute nel vettore ‘coord’; allora i segmenti di variabilità dovranno avere punti di partenza con ascisse contenute in ‘coord’ ed ordinate uguali all’altezza di ogni barra meno la deviazione standard. I punti di arrivo, invece, dovranno avere le stesse ascisse dei punti di partenza ed ordinate uguali all’altezza di ogni barra più la deviazione standard. Gli altri argomenti della funzione arrows() servono per meglio specificare l’aspetto dei segmenti di variabilità; ad esempio, il codice sottostante produce il risultato mostrato in Figura 3.2; il grafico non è bellissimo, ma, con un po’ di esercizio, è possibile ottenere grafici altamente professionali. coord &lt;- barplot(descript$Media, names.arg = row.names(descript), ylim = c(0, 200)) arrows(coord, descript$Media - descript$SD, coord, descript$Media + descript$SD, length = 0.05, angle = 90, code = 3) Figura 3.2: Esempio di boxplot in R Quando abbiamo a che fare con gruppi molto numerosi, con un certo numero di outliers, è bene sostituire la mediana alla media, in associazione con il 25-esimo e 75-esimo percentile, come indicazioni di variabilità. Da un punto di vista grafico, possiamo utilizzare un boxplot (grafico Box-Whisker). Si tratta di una scatola (box) che ha per estremi il 25-esimo e il 75-esimo percentile ed è tagliata da una linea centrale in corrispondenza della mediana. Dalla scatola partono due linee verticali (baffi = whiskers) che identificano il valore massimo e il minimo. Se il massimo (o il minimo) distano dalla mediana più di 1.5 volte la differenza tra la mediana stessa e il 75-esimo (o 25-esimo) percentile, allora le linee verticali si fermano ad un valore pari ad 1.5 volte il 75-esimo (o il 25-esimo) percentile ed i dati più estremi vengono considerati outliers e rappresentati con un piccolo cerchio. In Figura 3.3 abbiamo raprresentato tre gruppi di valori estratti casualmente nell’intervallo da 0 ad 1. set.seed(1234) A &lt;- runif(20) B &lt;- runif(20) C &lt;- runif(20) series &lt;- rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), each = 20) values &lt;- c(A, B, C) boxplot(values ~ series) Figura 3.3: Esempio di boxplot in R 3.3 Altre letture F. Crivellari (2006). Analisi statistica dei dati con R. Apogeo, Milano. G. Leti and L. Cerbara (2009). Elementi di statistica descrittiva. Il Mulino Editore, Bologna. R.R Sokal and Rohlf, F.J. (1981). Biometry. W.H. Freeman and Company, Books. 3.4 Domande ed esercizi Illustrare e discutere i principali indici di tendenza centrale per le variabili quantitative Illustrare e discutere i principali indici di variabilità per le variabili quantitative Illustrare e discutere il coefficiente di correlazione di Pearson Un’analisi chimica è stata eseguita in triplicato e i risultati sono stati i seguenti: 125, 169 and 142 ng/g. Calcolate la media e tutti gli indicatori di variabilità che conoscete. In che modo può essere espressa l’incertezza assoluta della misura? Un ricercatore ha misurato l’altezza di quattro alberi ed il loro diametro (entrambi in metri). I risultati ottenuti sono i seguenti: Altezza &lt;- c(2.3, 2.7, 3.1, 3.5) e Diametro &lt;- c(0.46, 0.51, 0.59, 0.64). Calcolare il coefficiente di correlazione di Pearson e valutare l’entità della correlazione in base ai valori massimi e minimi ammissibili per questa statistica. Considerate il file EXCEL ‘rimsulfuron.csv’, che potete trovare in questo percorso: https://www.casaonofri.it/_datasets/rimsulfuron.csv. In questo file sono riportati i risultati di un esperimento con 16 trattamenti e 4 repliche, nel quale sono stati posti a confronti diversi erbicidi e/o dosi per il diserbo nel mais. Calcolare le medie produttive ottenute con le diverse tesi sperimentali e riportarle su un grafico, includendo anche un’indicazione di variabilità. Verificare se la produzione è correlata con il ricoprimento (WeedCover) delle piante infestanti. "],["le-relazioni-causa-effetto.html", "Capitolo 4 Le relazioni causa-effetto 4.1 Modelli matematici e statistici 4.2 Componenti di un modello 4.3 Fitting di un modello 4.4 Esempio 1: il ‘modello della media’ 4.5 Esempio 2: un predittore quantitativo 4.6 Esempio 3: un predittore nominale 4.7 L’analisi della varianza (ANOVA) 4.8 Example 4: due predittori nominali 4.9 Example 5: due predittori nominali con interazione 4.10 Interazione tra fattori sperimentali 4.11 Example 5 (segue) 4.12 Dati non bilanciati 4.13 Esempio 6: un CRBD con un valore mancante 4.14 Conclusioni 4.15 Altre letture 4.16 Domande ed esercizi", " Capitolo 4 Le relazioni causa-effetto Nel capitolo precedente abbiamo visto come possiamo utilizzare semplici statistiche per descrivere alcuni tratti dei nostri dati sperimentali, come la tendenza centrale e la dispersione e, se abbiamo due o più variabili, abbiamo visto come possiamo descrivere la loro variabilità congiunta. Nel lavoro di ricerca, la relazione tra variabili più importante è la cosiddetta causalità, che si verifica ogni volta che una variabile (solitamente denominata “predittore”) provoca un cambiamento in un’altra variabile (solitamente denominata “risposta”); ad esempio, una variazione del genotipo può causare un cambiamento nella resa del frumento, oppure una variazione nella tecnica di lavorazione può causare un cambiamento nel tempo di emergenza del mais. Questo effetto diretto del predittore sulla risposta (e non viceversa) è ciò che rende la causalità diversa, ad esempio, dalla correlazione, che implica solo variazione congiunta, senza una chiara distinzione tra predittore e risposta, cioè tra la causa e l’effetto. Gli esperimenti controllati, replicati e randomizzati sono particolarmente adatti a stabilire relazioni causa-effetto; infatti, la probabilità di effetti confondenti è ridotta al minimo, così che le discrepanze tra le unità osservate sottoposte a trattamenti diversi possono essere ragionevolmente attribuite all’effetto di tali trattamenti sperimentali e non ad altre cause sistematiche, ma ignote. 4.1 Modelli matematici e statistici Per descrivere le relazioni causali, possiamo utilizzare i modelli statistici, cioè delle equazioni in cui le osservazioni sperimentali sono prodotte come risultato dell’effetto di uno o più predittori. In effetti, questo approccio alla scienza è fondato sull’eredità galileiana, che ci porta ad immaginare che il funzionamento della natura sia descrivibile utilizzando il linguaggio universale della matematica. In effetti era proprio questa l’ambizione più grande degli scienziati all’inizio dell’ottocento: conoscendo lo stato iniziale di un sistema, doveva essere possibile prevederne con precisione l’evoluzione futura. Laplace diceva: “Possiamo considerare lo stato attuale dell’universo come l’effetto del suo passato e la causa del suo futuro. Un intelletto che ad un determinato istante dovesse conoscere tutte le forze che mettono in moto la natura, e tutte le posizioni di tutti gli oggetti di cui la natura è composta, se questo intelletto fosse inoltre sufficientemente ampio da sottoporre questi dati ad analisi, esso racchiuderebbe in un’unica formula i movimenti dei corpi più grandi dell’universo e quelli degli atomi più piccoli; per un tale intelletto nulla sarebbe incerto ed il futuro proprio come il passato sarebbe evidente davanti ai suoi occhi”. In realtà si è ben presto scoperto che si trattava di un’ambizione irrealistica, non tanto e non solo per la comparsa della meccanica quantistica un secolo dopo, ma anche per l’aumento di importanza degli studi in ambito psichiatrico e medico/biologico. Questi studi, infatti, venivano (e vengono) eseguiti su organismi viventi molto complessi, che, se sottoposti allo stesso stimolo, davano (e danno) risposte altamente variabili e, spesso, anche difficilmente misurabili e controllabili. Queste difficoltà fecero prevalere, tra i biologi, la convinzione che la natura funzionasse in base a meccanismi deterministici ben definiti, anche se difficilmente osservabili nella pratica sperimentale, a causa dei numerosi elementi d’incertezza che si manifestavano nel corso delle osservazioni sperimentali. Insomma, la natura è perfetta, ma l’osservazione è fallace, perché influenzata dalla presenza di una forte componente stocastica ed imprevedibile, che va sotto il nome generico di errore sperimentale. Di questo abbiamo già parlato nei capitoli precedenti. Abbiamo anche visto che Ronald Fisher, nel suo famoso testo “Il disegno degli esperimenti” ha posto le basi per una corretta metodica sperimentale, finalizzata a minimizzare l’impatto della componente stocastica e, soprattutto, ad impedire che essa si confondesse con gli effetti degli stimoli sperimentali in studio. Minimizzare, tuttavia, non significa eliminare ed è evidente che, pur con tutti gli sforzi possibili, è impossibile evitare che i risultati sperimentali siano influenzati, sempre e comunque, da una certa quota di variabilità stocastica. Si vengono quindi a creare due contrapposte situazioni: la verità ‘vera’, immanente, che ‘agisce’ in base a meccanismi deterministici causa-effetto ben definiti. La ‘verità’ sperimentale, che si produce a partire dalla verità ‘vera’, per effetto dell’azione di elementi perturbativi casuali, che non ci permettono di osservare la verità ‘vera’. Di conseguenza, la descrizione di qualunque risultato sperimentale non può essere realistica se non utilizzando un modello in grado di considerare contemporaneamente sia i nessi causa-effetto, che le altre forze ignote e, almeno apparentemente, di natura stocastica. I modelli matematici che incorporano anche effetti di natura casuale sono detti modelli statistici. 4.2 Componenti di un modello In semplice linguaggio algebrico, possiamo scrivere un modello causa-effetto utilizzando un’a funzione’equazione generale come la seguente: \\[ Y_E = f(X, \\theta)\\] dove \\(Y_E\\) è l’effetto atteso dello stimolo \\(X\\), secondo la funzione \\(f\\), basata su una collezioni di parametri \\(\\theta\\) Le componenti di questo modello sono la risposta attesa (\\(Y_E\\)) che è l’oggetto del nostro studio e può assumere le forme più disparate: spesso è numerica, ma a volte rappresenta una qualità. In questo libro consideremo solo la situazione in cui \\(Y_E\\) è rappresentato da una sola variabile (analisi univariata), ma esistono casi in cui viene osservata ed analizzata la risposta di soggetti in relazione a molte variabili (analisi multivariata). Lo stimolo sperimentale (\\(X\\)) è costituito da una o più variabili continue, discrete o categoriche (predittori), che rappresentano i trattamenti sperimentali. Insieme ad \\(Y_E\\), \\(X\\) è l’elemento noto di un esperimento, in quanto viene definito a priori in fase di progettazione. La ‘funzione’ di risposta (\\(f\\)) è un’equazione, lineare o non-lineare, scelta in base a considerazioni di carattere biologico, o con un approccio puramente empirico, osservando l’andamento della curva di risposta. I parametri di una funzione (\\(\\theta\\)) sono un insieme di valori numerici che permettono di definire l’equazione di risposta. Il predittore può essere rappresentato da una dose; ad esempio un aumento della dose di una sostanza erbicida provoca una diminuzione della crescita delle erbe infestanti. In questo caso usiamo il termine modello dose-risposta, che è forse uno dei modelli più famosi e risale a Paracelso (1493-1541), che coniò la sua famosa massima “Cosa c’è che non sia veleno? Tutte le cose sono veleno e nulla è senza veleno. Soltanto la dose determina che una cosa non è un veleno”. Il modello sovrastante, in accordo con la logica galileiana, postula che un fenomeno naturale segua una legge ben definita. Tuttavia, la realtà è più complessa delle nostre aspettative e, a causa di errori sperimentali e altri effetti di natura puramente casuale, non osserviamo mai il risultato atteso \\(Y_E\\), ma osserviamo un valore diverso \\(Y_O \\neq Y_E\\). Dobbiamo quindi ampliare il modello aggiungendo la componente stocastica \\(\\varepsilon\\): \\[ Y_O = f(X, \\theta) + \\varepsilon\\] cioè il cosiddetto ‘residuo’, la discrepanza tra ciò che prevede il modello e ciò che effettivamente osserviamo: \\[\\varepsilon = Y_O - Y_E \\] In un esperimento con \\(n\\) unità sperimentali, abbiamo \\(n\\) residui, con media pari a 0 e deviazione standard pari a \\(\\sigma\\) (Root Mean Squared Error, ovvero l’RMSE o \\(\\sigma\\)). In parole povere, i residui misurano quanto “cattivo” è il modello: più alti sono i residui, peggiore è la capacità del modello di descrivere una certa relazione causa-effetto. 4.3 Fitting di un modello Nella ricerca, possiamo utilizzare i modelli per capire se due o più variabili sperimentali sono in una relazione causa-effetto tra di loro. Il nostro lavoro consisterà nel: definire un modello un modello statistico potenzialmente capace di descrivere adeguatamente le relazioni causa-effetto in studio. In altre parole si potrebbe dire che lo sforzo è quello di tradurre un’ipotesi scientifica in un modello statistico, per verificare se il modello è supportato dai dati, così come l’ipotesi scientifica di cui esso è la ‘traduzione’. Questo modello sarà posto nella sua forma generale e sarà basato su una serie di parametri dal valore ignoto (\\(\\theta\\) e \\(\\sigma\\)). Eseguire l’esperimento e raccogliere i dati; utilizzare il set di dati per assegnare valori precisi a tutti i parametri ignoti (fitting del modello o, in alcune applicazioni, calibrazione del modello); valutare se il modello parametrizzato fornisca una descrizione accurata dei dati sperimentali (valutazione del modello); se necessario, selezionare il modello migliore tra tutti quelli quelli possibili (confronto dei modelli). Il fitting del modello viene solitamente eseguito dall’algoritmo dei “minimi quadrati”, che consiste nel selezionare i valori dei parametri che minimizzano la somma dei residui al quadrato: \\[RSS = \\sum_{i = 1}^n{\\left( Y_{O_i} - Y_{E_i} \\right)^2}\\] In generale, la minimizzazione dei quadrati dei residui non viene eseguita mediante calcoli manuali, in quanto è molto più semplice avvalersi delle funzioni di adattamento più adatte in R. In particolare, per i modelli lineari utilizzeremo la funzione lm(), secondo la seguente sintassi: mod &lt;- lm(Y ~ X dati = set di dati) Il primo argomento è l’equazione che vogliamo adattare: sul lato sinistro dobbiamo specificare il nome della variabile di risposta, la ‘tilde’ (~) significa ‘è una funzione di’ e sostituisce il segno ‘=’, mentre, sul lato destro, dobbiamo specificare il nome del/i predittore/i. Come secondo argomento, se necessario, forniamo il nome del dataset in cui sono archiviate le variabili. Non dobbiamo specificare l’intercetta e il termine stocastico \\(\\varepsilon\\), che sono inclusi per impostazione predefinita. C’è inoltre da tenere presente che, prima dell’analisi, ogni volta che vogliamo utilizzare una variabile numerica come fattore, dovremmo eseguire esplicitamente questa trasformazione utilizzando la funzionottenere risultati sbagliati (come vedremo nei capitoli seguenti). Un modello causa-effetto completamente specificato può fornire una buona descrizione dei dati sperimentali, postulando l’esistenza di un meccanismo causa-effetto che produce i risultati sperimentali. Con la dovuta prudenza, questo modello può essere utilizzato per fare previsioni; ad esempio, il modello precedente suggerisce che una fertilizzazione con azoto di 150 kg/ha dovrebbe, prevedibilmente, dare come risultato un livello di resa \\(Y_E = 65\\) quintali per ettaro. 4.4 Esempio 1: il ‘modello della media’ Abbiamo condotto un esperimento misurativo, in cui abbiamo raccolto tre campioni di acqua da un pozzo, per misurare la concentrazione di una sostanza xenobiotica. I risultati sono 116, 119, 125 mg/L e vogliamo calcolare la media e la deviazione standard dei tre campioni. Questo problema è piuttosto semplice e potrebbe essere meglio risolto utilizzando semplici statistiche descrittive (vedi Capitolo 3); tuttavia, è interessante vedere come lo stesso problema può essere risolto con un’operazione di ‘model fitting’: non abbiamo alcun predittore e, pertanto, possiamo supporre che le osservazioni siano generate in base al modello della media, che abbiamo mostrato in precedenza (\\(Y_i = \\mu + \\varepsilon_i\\)). Assegnare un valore a tutti i parametri sconosciuti è banale, utilizzando i semplici calcoli mostrati nel Capitolo 3 (vale a dire, \\(\\mu = 120\\) e \\(\\sigma = 4.58\\)). Tuttavia, possiamo ottenere gli stessi risultati utilizzando l’approccio di minimizzazione dei minimi quadrati, come mostrato nel riquadro seguente. Si noti che utilizziamo ‘1’ come lato destro dell’equazione del modello, poiché non abbiamo alcun predittore. Y &lt;- c(116, 119, 125) mod &lt;- lm(Y ~ 1) La stima di \\(\\mu\\) può essere ottenuta con la seguente funzione R: coef(mod) ## (Intercept) ## 120 Per quanto riguarda la componente stocastica, possiamo ottenere i residui, la loro devianza e la loro deviazione standard con le seguenti funzioni R: # Residui residuals(mod) ## 1 2 3 ## -4 -1 5 # # Devianza dei residui deviance(mod) ## [1] 42 # # Deviazione standard dei residui summary(mod)$sigma ## [1] 4.582576 Il modello della media descrive una situazione in cui non abbiamo predittori e, pertanto, non vi sono nessi causa-effetto; di conseguwnza, è il peggior modello possibile, il punto di riferimento rispetto al quale valutare ogni altro modello alternativo. Per queste sue caratteristiche, il modello della media è spesso definito come modello nullo. 4.5 Esempio 2: un predittore quantitativo L’algoritmo dei minimi quadrati è facile da comprendere se consideriamo un’indagine in cui la resa del mais (in q/ha) è stata determinata, come conseguenza della copertura delle erbacce, all’inizio del ciclo colturale. In una situazione del genere, potremmo aspettarci una relazione causa-effetto, in cui la copertura delle erbacce è il predittore e la resa è la risposta, secondo la funzione lineare (linea retta) \\(Y_i = b_0 + b_1 \\, Xx_i + \\varepsilon_i\\), che è solitamente nota come modello di regressione semplice. I due parametri \\(b_0\\) e \\(b_1\\) rappresentano, rispettivamente, l’intercetta (livello di resa senza erbacce) e la pendenza (variazione della resa per un aumento di 1 unità nella copertura delle erbacce). Per stimare questi due valori, possiamo usare la funzione ‘lm()’ (riquadro codice 4.2), che produce i risultati mostrati nella Figura 4.1. # Code box 4.2 # Fitting a simple linear regression model # Entering the data yield &lt;- c(29.8, 88.9, 47.0, 96.6, 83.0, 95.3, 91.5, 97.9, 89.2, 88.3, 96.9, 93.9, 84.6, 51.9, 21.8, 35.7) weedCover &lt;- c(105.35, 27.5, 68.8, 23.8, 12.7, 42.7, 31.5, 37.8, 18.9, 35.8, 44.5, 11.4, 31.6, 87.9, 133.9, 136.525) # Fitting the model mod &lt;- lm(yield ~ weedCover) # Inspecting the estimates coef(mod) ## (Intercept) weedCover ## 106.5979798 -0.6033652 Figura 4.1: Example 2: the least square estimate is represented by the straight line that passes as close as possible to the observed points. 4.6 Esempio 3: un predittore nominale Immaginiamo un esperimento sul campo per confrontare la resa di quattro genotipi di avena (denominati A, B, C e D), con un disegno completamente randomizzato con tre repliche. I risultati (in tonnellate per ettaro) sono mostrati nella Tabella 4.1. Tabella 4.1: Esempio di una dataset proveniente da una prova varietale a randomizzazione completa con quattro genotipi di avena (A, B, C and D) e tre repliche. A 4.5 4.3 4.8 B 3.9 3.6 4.0 C 3.9 4.2 4.3 D 4.6 4.7 5.0 In questo esperimento, abbiamo una risposta quantitativa (la resa) e un fattore nominale (il genotipo) e la relazione causa-effetto tra queste due variabili può essere descritta con il modello seguente: \\[Y_i = \\mu + \\alpha_j + \\varepsilon_i\\] Questo modello postula che ogni osservazione \\(Y_i\\) derivi dal valore \\(\\mu\\) (la cosiddetta intercetta) più le quantità \\(\\alpha_j\\), che dipendono dal genotipo \\(j\\), più gli effetti stocastici \\(\\varepsilon_i\\), che sono specifici per ogni osservazione ed hanno media 0 e una deviazione standard pari a \\(\\sigma\\). Per comprendere il significato biologico di \\(\\mu\\) ed \\(\\alpha\\) dobbiamo entrare un po’ di più nei dettagli matematici. Consideriamo la prima osservazione \\(Y_1 = 4.5\\); dobbiamo stimare tre valori (\\(\\mu\\), \\(\\alpha_1\\) e \\(\\varepsilon_1\\)) che, sommati, restituiscano questa osservazione. Chiaramente il problema è indeterminato, in quanto esistono infinite triplette di valori, che, sommate, restituiscono 4.5; pertanto è necessario imporre dei vincoli su alcuni parametri del modello (parametrizzazioni del modello). Un vincolo molto comune è \\(\\alpha_1 = 0\\) (vincolo sul trattamento): \\[\\left\\{ {\\begin{array}{l} \\mu_1 = \\mu + \\alpha_1 = \\mu + 0\\\\ \\mu_2 = \\mu + \\alpha_2 \\\\ \\mu_3 = \\mu + \\alpha_3 \\\\ \\mu_4 = \\mu + \\alpha_4 \\end{array}} \\right.\\] Con tale vincolo, \\(\\mu\\) è la media del primo genotipo (in R: primo in ordine alfabetico), mentre \\(\\alpha_2\\), \\(\\alpha_3\\) e \\(\\alpha_4\\) sono, rispettivamente, le differenze tra le medie del secondo, terzo e quarto genotipo, rispetto al primo. In generale, con questa parametrizzazione, i parametri del modello sono medie o differenze tra medie. Un altro possibile vincolo è \\(\\sum{\\alpha_j} = 0\\) (vincolo sulla somma). Se prendiamo l’equazione precedente e sommiamo tutti i membri otteniamo: \\[\\mu_1 + \\mu_2 + \\mu_3 + \\mu_4 = 4 \\mu + \\sum{\\alpha_j}\\] Imponendo il vincolo di somma a zero otteniamo: \\[\\mu_1 + \\mu_2 + \\mu_3 + \\mu_4 = 4 \\mu\\] e quindi a: \\[\\mu = \\frac{\\mu_1 + \\mu_2 + \\mu_3 + \\mu_4}{4}\\] Con questa parametrizzazione \\(\\mu\\) è la media generale dei dati, mentre i valori \\(\\alpha_j\\) rappresentano le differenze tra le medie dei trattamenti e la media generale (effetti dei trattamenti): valori \\(\\alpha\\) positivi ed elevati identificano i genotipi superiori alla media, mentre valori \\(\\alpha\\) elevati, ma negativi identificano i genotipi inferiori alla media. In generale, con questa parametrizzazione, i parametri del modello rappresentano medie ed effetti. Un terzo possibile vincolo si ottiene rimuovendo l’intercetta (ovvero, imponendo che \\(\\mu = 0\\)). In questo caso, i valori di \\(\\alpha_j\\) saranno le medie dei genotipi ed il modello riduce a: \\[Y_i = \\mu_j + \\varepsilon_i\\] La selezione dei vincoli spetta all’utente, a seconda degli obiettivi dell’esperimento. In R, il vincolo del trattamento è utilizzato di default, sebbene gli altri vincoli possano essere facilmente ottenuti, utilizzando la codifica appropriata. La stima dei parametri del modello potrebbe essere facilmente eseguita a mano, ma noi utilizziamo la funzione ‘lm()’ in R. Yield &lt;- c(4.5, 4.3, 4.8, 3.9, 3.6, 4.0, 3.9, 4.2, 4.3, 4.6, 4.7, 5.0) Genotype &lt;- rep(LETTERS[1:4], each = 3) mod &lt;- lm(Yield ~ Genotype) I parametri stimati, i residui, la deviazione residua e la deviazione standard possono essere ottenuti con la solita codifica: # Stima dei parametri coef(mod) ## (Intercept) GenotypeB GenotypeC GenotypeD ## 4.5333333 -0.7000000 -0.4000000 0.2333333 # # Residui residuals(mod) ## 1 2 3 4 5 ## -0.03333333 -0.23333333 0.26666667 0.06666667 -0.23333333 ## 6 7 8 9 10 ## 0.16666667 -0.23333333 0.06666667 0.16666667 -0.16666667 ## 11 12 ## -0.06666667 0.23333333 # # Devianza dei residui deviance(mod) ## [1] 0.3866667 # # Deviazione standard del residui (RMSE) summary(mod)$sigma ## [1] 0.2198484 Ora che il modello è completamente specificato, abbiamo tutti gli ingredienti per descrivere le 12 osservazioni, sommando \\(\\mu + \\alpha_j + \\varepsilon_i\\); ad esempio, per la prima osservazione, appartenente al primo genotipo, abbiamo: \\[y_1 = 4.5 = 4.533 + 0 - 0.033\\] mentre, per la quarta osservazione, appartenente al 2° genotipo, abbiamo: \\[y_4 = 3.9 = 4.533 - 0.7 + 0.067\\] Per completezza, potrebbe essere utile mostrare che, in R, possiamo modificare la parametrizzazione, impostando l’argomento ‘contrasts’ e passando un elenco di fattori associati alla parametrizzazione richiesta. Ad esempio, se utilizziamo Treat = \"contr.sum\", otteniamo il vincolo sulla somma; di conseguenza, l’effetto dell’ultimo genotipo non è mostrato, perché è vincolato ad eseere l’opposto della somma degli altri tre effetti. mod2 &lt;- lm(Yield ~ Genotype, contrasts = list(Genotype = &quot;contr.sum&quot;)) coef(mod2) ## (Intercept) Genotype1 Genotype2 Genotype3 ## 4.3166667 0.2166667 -0.4833333 -0.1833333 Un’altra possibile parametrizzazione consiste nel rimuovere l’intercetta, che è possibile utilizzando -1 sul lato destro dell’espressione, come mostrato di seguito. mod3 &lt;- lm(Yield ~ Genotype - 1) coef(mod3) ## GenotypeA GenotypeB GenotypeC GenotypeD ## 4.533333 3.833333 4.133333 4.766667 Esistono diversi altri metodi per modificare la parametrizzazione, sia globalmente (per l’intera sessione R) sia a livello di fattore; ulteriori informazioni sono disponibili in letteratura. 4.7 L’analisi della varianza (ANOVA) In questo secondo esempio abbiamo descritto una relazione causa-effetto, tramite un modello contenente un predittore. L’RMSE (\\(\\sigma\\)) è uguale a 0.220, ma questa non è una buona metrica per capire se la relazione causa-effetto è rilevante o meno. Una possibilità è quella di dividere l’RMSE per la media dei valori osservati, per ottenere il coefficiente di variabilità (RRMSE: Relative Root Mean Squared Error), che è 0.051 (o 5.1%), il che indica che l’errore residuo è piuttosto piccolo, rispetto al valore medio atteso. Un altro indicatore per descrivere la bontà della relazione causa-effetto definita dal modello è il cosiddetto coefficiente di determinazione (R2), ottenuto sottraendo da 1 il rapporto tra la devianza dei residui e la devianza totale delle osservazioni (che poi sarebbe la devianza dei residui del modello nullo). Nel nostro caso, il modello nullo è ottenuto trascurando l’effetto del genotipo e la devianza dei residui è quella indicata nel box sottostante: modnull &lt;- lm(Yield ~ 1) deviance(modnull) ## [1] 1.936667 Il coefficiente di determinazione è quindi: \\[R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{0.3866667}{1.936667} = 0.800\\] cosa che può essere verificata utilizzando il codice R: summary(mod)$r.squared ## [1] 0.8003442 Il coefficiente di determinazione varia da 0 ad 1, più è alto il valore tanto migliore è la bontà del modello. Oltre a queste statistiche (RMSE, RRMSE e R2), vi è una tecnica famosissima per valutare l’entità dell’evidenza in favore dell’esistenza di una relazione causa effetto ben definita; questa tecnica si chiama Analisi della Varianza (ANOVA) ed è stata originariamente ideata da Ronald Fisher durante gli anni ’30 del XX secolo; oggi è ancora molto utilizzata, seppure in una forma leggermente diversa da quella originale. Il principio di fondo è che, considerando un modello che contenga almeno un predittore, è sempre possibile associare allo stesso dataset un secondo modello ‘nullo’ (modello della media), ottenuto dal precedente per rimozione del predittore. Ad esempio, con riferimento all’esempio 2, abbiamo già visto che il modello ANOVA è: Yield ~ Genotype mentre il modello nullo è: Yield ~ 1 Rimuovere l’effetto del genotipo dal modello npn può che indurre un incremento dei residui, dato che non si tiene più in considerazione il fatto che parte della differenza tra le osservazioni è dovuto al fatto che esse appartengono a genotipi di versi. Infatti, il codice sovrastante e sottostante mostrano che la devianza dei residui (RSS: Residual Sum of Squares) è pari a: epsilon &lt;- residuals(mod) RSS &lt;- sum(epsilon^2) RSS ## [1] 0.3866667 mentre la devianza dei residui del modello nullo (pari alla devianza totale delle osservazioni), è pari a: # Residual deviance null model RSS.null &lt;- sum(residuals(modnull)^2) RSS.null ## [1] 1.936667 Insomma, rimuovendo l’effetto del genotipo, il modello è ‘peggiorato’, con un incremento dei residui quantificabile come differenza: # Contribution of genotype effect SS_g &lt;- RSS.null - RSS SS_g ## [1] 1.55 È evidente che più è grande questa differenza, più è grande l’effetto del genotipo. In altre parole, abbiamo appena scomposto la devianza totale delle osservazioni (\\(SS_{tot} = 1.937\\)) in due quote, una dovuta all’effetto causale del trattamento sperimentale (\\(SS_g = 1.55\\)) e l’altra dovuta a tutti gli altri effetti ignoti di natura casuale (errore sperimentale: \\(RSS = 0.387\\)). Questa seconda quota costituisce una specie di ‘rumore di fondo’, contro il quale si può valutare il ‘segnale’, cioè l’intensità dell’effetto del trattamento sperimentale. Come abbiamo visto nel Capitolo 3, non possiamo confrontare direttamente \\(SS_g\\) e \\(RSS\\), poiché queste due devianze hanno un diverso numero di gradi di libertà (DF); il numero di DF per il trattamento è uguale al numero dei suoi livelli meno uno (\\(DF_g\\) = 3), mentre il numero di gradi di libertà per la devianza residua \\(RSS\\) è \\(p \\times (k -1)\\), dove \\(p\\) è il numero di trattamenti e \\(k\\) è il numero di repliche, supponendo che questo sia costante tra i trattamenti. Di conseguenza, \\(DF_{RSS} = 4 \\times (3 - 1) = 8\\). Possiamo quindi calcolare le relative varianze (Qudrati Medi: MS) come segue: # Varianza del genotipo MS_g &lt;- SS_g/3 MS_g ## [1] 0.5166667 # # Varianza del residuo RMS &lt;- RSS/8 RMS ## [1] 0.04833333 Queste due varianze (trattamento e residuo) possono essere confrontate direttamente, utilizzando il cosiddetto rapporto F: \\[F = \\frac{MS_g}{RMS} = \\frac{0.517}{0.048} = 10.69\\] Il nome ‘rapporto F’ deriva da Fisher, che lo inventò. Mostra che la variabilità imposta dal trattamento sperimentale è più di 10 volte superiore alla variabilità dovuta al rumore di fondo (errore sperimentale), il che supporta l’idea che l’effetto causale del genotipo sulla resa sia molto rilevante. In termini generali, più alto è il rapporto F, più forte è il nesso causa-effetto. Possiamo riassumere questi risultati nella cosiddetta tabella ANOVA, che si ottiene facilmente utilizzando il metodo ‘anova()’ con R. anova(mod) ## Analysis of Variance Table ## ## Response: Yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Genotype 3 1.55000 0.51667 10.69 0.003584 ** ## Residuals 8 0.38667 0.04833 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Rispetto a quanto esposto in precedenza, la tabella ottenuta con R contiene solo un valore che non abbiamo ancora spiegato, il cosidetto P-level, che si trova all’estrema destra (P = 0.003584). Si tratta di un indicatore inferenziale che sarà illustrato nei Capitoli seguenti anche se è opportuno dare ora indicazioni per la sua interpretazione. In dettaglio, più il P-level è basso, più è forte l’evidenza scientifica contro l’ipotesi ‘nulla’ che il trattamento sperimentale (in questo caso il genotipo) non abbia avuto alcun effetto sulla variabile risposta (produzione della coltura). Ancora più in dettaglio, se il P-level è inferiore a 0.05 ed è accompagnato da uno o più asterischi, la conclusione è che l’effetto del trattamento è statisticamente significativo. 4.8 Example 4: due predittori nominali Consideriamo lo stesso esperimento dell’esempio precedente ed immaginiamo che sia stato disegnato a blocchi randomizzati (la prima osservazione di ogni genotipo è stata presa nel primo blocco, la seconda nel secondo blocco e così via). In questo caso, il nesso causa-effetto e, di consegeunza, il modello interpretativo sono diversi, perché la resa dipende da due fattori sperimentali, ovvero il genotipo e il blocco. L’equazione è: \\[ Y_{ij} = \\mu + \\gamma_i + \\alpha_j + \\varepsilon_{ij}\\] dove \\(Y_{ij}\\) è la resa parcellare nell’ \\(i\\)esimo blocco e per il \\(j\\)esimo genotipo, \\(\\mu\\) è l’intercetta, \\(\\gamma_i\\) è l’effetto del \\(i\\)esimo blocco, \\(\\alpha_j\\) è l’effetto del \\(j\\)esimo genotipo e \\(\\varepsilon\\) è l’errore residuo di ogni parcella, con deviazione standard pari a \\(\\sigma\\). Come abbiamo fatto per il modello ANOVA ad una via, dobbiamo porre dei vincoli sui valori \\(\\alpha\\) e \\(\\gamma\\), in modo che i parametri del modello siano stimabili; in particolare, imporremo che \\(\\alpha_1 = \\gamma_1 = 0\\), in modo che \\(\\mu\\) è la produzione nel primo blocco e col primo genotipo (in R, convenzionalmente il primo in ordine alfabetico). Abbiamo quindi 3 parametri da stimare per l’effetto del genotipo e 2 parametri da stimare per l’effetto del blocco, oltre a \\(\\sigma\\). La stima dei parametri del modello può essere eseguita con R, aggiungendo l’effetto blocco all’equazione del modello: # I dati sono stati inseriti in un box precedente, # qui creiamo il vettore che identifica il blocco Block &lt;- rep(LETTERS[1:3], times = 4) mod &lt;- lm(Yield ~ Genotype + Block) Le stime dei parametri sono: # Alpha e beta coef(mod) ## (Intercept) GenotypeB GenotypeC GenotypeD BlockB ## 4.4416667 -0.7000000 -0.4000000 0.2333333 -0.0250000 ## BlockC ## 0.3000000 # # Sigma summary(mod)$sigma ## [1] 0.1443376 I residui e la loro devianza sono: epsilon &lt;- residuals(mod) RSS &lt;- sum(epsilon^2) RSS ## [1] 0.125 Come previsto, i residui di questo modello sono più piccoli e quindi hanno una devianza minore di quelli del modello precedente, senza l’effetto del blocco. La rimozione dell’effetto del blocco fa si che la devianza del residuo aumenti da 0.125 a 0.38667 (vedi sopra), con una differenza pari a 0.262, che misura appunto l’effetto del blocco 8devianza del blocco: SSb). Anche in questo caso, se consideriamo un modello ridotto, contenente solo il blocco, ma non il genotipo (quindi rimuoviamo dal modello l’effetto del genotipo), possiamo misurare la devianza del fattore sperimentale rimosso, che, coerentemente con quanto visto in precedenza, ammonta a 1.55. # Rimozione dei blocchi mod2 &lt;- lm(Yield ~ Genotype) # Stesso modello di prima deviance(mod2) ## [1] 0.3866667 SS_b &lt;- deviance(mod2) - RSS SS_b ## [1] 0.2616667 # Rimozione dei genotipi mod3 &lt;- lm(Yield ~ Block) deviance(mod3) ## [1] 1.675 SS_g &lt;- deviance(mod3) - RSS SS_g ## [1] 1.55 Il numero di gradi di libertà è, rispettivamente, 11 per la devianza totale (\\(SS_{tot} = n - 1 = 12 - 1 = 11\\)), 3 per i genotipi (numero dei genotipi meno 1) e 2 per i blocchi (numero dei blocchi meno 1); per sottrazione, arriviamo a 6 DF per la devianza del residuo. A questo punto possiamo calcolare le varianze dei blocchi, dei genotipi e del residuo, che anche in questo caso è attribuibile a tutte le sorgenti di variabilità casuali non controllate (errore sperimentale o rumore di fondo). In questo caso possiamo calcolare due rapporti F, uno per l’effetto del blocco e uno per l’effetto del genotipo; per comodità, possiamo saltare tutti i calcoli manuali e arrivare direttamente alla tabella ANOVA finale usando il metodo ‘anova()’ in R. anova(mod) ## Analysis of Variance Table ## ## Response: Yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Genotype 3 1.55000 0.51667 24.80 0.0008833 *** ## Block 2 0.26167 0.13083 6.28 0.0337847 * ## Residuals 6 0.12500 0.02083 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 I rapporti F suggeriscono che l’effetto causale del genotipo è elevato e significativo (presenza di asterischi), mentre l’effetto blocco è significativo, ma il valore F è più basso e P è più alto di quello del genotipo, il che porta a pensare che l’effetto prodotto dal blocco sia meno rilevante. 4.9 Example 5: due predittori nominali con interazione Immaginiamo che l’esperimento presentato nell’Esempio 1 sia stato ripetuto in un’altra località, utilizzando sempre un disegno completamente randomizzato. I dati osservati sono riportati nella Tabella 4.2. Tabella 4.2: Risultati di un esperimento di campo a randomizzazione completa per il confronto di quattro genotipi di avena (A, B, C and D), ripetuto in due località. Genotype Location Yield A LOC1 4.5 A LOC1 4.3 A LOC1 4.8 B LOC1 3.9 B LOC1 3.6 B LOC1 4.0 C LOC1 3.9 C LOC1 4.2 C LOC1 4.3 D LOC1 4.6 D LOC1 4.7 D LOC1 5.0 A LOC2 5.4 A LOC2 5.5 A LOC2 4.1 B LOC2 5.8 B LOC2 7.1 B LOC2 5.8 C LOC2 4.2 C LOC2 4.5 C LOC2 4.8 D LOC2 5.0 D LOC2 6.2 D LOC2 5.6 In questo esperimento abbiamo due fattori incrociati, ma, a differenza dell’esempio precedente, abbiamo tre repliche per ciascuna delle otto combinazioni tra i livelli di genotipo e località. In questo modo, oltre agli effetti di genotipo e località, possiamo anche valutare la cosiddetta interazione tra i due fattori sperimentali, che è un’informazione molto importante. 4.10 Interazione tra fattori sperimentali Per comprendere meglio il concetto di interazione, osserviamo la Figura 4.2, dove sono mostrate le medie di quattro trattamenti, ottenuti dalla combinazione fattoriale di un trattamento A con due livelli (A1 e A2) e di un trattamento B con altrettanti livelli (B1 e B2). Nel grafico, ogni combinazione è rappresentata da un simbolo. Concentriamoci un attimo sul grafico di sinistra e consideriamo la prima combinazione in ordine alfabetico (A1B1): per questa, la media è pari a 10. Se passiamo da A1 ad A2, fermo restando B1, l’incremento è + 4. Se invece passiamo da B1 a B2, fermo restando A1, l’incremento è + 5. Si deduce che, se gli effetti fossero puramente additivi, la media di A2B2 dovrebbe essere pari a 10 + 4 + 5 = 19, in quanto vengono modificati entrambi i livelli, da A1 ad A2 e da B1 a B2. Vediamo che l’osservazione conferma questa aspettativa di additività degli effetti e di mancanza di interazione. Al contrario, nel grafico centrale vediamo che il risultato osservato di A2B2 non può essere ottenuto per semplice somma di effetti, perché, a fronte di un risultato atteso pari a 19 otteniamo invece 16. Evidentemente, vi è qualcosa in questa combinazione che altera l’effetto congiunto di A e B. Questo qualcosa può essere quantificato con il valore -3, così che la media A2B2 è pari a 10 + 4 + 5 - 3 = 16. Il valore -3 rappresenta la mancanza di additività o interazione; in questo caso si tratta di interazione semplice, in quanto la graduatoria dei trattamenti non cambia: A2 è sempre meglio di A1 e B2 è sempre meglio di B1, anche se gli effetti non sono quelli previsti. Nel grafico di sinistra la situazione è analoga, ma più estrema: l’effetto dell’interazione è -10 e comporta un’inversione della graduatoria, per cui parliamo di interazione cross-over. Figura 4.2: Esempi di interazione tra fattori sperimentali Perchè siamo così interessati all’interazione e, in particolare, all’interazione cross-over? Esaminiamo più da vicino i valori nel grafico a destra in Figura 4.2, riportandoli nella tabella 4.3, insieme alle medie dei quattro livelli A1, A2, B1 e B2. Le medie delle combinazioni sono dette medie di cella, mentre le medie dei livelli principali sono dette medie marginali, perché si trovano al margine della tabella. Tabella 4.3: Interazione cross-over tra fattori sperimentali B1 B2 Media A1 10.0 15.0 12.0 A2 14.0 9.0 12.0 Media 12.5 11.5 12.0 Se guardassimo solo le medie marginali, avremmo l’impressione sbagliata che il fattore A, da solo, non ha alcun effetto (le medie A1 e A2 sono uguali) e che il fattore B ha solo un piccolissimo effetto. La realtà è invece che entrambi i fattori hanno un grande effetto, ma la presenza dell’interazione lo nasconde completamente, impedendoci di raggiungere conclusioni attendibili guardando ai due fattori, uno separatamente dall’altro. 4.11 Example 5 (segue) Tornando al nostro esempio, è chiaro che le produzioni osservate sono determinate dall’effetto di: genotipo località interazione ‘genotipo \\(\\times\\) località’ Il modello lineare può essere così definito: \\[Y_{ij} = \\mu + \\alpha_i + \\beta_j + \\alpha\\beta_{ij} + \\varepsilon_{ij}\\] dove \\(\\mu\\) è l’intercetta (produzione del primo genotipo nella prima località, sotto il vincolo che \\(\\alpha_1 = \\beta_1 = 0\\)), \\(\\alpha_i\\) è la differenza tra il genotipo \\(i\\)esimo ed il primo in ordine alfabetico, \\(\\beta_j\\) è la differenza tra la località \\(j\\)esima e la prima in ordine alfabetico e \\(\\alpha\\beta_{ij}\\) è l’interazione tra il genotipo \\(i\\)esimo e la località \\(j\\)esima (sotto i vincoli che \\(\\alpha\\beta_{1.} = \\alpha\\beta_{.1} = 0\\)). I residui sono quantificati dai valori \\(\\varepsilon_{ij}\\), con media uguale a 0 e deviazione standard uguale a \\(\\sigma\\). Per stimare i parametri del modello, possiamo utiliozzare R, considerando che il termine di interazione viene codificato con l’operatore ‘:’, ad esempio: Y ~ A + B + A:B che può essere abbreviato come: Y ~ A * B Yield &lt;- c(4.5, 4.3, 4.8, 3.9, 3.6, 4.0, 3.9, 4.2, 4.3, 4.6, 4.7, 5.0, 5.4, 5.5, 4.1, 5.8, 7.1, 5.8, 4.2, 4.5, 4.8, 5.0, 6.2, 5.6) Genotype &lt;- rep(rep(LETTERS[1:4], each = 3), 2) Location &lt;- rep(c(&quot;LOC1&quot;, &quot;LOC2&quot;), each = 12) dfr &lt;- data.frame(Genotype, Location, Yield) mod &lt;- lm(Yield ~ Genotype * Location, data = dfr) # Stima dei parametri coef(mod) ## (Intercept) GenotypeB GenotypeC ## 4.5333333 -0.7000000 -0.4000000 ## GenotypeD LocationLOC2 GenotypeB:LocationLOC2 ## 0.2333333 0.4666667 1.9333333 ## GenotypeC:LocationLOC2 GenotypeD:LocationLOC2 ## -0.1000000 0.3666667 # # Sigma summary(mod)$sigma ## [1] 0.4765326 L’analisi della varianza viene eseguita rimuovendo dal modello i tre termini uno alla volta, ma rispettando un criterio di marginalità, che tenga conto del fatto che l’interazione viene dopo che sono stati inseriti gli effetti principali che la costituiscono e, quindi, dovrebbe essere omessa per prima e non dovrebbe essere lasciata nel modello, quando uno degli effetti principali coinvolti viene rimosso. Lo schema è illustrato nel box seguente. RSS &lt;- deviance(mod) # # rimozione dell&#39;interazione modred &lt;- lm(Yield ~ Genotype + Location, data = dfr) SSint &lt;- deviance(modred) - RSS SSint ## [1] 4.008333 # # rimozione del genotipo E dell&#39;interazione modred &lt;- lm(Yield ~ Location, data = dfr) SSloc &lt;- deviance(modred) - RSS - SSint SSloc ## [1] 2.601667 # # rimozione della località E dell&#39;interazione modred &lt;- lm(Yield ~ Genotype, data = dfr) SSgen &lt;- deviance(modred) - RSS - SSint SSgen ## [1] 6.201667 Anche in questo esempio, abbiamo suddiviso la variabilità totale dei dati in quattro termini, tre dei quali sono correlati all’effetto causale, mentre il quarto è correlato a tutti gli altri effetti casuali. In pratica, i calcoli manuali non sono necessari, perchè possiamo utilizzare la funzione ‘anova()’ in R. Nella tabella sottostante, l’unico elemento di cui non abbiamo parlato finora è il numero di gradi di libertà per l’interazione, che è uguale al prodotto del numero di DF per gli effetti principali. anova(mod) ## Analysis of Variance Table ## ## Response: Yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Genotype 3 2.6017 0.8672 3.8190 0.03077 * ## Location 1 6.2017 6.2017 27.3101 8.322e-05 *** ## Genotype:Location 3 4.0083 1.3361 5.8838 0.00662 ** ## Residuals 16 3.6333 0.2271 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Vediamo che tutti gli effetti in gioco (genotipo, località ed interazione) sono significativi ed hanno quindi un nesso causa-effetto rilevante sulla produzione della coltura. La presnza di un’interaione significativa mostra che, probabilmente, la valutazione dei genotipi performanti non è comune alle due località anche se questa affermazione richiede analisi successive che vedremo in seguito. 4.12 Dati non bilanciati Prima di concludere questo capitolo, è necessario sottolineare che esistono diversi metodi per calcolare la somma dei quadrati per gli effetti del modello e che non portano necessariamente agli stessi risultati, in particolare quando i dati sono non bilanciati, ovvero quando c’è un numero diverso di repliche per ogni gruppo di trattamento. Il metodo da noi proposto si basa su: adattamento del modello completo ai dati osservati rimozione dell’effetto in studio e adattamento del modello ridotto sottrazione della somma residua dei quadrati del modello completo dalla somma residua dei quadrati del modello ridotto. Questo approccio produce la cosiddetta somma marginale dei quadrati e non è lo stesso dell’approccio utilizzato nella funzione ‘anova()’ in base R, che produce la cosiddetta somma sequenziale dei quadrati. Questi due metodi danno gli stessi risultati con dati bilanciati, sebbene, con dati non bilanciati, raccomandiamo la somma marginale dei quadrati, che può essere ottenuta utilizzando la funzione ‘Anova()’ (si noti la lettera maiuscola all’inizio) nel pacchetto ‘car’, come mostrato nel seguente esempio. 4.13 Esempio 6: un CRBD con un valore mancante Se consideriamo i dati nel precedente Esempio 3 e se immaginiamo che il genotipo A manchi dal terzo blocco (vedere il valore ‘NA’ nel riquadro Codice 4.14, che significa Non disponibile), il metodo ‘anova()’ in base R porta a diverse tabelle ANOVA, a seconda dell’ordine con cui i due effetti (genotipo e blocco) vengono inseriti nel modello (vedere riquadro Codice 4.14). Poiché non abbiamo una logica per decidere quale effetto debba essere inserito per primo, le conclusioni che otteniamo con la funzione ‘anova()’ sono puramente arbitrarie, il che non è accettabile nella scienza. # Codice box 4.14 # Dati non bilanciati Yield &lt;- c(4.5, 4.3, NA, 3.9, 3.6, 4.0, 3.9, 4.2, 4.3, 4.6, 4.7, 5.0) Genotype &lt;- rep(LETTERS[1:4], each = 3) Block &lt;- rep(LETTERS[1:3], times = 4) # Adattamento di un modello mod1 &lt;- lm(Yield ~ Genotype + Block) mod2 &lt;- lm(Yield ~ Block + Genotype) # Partizionamento della varianza anova(mod1) ## Analysis of Variance Table ## ## Response: Yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Genotype 3 1.40182 0.46727 19.7671 0.003338 ** ## Block 2 0.16181 0.08090 3.4224 0.115770 ## Residuals 5 0.11819 0.02364 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(mod2) ## Analysis of Variance Table ## ## Response: Yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Block 2 0.10765 0.05383 2.277 0.198135 ## Genotype 3 1.45597 0.48532 20.531 0.003061 ** ## Residuals 5 0.11819 0.02364 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 L’approccio proposto in precedenza, basato sulla rimozione dei due predittori, uno alla volta, porta alla somma dei quadrati mostrata nel Codice box 4.15 e possiamo notare che questa somma di quadrati (per gli effetti genotipo e blocco) sono gli stessi, indipendentemente dall’ordine con cui i due effetti sono stati inclusi nel modello completo. Queste somme marginali di quadrati possono essere riprodotte utilizzando la funzione ‘Anova()’ nel pacchetto ‘car’ e impostando l’argomento ‘type = 2’. Ulteriori informazioni sui tipi di somma di quadrati possono essere trovate in Lansrud (2003). # Casella di codice 4.15 # Rimozione dei predittori uno alla volta (modello 1) RSS &lt;- deviance(mod1) mod1.red &lt;- lm(Yield ~ Block) # Rimozione del genotipo SS_g &lt;- deviance(mod1.red) - RSS SS_g ## [1] 1.455972 mod1.red2 &lt;- lm(Yield ~ Genotype) # Rimozione del blocco SS_b &lt;- deviance(mod1.red2) - RSS SS_b ## [1] 0.1618056 # Rimozione dei predittori uno alla volta (modello 2) RSS &lt;- deviance(mod2) mod2.red &lt;- lm(Yield ~ Block) # Rimozione del genotipo SS_g &lt;- deviance(mod2.red) - RSS SS_g ## [1] 1.455972 mod2.red2 &lt;- lm(Yield ~ Genotype) # Rimozione del blocco SS_b &lt;- deviance(mod2.red2) - RSS SS_b ## [1] 0.1618056 # Utilizzo del metodo Anova() nel pacchetto &#39;car&#39; library(car) Anova(mod1, type = 2) ## Anova Table (Type II tests) ## ## Response: Yield ## Sum Sq Df F value Pr(&gt;F) ## Genotype 1.45597 3 20.5307 0.003061 ** ## Block 0.16181 2 3.4224 0.115770 ## Residuals 0.11819 5 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Anova(mod2, type = 2) ## Anova Table (Type II tests) ## ## Response: Yield ## Sum Sq Df F value Pr(&gt;F) ## Block 0.16181 2 3.4224 0.115770 ## Genotype 1.45597 3 20.5307 0.003061 ** ## Residuals 0.11819 5 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 4.14 Conclusioni In questo capitolo abbiamo presentato un metodo per valutare se un certo set di dati ottenuto da un esperimento controllato può ragionevolmente supportare l’esistenza di relazioni causa-effetto tra le variabili in esame. Questo metodo consiste in: adattamento di un modello causa-effetto ragionevole nei dati osservati; utilizzo del metodo di partizionamento della varianza (ANOVA) per ottenere i quadrati medi (varianze) per tutti gli effetti causali in esame e il quadrato medio per tutti gli altri effetti di natura casuale (quadrato medio residuo); confronto dei quadrati medi per gli effetti causali con il quadrato medio per gli effetti casuali, utilizzando i rapporti F. Più alto è il rapporto F, più forte è la relazione causa-effetto. Per il metodo di partizionamento della varianza con R, sono disponibili due funzioni, ‘anova()’ in base R e ‘Anova()’ nel pacchetto ‘car’. Queste due funzioni forniscono gli stessi risultati con dati bilanciati, ma la seconda è altamente consigliata quando i dati non sono bilanciati. 4.15 Altre letture Faraway, J.J., 2002. Practical regression and Anova using R. In: http://cran.r-project.org/doc/contrib/Faraway-PRA.pdf. Kuehl, R. O., 2000. Design of experiments: statistical principles of research design and analysis. Duxbury Press 4.16 Domande ed esercizi Qual è la differenza tra variazione congiunta e causalità? In valore, cosa intendiamo quando diciamo “effetto del trattamento”? Descrivi in poche frasi cos’è l’ANOVA e perché viene utilizzata. Qual è la definizione di “interazione tra due fattori sperimentali”? Spiega brevemente. Considera il file Excel “rimsulfuron.csv” da https://www.casaonofri.it/_datasets/rimsulfuron.csv (puoi scaricarlo o leggerlo direttamente dal repository web). Questo è un set di dati relativo a un esperimento sul campo per confrontare 14 erbicidi e due controlli non trattati, con 4 repliche per trattamento. L’esperimento è stato progettato in blocchi randomizzati. Esegui l’ANOVA con R e valuta la rilevanza dell’effetto erbicida. Hai eseguito un esperimento con un layout completamente randomizzato con due repliche, per confrontare due genotipi di mais (G1 e G2) con due diverse strategie di fertilizzazione (F1 e F2). Calcola i quadrati medi e i rapporti F per il genotipo, gli effetti della fertilizzazione e per la loro interazione. Gli effetti causali sono rilevanti? Il set di dati è mostrato di seguito. Genotype Fertiliser Yield G1 F1 11.292934 G1 F1 12.777429 G1 F2 12.584441 G1 F2 9.154302 G2 F1 14.929125 G2 F1 15.006056 G2 F2 12.925260 G2 F2 12.953368 "],["modelli-stocastici.html", "Capitolo 5 Modelli stocastici 5.1 Funzioni di probabilità/densità 5.2 Calcolare le probabilità 5.3 Simulazione stocastica 5.4 Conclusioni 5.5 Altre letture 5.6 Domande ed esercizi 5.7 Soluzioni", " Capitolo 5 Modelli stocastici Nel Capitolo precedente abbiamo visto che i fenomeni biologici possono essere descritti ricorrendo a modelli statistici, che contengono una componente deterministica che produce la risposta attesa (\\(Y_E = f(X, \\theta)\\)) ed una componente stocastica (\\(\\varepsilon = Y_O - Y_E\\)), che ‘confonde’ le nostre osservazioni (\\(Y_O\\)), rendendole diverse da quanto previsto dal modello deterministico. Abbiamo anche visto che i dati sperimentali possono essere utilizzati per specificare un modello generale (teorico), assegnando valori ben definiti ai parametri del modello. A questo punto è lecito chiedersi: possiamo utilizzare questo modello così specificato per prevedere i risultati di un esperimento futuro dello stesso tipo? La risposta non è così ovvia; infatti, possiamo utilizzare la parte deterministica del modello per fare previsioni sul risultato atteso (\\(Y_E\\)), che si ottiene tramite una relazione causa-effetto. Sfortunatamente, il risultato effettivo (\\(Y_O\\)) è totalmente imprevedibile, a causa degli effetti degli elementi stocastici \\(\\varepsilon\\), che cambiano casualmente a ogni tentativo di campionamento e confondono le nostre osservazioni. Sebbene non abbiamo alcun modo di prevedere un risultato casuale (che altrimenti non potrebbe essere tale), possiamo fare alcune ipotesi ragionevoli. Immaginiamo di studiare l’altezza delle piante in un campo di avena ed immaginiamo che il valore atteso, come previsto dal modello, sia \\(Y_E = 120\\); dovremmo aspettarci che, se il modello è corretto, sia molto probabile osservare un valore di 119 o 121 cm (\\(\\varepsilon = \\pm 1\\)), meno probabile osservare 100 o 140 cm (\\(\\varepsilon = \\pm 20\\)), molto improbabile osservare 80 o 160 cm (\\(\\varepsilon = \\pm 40\\)). Di conseguenza, dovremmo poter assegnare una probabilità a ciascun possibile valore di \\(\\varepsilon\\) (e quindi a ciascun possibile risultato osservato \\(Y_O\\)), utilizzando una qualche funzione di probabilità. 5.1 Funzioni di probabilità/densità Se avessimo rilevato una qualità del soggetto, come il sesso (M/F), la mortalità (vivo/morto), la germinabilità (germinato/non germinato), avremmo una variabile categorica nominale e potremmo calcolare le probabilità definita come rapporto tra il numero degli eventi favorevoli e il numero totale di eventi possibili (probabilità ‘frequentista’). Ad esempio, se il nostro esperimento consistesse nell’estrarre una carta da un mazzo di carte francesi, potremmo calcolare la probabilità di estrarre un asso \\(4/52 = 0.077\\), oppure, se il nostro esperimento consistesse nell’effettuare due lanci della monetina, potremmo calcolare la probabilità di ottenere due teste considerando che ci sono quattro eventi possibili (testa/testa, croce/testa, testa/croce e croce/croce) e quindi la probabilità di uno di questi è \\(1/4 = 0.25\\). Nel caso di una variabile quantitativa, come l’altezza, non ha molto senso chiedersi, ad esempio, qual è la probabilità di trovare un individuo esattamente alto 100 cm (e non 100.0000001, o 99.99999). Capiamo da soli che questa probabilità è infinitesima. Al contrario, potremmo pensare di calcolare la probabilità di ottenere un valore compreso in un intervallo, per esempio da 99 a 101 cm: se la popolazione è ampia, ma finita, basta usare la regola che conosciamo e contare il numero di soggetti nell’intervallo, dividendoli per il numero totale di soggetti nella popolazione. Il problema però sta nel fatto che si viene ad introdurre un elemento arbitrario, cioè l’ampiezza dell’intervallo prescelto per calcolare la probabilità. Possiamo tuttavia pensare di calcolare la densità di probabilità, vale a dire il rapporto tra la probabilità di un intervallo e la sua ampiezza (cioè la probabilità per unità di ampiezza dell’intervallo; per questo si parla di densità). Ora, se immaginiamo di restringere l’intervallo fino a farlo diventare infinitamente piccolo, anche la probabilità tende a diventare infinitesima con la stessa ‘velocità’, in modo che la densità di probabilità di un singolo valore di concentrazione tende ad un numero finito (ricordate il limite del rapporto di polinomi?), come mostrato in Figura 5.1. Figura 5.1: Densità di probabilità per una variabile continua discretizzata, su intervalli di ampiezza decrescente. Quando l’intervallo diviene piccolissimo, la funzione di densità tende a diventare un curva continua La funzione di densità (PDF) rappresentata nella Figura 5.1 è la gaussiana ed è così comune in agricoltura e biologia che è solitamente nota come curva normale. L’equazione è: \\[P(Y) = \\frac{1}{{\\sigma \\sqrt {2\\pi } }}\\exp \\left[{\\frac{\\left( {Y - \\mu } \\right)^2 }{2\\sigma ^2 }} \\right]\\] ove \\(P(Y)\\) è la densità di probabilità di una certa misura \\(Y\\), mentre \\(\\mu\\) e \\(\\sigma\\) sono rispettivamente la media e la deviazione standard della popolazione (per la dimostrazione si rimanda a testi specializzati). Le variabili casuali la cui densità può essere descritta con la curva di Gauss, prendono il nome di variabili normali o normalmente distribuite. Guardando la curva di Gauss possiamo notare che ha una forma ‘a campana’ che dipende da solo da \\(\\mu\\) e \\(\\sigma\\) (figura 5.2). Figura 5.2: Distribuzioni normali con diversa media e deviazione standard (rispettivamente 5 e 1 a sinistra, 6 e 3 a destra) Per calcolare la densità gaussiana con R, possiamo usare la funzione dnorm(); ad esempio, se vogliamo conoscere la densità di probabilità di ottenere un produzione di 12 t/ha, campionando una parcella da una popolazione di parcelle con media pari a 11 e deviazione standard pari a 1,5, possiamo usare il codice fornito nel riquadro 5.1. # Code box 5.1 # # Gaussian density calculation dnorm(12, mean = 11, sd = 1.5) ## [1] 0.2129653 La densità non è una probabilità reale e non è interessante di per sé (almeno, non in termini assoluti), ma la PDF ha il vantaggio di restituire la probabilità di un intervallo di eventi come Area Sotto la Curva (Area Under the Curve: AUC). Ad esempio, la Figura 5.3 evidenzia l’AUC tra 11 e 12, che rappresenta la probabilità di campionare una percella con una produzione in quell’intervallo, partendo da una popolazione di parcelle con media pari a 11 e deviazione standard pari a 1,5. Figura 5.3: Area-Under-the-Curve per una PDF gaussiana, che descrive la probabilità di campionare una parcella che ha una produzione nell’intervallo tra 11 e 12, quando la media è 11 e la deviazione standard è 1.5 Di conseguenza, l’AUC e, quindi, la probabilità, possono essere calcolate integrando la curva gaussiana su un intervallo; in relazione alla Figura 5.3, la probabilità tra 11 e 12 è 0,248 (vedere il riquadro 5.2). Più semplicemente, la funzione pnorm() restituisce l’AUC tra \\(-\\infty\\) e qualsiasi valore \\(y\\) (Funzione di distribuzione cumulativa; vedere la Figura 5.4) e può essere utilizzata per evitare il calcolo di un integrale. #Code box 5.2 # Integration of the gaussian density function AUC &lt;- integrate(function(x) dnorm(x, 11, 1.5), 11, 12) AUC$value ## [1] 0.2475075 # # Use of the cumulative probability function # (same result as above) pnorm(12, mean = 11, sd = 1.5) - pnorm(11, mean = 11, sd = 1.5) ## [1] 0.2475075 Figura 5.4: Probabilità cumulativa gaussiana, considerando una distribuzione con media pari ad 11 e deviazione standard pari a 1.5 Le più importanti proprietà di una curva Gaussiano sono le seguenti: la curva ha due asintoti e tende a 0 quando x tende a infinito. Questo ci dice che se assumiamo che un fenomeno è descrivibile con una curva di Gauss, allora assumiamo che tutte le misure sono possibili, anche se la loro frequenza decresce man mano che ci si allontana dalla media; L’integrale della curva di densità gaussiana da \\(-\\infty\\) a \\(+\\infty\\) è uguale ad 1. Infatti la somma delle frequenze relative di tutte le varianti possibili non può che essere uguale ad 1; la curva è simmetrica. Questo indica che la frequenza dei valori superiori alla media è esattamente uguale alla frequenza dei valori inferiori alla media; dato \\(\\sigma\\), possiamo dire che la frequenza dei valori superiori a \\(\\mu + \\sigma\\) è pari al 15.87% ed è uguale alla frequenza dei valori inferiori a \\(\\mu - \\sigma\\). Ora arriviamo alla domanda più interessante: come utilizzare la curva gaussiana? Se la variabile che stiamo studiando è continua (ma, con un po’ di prudenza, potremmo includere anche conteggi e rapporti), potremmo supporre che l’elemento stocastico \\(\\varepsilon\\) sia distribuito in modo gaussiano, con media uguale a 0 e deviazione standard uguale a \\(\\sigma\\): \\[\\varepsilon \\sim \\textrm{Norm}(0, \\sigma)\\] Analogamente, potremmo supporre che il risultato di un esperimento sia distribuito in modo gaussiano con media uguale a \\(Y_E\\) (come previsto dal modello deterministico) e deviazione standard uguale a \\(\\sigma\\): \\[Y_O \\sim \\textrm{Norm}(Y_E, \\sigma)\\] Se questa ipotesi è ragionevole, si aprono delle possibilità molto interessanti. In particolare, data una popolazione ed il modello che la descrive, possiamo: calcolare le probabilità di ottenere un certo risultato osservato; simulare i risultati di esperimenti futuri. Vediamo come possiamo operare in alcune situazioni piuttosto comuni. 5.2 Calcolare le probabilità In pratica, se assumiamo che un modello completamente specificato possa descrivere adeguatamente un particolare fenomeno, possiamo utilizzare tale modello per prevedere il risultato atteso. Successivamente, se conosciamo anche la deviazione standard del termine di errore residuo, possiamo utilizzare l’equazione della curva gaussiana per calcolare la probabilità di qualsiasi possibile risultato osservato. 5.2.1 Esempio 5.1: Calcolare la probabilità in un esperimento misurativo Ipotizziamo di avere un pozzo inquinato dai residui di una certa sostanza xeniobiotica ad una concentrazione pari a 120 \\(mg/L\\) ed ipotizziamo di effettuare l’analisi chimica per la determinazione della concentrazione dei residui, utilizzando uno strumento caratterizzato da un coefficiente di variabilità del 10%, che equivale ad una deviazione standard pari a 12 \\(mg/L\\) (\\(\\sigma = 12\\)). Con queste informazioni possiamo rispondere a tutte le seguenti domande: Che modello possiamo utilizzare per descrivere i risultati di questo esperimento? Qual è la misura di concentrazione più probabile? Qual è la densità di probabilità di ottenere una concentrazione pari a 120 \\(mg/L\\)? Qual è la probabilità di ottenere una concentrazione inferiore a 110 \\(mg/L\\)? Qual è la probabilità di ottenere una concentrazione superiore a 130 \\(mg/L\\)? Qual è la probabilità di ottenere una concentrazione compresa tra 110 e 130 \\(mg/L\\) Quale concentrazione è superiore al 90% di tutte i valori ottenibili (90° percentile)? Quali sono quei due valori, simmetrici rispetto alla media e tali da formare un intervallo all’interno del quale cadono il 95% delle misure possibili? Per questo esperimento misurativo, il modello della media è del tutto appropriato (\\(Y_E = 120\\) mg/L). Tuttavia, si tratta di un modello semplicistico, a causa del fatto che il nostro strumento chimico non è esente da errori di misura; di conseguenza, dovremmo aggiungere la componente stocastica, come \\(Y_O = 120 + \\varepsilon\\), dove \\(\\varepsilon \\sim \\textrm{Norm}(0, \\sigma = 12)\\), ovvero \\(Y_O \\sim \\textrm{Norm}(120, 12)\\). La risposta alla seconda domanda è banale (\\(Y_E = 120\\)), mentre per rispondere alle altre domande possiamo utilizzare le apposite funzioni di R. Per ogni distribuzione abbiamo a disposizione una funzione di densità (con prefisso ‘d’), una funzione di probabilità cumulata (con prefisso ‘p’) e una funzione inversa (prefisso ‘q’) che consente di calcolare i percentili. Nel caso della funzione gaussiana, abbiamo le funzioni dnorm(), pnorm() e qnorm(), che possiamo utilizzare per calcolare densità, probabilità e percentili, come indicato di seguito. # Domanda 2 dnorm(120, mean = 120, sd = 12) ## [1] 0.03324519 # Domanda 3 pnorm(110, mean = 120, sd = 12) ## [1] 0.2023284 Per la quarta domanda dobbiamo considerare che la funzione pnorm() fornisce la coda bassa della funzione, mentre dobbiamo individuare la coda alta (altezze maggiori della soglia data). Pertanto, abbiamo due possibili soluzioni, come indicato più sotto. # Domanda 4 pnorm(130, mean = 120, sd = 12, lower.tail = F) ## [1] 0.2023284 1 - pnorm(130, mean = 120, sd = 12) ## [1] 0.2023284 # Domanda 5 pnorm(130, mean = 120, sd = 12) - pnorm(110, mean = 120, sd = 12) ## [1] 0.5953432 # Domanda 6 qnorm(0.9, mean = 120, sd = 12) ## [1] 135.3786 # Domanda 7 qnorm(0.025, mean = 120, sd = 12) ## [1] 96.48043 qnorm(0.975, mean = 120, sd = 12) ## [1] 143.5196 5.2.2 Esempio 5.2: Calcolo della probabilità per un esperimento di degradazione Sappiamo che la concentrazione \\(C\\) di una sostanza erbicida nel suolo diminuisce con il tempo \\(t\\) secondo secondo una cinetica del primo ordine, che può essere descritta con il modello: \\(C = C_0 \\times 10{^{-0.01 \\, t}}\\), dove \\(C_0\\) è la concentrazione iniziale dell’erbicida. Supponiamo di arricchire un campione di suolo con questa sostanza fino a una concentrazione \\(C_0 = 75\\) ng g-1, qual è la probabilità di osservare una concentrazione inferiore a 3 ng g-1 a 20 giorni dal trattamento? Si consideri che tutte le fonti sconosciute di errore sperimentale possono essere considerate gaussiane, con un coefficiente di variabilità pari al 10%. Supponendo che la relazione causa-effetto sia affidabile, la concentrazione prevista a 20 giorni dal trattamento dovrebbe essere 4,22 ng g-1 (riquadro 5.5). Tuttavia, il risultato osservato dipende dall’errore sperimentale, che è un evento casuale imprevedibile; se assumiamo che la funzione di probabilità per la concentrazione osservata sia gaussiana, con media di 4,22 e deviazione standard di 0,422 (ovvero 7,5 volte il 10%), la probabilità di ottenere una misura minore o uguale a 3 ng g-1 è inferiore allo 0,2%, il che dimostra che si tratta di un evento alquanto improbabile. # Codice casella 5.5 # Concentrazione attesa Ct &lt;- 75 * 10^(-0.05 * 25) Ct ## [1] 4.21756 # Probabilità di osservare una concentrazione &lt;= 3 pnorm(3, Ct, Ct * 0.1) ## [1] 0.001945398 5.3 Simulazione stocastica Guardandolo dal punto di vista che abbiamo appena illustrato, ogni esperimento scientifico non è altro che un’operazione di campionamento da una certa distribuzione di probabilità, che può essere simulato impiegando un generatore di numeri casuali, con un procedimento che prende il nome di ‘metodo Monte Carlo’. In pratica, possiamo: 1. Simulare i risultati attesi utilizzando il modello causa-effetto selezionato per ciascuna unità sperimentale. 2. Associare la variabilità casuale ai risultati attesi campionando da una PDF gaussiana. In R, il generatore di numeri casuali gaussiani è implementato nella funzione rnorm(), che richiede tre argomenti: il numero di valori casuali che intendiamo estrarre, la media della distribuzione e la sua deviazione standard. 5.3.1 Esempio 5.3. Simulazione di un esperimento misurativo Prendiamo ancora il nostro pozzo inquinato e contenente 120 \\(mg/L\\) di un erbicida e immaginiamo di misurare la concentrazione di tre campioni d’acqua, utilizzando uno strumento caratterizzato da \\(\\sigma = 12\\). I risultati di questo esperimento possono essere simulati: usando il modello deterministico per definire il valore atteso della produzione per ogni dose di azoto, che sarà la stessa per tutte le repliche (in questo caso \\(Y_E = 120\\)); utilizzando un generatore gaussiano di numeri casuali, per simulare gli effetti stocastici, campionandoli da una distribuzione normale, con le caratteristiche desiderate. set.seed(1234) Y_E &lt;- 120 epsilon &lt;- rnorm(3, 0, 12) Y_O &lt;- Y_E + epsilon Y_O ## [1] 105.5152 123.3292 133.0133 La generazione di numeri casuali con il computer viene fatta attraverso algoritmi che, a partire da un seed iniziale, forniscono sequenze che obbediscono a certe proprietà fondamentali (numeri pseudo-casuali). Il comando set.seed(1234) ci permette di partire da un seed predefinito, in modo che, chiunque ripeta la simulazione con lo stesso seed, ottiene lo stesso risultato. Un’altra cosa da notare è che il nome della funzione che genera numeri casuali è formato dal nome della distribuzione (‘norm’) più il prefisso ‘r’. Questo è vero per tutte le altre distribuzioni in R (‘rbinom’, ‘rt’ e così via). Inoltre, il primo argomento definisce il numero di valori che vogliamo ottenere (tre, tanti quante sono le repliche). La stessa strategia può essere utilizzata per simulare risultati sotto modelli deterministici più complessi: definisco i risultati attesi con il modello deterministico prescelto e ci aggiungo una componente casuale, campionandola da un distribuzione di probabilità/densità adeguata (usualmente gaussiana). 5.3.2 Esempio 5.4: simulazione di un esperimento di fertilizzazione Con la stessa tecnica, possiamo provare a simulare i risultati di un esperimento per determinare la resa del grano trattato con quattro diversi dosaggi di azoto (0, 60, 120 e 180 kg/ha); immaginamo che il disegno sperimentale sia completamente randomizzato con quattro repliche (sedici dati in totale) e il modello causa-effetto sia: \\[Y_O = 25 + 0.15 \\, X + \\varepsilon\\] ove: \\(Y_O\\) è la produzione osservata, \\(X\\) è la dose di azoto, e l’elemento stocastico è \\(\\varepsilon \\sim N(0, \\sigma = 2.5)\\). Il codice per la simulazione è riportato nel box sottostante. # Code box 5.6 # Stochastic simulation, Example 5.3 set.seed(1234) # Creating the vector to host the experimental design Dose &lt;- rep(c(0, 60, 120, 180), each=4) # Predicting the expected yield Yield_E &lt;- 25 + 0.15 * Dose # Predicting the residuals epsilon &lt;- rnorm(16, 0, 2.5) # Predicting the observations Yield &lt;- Yield_E + epsilon dataset &lt;- data.frame(Dose, Yield) dataset ## Dose Yield ## 1 0 21.98234 ## 2 0 25.69357 ## 3 0 27.71110 ## 4 0 19.13576 ## 5 60 35.07281 ## 6 60 35.26514 ## 7 60 32.56315 ## 8 60 32.63342 ## 9 120 41.58887 ## 10 120 40.77491 ## 11 120 41.80702 ## 12 120 40.50403 ## 13 180 50.05937 ## 14 180 52.16115 ## 15 180 54.39874 ## 16 180 51.72429 5.3.3 Esempio 5.4: Simulazione di una prova di confronto varietale Proviamo ora a simulare i risultati di un esperimento di confronto varietale, con cinque genotipi in quattro blocchi (20 osservazioni in totale). La relazione causa-effetto è la seguente: \\[Y_{O(ij)} = \\mu + \\alpha_i + \\gamma_j + \\varepsilon_{ij}\\] dove \\(Y_O\\) è la resa osservata, \\(\\mu\\) è la resa media del primo genotipo nel primo blocco, \\(\\alpha\\) è l’effetto del genotipo e \\(\\gamma\\) è l’effetto del blocco a cui appartiene ogni parcella. Poniamo che \\(\\mu\\) sia 48 q/ha, i valori di \\(\\alpha\\) siano rispettivamente 0, 1, 3, -2, -3 per i cinque genotipi, mentre i valori di \\(\\gamma\\) siano rispettivamente 0, -2, 3, 1 per i quattro blocchi. Poniamo inoltre che l’errore sperimentale \\(\\varepsilon\\) sia gaussiano con media uguale a 0 e \\(\\sigma = 5\\). Con questi dati, il processo di simulazione è mostrata nel riquadro sottostante. # Code box 5.7 # Stochastic simulation, Example 5.4 set.seed(1234) # Prepare the vectors for the experimental design Genotype &lt;- rep(LETTERS[1:5], each=4) Block &lt;- rep(1:4, times = 5) # Input the value of parameters mu &lt;- 48 alpha &lt;- rep(c(0, 1, 3, -2, -3), each = 4) gamma &lt;- rep(c(0, -2, 3, 1), times = 5) sigma &lt;- 5 # Predict the expected yields Yield_E &lt;- mu + alpha + gamma # Simulate the residuals and the observed values epsilon &lt;- rnorm(20, 0, sigma) Yield &lt;- Yield_E + epsilon dataset &lt;- data.frame(Genotype, Block, Yield) dataset ## Genotype Block Yield ## 1 A 1 41.96467 ## 2 A 2 47.38715 ## 3 A 3 56.42221 ## 4 A 4 37.27151 ## 5 B 1 51.14562 ## 6 B 2 49.53028 ## 7 B 3 49.12630 ## 8 B 4 47.26684 ## 9 C 1 48.17774 ## 10 C 2 44.54981 ## 11 C 3 51.61404 ## 12 C 4 47.00807 ## 13 D 1 42.11873 ## 14 D 2 44.32229 ## 15 D 3 53.79747 ## 16 D 4 46.44857 ## 17 E 1 42.44495 ## 18 E 2 38.44402 ## 19 E 3 43.81414 ## 20 E 4 58.07918 5.4 Conclusioni Come conclusione di questa parte, possiamo fare le seguenti affermazioni: i modelli possono fornire una descrizione molto utile delle relazioni causa-effetto e possono essere utilizzati per descrivere i risultati sperimentali in una data situazione, sebbene possano solo prevedere il valore atteso; a causa della presenza di effetti casuali, il risultato esatto di ogni singolo individuo è imprevedibile; tuttavia possiamo calcolare la probabilità di ottenere uno dei diversi risultati possibili utilizzando modelli stocastici, sotto forma di funzioni di densità di probabilità (PDF); la PDF gaussiana è quella più utilizzata per le variabili continue, ma, con le dovute precauzioni (vedi più avanti) può essere utilizzata anche con conteggi e rapporti. Sebbene in questo capitolo abbiamo considerato solo un modello stocastico (PDF gaussiana), esistono diverse altre funzioni di densità di probabilità, che potrebbero essere utilizzate per raggiungere lo stesso obiettivo, ovvero descrivere la variabilità casuale. Ad esempio, nel resto di questo libro incontreremo la distribuzione t di Student e la distribuzione di Fisher-Snedecor. Chi fosse interessato a questo argomento, potrà trovare numerose informazioni nel grande libro di Ben Bolker, citato di seguito. 5.5 Altre letture Bolker, B.M., 2008. Ecological models and data in R. Princeton University Press, Books. Schabenberger, O., Pierce, F.J., 2002. Contemporary statistical models for the plant and soil sciences. Taylor &amp; Francis, CRC Press, Books. 5.6 Domande ed esercizi Un ricercatore sta studiando una popolazione di insetti ed ha valutato che la loro lunghezza è distribuita normalmente, con \\(\\mu = 23 \\, \\textrm{mm}\\) e \\(\\sigma = 1.6\\). Calcolare la probabilità di estrarre individui con lunghezza: (1) maggiore di 25, (2) minore di 21 e (3) compresa tra 21 e 25. Una macchina confezionatrice riempe automaticamente delle confezioni di seme. Il peso dichiarato sulla confezione è 12.5 kg, ma la precisione della macchina è \\(\\pm\\) 1 kg. Calcolare la probabilità che una confezione contenga: (1) meno del peso dichiarato, (2) meno di 12 kg e (3) più di 13 Kg. Si vuole regolare la macchina in modo che non più del 5% dei sacchi contenga un peso inferiore a quello dichiarato. Su quale peso dovrebbe essere regolata la macchina di riempimento? (SUGGERIMENTO: se io regolo la macchina a 12.5 kg, la quantità effettivamente erogata è normalmente distribuita, con media 12.5 e deviazione standard 1. In questo caso, c’è un 5% di probabilità di erogare meno di _____ kg; di conseguenza, devo alzare la media di ____ kg per far si che la quantità erogata non sia inferiore a 12.5 kg, se non nel 5% dei casi) Uno strumento di analisi ha un coefficiente di variabilità pari al 10%. Ammettendo di utilizzare quello strumento su una matrice la cui concentrazione è 10 ng/g, calcolare la probabilità di ottenere una misura: (1) inferiore a 9 ng/g, (2) superiore a 11 ng/g e (3) compresa tra 9 e 11 ng/g. Un erbicida si degrada nel terreno seguendo una cinetica del primo ordine (\\(Y = 100 \\, e^{-0.07 \\, t}\\)), dove Y è la concentrazione al tempo t. Dopo aver spruzzato questo erbicida, che probabilità abbiamo di osservare, dopo 50 giorni, una concentrazione che risulti al disotto della soglia di tossicità per i mammiferi (2 ng/g)? Tenere conto che lo strumento di misura produce un coefficiente di variabilità del 20% Una sostanza xenobiotica si degrada nell’acqua a 20°C seguendo una cinetica del primo ordine (\\(Y = C_0 \\, e^{-0.06 \\, t}\\), dove Y è la concentrazione al tempo t. Simulare i risultati di un esperimento in cui, dopo la somministrazione di questa sostanza alla dose \\(C_0 = 63\\) ng/mL, facciamo dodici prelievi settimanali e misuriamo la concentrazione del residuo. Considerare che (1) l’errore sperimentale è gaussiano e omoscedastico sul logaritmo della concentrazione, con media 0 e deviazione standard pari a 0.25; (2) l’esperimento è a randomizzazione completa con tre repliche. Una coltura produce in funzione della sua fittezza, secondo la seguente relazione: $ Y = 0.8 + 0.8 , X - 0.07 , X^2$. Stabilire la fittezza necessaria per ottenere il massimo produttivo (graficamente o analiticamente). Valutare la probabilità di ottenere una produzione compresa tra 2.5 e 3 t/ha, seminando alla fittezza ottimale. Considerare che la variabilità stocastica è del 12%. La tossicità di un insetticida varia con la dose, secondo la legge log-logistica: $ Y = $, dove Y è la proporzione di animali morti e X è la dose. Se trattiamo 150 insetti con una dose pari a 35 g, qual è la probabilità di trovare più di 120 morti? Considerare che la risposta è variabile da individuo ad individuo nella popolazione e questa variabilità può essere approssimata utilizzando una distribuzione gaussiana con una deviazione standard pari a 0.10. Simulare i risultati di un esperimento varietale, con sette varietà di frumento e quattro repliche. Considerare che il modello deterministico è un modello ANOVA, nel quale vengono definite le medie delle sette varietà (valori attesi). Decidere autonomamente sui parametri da impiegare per la simulazione (da \\(\\mu_1\\) a \\(\\mu_7\\) e \\(\\sigma\\)) Considerando il testo dell’esercizio 6, simulare un esperimento in cui la coltura viene seminata a fittezze di 2, 4, 6, 8 piante per metro quadrato, con quattro repliche. Considerando il testo dell’esercizio 7, simulare un esperimento in cui l’insetticida viene utilizzato a cinque dosi crescenti (a vostra scelta), con quattro repliche. 5.7 Soluzioni # Esercizio 2 delta &lt;- 125 - qnorm(0.05, 125, 1) pnorm(125, 125 + delta, 1) ## [1] 0.05 # Esercizio 4 res &lt;- 100 * exp(-0.07 * 50) res ## [1] 3.019738 pnorm(2, res, res * 20/100) ## [1] 0.04566198 # Esercizio 5 time &lt;- rep(seq(0, 84, 7), each = 3) logConc &lt;- log(63) - 0.06 * time + rnorm(39, 0, 0.25) Conc &lt;- exp(logConc) Conc ## [1] 65.1476858 55.7269155 56.4298209 46.4340064 34.8030374 28.8204008 ## [7] 31.4004950 21.0567420 27.0950255 14.1419785 23.5401886 15.8669203 ## [13] 9.8333013 10.3586323 7.8135653 5.7616847 4.4732929 5.5172880 ## [19] 4.7094035 4.5116383 7.2827519 2.5496958 2.6893340 3.1048921 ## [25] 1.7066796 1.7177343 1.6591496 1.0514164 1.2613438 1.2698798 ## [31] 0.6014733 0.8167810 0.7159910 0.4816171 0.5960429 0.7145507 ## [37] 0.6157521 0.3361480 0.6093345 mod &lt;- lm(log(Conc) ~ time) summary(mod) ## ## Call: ## lm(formula = log(Conc) ~ time) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.41736 -0.14930 -0.02928 0.05614 0.51074 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.994864 0.068446 58.37 &lt;2e-16 *** ## time -0.059411 0.001383 -42.96 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2262 on 37 degrees of freedom ## Multiple R-squared: 0.9803, Adjusted R-squared: 0.9798 ## F-statistic: 1846 on 1 and 37 DF, p-value: &lt; 2.2e-16 # Esercizio 6 curve(0.8 + 0.8*x - 0.07*x^2, xlim = c(0,10)) D(expression(0.8 + 0.8*x - 0.07*x^2), &quot;x&quot;) ## 0.8 - 0.07 * (2 * x) x &lt;- 0.8/(2*0.07) prod &lt;- 0.8 + 0.8*x - 0.07*x^2 prod ## [1] 3.085714 pnorm(3, prod, prod * 0.12) - pnorm(2.5, prod, prod * 0.12) ## [1] 0.3516216 # Esercizio 7 prob &lt;- 1/(1 + exp ( -2 * (log(35) - log(15)))) prob ## [1] 0.8448276 pnorm(120, 150*prob, 10, lower.tail = F) ## [1] 0.7493398 "],["stime-ed-incertezza.html", "Capitolo 6 Stime ed incertezza 6.1 Ripetere gli esperimenti 6.2 La ‘sampling distribution’ teorica 6.3 L’intervallo di confidenza frequentista 6.4 Come otteniamo l’errore standard? 6.5 Come otteniamo il moltiplicatore \\(k\\)? 6.6 Gli intervalli di confidenza in pratica 6.7 Altri approcci per il calcolo dei CI 6.8 Limitazioni del CI frequentista 6.9 Altre letture 6.10 Domande ed esercizi", " Capitolo 6 Stime ed incertezza Abbiamo visto che: i fenomeni biologici seguono una legge di natura (verità ‘vera’), che ne costituisce il meccanismo deterministico fondamentale. A livello di popolazione, questa legge di natura produce un risultato atteso (media) \\(Y_E\\). Quando si organizza un esperimento, i soggetti sperimentali obbediscono a questo meccanismo di fondo, al quale tuttavia si sovrappongono molto altri elementi di ‘confusione’, altamente incontrollabili, che vanno sotto il nome di errore sperimentale. Il più importante ed inevitabile elemento di confusione è il fatto che il campione prescelto, anche se rappresentativo non riflette mai esattamente le caratteristiche della popolazione da cui proviene (sampling error). L’osservazione sperimentale è quindi un’immagine confusa della verità vera (\\(Y_O \\neq Y_E\\)) e, soprattutto, essa tende ad essere sempre diversa, anche quando ripetiamo lo stesso esperimento nelle stesse condizioni. Come facciamo, quindi, a gestire questa fondamentale ‘irriproducibilità’ dei risultati? E, soprattutto, come facciamo a dare informazioni sulla ‘verità vera’ quando ne conosciamo soltanto una ‘copia sbiadita’ (Fig. 6.1)? Usualmente ci serviamo di un processo che prende il nome di inferenza statistica ed è basato sulle teorie di Karl Pearson (1857-1936), di suo figlio Egon Pearson (1895-1980), di Jarzy Neyman (1894-1981), in aggiunta al contributo di Ronald Fisher, del quale abbiamo già detto in precedenza. Figura 6.1: Osservazioni sperimentali e meccanismi perturbativi Riprendiamo l’esempio relativo ad un pozzo inquinato da un erbicida a concentrazione pari a 120 \\(mg/L\\) (Capitolo 5), misurata tramite uno strumento che, unitamente a tutte le altre fonti ignote di errore, produce un coefficiente di variabilità del 10% (corrispondente ad una deviazione standard di 12 \\(mg/L\\)). Abbiamo visto che, immaginando di fare le analisi in triplicato, i risultati di questo esperimento possono essere simulati con il modello della media, come lo abbiamo descritto nel capitolo precedente, cioè \\(Y_O = Y_E + \\varepsilon\\), con \\(\\varepsilon \\sim N(0, \\sigma)\\), \\(Y_E = 120\\) e \\(\\sigma = 12\\). Nell’esempio 5.3, la simulazione di Monte Carlo ha portato ai seguenti risultati: 105,5, 123,3 e 133,01 mg/L. Se adattiamo il “modello della media” a questo set di dati otteniamo un valore \\(m = 120.62\\), che differisce, anche se di poco, dal valore vero \\(\\mu = 120\\). C’è quindi una discrasia tra la statistica campionaria e quella della popolazione (\\(m \\neq \\mu\\)). set.seed(1234) Y_E &lt;- 120 epsilon &lt;- rnorm(3, 0, 12) Y_O &lt;- Y_E + epsilon # Fitting the ’model of the mean’ to the observed results mod &lt;- lm(Y_O ~ 1) coef(mod) ## (Intercept) ## 120.6192 A questo punto rimettiamoci in una situazione reale: non sappiamo quale sia la concentrazione nel pozzo e cerchiamo di determinarla utilizzando i risultati dell’esperimento appena citato. In assenza di altre informazioni, è logico concludere che \\(\\mu = m\\), cioè che la statistica della popolazione coincida con quella campionaria. Questo processo con il quale assegniamo alla popolazione il valore della statistica campionaria prende il nome di stima puntuale. È un processo legittimo, ma insufficiente, in quanto \\(m \\neq \\mu\\), il che non ci sorprende: non è ragionevole infatti pensare che un qualunque campione possa riflettere con esattezza le caratteristiche della popolazione che lo ha generato. La nostra stima dovrà quindi essere ben più prudenziale. L’approccio tradizionale consiste nel determinare un un intervallo di valori, che sia in grado di “catturare” la statistica della popolazione con elevata confidenza e una bassa probabilità di errore (stima per intervallo). Tale intervallo è chiamato Intervallo di confidenza (Confidence Interval: CI) ed è basato sulle teorie di Karl Pearson (1857-1936), di suo figlio Egon Pearson (1895-1980) e di Jerzy Neyman (1894-1981), nonché sul lavoro di Ronald Fisher. Il CI è uno dei fondamenti della cosiddetta inferenza frequentista, che non è l’unico tipo di inferenza disponibile e non è esente da alcune incongruenze concettuali (vedi Morey et al., 2016). Tuttavia, è molto comune e ampiamente utilizzata nella maggior parte degli articoli scientifici. Il termine “frequentista” deriva dal fatto che l’IC è costruito considerando la variabilità delle stime campionarie quando gli esperimenti vengono ripetuti e la frequenza con cui vengono ottenute i valori ‘sbagliati’. 6.1 Ripetere gli esperimenti Il nostro esperimento è solo simulato e possiamo quindi ripeterlo ‘gratuitamente’ un numero anche molto elevato di volte, seguendo questa procedura: Ripetiamo l’estrazione precedente per 100’000 volte (in altre parole: immaginiamo di ripetere l’analisi chimica per 100’000 volte, sempre con tre repliche) Otteniamo 100’000 medie Calcoliamo la media delle medie e la deviazione standard delle medie # Code box 6.2 # Monte Carlo simulation #1 nrep &lt;- 3 mean &lt;- 120 sigma &lt;- 12 set.seed(1234) result &lt;- rep(0, 100000) for (i in 1:100000){ sample &lt;- rnorm(nrep, mean, sigma) mod &lt;- lm(sample ~ 1) result[i] &lt;- coef(mod) } # Characterising the population of estimates min(result) ## [1] 90.14123 max(result) ## [1] 149.0346 result[result == 120] ## numeric(0) mean(result) ## [1] 120.0341 sd(result) ## [1] 6.939063 Alla fine del processo ci troviamo con una popolazione di medie, che viene detta distribuzione campionaria (sampling distribution); si tratta di un ‘oggetto’ abbastanza ‘teorico’, ma fondamentale per la statistica frequentista, perché caratterizza la variabilità dei risultati di un esperimento, e quindi la sua riproducibilità. Notiamo che: La media delle medie è praticamente coincidente con \\(\\mu\\), la verità ‘vera’. Ciò conferma che la stima puntuale \\(m\\) è uno stimatore non distorto di \\(\\mu\\), perché tende a convergere su \\(\\mu\\) quando il numero di repliche tende a diventare molto elevato; La deviazione standard delle medie è pari a 6.939063 e prende il nome di errore standard (SE). Quest’ultima statistica è di importanza fondamentale, in quanto caratterizza la replicabilità di un esperimento, ovvero la sua precisione. Più è alto l’errore standard, più è incerta la stima e più è alta la sua variabilità in caso di esperimenti ripetuti. Inoltre, possiamo osservare che il 2.5° e il 97.5° percentile sono, rispettivamente: quantile(result, probs =c(0.025, 0.975)) ## 2.5% 97.5% ## 106.4884 133.6434 Possiamo quindi dire che, ripetendo un esperimento un numero elevatissimo di volte, il 95% dei risultati sono contenuti in un intervallo ben definito, che comprende al suo interno il valore ‘vero’ della statistica da stimare. 6.2 La ‘sampling distribution’ teorica La sampling distribution definita più sopra è puramente empirica e sarebbe molto utile poterla descrivere con una funzione di densità formale. Se discretizziamo il vettore ‘result’ e riportiamo le frequenze su un grafico a barre (Fig. 6.2 ), vediamo con chiarezza che la sampling distribution empirica somiglia molto ad una distribuzione normale, con media pari a 120 e deviazione standard pari a 6.94. Figura 6.2: Empirical distribution of 100,000 sample estimates (n = 3), drawn from a Gaussian population with mean = 120 and SD = 12. The solid line shows the theoretical Gaussian PDF, with mean = 120 and SD = 6.94 Questa somiglianza può essere spiegato in base al teorema centrale del limite (o teorema del limite centrale), che teorizza che, qualunque sia la popolazione di partenza, molte statistiche campionarie, tra cui la media, calcolate su campioni casuali ed indipendenti, tendono a distribuirsi in modo approssimativamente normale, con una media pari alla corrispondente statistica della popolazione1. Ammettendo che la sampling distribution fosse Gaussiana, l’intervallo di cui abbiamo parlato poco sopra potrebbe essere individuato facilmente considerando un multiplo dell’errore standard, come \\(\\mu - k \\times SE\\) e \\(\\mu + k \\times SE\\) (Fig. 6.3). Inoltre, \\(k\\) sarebbe pari al 97.5° percentile di una distribuzione gaussiana standardizzata (ovvero una distribuzione gaussiana con media uguale a 0 e deviazione standard pari a 1), che è prossimo a 2 (con R: qnorm(0,975) = 1.960). Sfortunatamente, nella maggior parte dei casi, la distribuzione campionaria è solo approssimativamente gaussiana, quindi \\(k\\) deve essere determinato in modo diverso, come vedremo in seguito. Figura 6.3: A gaussian sampling distribution with a mean of 120 and standard deviation equal to 6.94 (n = 3); the red interval contains 95% of our sample means and it is obtained by adding/subtracting to/from 120 a value equal to, approximately, twice the standard error 6.3 L’intervallo di confidenza frequentista Come abbiamo detto, l’intervallo menzionato in precedenza contiene il 95% delle stime campionarie e, di conseguenza, soddisfa la seguente espressione: \\[P \\left[ \\mu - k \\times SE \\leq m \\leq \\mu + k \\times SE \\right] = 0.95\\] Con semplici passaggi algebrici (sottraiamo \\(\\mu\\) ed \\(m\\) da tutti i termini, moltiplichiamo per \\(-1\\) e riorganizziamo l’espressione), possiamo ricavare la seguente: \\[P \\left[ m - k \\times SE \\leq \\mu \\leq m + k \\times SE \\right] = 0.95\\] che è di estrema importanza, in quanto esprime il concetto che, se facciamo un esperimento ed otteniamo una media pari ad \\(m\\) e scegliamo accuratamente \\(k\\), possiamo costruire un intervallo di confidenza intorno alla nostra stima, pari a \\(k\\) volte l’errore standard e tale da contenere la media vera \\(\\mu\\) con una probabilità del 95%. Questa espressione costituisce l’euristica più utilizzata per costruire l’intervallo di confidenza, anche se dobbiamo capire come ottenere SE e k. 6.4 Come otteniamo l’errore standard? In alcuni casi, l’errore standard può essere ottenuto tramite semplici regole (Cochran, 1950), a partire dalla deviazione standard della popolazione di partenza. Ad esempio, nel caso della media campionaria, l’errore standard (SEM: Standard Error of a Mean) può essere ottenuto con la legge di propagazione degli errori (vedi capitolo 3.3): \\[\\textrm{SEM} = \\frac{\\sigma}{\\sqrt n}\\] Nell’esempio precedente, l’errore standard è \\(12/\\sqrt{3} = 6,928\\), molto vicino alla deviazione standard della distribuzione campionaria empirica. Allo stesso modo, è possibile dimostrare che l’errore standard della differenza tra le medie di due campioni (SED: Standard Error of a Difference) indipendenti con numerosità, rispettivamente, pari a \\(n_1\\) ed \\(n_2\\), estratti da due popolazioni con la stessa varianza e la stessa media è: \\[\\textrm{SED} = \\sqrt{ \\frac{\\sigma^2}{n_1} + \\frac{\\sigma^2}{n_2}}\\] A parte questi due semplici casi, calcolare manualmente l’errore standard è difficile, ma, fortunatamente, possiamo utilizzare quelli prodotti dal software statistico in nostra vece. In particolare, per i modelli ottenuti con la funzione lm() o con altre funzioni di fitting in R, gli errori standard per le stime dei parametri possono essere ricavati con la funzione summary(), passando l’oggetto che risulta dal fitting come argomento. Ad esempio, riconsideriamo i dati dell’esperimento varietale a randomizzazione completa con tre repliche e quattro genotipi di avena, denominati A, B, C e D (Esempio 4.3). Se adattiamo ai risultati un semplice modello ANOVA ad una via (\\(Y_i = \\mu + \\alpha_j + \\varepsilon_i\\)), le stime dei parametri con i relativi errori standard possono essere ottenute come mostrato nel riquadro sottostante. # Standard errors for parameter estimates # Input the data and fit the model (as in Chapter 4) library(statforbiology) dataset &lt;- getAgroData(&quot;Oat1L&quot;) mod6.1 &lt;- lm(Yield ~ Genotype, data = dataset) # Derive estimates and standard errors summary(mod6.1) ## ## Call: ## lm(formula = Yield ~ Genotype, data = dataset) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.17333 -0.08917 0.01833 0.07417 0.16333 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.58000 0.07566 60.531 6.17e-12 *** ## GenotypeB -1.02667 0.10700 -9.595 1.16e-05 *** ## GenotypeC -0.49667 0.10700 -4.642 0.00166 ** ## GenotypeD 0.01667 0.10700 0.156 0.88008 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1311 on 8 degrees of freedom ## Multiple R-squared: 0.9412, Adjusted R-squared: 0.9192 ## F-statistic: 42.71 on 3 and 8 DF, p-value: 2.866e-05 6.5 Come otteniamo il moltiplicatore \\(k\\)? Per selezionare il moltiplicatore \\(k\\), dobbiamo considerare il coverage dell’intervallo di confidenza, ovvero la frequenza con cui esso “cattura” il valore reale della statistica della popolazione. Generalmente, maggiore è il valore di \\(k\\), maggiore è l’ampiezza dell’intervallo e maggiore è il coverage. Le informazioni di letteratura suggeriscono un coverage del 95%, corrispondente a una probabilità di errore del 5%; di conseguenza, dovremmo chiederci: quale valore di \\(k\\) consenta di raggiungere tale confidenza? Abbiamo già visto che, se la sampling distribution fosse veramente gaussiana, \\(k\\) sarebbe all’incirca uguale a 2. Per determinare il coverage con questo valore di \\(k\\) possiamo utilizzare il metodo Monte Carlo; in relazione all’esempio iniziale, riguardante il pozzo inquinato con una sostanza erbicida, possiamo eseguire, ripetutamente, queste operazioni: campioniamo tre individui da una popolazione gaussiana, con media pari a 120 e deviazione standard pari a 12; adattiamo a questi tre individui il modello della media per ottenere una stima della media dell’intero pozzo, insieme al suo errore standard; costruiamo un CI, utilizzando come moltiplicatore \\(k = 2\\). Se tale CI contiene il valore reale di 120 mg/L, l’esito è positivo e quindi assegniamo al risultato il valore 1 e lo immagazziniamo nel vettore ‘result’. Altrimenti assegniamo il valore 0 (funzione ifelse());; ripetiamo i passaggi da 1 a 3 almeno per 100.000 volte e contiamo il numero di successi. # Code box 6.4 # Monte Carlo simulation - 2 # Coverage of a confidence interval # depending on the multiplier k # Sampling 3 reps from a gaussian with mean=120 and sd=12 mean &lt;- 120 sigma &lt;- 12 nrep &lt;- 3 # nrep &lt;- 20 k &lt;- 2 # k &lt;- qt(0.975, nrep - 1) set.seed(1234) result &lt;- rep(0, 100000) for (i in 1:100000){ sample.i &lt;- rnorm(nrep, mean, sigma) mod &lt;- lm(sample.i ~ 1) m &lt;- coef(mod) se &lt;- summary(mod)$coef[1,2] limInf &lt;- m - k * se limSup &lt;- m + k * se # did we capture the mean? result[i] &lt;- ifelse(limInf &lt; 120 &amp; limSup &gt; 120, 1, 0) } sum(result)/100000 ## [1] 0.81708 Il box sovrastante mostra che, impostando \\(k = 2\\) si ottiene un coverage molto basso (inferiore all’82%), corrispondente a una probabilità di errore di quasi il 19%, che è inaccettabile. Il problema è che la dimensione del campione è molto piccola e, pertanto, la distribuzione campionaria di \\(m\\) non è ben approssimata con una PDF gaussiana. Se la stessa simulazione viene eseguita con 20 repliche anziché 3, il coverage aumenta al 94% (provare per credere; basta cambiare la linea di codice nrep &lt;- 3 con nrep &lt;- 20). In pratica, utilizzare \\(k = 2\\) è ritenuto accettabile solo quando la dimensione del campione è superiore a 20-25 unità. Per piccoli campioni (e in generale), è possibile ottenere un coverage esatto del 95% utilizzando il 97,5° percentile della distribuzione t di Student. Per ottenere questo valore, si può utilizzare la funzione qt() in R, che richiede, come minimo, due argomenti: il primo è il percentile desiderato, mentre il secondo rappresenta il numero di gradi di libertà per l’errore standard. Nel nostro esempio abbiamo tre repliche, quindi il numero di DF è 3 − 1 = 2 e il 97,5° percentile della distribuzione t di Student è pari a qt(0,975, 2) = 4,303, molto più alto di 2. In genere, il 97,5° percentile della distribuzione t di Student diminuisce all’aumentare del numero di gradi di libertà, tendendo ad 1,96, quando il numero di DF tende a \\(\\infty\\). Se utilizziamo il codice sovrastante e sostituiamo alla linea k &lt;- 2, il comando k &lt;- qt(0.975, nrep - 1) possiamo confermare che il coverage diviene quasi esattamente del 95% (quasi, poiché il numero di simulazioni è molto alto, ma non infinito). Se necessario, possiamo anche costruire un intervallo di confidenza del 99%, che riduce il rischio di errore all’1%. Basta utilizzare il 99,5° percentile di una distribuzione t di Student. In generale, se \\(\\alpha\\) è il livello di confidenza desiderato, il percentile corrispondente è \\(q_{\\alpha} = 1 − (1 − \\alpha/2)\\) (quindi \\(q_{0,05} = 1−(1−0,95)/2=0,975\\) e \\(q_{0,99} =1−(1−0,99)/2=0,995)\\). 6.6 Gli intervalli di confidenza in pratica 6.6.1 Esempio 6.1: IC per una media campionaria Immaginiamo di aver condotto un esperimento misurativo per determinare la resa media dei girasoli in un macro-ambiente dell’Italia centrale. Abbiamo quindi selezionato venti campi casuali in questo macro-ambiente ed abbiamo determinato i valori di resa riportati nel riquadro sottostante; sulla base di questi risultati, qual è la resa media nell’intero macro-ambiente? In questo esempio, la media campionaria è \\(m = 58,68\\) ed è una stima puntuale affidabile della resa media nell’intero macro-ambiente. Per calcolare il CI, dobbiamo determinare: 1. l’errore standard, che può essere facilmente calcolato utilizzando la semplice equazione riportata più sopra (\\(\\textrm{SEM} = {\\sigma}/{\\sqrt n}\\)). La deviazione standard della popolazione \\(\\sigma\\) è ignota, ma possiamo sostituirla con la deviazione standard del campione, che è 3,47 (principio del ‘plug-in’); 2. Il moltiplicatore \\(k\\), pari al 97,5° percentile della distribuzione t di Student (ovvero, 2,09). Di conseguenza, i due limiti dell’intervallo di confidenza sono rispettivamente 58,68 − 2,09 × 0,775 = 57,1 e 58,68 + 2,09 × 0,775 = 60,3. La conclusione è che, con un livello di confidenza del 95%, la resa media nel macro-ambiente rientra nell’intervallo tra 57,1 e 60,3. # Example 6.1 # Confidence interval for a sample mean # Input the sample and calculate the mean Y &lt;- c(54.08, 66.31, 56.17, 56.32, 52.01, 58.91, 58.74, 57.49, 59.57, 61.71, 56.89, 54.82, 56.88, 60.05, 59.39, 57.19, 64.76, 61.36, 62.03, 58.83) m &lt;- mean(Y) m ## [1] 58.6755 ## [1] 58.6755 # Calculate the standard error s &lt;- sd(Y) SEM &lt;- s/sqrt(length(Y)) SEM ## [1] 0.7754783 ## [1] 0.7754783 # Determine the multiplier k &lt;- qt(0.975, length(Y) - 1) k ## [1] 2.093024 ## [1] 2.093024 # Calculate the limits of the CI # Lower limit mean(Y) - k * SEM ## [1] 57.05241 ## [1] 57.05241 # Higher limit mean(Y) + k * SEM ## [1] 60.29859 Più facilmente, possiamo pervenire allo stesso risultato stimando un modello della media, ed utilizzando la funzione confint(), come indicato nel riquadro sottostante. # Example 6.1 [continuation] # Retrieving confidence intervals from model fit mod &lt;- lm(Y ~ 1) confint(mod) ## 2.5 % 97.5 % ## (Intercept) 57.05241 60.29859 6.6.2 Example 6.2: CIs for model parameters Lo stesso approccio del riquadro sovrastante può essere utilizzato praticamente con ogni altro modello in R. Ad esempio, riconsiderando i dati ‘Oat1L’ dell’ Esempio 4.3 e stimando un modello ANOVA ad una via come nel riquadro 4.3, gli intervalli di confidenza per le stime dei parametri possono essere ottenuti come nel riquadro 6.7. # Code box 6.7 # Example 6.2 # CIs for model parameters for the ’Oat1l’ data # Load libraries and data library(statforbiology) dataset &lt;- getAgroData(&quot;Oat1L&quot;) # Fit the model mod6.1 &lt;- lm(Yield ~ Genotype, data = dataset) # CIs for model parameters confint(mod6.1) ## 2.5 % 97.5 % ## (Intercept) 4.4055191 4.7544809 ## GenotypeB -1.2734199 -0.7799134 ## GenotypeC -0.7434199 -0.2499134 ## GenotypeD -0.2300866 0.2634199 6.7 Altri approcci per il calcolo dei CI L’approccio proposto in questo capitolo si basa su due pre-requisiti fondamentali: la distribuzione campionaria sia gaussiana (almeno approssimativamente), e sia possibile, in qualche modo, calcolare un errore standard affidabile. Nei casi in cui questi due pre-requisiti non siano soddisfatti, gli intervalli di confidenza possono essere determinati con altri approcci, come il metodo Monte Carlo (simile a quello utilizzato nel riquadro 6.2) o il metodo bootstrap (Chernick, 2011). Inoltre, vale la pena menzionare l’“Intervallo Credibile” (Credible Interval), che è la controparte bayesiana dell’intervallo di confidenza frequentista (Kruschke, 2011). Questi metodi fanno parte della cosiddetta computer intensive statistic e possono essere molto utili in alcune circostanze, ma non saranno illustrati in dettaglio perché sono molto avanzati ed esulano dallo scopo di questo libro introduttivo. 6.8 Limitazioni del CI frequentista L’intervallo di confidenza frequentista è ampiamente utilizzato nella letteratura scientifica, mentre la stima puntuale è spesso considerata inaccettabile. Ad esempio, le linee guida per gli autori di Weed Research, una rivista internazionale di alto livello nel campo delle scienze vegetali, affermano: “Tutti i valori stimati (ad esempio, parametri del modello, medie, differenze, ecc.) devono essere presentati insieme a un’adeguata misura di variabilità sia nel testo, che nelle tabelle e nei grafici”. Gli intervalli di confidenza, molto spesso, sono presentati nella forma più semplice “stima ± SE”, sebbene la copertura di tale intervallo sia piuttosto bassa. Basta comunque che il lettore sia avvisato sulla modalità utilizzata per la costruzione dell’intervallo presentato. Per evitare gravi abusi interpretativi o di linguaggio, è necessario essere ben consapevoli dei limiti dell’intervallo di confidenza frequentista (Hastie et al., 2009), che deve essere sempre interpretato con riferimento ad una distribuzione campionaria, ovvero alle ipotetiche ripetizioni dello stesso esperimento con campioni diversi. Al contrario, è sbagliato interpretare il CI con riferimento ad ogni singolo esperimento; in altre parole, se il nostro intervallo di confidenza, determinato per uno specifico esperimento, va da 10 a 13, non è corretto affermare che il parametro incognito della popolazione è compreso tra 10 e 13 con una probabilità del 95% perché ciò non è vero (ricordate che l’IC cambia a ogni tentativo di campionamento; vedere il riquadro 6.4 e vedere anche Morey et al., 2016). Possiamo invece affermare che, nel lungo periodo, ripetendo lo stesso esperimento e continuando a calcolare gli intervalli di confidenza nello stesso modo, la nostra probabilità di errore si mantiene entro il 5%. Si tratta di una differenza piuttosto sottile, ma di fondamentale importanza! 6.9 Altre letture Chernick MR (2011) An Introduction to Bootstrap Methods with Applications to R. Wiley, USA Cochran WG, Cox GM (1950) Experimental design. John Wiley &amp; Sons, Inc., USA Hastie, T., Tibshirani, R., Friedman, J., 2009. The elements of statistical learning, Springer Series in Statistics. Springer Science + Business Media, California, USA. Kruschke JK (2011) Doing bayesian data analyses. A tutorial with R and BUGS. Academic Press, Burlington, MA (USA) Morey, RD, R Hoekstra, JN Rouder, MD Lee, E-J Wagenmakers, 2016. The fallacy of placing confidence in confidence intervals. Psychonomic Bulletin &amp; Review 23, 103–123 6.10 Domande ed esercizi In un campo di frumento sono state campionate trenta aree di saggio di un metro quadrato ciascuna, sulle quali è stata determinata la produzione. La media delle trenta aree è stata di 6.2 t/ha, con una varianza pari a 0.9. Stimare la produzione dell’intero appezzamento. Siamo interessati a conoscere il contenuto medio di nitrati dei pozzi della media valle del Tevere. Per questo organizziamo un esperimento, durante il quale campioniamo 20 pozzi rappresentativi, riscontrando le concentrazioni riportate di seguito. Stimare la concentrazione media per l’intera valle del Tevere 38.3 38.6 38.1 39.9 36.3 41.6 37.0 39.8 39.1 35.0 38.1 37.4 38.3 34.8 40.4 39.3 37.0 38.7 38.2 38.4 E’stata impostata una prova sperimentale per confrontare due varietà di mais, con uno schema sperimentale a blocchi randomizzati con tre repliche. La prima varietà ha mostrato produzioni di 14, 12, 15 e 13 t/ha, mentre la seconda varietà ha mostrato produzioni pari a 12, 11, 10.5 e 13 t/ha. Stimare le produzioni medie delle due varietà, nell’ambiente di studio. Un campione di 400 insetti a cui è stato somministrato un certo insetticida mostra che 136 di essi sono sopravvissuti. Determinare un intervallo di confidenza con grado di fiducia del 95% per la proporzione della popolazione insensibile al trattamento. È stata studiata la risposta produttiva del sorgo alla concimazione azotata, con un esperimento i cui risultati sono riportati di seguito .Assumendo che la relazione sia lineare (retta), stimare la pendenza e l’intercetta della popolazione di riferimento, dalla quale è stato estratto il campione in studio. Utilizzare la funzione lm(Yield ~ Dose) ed estrarre gli errori standard con il metodo summary(). Dose Yield 0 1.26 30 2.50 60 3.25 90 4.31 120 5.50 Utilizzando una simulazione Monte Carlo opportunamente pianificata, mostrare che la varianza del campione (uguale alla devianza divisa per il numero di individui meno uno) fornisce una stima più accurata della varianza della popolazione, rispetto allo scarto quadratico medio (devianza divisa per il numero di soggetti) che è invece uno stimatore distorto. Suggerimento: ricordare che uno stimatore accurato ha una distribuzione campionaria (sampling distribution) il cui valore atteso coincide con il valore da stimare. Il teorema centrale del limite vale per campioni di dimensione elevata, composti da almeno 20-25 unità↩︎ "],["decisioni-ed-incertezza.html", "Capitolo 7 Decisioni ed incertezza 7.1 Esempio 7.1: Confronto tra due genotipi 7.2 Altri test di t 7.3 Differenze generalizzate tra parametri 7.4 Il test F nell’ANOVA 7.5 Conclusioni 7.6 Altre letture 7.7 Esercizi", " Capitolo 7 Decisioni ed incertezza Dovrebbero ormai essere chiari i motivi per cui i risultati di un esperimento non corrispondono alla verità vera e si presentano in modo diverso ogni volta che lo ripetiamo. Nel capitolo precedente abbiamo visto come è possibile (e necessario) esplicitare la nostra incertezza in relazione alla verità vera, aggiungendo alle nostre stime campionarie il cosiddetto intervallo di confidenza, basato sulla sampling distribution della stima, che mostra come quest’ultima vari quando ripetiamo l’esperimento. Un approccio affine può essere utilizzato per prendere decisioni in presenza di incertezza, con un procedimento che si chiama test d’ipotesi ed è basato sul cosiddetto P-level. Anche per questo argomento, vediamo alcuni semplici, ma realistici, esempi. 7.1 Esempio 7.1: Confronto tra due genotipi Immaginiamo che un ricercatore abbia testato la produzione di due genotipi (A e P) in un disegno sperimentale a randomizzazione completa, con cinque repliche (dieci parcelle in totale). I risultati ottenuti (q/ha) sono i seguenti: Come al solito, l’analisi dei dati inizia con il calcolo delle più importanti statistiche descrittive per ogni campione, come abbiamo visto nel Capitolo 3. Trattandosi di una serie di misure quantitative, calcoliamo quindi media e deviazione standard, come indicato nel box sottostante. # Example 7.1 # A comparison between two genotypes # Load the data A &lt;- c(65, 68, 69, 71, 78) P &lt;- c(80, 81, 84, 88, 94) # Descriptive statistics for A m1 &lt;- mean(A) s1 &lt;- sd(A) n1 &lt;- length(A) m1; s1; n1 ## [1] 70.2 ## [1] 4.868265 ## [1] 5 # Descriptive statistics for P m2 &lt;- mean(P) s2 &lt;- sd(P) n2 &lt;- length(P) m2; s2; n2 ## [1] 85.4 ## [1] 5.727128 ## [1] 5 Vediamo che la media per il genotipo P è più alta della media per il genotipo A, ma tali medie campionarie non sono sufficienti per i nostri obiettivi. Il passo successivo è postulare un modello descrittivo per rappresentare il meccanismo tramite cui le nostre osservazioni (e altre osservazioni future) potrebbero essere originate. Tale modello dovrebbe tenere conto dell’effetto di una variabile predittiva, ovvero il genotipo. Un modello ragionevole è: \\[ Y_i = \\mu + \\delta_j + \\varepsilon_{i} \\] dove \\(Y_i\\) è la resa dell’i-esimo grafico (\\(i\\) va da 1 a 10), \\(\\mu\\) è la resa prevista per il genotipo A, mentre \\(\\delta_j\\) è l’effetto del genotipo (con \\(j\\) che va da 1 a 2) che è vincolato a essere 0 per il primo genotipo (\\(\\delta_1 = 0\\)) e, per il secondo genotipo, è uguale alla differenza di resa tra i due genotipi (\\(\\delta_2 = \\mu_2 - \\mu_1\\)). Di conseguenza, la resa prevista per P è \\(\\mu_2 = \\mu_1 + \\delta_2\\) e i residui \\(\\varepsilon_i\\) rappresentano tutte le altre fonti sconosciute di variabilità, che sono indipendenti e specifiche per ogni grafico. I residui sono assunti come gaussiani, con media uguale a 0 e deviazione standard uguale a \\(\\sigma\\). La scelta di usare \\(\\delta_2\\) (differenze tra la seconda varietà è la prima) come parametro esplicito nel modello è puramente arbitraria: avremmo potuto anche includere \\(\\delta_1\\) (differenze tra la prima varietà e la seconda) che sarebbe stata uguale a \\(\\delta_2\\) in valore assoluto, ma con segno invertito e avrebbe reso \\(\\mu\\) uguale alla media del secondo genotipo, invece che del primo. La stima dei parametri del modello può essere eseguita utilizzando la funzione lm() in R, come mostrato nel Capitolo 4. # Example 7.1 [continuation] # Fitting a model with one nominal predictor # to the data at Code box 7.1 yield &lt;- c(A, P) genotype &lt;- rep(c(&quot;A&quot;, &quot;P&quot;), each = 5) mod &lt;- lm(yield ~ genotype) summary(mod) ## ## Call: ## lm(formula = yield ~ genotype) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.40 -3.85 -1.30 2.15 8.60 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 70.200 2.377 29.533 1.87e-09 *** ## genotypeP 15.200 3.362 4.522 0.00195 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 5.315 on 8 degrees of freedom ## Multiple R-squared: 0.7188, Adjusted R-squared: 0.6836 ## F-statistic: 20.45 on 1 and 8 DF, p-value: 0.001945 confint(mod) ## 2.5 % 97.5 % ## (Intercept) 64.718691 75.68131 ## genotypeP 7.448258 22.95174 È importante notare che la deviazione standard residua (\\(\\sigma\\)), con una terminologia confusa, è indicata come ‘errore standard residuo’ (\\(\\sigma = 5,315\\)) nell’output R. È anche importante notare che, in base al nostro modello, la deviazione standard dei residui è unica e comune a tutte le osservazioni e, pertanto, stiamo assumendo che l’effetto genotipo influenzi il livello di resa e non la sua variabilità tra le repliche. Tale ipotesi è chiamata omoschedasticità (od omoscedasticità) e dovrebbe essere attentamente verificata, come mostreremo più avanti in questo libro. Gli errori standard per tutte le stime puntuali sono già disponibili nell’output di R: confermano che c’è una certa incertezza sulla reale differenza basata sulla popolazione \\(\\delta_2\\), che dovrebbe essere compresa tra 7,45 e 22,95. Il fatto che l’intervallo di confidenza per \\(\\delta_2\\) non contenga 0 è una prova indiretta che l’effetto genotipo è significativo. 7.1.1 L’ipotesi ‘nulla’ Dopo aver completato l’inferenza statistica, ci chiediamo se, a livello di popolazione, sia possibile concludere che il genotipo P è più produttivo del genotipo A, coerentemente con i risultati osservati nei due campioni. Non dimentichiamoci che i due campioni sono totalmente irrilevanti, perché vogliamo trarre conclusioni generali e non specifiche per il nostro esperimento. Dobbiamo quindi trovare un metodo per decidere se il genotipo P, in generale, è più produttivo del genotipo A, pur in presenza dell’incertezza legata all’errore sperimentale. Innanzitutto, ricordiamo la logica Popperiana illustrata nel primo capitolo, secondo la quale nessun esperimento può dimostrare che un’ipotesi scientifica è vera, mentre è possibile dimostrare che essa è falsa. E’quindi conveniente porre l’ipotesi scientifica di nostro interesse (\\(H_0\\)) in modo che essa possa essere falsificata, cioè, ad esempio: \\[H_0: \\delta_2 = 0\\] In altre parole, stiamo cercando di dimostrare che uno dei parametri stimati nel modello sia, in realtà, uguale a 0; questa ipotesi si chiama ipotesi nulla e, se riuscissimo a falsificarla, avremmo conseguito il nostro obiettivo, in totale coerenza con la logica Popperiana. 7.1.2 Il test di t (Wald test) In practica, stiamo cercando di dimostrare che un parametro del modello è uguale a 0, quando, in realtà, la nostra stima puntuale è diversa da 0. È intuitivamente chiaro che un certo grado di discrepanza tra la realtà e l’osservazione è accettabile come caratteristica intrinseca del processo di campionamento, ma è anche chiaro che maggiore è la discrepanza, minore è la probabilità che l’ipotesi “nulla” sia vera. In particolare, la nostra intuizione è che un parametro è significativamente diverso da zero quando il suo valore è molto più grande dell’incertezza con cui lo abbiamo stimato. Un statistica che risponde alla nostra esigenza è quella indicata di seguito: \\[T = \\frac{d_2}{SE_{d_2}} = \\frac{15.2}{3.362} = 4.521727\\] Se l’ipotesi nulla fosse vera, dovremmo osservare \\(T = 0\\), mentre abbiamo osservato \\(T = 4,522\\). Possiamo rifiutare il nullo? Non lo sappiamo, dipende da quanto è probabile ottenere un valore così discrepante quando il nullo è vero. Pertanto, dobbiamo chiederci: qual è la distribuzione campionaria per \\(T\\) sotto l’ipotesi nulla? 7.1.3 Simulazione Monte Carlo Per rispondere a questa domanda, supponiamo che l’ipotesi nulla sia vera. In questo caso, immaginiamo che le nostre dieci parcelle siano tutte estratte da una sola popolazione di parcelle con media e deviazione standard stimate (stima puntuale) come segue: # Example 7.1 [ continuation] # We assume a single group, with no genotype distinction # and calculate the descriptive statistics mu &lt;- mean(yield) devStAP &lt;- sd(c(A, P)) mu; devStAP ## [1] 77.8 ## [1] 9.44928 Prendiamo quindi questa popolazione normale, con \\(\\mu = 77.8\\) e \\(\\sigma = 9.45\\), ed utilizziamo un generatore di numeri casuali gaussiani per estrarre numerose (100’000) coppie di campioni, calcolando, per ogni coppia, il valore T, come abbiamo fatto con la nostra coppia iniziale. Il codice da utilizzare in R per le simulazioni è il seguente: # Example 7.1 [ continuation] # Building a sampling distribution for T # assuming that the null hypothesis is true set.seed(34) result &lt;- rep(NA, 100000) for (i in 1:100000){ epsilon &lt;- rnorm(10, 0, devStAP) Yo &lt;- mu + epsilon mod &lt;- lm(Yo ~ genotype) d2 &lt;- coef(mod)[2] SE &lt;- summary(mod)$coefficients[[2,2]] Ti &lt;- d2 / SE result[i] &lt;- Ti } mean(result) ## 0.001230418 min(result) ## -9.988315 max(result) ## 9.993187 mean(result) ## [1] 0.001230418 min(result) ## [1] -9.988315 max(result) ## [1] 9.993187 Quali valori abbiamo ottenuto per \\(T\\)? In media, i valori sono prossimi a 0, come previsto, considerando che abbiamo simulato i risultati di esperimenti in cui \\(\\delta_2\\) era assunto pari a 0. Tuttavia, notiamo anche valori piuttosto alti e bassi (vicini a 10 e -10), il che dimostra che le fluttuazioni del campionamento casuale possono anche portare a risultati molto “strani”. Per il nostro esperimento reale abbiamo ottenuto \\(T = 4,522\\), sebbene il segno positivo sia solo un artefatto, legato al modo in cui abbiamo formulato il nostro modello: avremmo potuto ottenere anche \\(T = -4,522\\) se avessimo utilizzato \\(\\mu_2\\) come parametro esplicito, invece di \\(\\mu_1\\). Ronald Fisher ha proposto di rifiutare l’ipotesi nulla, in base alla probabilità di ottenere valori tanto ‘estremi’ o più ‘estremi’ di quello osservato, quando l’ipotesi nulla è vera. Osservando il vettore “result”, vediamo che la proporzione di valori inferiori a -4,521727 e superiori a 4,521727 è \\(0,00095 + 0,00082 = 0,00177\\). Questo è il cosiddetto P-Level o P-value (vedere il codice sottostante). # Example 7.1 [ continuation] # P-value with Monte Carlo simulation T_obs &lt;- 4.521727 upperTail &lt;- length(result[result &gt; T_obs]) / 100000 lowerTail &lt;- length(result[result &lt; - T_obs]) /100000 upperTail + lowerTail ## [1] 0.00177 Ora proviamo a riassumere. Abbiamo visto che, quando l’ipotesi nulla è vero, la distribuzione campionaria di \\(T\\) contiene una percentuale molto bassa di valori al di fuori dell’intervallo da -4,522 a 4,522. Pertanto, la nostra osservazione rientra in un intervallo molto improbabile, che ha scarsissima probabilità di verificarsi (P-value = 0.0017); il P-value di riferimento per il rigetto della nulla è 0,05, quindi, coerentemente, la rigettiamo. Lo facciamo perché, se l’ipotesi nulla fosse vera, avremmo ottenuto un risultato molto improbabile; in altre parole, l’e nostre prove scientifiche contro il valore nullo ’evidenza scientifica contro l’ipotesi nulla è sufficientemente forte da permetterci di rigettarla. 7.1.4 Una soluzione formale Calcolare il P-value poco sopra ha richiesto di costruire una sampling distribution empirica con una serie di simulazioni Monte Carlo, piuttosto ‘costose’ in termini di tempo di calcolo. Allora è opportuno chiedersi: esiste una Funzione di Densità di Probabilità (PDF) formale che possiamo utilizzare al posto sampling distribution empirica? Se prendiamo il vettore ‘result’ e lo ‘discretizziamo’, riportandolo in un istogramma (Fig. 7.1) possiamo vedere che la distribuzione empirica non assomiglia del tutto ad una gaussiana standardizzata, ma può essere descritta con un altro tipo di distribuzione, ovvero la ‘t di Student’, con otto gradi di libertà (ovvero la somma dei gradi di libertà dei due campioni)2. ## Warning: Removed 25 rows containing non-finite outside the scale range ## (`stat_bin()`). ## Warning: Removed 32 rows containing missing values or values outside the scale ## range (`geom_bar()`). Figura 7.1: Empirical sampling distribution for the T statistic, compared to a standardised gaussian (blue line) and a Student’s t distribution with 8 degrees of freedom (red line). The observed T-values have been highlighted and the total probability (area-under-the-curve) of sampling outside the interval from -4.522 to 4.522 represents the P-value Di conseguenza, possiamo utilizzare la distribuzione t di Student per calcolare il P-value, come mostrato nel riquadro sottostante. Invece che sommare le probabilità di ottenere valori superiori a 4.522 e di ottenere valori inferiori a -4.522, possiamo anche moltiplicare per due la probabilità di ottenere valori superiori al valore assoluto del T osservata. Infatti, la distribuzione di t di Student è simmetrica, e quindi le due code sono uguali. # Example 7.1 [continuation} # P-value from the Student&#39;s t distribution pt(T_obs, df=8, lower.tail = FALSE) # probability that T &gt; 4.522 ## [1] 0.0009727353 pt(-T_obs, df=8) # probability that T &lt; -4.522 ## [1] 0.0009727353 2 * pt(abs(T_obs), df=8, lower.tail = F) # P-value ## [1] 0.001945471 Vediamo che il P-level ottenuto formalmente è simile a quello ottenuto empiricamente, ma, rispetto a quest’ultimo, è più preciso, in quanto con la simulazione di Monte Carlo non abbiamo potuto considerare, come avremmo dovuto, un numero infinito di repliche dell’esperimento. Per concludere questa sezione, dobbiamo precisare che l’impiego di una sampling distribution formale richiede che siano verificate due condizioni di base: i residui sono campionati da una distribuzione normale (normalità); la deviazione standard è unica e non è influenzata dal trattamento sperimentale (omoschedasticità). Avrete infatti notato che queste due condizioni erano ‘incapsulate’ nella simulazione Monte Carlo che abbiamo eseguito in precedenza per ottenere la sampling distribution empirica di T. Se le due ipotesi non fossero rispettate, la distribuzione t di Student non rappresenterebbe esattamente la sampling distribution della statistica T e, di conseguenza, il P-level non sarebbe valido. Più avanti in questo libro vedremo come è possibile verificare che le due assunzioni di base siano effettivamente rispettate. 7.2 Altri test di t 7.2.1 Il test t di Student Il test t che abbiamo appena mostrato è utilizzato come supporto alle procedure di model fitting (Wald test) e permette di verificare l’ipotesi che uno dei parametri stimati sia significativamente diverso da 0. Il test t di Student è invece una tecnica tradizionale di analisi dei dati (risale al 1908) per il confronto tra due medie campionarie, senza alcun legame col model fitting. Sebbene, al giorno d’oggi il test t di Student debba essere considerato un po’ obsoleto, è comunque opportuno conoscere come questa procedura possa essere eseguita in R, con la funzione t.test(). Il box sottostante mostra che i risultati che si ottengono sono identici a quelli ottenuti nella sezione precedente. # Example 7.1 [continuation] # Traditional Student&#39;s t-test with R t.test(A, P, var.equal = TRUE) ## ## Two Sample t-test ## ## data: A and P ## t = -4.5217, df = 8, p-value = 0.001945 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -22.951742 -7.448258 ## sample estimates: ## mean of x mean of y ## 70.2 85.4 7.2.2 Il test di Welch Anche il test di t di Student richiede l’omoschedasticità dei dati e necessita dell’argomento var.equal = TRUE. Tuttavia, la funzione t.test() può essere facilmente estesa alle situazioni in cui i due campioni hanno varianze diverse, modificando il codice con l’argomento var.equal = FALSE. In questo modo viene eseguito il test di t eteroschedastico, noto anche come test di Welch. Grazie al suo maggiore livello di robustezza, il test di Welch è solitamente preferito al test t di Student ed è, quindi, l’opzione predefinita in R. # Code box 7.8 # Example 7.1 [continuation] # Heteroscedastic t-test (Welch test) with R t.test(A, P, var.equal = F) ## ## Welch Two Sample t-test ## ## data: A and P ## t = -4.5217, df = 7.7977, p-value = 0.002076 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -22.986884 -7.413116 ## sample estimates: ## mean of x mean of y ## 70.2 85.4 7.2.3 Il test di t appaiato In alcuni casi, l’esperimento prevede due misure sullo stesso soggetto ed è finalizzato a verificare se esiste una differenza significativa tra la prima e la seconda misura. Ad esempio, immaginiamo di aver esaminato un campione di venti topi pesandoli all’inizio e alla fine di un certo programma alimentare; in questo modo,si viene ad avere, per ogni individuo, due misurazioni appaiate, per un totale di quaranta valori. In tali condizioni, le due misure non sono indipendenti tra di loro e dobbiamo necessariamente eseguire un test di t appaiato, impostando l’argomento paired = TRUE, come mostrato nel riquadro sottostante. Si noti che, anche se abbiamo 40 valori, il numero di gradi di libertà è 19, perché abbiamo solo 20 soggetti indipendenti e due misure per soggetto. 7.3 Differenze generalizzate tra parametri Il test di Welch può essere generalizzato a qualunque situazione in cui abbiamo due stime indipendenti e vogliamo valutare se la loro differenza è significativa. Ad esempio, immaginiamo di aver stimato il tasso di crescita della barbabietola da zucchero con due diverse pratiche agronomiche e di aver ottenuto le stime \\(\\rho_1 = 0.22\\) con un errore standard di 0.013 e \\(\\rho_2 = 0.31\\) con un errore standard di 0.029. Il valore di T può essere ottenuto come: \\[T = \\frac{0.31 - 0.22}{\\sqrt{0.031^2 + 0.029^2}} = -2.12\\] Se la dimensione del campione è sufficientemente ampia e le due stime provengono da un ugual numero di soggetti, potremmo utilizzare un’approssimazione gaussiana per ottenere il P-value, come mostrato nel box sottostante. # Code box 7.10 # Example 7.3 # testing differences between model parameters T_obs &lt;- (0.22 - 0.31)/sqrt(0.031^2 + 0.029^2) 2 * pnorm(abs(T_obs), lower.tail = F) ## [1] 0.033994 Anche in questo caso il P-level è abbondantemente inferiore allo 0.05, per cui rigettiamo l’ipotesi nulla. 7.4 Il test F nell’ANOVA Il rapporto F è una misura della forza di una relazione causale tra un insieme di predittori nominali/quantitativi e una risposta quantitativa (vedi Capitoli 3 e 4). Ogni volta che i dati osservati rappresentano un campione di una popolazione più ampia, il valore F osservato è solo una stima di un numero infinito di possibili valori F, che definiscono una distribuzione campionaria. Che forma ha questa distribuzione campionaria? Ad esempio, se riconsideriamo l’esperimento di confronto varietale nell’Esempio 4.3 (dati ‘oat1L’), il rapporto F nell’ANOVA (box 4.7) per il genotipo è pari a 42.71, con 3 gradi di libertà al numeratore e 8 gradi di libertà al denominatore. Per questo esperimento, l’ipotesi nulla corrisponderebbe a una situazione in cui, a livello di popolazione, è: \\[H_0: \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4\\] Ciò equivale a dire che tutti gli effetti dei trattamenti sono uguali a 0: \\[H_0: \\alpha_1 = \\alpha_2 = \\alpha_3 = \\alpha_4 = 0\\] Il rapporto F osservato sembra contraddire l’ipotesi nulla, ma potrebbe trattarsi di un valore inaspettatamente alto capitato per caso, senza che vi sia una reale differenza tra i genotipi. Dobbiamo chiederci: qual è la distribuzione campionaria del rapporto F quando l’ipotesi nulla è vera? Una tale distribuzione campionaria potrebbe essere costruita tramite simulazione Monte Carlo; tuttavia, l’impiego di una CDF teorica è un approccio più semplice. Il matematico americano George Snedecor ha dimostrato che quando il valore nullo è vero e i residui sono indipendenti, distribuiti gaussianamente e omoschedastici, Sebbene potremmo costruire una tale distribuzione campionaria tramite simulazione Monte Carlo, il più delle volte è molto meglio utilizzare una CDF teorica. Il matematico americano George Snedecor ha dimostrato che, quando l’ipotesi nulla è vera e i residui sono gaussiani e omoschedastici, la distribuzione campionaria per il rapporto F può essere descritta con la cosiddetta distribuzione F di Fisher (o meglio, Fisher-Snedecor), che è definita solo per valori positivi e ha una forma asimmetrica (right-skewed), che dipende del numero di gradi di libertà al numeratore e al denominatore. Un esempio è mostrato in Figura \\(\\ref{fig:figNameF}\\). Figura 7.2: Fisher-Snedecor density function with 3 and 8 degrees of freedom. Considering a hypothetical F-ratio of 3, the total probability (Area-Under-the-Curve) above this value represents the P-value, that is 0.095 In R, il P-value si può calcolare con la funzione pf(), come indicato nel box sottostante. pf(42.707, 3, 8, lower.tail = F) ## [1] 2.866138e-05 Possiamo vedere che il valore P è inferiore a 0,05 e, di conseguenza, possiamo rifiutare l’ipotesi nulla e accettare l’alternativa, ovvero che l’effetto del genotipo è significativo e che c’è almeno un genotipo con una media diversa rispetto agli altri. 7.5 Conclusioni Concludiamo ribadendo che l’incertezza intrinseca nei dati sperimentali non consente di trarre conclusioni senza rischio di errore. Poiché il nostro obiettivo è quello di rifiutare l’ipotesi nulla, dobbiamo proteggerci dal rischio di un rifiuto erroneo, che ci porterebbe a concludere che il trattamento è ‘efficace’ quando in realtà ciò non è vero (falso positivo). La protezione dall’errore di falso positivo si mette in atto con la seguente procedura: calcolare una statistica utile (statistica pivotale) per riassumere i risultati di un esperimento (come il valore T o il rapporto F); identificare una distribuzione campionaria per esprimere la variabilità della statistica oggetto di studio, quando l’ipotesi nulla è vera e si ripete l’esperimento con lo stesso disegno sperimentale, ma un diverso campione di soggetti. La distribuzione campionaria può essere una funzione di probabilità teorica od empirica, ad esempio ottenuta con una simulazione di Monte Carlo; utilizzare la distribuzione campionaria selezionata per derivare la probabilità di eventi altrettanto estremi o più estremi di quello osservato nello specifico esperimento in studio; rigettare l’ipotesi nulla se la probabilità calcolata al punto 3 è inferiore a 0.05. Prima di concludere, vorremmo sottolineare tre questioni fondamentali, che dovremmo sempre tenere a mente: Il P-value è considerato come la probabilità di rifiutare erroneamente l’ipotesi nulla (errore di I specie o di falso positivo). Tuttavia, tale probabilità va interpretata con riferimento alla distribuzione campionaria, non mai in relazione al singolo esperimento oggetto di studio. Insomma, quando riusciamo a rigettare l’ipotesi nulla, siamo in grado di concludere che: se l’ipotesi nulla fosse vera e ripetessimo l’esperimento un numero infinito di volte, avremmo meno del 5% di probabilità di ottenere un valore T o F altrettanto elevato o più elevato (in valore assoluto) di quello da noi osservato. Quindi avere una probabilità d’errore del 5% significa che, adottando una procedura formale di test d’ipotesi, su 100 esperimenti in cui l’ipotesi nulla è vera, solo in cinque di essi l’ipotesi nulla verrebbe rigettata errorneamente. Al contrario, non possiamo concludere che la nostra specifica conclusione di rigettare l’ipotesi nulla abbia meno del 5% di probabilità di essere errata, perchè non abbiamo nessun elemento per stabilire se l’ipotesi nulla è vera o falsa nel nostro caso. Il P-value è calcolato a partire da una certa sampling distribution teorica, individuata assumendo che i residui siano normali ed omoschedastici. Se queste assunzioni di base non sono soddisfatte, il P-value è invalido. In uno dei prossimi capitoli mostreremo come verificare che gli assunti di base siano rispettati. Oltre all’ipotesi nulla, Neyman e Pearson hanno proposto di adottare un’ipotesi alternativa che si considera vera quando l’ipotesi nulla viene rifiutata. Ad esempio (vedi Sezione 7.1), se l’ipotesi nulla è \\(H_0: \\delta_2 = 0\\), l’alternativa è \\(H_1: \\delta_δ_2 \\neq 0\\). Sono possibili anche ipotesi alternative più complesse, come \\(H_1: \\delta_2 &gt; 0\\) o \\(H1: \\delta_2 &lt; 0\\), sebbene queste ipotesi alternative complesse possano essere adottate solo quando vi è una conoscenza a priori che le giustifica. Ciò si rende necessario in quanto un test d’ipotesi con un’ipotesi alternativa complessa (test ad una coda) è più potente di un test a due code.In ogni caso, dovremmo evitare il comune equivoco secondo cui rifiutare l’ipotesi nulla implichi che l’alternativa sia dimostrata o che l’alternativa sia vera con una probabilità \\(P_{alt} = 1 − \\textrm{P-value}\\) (Gigerenzer, 2018). Quando prendiamo una decisione “statistica”, non corriamo solo il rischio di commettere un errore di falso positivo (errore di tipo I), ma corriamo anche il rischio di commettere un errore di falso negativo (errore di tipo II), se non rifiutiamo un’ipotesi falsa nulla. Questi due tipi di errore sono ben rappresentati nella Figura 7.3, comunemente disponibile sul web. Si noti inoltre che i due tipi di errore sono correlati e maggiore è la protezione contro l’errore falso positivo, maggiore è il rischio di commettere un errore falso negativo. In generale, dovremmo sempre essere attenti a decidere quale dei due errori potrebbe essere più pericoloso per il nostro obiettivo specifico. Figura 7.3: The two types of statistical errors 7.6 Altre letture Gigerenzer G (2018) Statistical Rituals: The Replication Delusion and How We Got There. Advances in Methods and Practices in Psychological Science 1(2):198–218, DOI 10.1177/2515245918771329, URL https://journals.sagepub.com/doi/10.1177/2515245918771329 7.7 Esercizi La nostra miglior stima puntuale del parametro \\(\\gamma\\) di un modello statistico è \\(g = -7.2\\), con un errore standard pari a 2.8, con 16 gradi di libertà. E’possibile che, in realtà, sia \\(\\gamma = 0\\)? Qual è il P-level per l’ipotesi nulla? Devo accettarla o posso rifiutarla? La nostra miglior stima puntuale del parametro \\(\\delta\\) di un modello statistico è \\(d = 13.5\\), con un errore standard pari a 8.4, ma non è disponibile, per questo errore standard, una stima accurata dei gradi di libertà. E’possibile che, in realtà, sia \\(\\delta = 0\\)? Qual è il P-level per l’ipotesi nulla? Devo accettarla o posso rifiutarla? Uno sperimentatore ha impostato un esperimento per confrontare due tesi sperimentali (A, B). I risultati sono i seguenti (in t/ha) A &lt;- c(9.3, 10.2, 9.7) e B &lt;- c(12.6, 12.3, 12.5). Stabilire se i risultati per le due tesi sperimentali possono essere considerati significativamente diversi, per un livello di probabilità di errore di I specie del 5%. Uno sperimentatore ha impostato un esperimento per confrontare se l’effetto di un fungicida è significativo, in un disegno sperimentale con tre ripetizioni. Con ognuna delle due opzioni di trattamento i livelli di infestazione (in percentuale) sono: A &lt;- c(6.5, 7.1, 6.8) e NT &lt;- c(54.1, 48.2, 63.1). E’significativo l’effetto del trattamento fungicida, per un livello di probabilità del 5%? SUGGERIMENTO: prestare attenzione all’omogeneità delle varianze. Con un esperimento in laboratorio, abbiamo stimato che il tasso di degradazione di una sostanza xenobiotica in acqua è \\(k_1 = -0.071 \\pm 0.012\\) (7 gradi di libertà). Per una sostanza affine il tasso di degradazione è pari a \\(k_2 = -0.153 \\pm 0.024\\) (7 gradi di lbertà); possiamo concludere che il tasso di degradazione delle due sostanze, in realtà, non è significativamente diverso? In un ospedale, è stata misurata la concentrazione di colesterolo nel sangue di otto pazienti, prima e dopo un trattamento medico. Per ogni paziente, sono stati analizzati due campioni, ottenendo le seguenti concentrazioni (in ordine di paziente): Prima &lt;- c(167.3, 186.7, 107.0, 214.5, 149.5, 171.5, 161.5, 243.6) e Dopo &lt;- c(166.7, 184.2, 104.9, 205.3, 148.5, 157.3, 149.4, 241.5). Si può concludere che il trattamento medico è stato efficace? Un veterinario ha organizzato un esperimento per valutare l’effetto di una dieta innovativa, sulla pressione arteriosa sistolica di cavalli da corsa. Le informazioni preliminari mostrano con chiarezza che questa dieta innovativa non può avere effetti negativi, ma, eventualmente, solo positivi. Il ricercatore ha selezionato a caso 16 animali, ne ha misurato la pressione arteriosa a riposo ed ha ripetuto la stessa misurazione dopo sei mesi di questa dieta. I risultati ottenuti sono i seguenti: I risultati ottenuti sono: prima &lt;- c(113.5, 116.5, 118.1, 111.3, 116.8, 117.0, 114.8, 114.9, 114.8, 114.2, 115.0, 114.0, 114.4, 116.1, 117.9, 115.7) e dopo &lt;- c(110.9, 110.1, 110.3, 116.8, 112.2, 111.0, 111.1, 112.9, 110.6, 109.1, 113.1, 109.9, 111.9, 110.1, 114.2, 111.0). Stabilire se la dieta è efficace, con una probabilità di errore P &lt; 0.05. SUGGERIMENTO: ricordare che la l’effetto atteso della dieta, per le informazioni preliminari disponibili, può, eventualmente, essere solo quello di abbassare la pressione, mai quello di alzarla. I Q.I. di 16 studenti provenienti da un quartiere di una certa città sono risultati pari a: QI1 &lt;- c(90.31, 112.63, 101.93, 121.47, 111.37, 100.37, 106.80, 101.57, 113.25, 120.76, 88.58, 107.53, 102.62, 104.26, 95.06, 104.88). Gli studenti provenienti da un altro quartiere della stessa città hanno invece mostrato i seguenti Q.I.: QI2 &lt;- c(90.66, 101.41, 104.61, 91.77, 107.06, 89.51, 87.91, 92.31, 112.96, 90.33, 99.86, 88.99, 98.97, 97.92). Esiste una differenza significativa tra i Q.I. nei due quartieri della città? Viene estratto un campione di rondelle da una macchina in perfette condizioni di funzionamento. Lo spessore delle rondelle misurate è: S1 &lt;- c(0.0451, 0.0511, 0.0478, 0.0477, 0.0458, 0.0509, 0.0446, 0.0516, 0.0458, 0.0490). Dopo alcuni giorni, per determinare se la macchina sia ancora a punto, viene estratto un altro campione di 10 rondelle, il cui spessore medio risulta: S2 &lt;- c(0.0502, 0.0528, 0.0492, 0.0556, 0.0501, 0.0500, 0.0498, 0.0526, 0.0517, 0.0550). Verificare se la macchina sia ancora ben tarata, oppure necessiti di revisione. Le varianze di due campioni composti da 30 unità sono risultate pari, rispettivamente a 115.3 e 356.4; stabilire se il secondo campione ha una varianza significativamente più alta del primo. SUGGERIMENTO: considerare che il rapporto tra due varianze di campioni estratti dalla stessa popolazione gaussiana segue la distribuzione F di Fisher. Considerare anche che, in R, la funzione pf(x, n1, n2, lower.tail = F) restituisce la probabilità di ottenere valori pari o superiori ad \\(x\\), da una distribuzione \\(F\\) di Fisher con \\(n1\\) ed \\(n2\\) gradi di libertà. Considerare anche che il rapporto di due varianze può solo essere positivo. Un agronomo ha organizzato un esperimento varietale, per confrontare tre varietà di frumento, cioè GUERCINO, ARNOVA e BOLOGNA. Per far questo ha individuato, in un campo uniforme dell’areale umbro, trenta parcelle da 18 m2 e ne ha selezionate dieci a caso, da coltivare con GUERCINO, altre dieci a caso sono state coltivate con ARNOVA e le ultime dieci sono state coltivate con BOLOGNA. Al termine dell’esperimento, le produttività osservate erano le seguenti: guercino &lt;- c(53.2, 59.1, 62.3, 48.6, 59.7, 60, 55.7, 55.8, 55.7, 54.4), arnova &lt;- c(53.1, 51, 51.9, 55.3, 58.8, 54.6, 53, 51.4, 51.7, 64.7) e bologna &lt;- c(43.5, 41, 41.2, 44.8, 40.2, 37.2, 45.3, 38.9, 42.9, 39.3). Descrivere i tre campioni, utilizzando opportunamente un indicatore di tendenza centrale ed un indicatore di variabilità. Inferire le medie delle tre popolazioni (cioè quelle che hanno generato i tre campioni), utilizzando opportunamente un intervallo di incertezza. Per ognuna delle tre coppie (guercino vs arnova, guercino vs bologna, arnova vs bologna), valutare la differenza tra le medie e il suo errore standard. Valutare la significatività della differenza tra le medie delle tre popolazioni, esplicitando l’ipotesi nulla e calcolando il livello di probabilità di errore nel rifiuto dell’ipotesi nulla. La distribuzione t di Student fu ideata dallo ‘studente’ William Sealy Gosset (1876 - 1937), che utilizzava questo pseudonimo nei suoi articoli scientifici mentre lavorava alla Guinness Brewery di Dublino. E’ simile a una distribuzione gaussiana standardizzata, ma con code più alte, cioè con una maggiore probabilità di ottenere outliers, sia positivi, che negativi. L’altezza delle code è inversamente proporzionale al parametro \\(\\nu\\) (il numero di DF), in modo che questa distribuzione tende ad una gaussiana quando \\(\\nu\\) tende ad infinito↩︎ "],["verifica-dei-modelli.html", "Capitolo 8 Verifica dei modelli 8.1 Deviazioni rispetto alle assunzioni di base 8.2 Scoprire le violazioni 8.3 Analisi grafica dei residui 8.4 Test d’ipotesi 8.5 Esempio 8.1: Analisi dei residui per il dataset “mixture” 8.6 Esempio 8.2: Analisi dei residui per il dataset ‘insects’ 8.7 Misure correttive 8.8 Risultati contraddittori 8.9 Altri approcci ‘avanzati’ 8.10 Altre letture 8.11 Esercizi", " Capitolo 8 Verifica dei modelli Nei capitoli precedenti, abbiamo studiato i modelli come “strumenti” per descrivere le relazioni causa-effetto tra le variabili sperimentali e per trarre conclusioni testando ed eventualmente rigettando ipotesi scientifiche rilevanti. Tuttavia, abbiamo anche visto che i modelli statistici e le inferenze su di essi basate, assumono che siano verificate alcune condizioni fondamentali: il modello fornisce una buona descrizione dei dati sperimentali (bontà di adattamento); i residui sono indipendenti l’uno dall’altro (indipendenza); i residui hanno una distribuzione gaussiana di probabilità (normalità); tutti i residui hanno la stessa varianza (omoschedasticità). Oltre alle ipotesi di cui sopra, i dati osservati devono rispettare anche un altro requisito essenziale: l’assenza di valori anomali (outliers), ovvero osservazioni che differiscono notevolmente da tutte le altre osservazioni nello stesso gruppo di trattamento. Questi valori anomali producono residui negativi o positivi enormi, che possono essere molto influenti, sia per il test d’ipotesi che per l’affidabilità delle stime. Purtroppo, bisogna riconoscere che i problemi relativi alle assunzioni di base sono tutt’altro che infrequenti, come vedremo in seguito. 8.1 Deviazioni rispetto alle assunzioni di base La mancanza di ‘bontà d’adattamento’ (più semplicemente: ‘mancanza d’adattamento’) può verificarsi quando le previsioni del modello sembrano deviare sistematicamente rispetto ai dati osservati, ad esempio quando una modello di regressione lineare viene adattato ad una risposta curvilinea. In caso di mancanza di adattamento, dovremo concludere che i dati e il modello non si supportano a vicenda e, quindi, che il modello “non consente al ricercatore di rispondere alle sue domande scientifiche” (Kass et al., 2016). La mancanza d’indipendenza dei residui del modello può verificarsi a causa di: intrusioni sistematiche, presenza di fattori di raggruppamento non considerati nel modello, mancanza di adattamento sistematica dovuta alla selezione errata del modello, o mancanza di randomizzazione adeguata (vedere anche Sezione 4.6 e Capitolo 12). La mancanza di indipendenza è considerata una delle assunzioni di base più pericolose da violare, poiché comporta un rischio elevato di errore di I specie (Frey et al., 2024), ovvero un rischio maggiore di rifiutare erroneamente un’ipotesi nulla vera (falso positivo). La normalità viene violata quando i residui del modello non “riflettono” la forma tipica di una distribuzione gaussiana, ovvero quando sono asimmetrici (distribuzione asimmetrica: la media non è uguale alla mediana) o quando le code sono troppo ‘alte’ (distribuzione platicurtica: troppi valori estremi) o troppo ‘basse’ (distribuzione leptocurtica: i valori sono troppo “concentrati” attorno alla media)(Fig. 8.1). In assenza di outliers (vedi più avanti), la non normalità è considerata meno dannosa di altre deviazioni (Knief e Forstmeier, 2021), in quanto non provoca forti distorsioni nella stima dei parametri od un incremento del rischio di errore di I specie. Tuttavia, si raccomanda sempre un atteggiamento cauto, poiché le deviazioni dalla normalità possono essere associate ad altri tipi di deviazioni più pericolose, come l’eteroschedasticità. Deviazioni dalla normalità possono verificarsi anche a causa della presenza di outliers, collegati ad errori casuali di entità eccezionale (ad esempio, procedure difettose, scarso controllo o intrusioni di qualsiasi tipo). Questi outliers modificano profondamente medie e deviazioni standard, portando ad un’errata interpretazione dei risultati sperimentali (Cochran, 1947). Figura 8.1: Alcune distribuzioni non-normali dei residui. L’eteroschedasticità può verificarsi, ad esempio, quando i trattamenti sperimentali producono effetti sia sulla media che sulle deviazioni standard (ad esempio, effetti moltiplicativi) in modo tale che queste due statistiche diventino proporzionali tra loro (quando la media aumenta, aumenta proporzionalmente anche la deviazione standard). Altre cause comuni di eteroschedasticità includono attacchi di parassiti e altre intrusioni, nonché un grado inferiore di controllo in alcune parti dell’esperimento di campo. È stato dimostrato che l’eteroschedasticità si traduce in una stima distorta della deviazione standard dei residui e porta a P-value non validi, così che il reale rischio d’errore di I specie può essere anche molto diverso da quello nominale (Glass et al., 1972). 8.2 Scoprire le violazioni Il rispetto di alcune assunzioni di base, come l’indipendenza dei residui e l’assenza di errori sistematici, è garantito dall’adozione di un disegno sperimentale a ‘regola d’arte’, cioè basato su repliche indipendenti e correttamente randomizzate. Bisogna tenere presente che gli eventuali vincoli alla randomizzazione introdotti in fase di disegno sperimentale (blocchi randomizzati, quadrato latino, split-plot…) possono inficiare l’indipendenza dei residui; ad esempio, con i blocchi randomizzati, le osservazioni all’interno dello stesso blocco si assomigliano di più che non quelle in blocchi diversi, proprio perché condividono le condizioni ambientali caratteristiche di ciascun blocco. Insomma, si realizza un certo grado di ‘parentela’ tra le osservazioni, che non è compatibile con l’ipotesi di totale indipendenza. Vedremo nei capitoli successivi che queste situazioni vengono gestite includendo nel modello ANOVA anche il fattore di blocco o gli altri vincoli eventualmente imposti alla randomizzazione completa. Per quanto riguarda le altre assunzioni di base, come la bontà di adattamento, l’omogeneità delle varianze e la normalità dei residui, la verifica può essere fatta solo a posteriori, cioè dopo aver effettuato la stima dei parametri ed aver individuato i residui stessi. Oltre a quanto abbiamo finora dotto, dobbiamo anche tener presente che il dataset non dovrebbe contenere le cosiddette osservazioni aberranti od outliers. Si tratta di osservazioni molto diverse dalle altre, che spesso fanno sospettare che sia avvenuto qualche errore grossolano; la loro assenza non è postulata da alcun modello statistico, anche se esse, proprio perché molto diverse dalle altre, finiscono per inficiare la normalità dei residui e l’omogeneità delle varianze, oltre a stravolgere pericolosamente le nostre conclusioni. Pertanto, alla loro individuazione deve essere sempre dedicata la debita attenzione. Per diagnosticare eventuali problemi con le assunzioni di base e/o con la presenza di outliers, possiamo utilizzare sia metodi grafici che metodi formali, basati sul test d’ipotesi. Vediamo ora alcune possibilità. 8.3 Analisi grafica dei residui Dato che la gran parte delle assunzioni riguarda la struttura dei residui, l’ispezione grafica di questi ultimi è in grado di evidenziare chiaramente la gran parte dei problemi e dovrebbe, pertanto, essere considerata come una metodica da applicare in modo routinario. Esistono diversi tipi di grafici, ma ne elenchiamo fondamentalmente due: il grafico dei residui contro i valori attesi e il QQ-plot. 8.3.1 Grafico dei valori osservati, aumentato con le previsioni del modello Per tutti i tipi di modelli di regressione, lo strumento più importante per verificare la bontà di adattamento è un grafico a dispersione della risposta osservata rispetto al predittore, integQuest’ultima dovrebbe seguire fedelmente i dati osservati (Fig. 8.2A) senza mostrare alcun segno di deviazioni sistematiche, come illustrato nelle Figure 8.2B, C e D. Figura 8.2: Grafico a dispersione delle risposte osservate (simboli), integrati con le previsioni del modello (linee e curve). Il panel in alto a sinistra mostra un modello con un buon adattamento, mentre gli altri grafici mostrano diversi tipi di violazioni. 8.3.2 Grafico dei residui contro i valori attesi Il metodo grafico più utilizzato per l’analisi dei residui consiste nel plottare i residui stessi contro i valori attesi. Se non vi sono problemi, i punti nel grafico dovrebbero essere distribuiti in modo assolutamente casuale, come in Figura 8.3, in alto a sinistra. Le osservazioni aberranti (outliers) appaiono invece come punti isolati rispetto agli altri (Fig. 8.3; in alto a destra). L’eterogeneità delle varianze è invece indicata da residui che si allargano o si stringono procedendo verso i margini del grafico (Figura 8.3, in basso a sinistra), facendo emergere una sorta di proporzionalità tra media e varianza. In ultimo, la mancanza di adattamento nei modelli di regressione è evidenziata da un qualche evidente pattern, come quando i residui sono tendenzialmente negativi per bassi valori attesi e positivi per alti valori, chiaro segnale di un modello deterministico che sovrastima le osservazioni quando sono basse e le sottostima quando sono alte (Fig. 8.3; in basso a destra). Figura 8.3: Plot dei residui contro i valori attesi: una disposizione dei punti totalmente casuale supportata l’ipotesi che le assunzioni di base siano rispettate (in alto a sinistra). Gli outliers sono evidenziati come punti ‘isolati’ (in alto a destra), mentre una disposizione ad ‘imbuto’ rivela che le varianze sono direttamente o inversamente proporzionali alle medie (in basso a sinistra). La mancanza d’adattamento è invece rivelata da un qualkunque evidente pattern nella disposizione dei punti, come, ad esempio, dei residui associati di ugual segno in una certa zona del grafico (in basso a destra). 8.3.3 QQ-plot Per evidenziare problemi di non-normalità, risulta molto utile un QQ-plot (quantile-quantile plot), nel quale i residui standardizzati vengono ‘plottati’ contro i rispettivi percentili di una distribuzione normale standardizzata. Con residui normali, queste due entità (i residui standardizzati e i percentili corrispondenti di una distribuzione normale standardizzata) sono largamente coincidenti, in modo che i punti nel QQ-plot giacciono lungo la bisettrice del primo e del terzo quadrante (8.4 in alto a sinistra). Le deviazioni più diffuse dalla normalità sono relative alla simmetria (skewness) e alla curtosi della popolazione da cui i residui sono campionati. In particolare, può capitare che i residui provengano da una popolazione con asimmetria positiva (right-skewed), come, ad esempio, una popolazione log-normale. In questo caso, la media è maggiore della mediana e i residui negativi sono più numerosi, ma più piccoli in valore assoluto di quelli positivi. Il QQ-plot si presenta come in figura 8.4 in alto al centro. Al contrario, se i residui provengono da una popolazione con asimmetria negativa (‘left-skewed’), caratterizzata, ad esempio, da una funzione di densità ‘beta’, la media è minore della mediana e, di conseguenza, i valori positivi sono più numerosi, ma più vicini allo zero di quelli negativi. In questa situazione, il QQ-plot presenta un andamento abbastanza tipico, come indicato in Figura 8.4 in alto a destra. Per quanto riguarda la curtosi, è necessario osservare le code della distribuzione: se queste sono più alte di una distribuzione normale parliamo di distribuzione platicurtica, mentre se sono più basse parliamo di distribuzione leptocurtica. Ad esempio, se i residui provengono da una distribuzione t di Student con pochi gradi di libertà sono platicurtici ed il QQ-plot mostra l’andamento indicato in figura 8.4 in basso a sinistra. Al contrario, se i residui provengono da una distribuzione uniforme sono tipicamente leptocurtici e presentano un QQ-plot come quello riportato in Figura 8.4 in basso al centro. Figura 8.4: QQ-plot per residui gaussiani (in alto a sinistra) e per residui che mostrano diversi tipi di violazioni dalla normalità (vedi anche Fig. 8.1). 8.4 Test d’ipotesi La valutazioni illustrate in precedenza sono basate sulla semplice osservazione di uno o più grafici, ma sono considerate sufficientemente attendibili per la maggior parte delle situazioni. Tuttavia, esistono anche test statistici formali che consentono di saggiare l’ipotesi nulla di ‘assenza di deviazioni’, che può essere rifiutata qualora il P-level fosse inferiore a 0.05. Rispetto alle procedure grafiche, il test d’ipotesi formale può dare una miglior sensazione di obiettività, anche se non è tutto oro quel che luccica. Infatti, questi test possono creare più problemi di quanti ne risolvano dato che, ad esempio, richiedono campioni di grandi dimensioni e fanno affidamento su assunzioni di base molto stringenti, tanto che, alla fine, l’affidabilità dei risultati è spesso discutibile (Kozak e Piepho 2018). Per questi motivi, il loro utilizzo è sconsigliato e dovrebbe essere riservato a supportare situazioni complesse in cui i metodi grafici non forniscono risposte sufficientemente chiare. Le procedure presentate in questo capitolo sono state selezionate perché ampiamente utilizzate e facilmente disponibili in R. 8.4.1 Test di Levene per l’omogeneità delle varianze Secondo gli studi di Conover et al. (1981), il test di Levene è una delle procedure più affidabili per saggiare l’ipotesi di omoschedasticità nei modelli con predittori nominali; consiste nel’eseguire l’analisi della varianza di una ‘pseudo-risposta’, ottenuta sostituendo ciascun dato osservato con il valore assoluto della sua differenza con il centro del gruppo a cui appartiene (dati ‘group-centered’). Inizialmente, Levene propose di utilizzare come centro di gruppo la media; l’idea di fondo era che, sebbene le medie di gruppo di dati ‘group-centered’ siano pari a zero, prendendo i valori assoluto (cioè rimuovendo i segno negativi), queste medie diventano diverse da zero e sono tanto più alte quanto più la varianza di gruppo è alta. Questo concetto sarà più semplice da comprendere utilizzando un esempio pratico. Consideriamo due gruppi sperimentali A &lt;- c(19, 20, 21) e B &lt;- c(26, 30, 34), che hanno, rispettivamente, medie pari a 20 e 30, e varianze pari a 1 e 16. Sottraendo dalle osservazioni di ogni gruppo la media del gruppo stesso, otteniamo le pseudo-osservazioni Ac &lt;- c(-1, 0, 1) e Bc &lt;- c(-4, 0, 4), la cui media è zero, mentre le varianze restano inalterate. Se escludiamo i segno negativi, le medie dei due gruppi divengono pari, rispettivamente, a 2/3 e 8/3, mostrando come il gruppo con più alta varianza abbia prodotto pseudo-osservazioni con media più alta. Se la differenza tra le due medie delle pseudo-osservazioni è significativa, l’ipotesi nulla di omogeneità delle varianze può essere rigettata. Lavori successivi (Brown e Forsythe, 1974) hanno mostrato che è preferibile sostituire la media del gruppo con la sua mediana, per ottenere un test più robusto per dati non normali. Sia il test di Levene che il test di Brown-Forsythe sono disponibili nella funzione leveneTest() del package car, ma il secondo è largamente preferito e considerato come la procedura di ‘default’. Un esempio di questo test è fornito nel Riquadro 8.3, che confronta due genotipi di mais in un disegno completamente randomizzato con 11 repliche. Il secondo genotipo (B) presenta una varianza maggiore e il test di Levene risulta significativo (il valore P è inferiore a 0,05 e l’ipotesi nulla di omoschedasticità viene rifiutata). I due test (centrato sulle medie o centrato sulle mediane) producono risultati simili, il che potrebbe suggerire che i dati originali non si discostino significativamente dalla normalità. # Code Box 8.1 # Testing hypotheses about model residuals # Levene’s test for homoscedasticity library(car) # Entering the data dataset &lt;- data.frame(Genotype = c(&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;, &quot;B&quot;), Yield = c(10.0, 10.7, 11.9, 10.3, 10.0, 7.8, 10.4, 9.7, 10.0, 9.2, 9.7, 15.0, 11.2, 13.7, 11.9, 9.4, 10.6, 12.6, 10.1, 9.9, 15.3, 12.2)) head(dataset) ## Genotype Yield ## 1 A 10.0 ## 2 A 10.7 ## 3 A 11.9 ## 4 A 10.3 ## 5 A 10.0 ## 6 A 7.8 dataset$Genotype &lt;- factor(dataset$Genotype) # Fitting the model mod &lt;- lm(Yield ~ Genotype, data = dataset) # Centering the data by subtracting, for each genotype # the group mean (Levene’s test) GroupMeans &lt;- tapply(dataset$Yield, dataset$Genotype, mean) YieldC &lt;- dataset$Yield - rep(GroupMeans, each = 11) # Re-fitting the same model to the absolute values of # centered data and run an ANOVA modlevene &lt;- lm(abs(YieldC) ~ dataset$Genotype) anova(modlevene) ## Analysis of Variance Table ## ## Response: abs(YieldC) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dataset$Genotype 1 5.2129 5.2129 5.8944 0.02475 * ## Residuals 20 17.6878 0.8844 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Centering the data by subtracting, for each genotype # the group median (Brown-Forsythe’s test) GroupMedians &lt;- tapply(dataset$Yield, dataset$Genotype, median) YieldC &lt;- dataset$Yield - rep(GroupMedians, each = 11) # Re-fitting the same model to the absolute values of # centered data and run an ANOVA modlevene &lt;- lm(abs(YieldC) ~ dataset$Genotype) anova(modlevene) ## Analysis of Variance Table ## ## Response: abs(YieldC) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## dataset$Genotype 1 5.2041 5.2041 5.7245 0.02666 * ## Residuals 20 18.1818 0.9091 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Non-robust Levene’s test with R (centering with means) leveneTest(mod, center = &quot;mean&quot;) ## Levene&#39;s Test for Homogeneity of Variance (center = &quot;mean&quot;) ## Df F value Pr(&gt;F) ## group 1 5.8944 0.02475 * ## 20 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Levene’s test with R (centering with medians; default) leveneTest(mod) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 1 5.7245 0.02666 * ## 20 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 8.4.2 Test di Shapiro-Wilk per la normalità Il test di Shapiro-Wilk per la normalità fornisce la statistica W e un valore P per l’ipotesi nulla che i residui siano distribuiti normalmente. La procedura di test non è così semplice come quella del test di Levene e i calcoli manuali non sono altrettanto facili da eseguire. Tuttavia, possiamo utilizzare la funzione shapiro.test() in R, passando i residui del modello come argomento (vedi l’esempio seguente). 8.4.3 Altri test Vale la pena menzionare alcune tecniche numeriche per l’individuazione di valori anomali, come i metodi proposti da Anscombe e Tukey (1963) e Grubbs (1969). 8.5 Esempio 8.1: Analisi dei residui per il dataset “mixture” Abbiamo eseguito un esperimento in vaso, nel quale abbiamo utilizzato quattro trattamenti erbicidi: Metribuzin Rimsulfuron Metribuzin + rimsulfuron Testimone non trattato Lo scopo dell’esperimento era quello di verificare se la miscela metribuzin e rimsulfuron è più efficace dei due componenti utilizzati separatamente. A questo fine, sono stati preparati sedici vasi uniformi e sono stati seminati con Solanum nigrum, un importante infestante di alcune colture primaverili estive, come mais e pomodoro. Quando le piante hanno raggiunto lo stadio di 4 foglie vere, sono state trattate con una delle tesi sopra elencate, secondo un disegno sperimentale completamente randomizzato con quattro repliche. Tre settimane dopo i trattamenti, le piante in ciascun vaso sono state raccolte e pesate; minore era il peso, maggiore era l’efficacia degli erbicidi (Onofri et al. 1995). Per questo esperimento, è possibile adattare un modello lineare con un predittore nominale (il trattamento erbicida) (vedere Eq. 4.6 nel Cap. 4), come mostrato nel riquadro sottostante. # Code box 8.2 # Example 8.1 # Checking the residuals for the `mixture&#39; data # Loading the packages library(statforbiology) library(car) # Loading and transforming the data mixture &lt;- getAgroData(&quot;mixture&quot;) mixture$Treat &lt;- factor(mixture$Treat) head(mixture) ## Treat Weight ## 1 Metribuzin__348 15.20 ## 2 Metribuzin__348 4.38 ## 3 Metribuzin__348 10.32 ## 4 Metribuzin__348 6.80 ## 5 Mixture_378 6.14 ## 6 Mixture_378 1.95 # Model fitting mod1 &lt;- lm(Weight ~ Treat, data = mixture) Dopo aver effettuato la stima dei parametri, i grafici dei residui possono essere ottenuti utilizzando la funzione plot() applicata al risultato del fitting lineare. L’argomento ‘which’ specifica il tipo di grafico: se utilizziamo: ‘which = 1’ otteniamo il grafico dei residui verso gli attesi, se invece utilizziamo ‘which = 2’ otteniamo il QQ-plot. I due comandi sono: plot(mod, which = 1) plot(mod, which = 2) e il risultato è mostrato nella figura 8.5. Figura 8.5: Analisi grafica dei residui per un modello ANOVA ad una via adattato al dataset ‘mixture.csv’ Nessuno dei grafici suggerisce l’esistenza di particolari problematiche e, considerando anche che che non si tratta di un conteggio o una proporzione e che le differenze tra le medie sono piuttosto piccole (meno di un ordine di grandezza), possiamo concludere che non vi sono motivi per dubitare del rispetto delle assunzioni di base. Sebbene ciò non sia necessario, possiamo confermare la nostra conclusione eseguendo i test di Levene e Shapiro-Wilk. Nel codice sottostante possiamo notare come la funzione leveneTest() richieda come argomento l’oggetto risultante dal fitting lineare, mentre la funzione shapiro.test() richiede i residui del modello. # Example 8.1 [continuation] # Levene&#39;s test and Shapiro-Wilk&#39;s test leveneTest(mod1) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 3 1.0698 0.3984 ## 12 shapiro.test(residuals(mod1)) ## ## Shapiro-Wilk normality test ## ## data: residuals(mod1) ## W = 0.97615, p-value = 0.9257 8.6 Esempio 8.2: Analisi dei residui per il dataset ‘insects’ Proviamo ad analizzare il dataset ‘insects’, che si riferisce ad un esperimento nel quale quindici piante sono state trattate con tre insetticidi diversi in modo completamente randomizzato, scegliendo cinque piante a caso per insetticida. Tre settimane dopo il trattamento è stato rilevato il numero di insetti presenti su ciascuna pianta. Per testare l’effetto degli insetticidi, è stato adattato ai dati osservati un modello ANOVA ad una via, utilizzando la variabile “Insecticide” come predittore nominale. In questo caso, il controllo delle deviazioni dagli assunti di base richiede grande attenzione, poiché la variabile di risposta è un conteggio e le statistiche descrittive, che si lasciano per eercizio al lettore, indicano che le deviazioni standard sono in qualche modo proporzionali alle medie. Le analisi grafiche dei residui in Figura 8.6 mostrano chiari segni di eteroschedasticità (grafico a sinistra) e residui asimmetrici a destra (grafico a destra). Queste deviazioni sono confermate dal test di Levene (valore P = 0,043) e dal test di Shapiro-Wilks (valore P = 0,048). # Example 8.2 # checking the residuals for the `insects&#39; data # Loading the packages library(statforbiology) library(car) # Loading and transforming the data insects &lt;- getAgroData(&quot;insects&quot;) insects$Insecticide &lt;- factor(insects$Insecticide) head(insects) ## Insecticide Rep Count ## 1 T1 1 448 ## 2 T1 2 906 ## 3 T1 3 484 ## 4 T1 4 477 ## 5 T1 5 634 ## 6 T2 1 211 # Fitting a model mod2 &lt;- lm(Count ~ Insecticide, data = insects) # Graphical analyses of residuals (not run, see Figure) # plot(mod2, which = 1) # plot(mod2, which = 2) # Levene&#39;s test leveneTest(mod2) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 1.0263 0.3878 ## 12 # Shapiro-Wilks&#39; test shapiro.test(residuals(mod2)) ## ## Shapiro-Wilk normality test ## ## data: residuals(mod2) ## W = 0.87689, p-value = 0.04265 Figura 8.6: Analisi grafica dei residui per il dataset ‘insects.csv’ 8.7 Misure correttive Se le procedure diagnostiche hanno evidenziato deviazioni rispetto agli assunti di base, è necessario valutare se e come intraprendere azioni correttive. Ovviamente, la ‘terapia’ cambia al cambiare della ‘patologia’. 8.7.1 Correzione/Rimozione degli outliers In presenza di outliers, la ‘terapia’ più opportuna è, banalmente, quella di rimuoverli, ottenendo così un dataset ‘sbilanciato’ (diverso numero di repliche per trattamento). Oggigiorno, trattare un dataset sbilanciato non costituisce un problema, ovviamente se si utilizzano le metodiche di analisi opportune. Qualche anno fa, al contrario, si cercava di evitare lo sbilanciamento a tutti i costi, utilizzando tecniche di imputing per l’immissione di valori ‘ragionevoli’ in sostituzione di quelli mancanti/aberranti. Con le dovute eccezioni, le tecniche di imputing sembrano oggi abbastanza obsolete, almeno in questo contesto. Vorremmo porre l’attenzione sul fatto che i dati aberranti possono influenzare in modo molto marcato il risultato dell’analisi (sono dati ‘influenziali’); pertanto, se è sbagliato correggerli arbitrariamente, senza aver prima accertato che siano effettivamente frutto di errore, può essere altrettanto sbagliato lasciarli nel dataset. Ovviamente, la rimozione non può che riguardare una larga minoranza dei dati sperimentali raccolti, altrimenti si dovrà necessariamente pensare di ripetere l’esperimento. 8.7.2 Correzione del modello Abbiamo visto che il modello impiegato potrebbe non essere adatto a descrivere il dataset (mancanza di adattamento). Gli effetti potrebbero non essere additivi, ma moltiplicativi, oppure potrebbero essere non-lineari. Potrebbero essere presenti asintoti che il nostro modello non è in grado di descrivere, oppure la crescita/decrescita osservata potrebbero essere più lente/veloci di quanto la nostra funzione sia in grado di descrivere. Per tutti questi casi, ovviamente, la strategia più consigliabile è quella di utilizzare un diverso modello, capace di descrivere meglio le osservazioni sperimentali. 8.7.3 Trasformazione del predittore Quando il predittore è quantitativo e la risposta sembra non essere lineare è possibile trasformare il predittore stesso in modo da linearizzare la risposta. Ad esempio, se la risposta mostra un andamento esponenziale, la trasformazione del predittore in logaritmo può portare al sensibile miglioramento del fitting con un’equazione lineare. Vedremo un esempio di questa tecnica in un capitolo successivo. 8.7.4 Trasformazione della risposta Una strategia empirica, ma molto semplice, diffusa ed efficace, è quella di ricorrere alle trasformazioni correttive. Con questa tecnica, si trasformano i dati in modo da portarli su una metrica che soddisfi le assunzioni di base dei modelli lineari; successivamente si ripete l’elaborazione sui dati trasformati. Le trasformazioni possibili sono molte: ad esempio, i libri di testo più tradizionali (esempio: Snedecor e Cochran, 1991) consigliano la trasformazione in radice quadrata per i conteggi, la trasformazione angolare (arcoseno della radice quadrata) per le percentuali e la trasformazione in logaritmo per i dati log-normali, dove le variance sono proporzionali alle medie. Per evitare di scegliere la trasformazione ‘al buio’, si può impiegare la procedura suggerita da Box e Cox (1964), basata su una ‘famiglia di trasformazioni’, così definita: \\[ W = \\left\\{ \\begin{array}{ll} \\frac{Y^\\lambda - 1}{\\lambda} &amp; \\quad \\textrm{if} \\,\\,\\, \\lambda \\neq 0 \\\\ \\log(Y) &amp; \\quad \\textrm{if} \\,\\,\\, \\lambda = 0 \\end{array} \\right.\\] dove \\(W\\) è la variabile trasformata, \\(Y\\) è la variabile originale e \\(\\lambda\\) è il parametro che definisce la trasformazione 3 Questa famiglia è molto flessibile, nel senso che cambiando il valore di \\(\\lambda\\) possiamo rimediare alla gran parte delle deviazioni rispetto alle assunzioni di base. Il valore ottimale (di massima verosimiglianza) per questo parametro può essere scelto con la funzione boxcox(), nel package MASS, come sarà mostrato negli esempi seguenti. Bisogna tener presente che, qualora il valore ottimale risultasse \\(\\lambda = 1\\), la trasformazione sarebbe completamente fittizia, in quanto, da ogni dato, verrebbe semplicemente sottratta un’unità, senza quindi alterare minimamente i risultati dell’analisi. Di conseguenza, trovare che \\(\\lambda\\) ottimale è uguale ad 1 viene considerato come evidenza del fatto che la trasformazione non è necessaria. 8.7.5 Esempio 8.1 (segue) Sebbene le analisi precedenti abbiano mostrato che il dataset “mixture” non viola significativamente le assunzioni di base per i modelli lineari, possiamo comunque valutare la necessità di una trasformazione, utilizzando la funzione boxcox() contenuta nel package MASS e passando l’oggetto risultante dal fitting come argomento (Codice sottostante). Questa funzione restituisce un grafico delle verosimiglianze associate a diversi valori di \\(\\lambda\\) (Fig. 8.7); il valore ottimale sarebbe \\(\\lambda = 0.83\\), ma vediamo che anche \\(\\lambda = 1\\) rientra nell’intervallo di confidenza di \\(\\lambda\\) ottimale e, di conseguenza, si conferma che non è necessaria alcuna trasformazione stabilizzante. Figura 8.7: Scelta del valore ottimale di ‘lambda’ per la trasformazione di Box e Cox: caso in cui la trasformazione non è necessaria 8.7.6 Esempio 8.2 (segue) Il metodo Box-Cox per il dataset “insects” restituisce il grafico in Figura 8.8; il valore di massima verosimiglianza è \\(\\lambda = 0.14\\), e l’intervallo di confidenza del 95% va da poco meno di zero a circa 0.5. Pertanto, per semplicità, selezioniamo \\(\\lambda = 0\\), che corrisponde a una trasformazione logaritmica. Questa scelta è motivata dal fatto che si tratta di una trasformazione molto nota e, quindi, facilmente comprensibile. Figura 8.8: Scelta del valore ottimale di ‘lambda’ per la trasformazione di Box e Cox: caso in cui è consigliabile una trasformazione logaritmica Il processo di analisi dei dati continua quindi trasformando i dati osservati nel loro logaritmo,e ripetendo il processo di stima del modello e sottoponendo a nuova verifica i residui risultanti. E’ importante notare nel codice sottostante come la trasformazione dei dati venga eseguita all’interno del comando di adattamento del modello, il che è utile per motivi che saranno discussi nel prossimo capitolo. L’analisi grafica dei residui (che si lascia per esercizio) relativi ai dati trasformati non mostra più alcun sintomo di eteroschedasticità e, di conseguenza, il P-level calcolato sulla metrica logaritmica è totalmente affidabile. Procediamo quindi con l’analisi e richiediamo la tabella ANOVA, da cui si deduce che le differenze tra insetticidi sono significative (\\(P = 1.49 \\times 10^{−6}\\). Se confrontiamo le tabelle ANOVA ottenute con e senza trasformazione, osserviamo che vi sono lievi differenze nel P-value e che, in questo caso specifico, l’analisi sui dati trasformati è leggermente più potente. Comunque, l’analisi sui dati non trasformati è sbagliata ed invalida, perché non rispetta le assunzioni di base dei modelli lineari. # Adopting a stabilizing transformation mod2t &lt;- lm(log(Count) ~ Insecticide, data = insects) anova(mod2t) ## Analysis of Variance Table ## ## Response: log(Count) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Insecticide 2 15.8200 7.9100 50.122 1.493e-06 *** ## Residuals 12 1.8938 0.1578 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Comparing with ANOVA on the untransformed data anova(mod2) ## Analysis of Variance Table ## ## Response: Count ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Insecticide 2 714654 357327 18.161 0.0002345 *** ## Residuals 12 236105 19675 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Concludiamo con un’osservazione pratica: nel caso in cui risultasse che il valore di \\(\\lambda\\) ottimale è diverso sia da 1 che da 0, la trasformazione \\(W = (Y^\\lambda - 1)/\\lambda\\) potrebbe essere semplificata in \\(W = Y^\\lambda\\), in modo da ottenere una metrica più facile da interpretare. Infatti, con \\(\\lambda = 0.5\\) avremmo una semplice trasformazione nella radice quadrata, mentre con \\(\\lambda = -1\\) avremmo l’altrettanto semplice trasformazione nel reciproco. Il box seguente mostra un esempio dell’equivalenza della trasformazione di Box e Cox nella forma originale e in quella semplificata: possiamo infatti notare che il rapporto F e il P-level sono esattamente uguali. mod.1 &lt;- lm(sqrt(Count) ~ Insecticide, data = insects) mod.2 &lt;- lm((Count^0.5 - 1)/0.5 ~ Insecticide, data = insects) anova(mod.1) ## Analysis of Variance Table ## ## Response: sqrt(Count) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Insecticide 2 724.22 362.11 35.022 9.791e-06 *** ## Residuals 12 124.08 10.34 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(mod.2) ## Analysis of Variance Table ## ## Response: (Count^0.5 - 1)/0.5 ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Insecticide 2 2896.9 1448.44 35.022 9.791e-06 *** ## Residuals 12 496.3 41.36 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Un’altra osservazione di cui tener conto è che la famiglia di trasformazioni di Box-Cox non funziona quando i dati sono negativi o uguali a zero. In questi casi, è possibile selezionare un valore costante, \\(k\\), da aggiungere alle osservazioni originali in modo che diventino strettamente positive. Ad esempio, se l’osservazione negativa più bassa è \\(-0.9\\), possiamo usare la trasformazione \\(W = log(y + 1)\\), che non produce errore in quanto non implica il calcolo del logaritmo di un numero negativo. 8.8 Risultati contraddittori La valutazione degli assunti di base è un passo fondamentale nell’analisi dei dati sperimentali è non deve mai essere dimenticata. Tuttavia, l’esperienza insegna che, nella pratica, è molto facile incontrare situazioni dubbie, nelle quali i risultati ottenuti con le diverse tecniche diagnostiche appaiono contraddittori e difficili da interpretare. Come comportarsi in questi casi? A mio parere bisogna sempre ricordare che la ‘verità vera’ ci sfugge e, di conseguenza, tutte le valutazioni debbono essere sempre condotte con il massimo ‘buon senso’. Un aspetto importante da considerare è la tipologia del dato: conteggi e proporzioni difficilmente sono normalmente distribuiti ed omoscedastici e, con questi dati, la prudenza non è mai troppa, quando si tratta di impiegare modelli lineari. Allo stesso modo, è necessaria una grande prudenza quando si analizzano variabili quantitative dove la differenza tra le diverse tesi è molto grande, orientativamente più di un ordine di grandezza. Con conteggi proporzioni e variabili quantitative con medie molto diverse tra loro, l’assunzione di omogeneità delle varianze è quasi sempre violata ed è quindi necessario essere molto prudenti prima di confermare il rispetto delle assunzioni di base. 8.9 Altri approcci ‘avanzati’ L’uso di trasformazioni stabilizzanti è stato molto di moda fino agli anni ’80 del ’900, quando la potenza di calcolo era estremamente bassa e rendeva possibile solo l’impiego di procedure semplici, come quelle indicate in questo libro. Oggigiorno, la diffusione di computer potenti a costo relativamente basso ha permesso la diffusione di modelli in grado di gestire anche errori non-normali e dati eteroscedastici. Questi modelli appartengono alle classi dei cosiddetti Modelli Lineari Generalizzati (GLM) o dei modelli con fitting basato sui Minimi Quadrati Generalizzati (GLS); sono molto flessibili, ma sono anche abbastanza complessi e non possono essere trattati su un testo introduttivo (potete studiare, ad esempio, Venables e Ripley, 2002). Inoltre, per completezza di informazione, mensioneremo il fatto che esistono anche metodi di analisi dei dati che non fanno assunzioni parametriche o che ne fanno molto poche e sono, pertanto, noti come metodi non-parametrici. Non parleremo neanche di questi, rinviando chi fosse interessato alla lettura di testi specifici (esempio: Siegel e Castellan 1988). 8.10 Altre letture Ahrens, W. H., D. J. Cox, and G. Budwar. 1990, Use of the arcsin and square root trasformation for subjectively determined percentage data. Weed science 452-458. Anscombe, F. J. and J. W. Tukey. 1963, The examination and analysis of residuals. Technometrics 5: 141-160. Box, G. E. P. and D. R. Cox. 1964, An analysis of transformations. Journal of the Royal Statistical Society, B-26, 211-243, discussion 244-252. Brown MB, Forsythe AB (1974) Robust tests for the equality of variances. J Am Stat Assoc 69(346):364–367 Cochran WG (1947) Some consequences when the assumptions for the analysis of variance are not satisfied. Biometrics 3(1):22. https://doi.org/10.2307/3001535. https://www.jstor.org/stable/3001535?origin=crossref Conover WJ, Johnson ME, Johnson MM (1981) A comparative study of tests for homogeneity of variances, with applications to the outer continental shelf bidding data. Technometrics 23(4):351–361 Frey J, Hartung J, Ogutu J, Piepho H (2024) Analyze as randomized—why dropping block effects in designed experiments is a bad idea. Agron J 116(3):1371–1381. https://doi.org/10.1002/agj2. 21570. https://acsess.onlinelibrary.wiley.com/doi/10.1002/agj2.21570 Glass G, Peckham P, Sanders J (1972) Consequences of failure to meet assumptions underlying the fixed effects analyses of variance and covariance. Rev Educ Res 42(3):237–288 Grubbs FE (1969) Procedures for detecting outlying observations in samples. Technometrics 11(1):1–21 Kass RE, Caffo BS, Davidian M, Meng XL, Yu B, Reid N (2016) Ten simple rules for effective statistical practice. PLOS Comput Biol 12(6):e1004961. https://doi.org/10.1371/journal.pcbi. 1004961. https://dx.plos.org/10.1371/journal.pcbi.1004961 Knief U, Forstmeier W (2021) Violating the normality assumption may be the lesser of two evils. Behav Res Methods 53(6):2576–2590. https://doi.org/10.3758/s13428-021-01587-5. https:// link.springer.com/10.3758/s13428- 021- 01587- 5 Kozak M, Piepho H (2018) What’s normal anyway? Residual plots are more telling than significance tests when checking ANOVA assumptions. J Agron Crop Sci 204(1):86–98. https:// doi.org/10.1111/jac.12220. https://onlinelibrary.wiley.com/doi/10.1111/jac.12220 Onofri A, Covarelli L, Tei F (1995) Efficacy of rimsulfuron and metribuzin against Solanum nigrum L. at different growth stages in tomato. In: International Meeting on Weed Control. Proceedings 16th COLUMA Conference, Reims, ANPP, Reprints, pp 993–1000 Siegel S, Castellan NJ (1988) Nonparametric Statistics for the Behavioral Sciences. McGraw-Hill, Columbus Snedecor GW, Cochran WG (1991) Statistical Methods, 8th edn. IOWA State University Press, Ames Venables WN, Ripley BD (2002) Modern Applied Statistics with S. Statistics and Computing, 4th edn. Springer, New York 8.11 Esercizi Considerare gli esercizi dal 5 al 7 nel capitolo 4. Per tutti questi esercizi, verificare che le ipotesi di base per i modelli lineari siano soddisfatte, utilizzando metodi grafici e test di ipotesi formali. Nota: Considerate che il limite dell’espressione \\((Y^\\lambda -1)/\\lambda\\) per \\(\\lambda \\rightarrow 0\\) è proprio \\(\\log(Y)\\)↩︎ "],["combinazioni-linearinonlineari-dei-parametri.html", "Capitolo 9 Combinazioni lineari/nonlineari dei parametri 9.1 Esempio 9.1: Determinare l’effetto medio degli erbicidi 9.2 Esempio 9.2: Determinare l’efficiacia erbicida media 9.3 Combinazioni di interesse generale 9.4 Example 9.4: Contrasti ortogonali (e non) 9.5 Esempio 9.5: I confronti multipli a coppie 9.6 Esempio 9.6: confronti multipli con dati trasformati 9.7 Esempio 9.7: Previsioni e previsioni inverse 9.8 Altre letture 9.9 Esercizi", " Capitolo 9 Combinazioni lineari/nonlineari dei parametri Dopo aver dimostrato che un modello fornisca una buona descrizione dei dati sperimentali e che non vi siano violazioni degli assunti di base, è possibile testare diverse ipotesi rilevanti che siano ‘traducibili’ in combinazioni lineari o non lineari dei parametri del modello, cioè delle funzioni che coinvolgono i parametri ed un insieme di coefficienti; per comprendere questo concetto e la sua importanza, iniziamo con un esempio. 9.1 Esempio 9.1: Determinare l’effetto medio degli erbicidi Torniamo al nostro esperimento in cui abbiamo confrontato due erbicidi e la loro miscela con il testimone non trattato, in un disegno sperimentale completamente randomizzato con quattro repliche. Nel capitolo precedente, abbiamo visto che non vi sono problemi con nessuna delle assunzioni di base per il fitting dei modelli lineari, mentre l’analisi della varianza ed il relativo test di F hanno mostrato come esistano differenze significative tra alcuni dei trattamenti. Nel riquadro sottostante riportimo nuovamente il codice R per l’adattamento del modello. # Example 9.1 # Determining the average effect of herbicides in the &#39;mixture&#39; data # Loading the packages library(statforbiology) library(multcomp) # Loading the data dataset &lt;- getAgroData(&quot;mixture&quot;) # Fitting a one-way ANOVA model model &lt;- lm(Weight ~ Treat, data=dataset) summary(model) ## ## Call: ## lm(formula = Weight ~ Treat, data = dataset) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.360 -2.469 0.380 2.567 6.025 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.175 1.959 4.684 0.000529 *** ## TreatMixture_378 -4.047 2.770 -1.461 0.169679 ## TreatRimsulfuron_30 7.685 2.770 2.774 0.016832 * ## TreatUnweeded 17.598 2.770 6.352 3.65e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.918 on 12 degrees of freedom ## Multiple R-squared: 0.8554, Adjusted R-squared: 0.8193 ## F-statistic: 23.66 on 3 and 12 DF, p-value: 2.509e-05 # Variance partitioning anova(model) ## Analysis of Variance Table ## ## Response: Weight ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Treat 3 1089.53 363.18 23.663 2.509e-05 *** ## Residuals 12 184.18 15.35 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 A questo punto, è rilevante chiedersi: “Il controllo delle piante infestanti è stato (in media) una pratica efficace?”. Questa domanda ‘biologica’ può essere tradotta in una combinazione lineare dei parametri stimati, cioè: \\(\\mu\\) = 9.175, \\(\\alpha_2\\) = -4,0475, \\(\\alpha_3\\) = 7.685 e \\(\\alpha_4\\) = 17.5975, dove \\(\\mu\\) è la media del primo erbicida (in ordine alfabetico), \\(\\alpha_2\\), \\(\\alpha_3\\) e \\(\\alpha_4\\) sono, rispettivamente, le differenze tra le medie del secondo, terzo e quarto trattamento e la media del primo (vedi Capitolo 4). Con queste stime, possiamo calcolare la media dei vasi non trattati come \\(\\mu_u = \\mu + \\alpha_4\\), e la media dei vasi trattati come \\(\\mu_t = [\\mu + (\\mu + \\alpha_2) + (\\mu + \\alpha_3)]/3\\), ovvero \\(\\mu_t = \\mu + 1/3 \\, \\alpha_2 + 1/3 \\, \\alpha_3\\). Di conseguenza, la differenza tra vasi trattati e non trattati è uguale alla seguente combinazione lineare: \\(\\delta_{tu} = \\mu_t - \\mu_{ut} = 1/3 \\, \\alpha_2 + 1/3 \\, \\alpha_3 - \\alpha_4\\). Il risultato di questa combinazione (\\(\\delta_{tu}\\)) risponde alla domanda precedente: se \\(\\delta_{tu} &lt; 0\\) possiamo concludere che il trattamento erbicida è, in media, efficace nel ridurre la biomassa di Solanum nigrum. La combinazione lineare sopra definita può essere espressa come somma dei prodotti di un insieme di parametri per un insieme di coefficienti: \\[C = 0 \\cdot \\mu + \\frac{1}{3} \\cdot \\alpha_2 + \\frac{1}{3} \\cdot \\alpha_3 - 1 \\cdot \\alpha_4\\] In questa espressione, la matrice dei coefficienti è: \\[K = \\left[0 \\,\\,\\, 1/3 \\,\\,\\, 1/3 \\,\\, -1 \\right]\\] Vedremo che in R esistono alcune funzioni che ricevono in input l’elenco dei parametri stimati e la matrice dei coefficienti e restituiscono il valore della combinazione (in questo caso: \\(C = \\delta_{tu} = -16,385\\)), insieme al suo errore standard ottenuto tramite la legge di propagazione degli errori, considerando le varianze e le covarianze dei parametri del modello. Maggiori dettagli sulla propagazione degli errori sono reperibili nel blog associato a questo libro4. Una delle funzioni più importanti è flessibili è glht(), contenuta nel package multcomp, il cui impiego è mostrato nel riquadro sottostante, insieme a quello della funzione confint() che può essere utilizzata per ottenere l’intervallo di confidenza. # Example 9.1 [continuation] # Fitting linear combinations with the &#39;glht()&#39; function in R library(multcomp) # Setting the matrix of coefficients K &lt;- matrix(c(0, 1/3, 1/3, -1), nrow = 1, ncol = 4, byrow = T) row.names(K) &lt;- c(&quot;delta_tu&quot;) K ## [,1] [,2] [,3] [,4] ## delta_tu 0 0.3333333 0.3333333 -1 # Fitting the contrast con &lt;- glht(model, linfct = K) summary(con) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Fit: lm(formula = Weight ~ Treat, data = dataset) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## delta_tu == 0 -16.385 2.262 -7.244 1.02e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) # Confidence intervals confint(con) ## ## Simultaneous Confidence Intervals ## ## Fit: lm(formula = Weight ~ Treat, data = dataset) ## ## Quantile = 2.1788 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## delta_tu == 0 -16.3850 -21.3132 -11.4568 È importante notare che la stima \\(\\delta_{tu}\\) può essere divisa per il suo errore standard per ottenere un test t per l’ipotesi nulla che la stima osservata non sia significativamente diversa da zero (vedere Sezione 7.1). Il valore P corrispondente è molto basso, consentendo il rifiuto dell’ipotesi nulla. Pertanto, concludiamo che l’effetto medio dell’erbicida è statisticamente significativo. 9.2 Esempio 9.2: Determinare l’efficiacia erbicida media I concetti precedenti possono essere estesi a qualsiasi altra funzione dei parametri del modello, anche se non può essere ricondotta alla somma dei prodotti dei coefficienti per i parametri (come nell’Equazione riportata nel precedente paragrafo) oppure se è intrinsecamente non lineare (cioè contiene logaritmi o altre funzioni che non siano semplici somme di parametri). L’unica differenza è che, con le combinazioni non lineari, gli errori standard non possono essere calcolati con il metodo di propagazione degli errori, ma debbono essere approssimati utilizzando il cosiddetto metodo delta (Weisberg, 2005)5. In R, possiamo utilizzare la funzione gnlht() nel package statforbiology, che generalizza l’approccio della glht(). Come esempio, riconsideriamo il dataset “mixture” ed utilizziamo i parametri del modello per calcolare la riduzione percentuale della crescita delle infestanti rispetto al controllo non trattato (efficacia erbicida; HE). Per il primo erbicida, è: \\[\\textrm{HE} = \\frac{\\mu_4 - \\mu_1}{\\mu_4} \\times 100 = \\frac{\\mu_1 + \\alpha_4 - \\mu_1}{\\mu_1 + \\alpha_4} \\times 100 = \\frac{\\alpha_4}{\\mu_1 + \\alpha_4} \\times 100\\] In questa espressione, i parametri \\(\\mu_1\\) e \\(\\alpha_4\\) sono al denominatore e, pertanto, questa combinazione è non lineare. Le espressioni per ottenere gli HE per tutti gli altri erbicidi possono essere ottenute con semplici calcoli algebrici, come riportato nel succesivo riquadro. Per utilizzare la funzione gnlht() bisogna codificare la lista delle funzioni da calcolare e passarla come argomento. Inoltre, il legame tra il nome dei parametri utilizzati in tali combinazioni e la posizione delle relative stime come risulta nell’output della funzione coef() viene creato con l’argomento parameterNames. Le efficacie dei tre erbicidi sono rispettivamente del 65%, 80% e 37% e sono tutte significativamente diverse da 0 (riquadro sottostante) # Esempio 9.2 # Determinazione dell&#39;efficacia media degli erbicidi nei dati della miscela # Caricamento dei pacchetti e dei dati library(statforbiology) dataset &lt;- getAgroData(&quot;mixture&quot;) # Adattamento di un modello ANOVA ad una via model &lt;- lm(Weight ~ Treat, data=dataset) # Adattamento di combinazioni non lineari con &#39;gnlht()&#39; library(statforbiology) funList &lt;- list(~ a4/(mu1 + a4) * 100, ~ (a4 - a2)/(mu1 + a4) * 100, ~ (a4 - a3)/(mu1 + a4) * 100) gnlht(model, funList, parameterNames = c(&quot;mu1&quot;, &quot;a2&quot;, &quot;a3&quot;, &quot;a4&quot;)) ## Form Estimate SE t-value p-value ## 1 a4/(mu1 + a4) * 100 65.72976 7.734313 8.498461 2.014359e-06 ## 2 (a4 - a2)/(mu1 + a4) * 100 80.84788 7.449568 10.852694 1.469226e-07 ## 3 (a4 - a3)/(mu1 + a4) * 100 37.02493 8.646543 4.282050 1.065143e-03 9.3 Combinazioni di interesse generale Le funzioni lineari e non lineari dei parametri del modello sono molto utili per rispondere a specifiche domande di ricerca, anche se, soprattutto quando sono molte, la codifica ‘manuale’ della matrice dei coefficienti può rivelarsi un compito molto noioso. Fortunatamente, R ci ci mette a disposizione diverse matrici pre-definite per le combinazioni lineari o non lineari di maggior interesse generale, cioè: Medie Marginali attese (EMMs) Contrasti ortogonali (e non) Confronti a coppie Retrotrasformazioni Previsioni e previsioni inverse Nelle situazioni in cui abbiamo uno o più predittori nominali, il nostro interesse principale, di solito, è quello di stimare le medie della popolazione per ogni livello di trattamento (ad esempio, \\(\\mu_1\\), \\(\\mu_2\\), \\(\\mu_3\\), \\(\\ldots{}\\) e \\(\\mu_n\\), dove \\(n\\) è il numero di livelli di trattamento). Sebbene le medie aritmetiche dei gruppi di trattamento possano essere utilizzate come stimatori delle medie delle relative popolazioni (vedere la funzione tapply() nel Capitolo 3), è necessario tener conto che si tratta di stimatori che, in alcune circostanze, possono essere distorti, ad esempio quando i dati sono sbilanciati (numero diverso di repliche per ciascun gruppo di trattamento). Le medie marginali attese (Expected Marginal Means; EMMs) rappresentano un’importante alternativa: sono uguali alle medie aritmetiche quando i dati sono bilanciati, mentre forniscono stimatori migliori delle medie della popolazione quando i dati sono sbilanciati. Le EMMs possono essere facilmente ottenute come combinazioni lineari dei parametri del modello; ad esempio, tornando al dataset “mixture”, nell’esempio 9.1, dove i parametri stimati sono \\(\\mu = 9.175\\), \\(\\alpha_2 = -4.0475\\), \\(\\alpha_3 = 7.685\\) e \\(\\alpha_4 = 17.5975\\) ed hanno il significato biologico illustrato in precedenza (media del primo gruppo e differenze tra le medie degli altri gruppi rispetto al primo), le quattro EMMs possono essere ottenuti dalle seguenti combinazioni lineari: \\[\\left\\{ {\\begin{array}{l} C_1 = \\mu_1 = 1 \\cdot \\mu + 0 \\cdot \\alpha_2 + 0 \\cdot\\alpha_3 + 0 \\cdot\\alpha_4 = 9,18\\\\ C_2 = \\mu_2 = 1 \\cdot \\mu + 1 \\cdot \\alpha_2 + 0 \\cdot\\alpha_3 + 0 \\cdot\\alpha_4 = 5,13\\\\ C_3 = \\mu_3 = 1 \\cdot \\mu + 0 \\cdot \\alpha_2 + 1 \\cdot\\alpha_3 + 0 \\cdot\\alpha_4 = 16:86\\\\ C_4 = \\mu_4 = 1 \\cdot \\mu + 0 \\cdot \\alpha_2 + 0 \\cdot\\alpha_3 + 1 \\cdot\\alpha_4 = 26,77\\\\ \\end{array}} \\right.\\] La matrice dei coefficienti è: \\[ K = \\left[ {\\begin{array}{llll} 1 &amp; 0 &amp; 0 &amp; 0\\\\ 1 &amp; 1 &amp; 0 &amp; 0\\\\ 1 &amp; 0 &amp; 1 &amp; 0\\\\ 1 &amp; 0 &amp; 0 &amp; 1 \\end{array}} \\right]\\] In linea di principio, per calcolare queste combinazioni si può utilizzare la funzione glht() nel package multcomp, come mostrato nel riquadro sottostante. # Esempio 9.3 # Medie dei minimi quadrati per i dati &#39;mixture&#39; # Caricamento dei pacchetti library(statforbiology) library(multcomp) # Caricamento dei dati dataset &lt;- getAgroData(&quot;mixture&quot;) # Adattamento di un modello ANOVA ad una via model &lt;- lm(Weight ~ Treat, data=dataset) # Stima degli EMM con la funzione &#39;glht()&#39; # Impostazione della matrice dei coefficienti K &lt;- matrix(c(1,0,0,0,1,1,0,0,1,0,1,0,1,0,0,1), nrow = 4, ncol = 4, byrow = T) row.names(K) &lt;- c(&quot;mu1&quot;, &quot;mu2&quot;, &quot;mu3&quot;, &quot;mu4&quot;) K ## [,1] [,2] [,3] [,4] ## mu1 1 0 0 0 ## mu2 1 1 0 0 ## mu3 1 0 1 0 ## mu4 1 0 0 1 # Calcolo della combinazione lineare con &lt;- glht(model, linfct = K) summary(con) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Fit: lm(formula = Weight ~ Treat, data = dataset) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## mu1 == 0 9.175 1.959 4.684 0.00199 ** ## mu2 == 0 5.127 1.959 2.618 0.08143 . ## mu3 == 0 16.860 1.959 8.607 &lt; 0.001 *** ## mu4 == 0 26.773 1.959 13.668 &lt; 0.001 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) # Intervalli di confidenza confint(con) ## ## Simultaneous Confidence Intervals ## ## Fit: lm(formula = Weight ~ Treat, data = dataset) ## ## Quantile = 2.8936 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## mu1 == 0 9.1750 3.5069 14.8431 ## mu2 == 0 5.1275 -0.5406 10.7956 ## mu3 == 0 16.8600 11.1919 22.5281 ## mu4 == 0 26.7725 21.1044 32.4406 Tuttavia, soprattutto quando il numero di medie è molto elevato, codificare la matrice dei coefficienti da zero può essere un compito arduo; pertanto, per il calcolo degli EMMs, si preferisce la funzione emmeans() nel pacchetto emmeans (Lenth, 2016), perché è molto più semplice da usare. Richiede due argomenti di base: l’oggetto modello e il predittore per il quale si desidera calcolare le EMMs (riquadro sottostante). # Esempio 9.3 [continuazione] # EMMs con la funzione &#39;emmeans()&#39; library(emmeans) # Carica il pacchetto muj &lt;- emmeans(model, ~Treat) muj ## Treat emmean SE df lower.CL upper.CL ## Metribuzin__348 9.18 1.96 12 4.91 13.4 ## Mixture_378 5.13 1.96 12 0.86 9.4 ## Rimsulfuron_30 16.86 1.96 12 12.59 21.1 ## Unweeded 26.77 1.96 12 22.50 31.0 ## ## Confidence level used: 0.95 Oltre a essere stime affidabili delle medie della popolazione, le EMMs possono anche servire come punto di partenza per costruire ulteriori combinazioni lineari o non lineari, che saranno esaminate in seguito. 9.4 Example 9.4: Contrasti ortogonali (e non) Nell’Esempio 9.1, abbiamo visto che una combinazione lineare dei parametri del modello può aiutare a rispondere ad una domanda ‘biologica’ rilevante, basata sulla differenza tra la media dei vasi non trattati e la media dei vasi trattati. Considerando sempre il dataset “mixture”, è possibile pianificare tre combinazioni che reppresentano differenze tra medie, cioè: trattato vs. non trattato (in media) miscela vs. erbicidi singoli (in media) metribuzin vs. rimsulfuron Invece che combinare i parametri del modello come nell’Esempio 9.1, le tre combinazioni di cui sopra possono anche essere codificate come combinazioni tra le medie. Se consideriamo l’ordine con cui compaiono le quattro medie nel dataset muj in un riquadro precedente, in Code box 9.5, le tre combinazioni lineari possono essere scritte come: \\[\\left\\{ {\\begin{array}{l} C_1 = \\frac{1}{3} \\, \\mu_1 + \\frac{1}{3} \\, \\mu_2 + \\frac{1}{3} \\,\\mu_3 - \\mu_4\\\\ C_2 = \\frac{1}{2} \\, \\mu_1 - \\mu_2 + \\frac{1}{2} \\,\\mu_3 - 0 \\cdot \\mu_4\\\\ C_3 = \\mu_1 - 0 \\cdot \\mu_2 - \\mu_3 - 0 \\cdot \\mu_4 \\end{array}} \\right.\\] Le tre combinazioni lineari C1, C2 e C3 hanno la tipica proprietà che, per ognuna, la somma dei coefficienti è zero e, per questo, sono chiamate contrasti. Ne consegue che il risultato di un contrasto deve essere uguale a 0, quando la differenza tra medie o gruppi di medie che esso sottende è uguale a zero, di modo che sia possibile utilizzare un test di t per saggiare questa ipotesi nulla. Inoltre, i tre contrasti sopra riportati hanno l’ulteriore caratteristica che i loro coefficienti sono reciprocamente non correlati e, pertanto, sono chiamati contrasti ortogonali. Normalmente, in un dataset esistono tanti contrasti ortogonali quante sono le medie meno una. L’ortogonalità era considerata una proprietà desiderabile perché la somma delle devianze associate ad ogni contrasto corrisponde alla devianza del trattamento (vedere il riquadro sottostante). Pertanto, l’applicazione dei contrasti ortogonali era considerata un metodo elegante ed efficiente per sfruttare l’intera informazione contenuta (Chew, 1976). Oggigiorno, l’enfasi sull’ortogonalità è minore, ma può essere utile fornire un esempio di come i contrasti ortogonali possano essere calcolati con R, utilizzando la funzione contrast() nel package emmeans. I tre passaggi tipici sono: preparare una lista con i coefficienti, assegnando un nome a ciascun contrasto (si noti che questa è una differenza rispetto alla funzione glht(), che richiede una matrice di coefficienti, non una lista); utilizzare la funzione contrast() nel package emmeans, passando i seguenti argomenti: (i) l’oggetto risultante dalla chiamata alla funzione emmeans(); (ii) la lista dei contrasti \\(K\\), come argomento method; (iii) il tipo di aggiustamento (ne parleremo più avanti, per ora utilizzate il comando così come mostrato nel riquadro sottostante) # Example 9.4 # Orthogonal contrasts with the &#39;emmeans()&#39; function # Loading the packages library(statforbiology) library(emmeans) library(multcomp) # Loading the data dataset &lt;- getAgroData(&quot;mixture&quot;) # Fitting a one-way ANOVA model model &lt;- lm(Weight ~ Treat, data=dataset) # Creating a vector of coefficients for each contrast C1 &lt;- c(1/3, 1/3, 1/3, -1) C2 &lt;- c(1/2, -1, 1/2, 0) C3 &lt;- c(1, 0, -1, 0) # Creating a list of contrasts (NOT a matrix) K &lt;- list(&quot;U vs T&quot; = C1, &quot;mix vs single&quot; = C2, &quot;met vs rim&quot; = C3) # Fitting the contrasts, using the &#39;muj&#39; object muj &lt;- emmeans(model, ~Treat) con &lt;- contrast(muj, method = K, adjust=&quot;none&quot;) con ## contrast estimate SE df t.ratio p.value ## U vs T -16.39 2.26 12 -7.244 &lt;.0001 ## mix vs single 7.89 2.40 12 3.289 0.0065 ## met vs rim -7.68 2.77 12 -2.774 0.0168 # Confidence intervals confint(con) ## contrast estimate SE df lower.CL upper.CL ## U vs T -16.39 2.26 12 -21.31 -11.46 ## mix vs single 7.89 2.40 12 2.66 13.12 ## met vs rim -7.68 2.77 12 -13.72 -1.65 ## ## Confidence level used: 0.95 I contrasti ortogonali possono essere calcolati anche utilizzando la funzione aov(). In questo caso, l’elenco dei contrasti deve essere trasformato in una matrice e associato al fattore sperimentale tramite la funzione C() (notare la lettera maiuscola; vedere il riquadro sottostante). Utilizzando questa codifica, è possibile vedere che la somma dei quadrati per l’effetto del trattamento è completamente suddivisa in tre parti, una per ciascun contrasto, producendo valori P identici a quelli mostrati nel riquadro precedente. # Example 9.4 [continuation] # Fitting orthogonal contrasts and partitioning # the sum of squares for the treatment effect # Creating a vector of coefficients for each contrast (as in Code box 9.6) C1 &lt;- c(1/3, 1/3, 1/3, -1) C2 &lt;- c(1/2, -1, 1/2, 0) C3 &lt;- c(1, 0, -1, 0) # Creating a list of contrasts (as in Code box 9.6) K &lt;- list(&quot;U vs T&quot; = C1, &quot;mix vs single&quot; = C2, &quot;met vs rim&quot; = C3) # Transform the list of contrasts into a matrix Kmat &lt;- do.call(rbind, K) # Associate the matrix of coefficients to the treatment factor dataset$Treat2 &lt;- C(factor(dataset$Treat), t(Kmat)) # Fit the model with the &#39;aov()&#39; function mod &lt;- aov(Weight ~ Treat2, dataset) summary(mod, split = list(Treat2 = list(1,2,3))) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Treat2 3 1089.5 363.2 23.663 2.51e-05 *** ## Treat2: C1 1 805.4 805.4 52.476 1.02e-05 *** ## Treat2: C2 1 166.0 166.0 10.816 0.00647 ** ## Treat2: C3 1 118.1 118.1 7.696 0.01683 * ## Residuals 12 184.2 15.3 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 9.5 Esempio 9.5: I confronti multipli a coppie Non sempre le prove sperimentali consentono di saggiare pochi contrasti pre-stabiliti, ma spesso è necessario confrontare tutte le possibili coppie di trattamenti (pairwise comparisons). In questo caso dovremmo definire un contrasto per ogni coppia di medie, anche se l’impiego del package ‘emmeans’ agevola, non di poco, il lavoro. In particolare, possiamo immaginare due situazioni di riferimento: tutti contro tutti (confronti tipo “Tukey”) e tutti verso uno (confronti tipo “Dunnett”)(Hsu, 1996). Questo secondo tipo di contrasto può essere interessante, quando sia importante confrantare tutti i trattamenti verso un riferimento prescelto, ad esempio la miscela tra i due erbicidi. Con il metodo di Tukey, il numero di contrasti è molto elevato, ed è pari a \\(n \\times (n - 1) / 2\\), dove \\(n\\) è il numero di medie da confrontare. Con il metodo di Dunnett, il numero di contrasti si riduce a \\(n - 1\\), e tale riduzione potrebbe essere importante per ragioni che verranno descritte più avanti. Bisogna tener presente che l’adozione di confronti a coppie non è particolarmente elegante perché implica molti test non pianificati e privi di un obiettivo chiaro (una sorta di “spray and pray”; Cousens, 1988). Inoltre, secondo lo scienziato inglese John Tukey: “tutto ciò che sappiamo del mondo ci insegna che gli effetti di A e B sono sempre diversi, purchè noi consideriamo un numero di decimali sufficientemente elevato. Pertanto, chiedersi se gli effetti siano diversi è sciocco”. Ciononostante, i confronti a coppie possono essere molto utili; sono di moda da quasi un secolo e quindi vale la pena conoscerli. Per il dataset “mixture”, ci sono quattro medie da confrontare e, quindi, un totale di sei confronti a coppie che possono essere definiti come segue: \\[\\left\\{ {\\begin{array}{*{20}{c}} C_1 = \\mu_1 - \\mu_2 = 1 \\cdot \\mu_1 - 1 \\cdot \\mu_2 + 0 \\cdot \\mu_3 + 0 \\cdot \\mu_4 \\\\ C_2 = \\mu_1 - \\mu_3 = 1 \\cdot \\mu_1 - 0 \\cdot \\mu_2 - 1 \\cdot \\mu_3 + 0 \\cdot \\mu_4 \\\\ C_3 = \\mu_1 - \\mu_4 = 1 \\cdot \\mu_1 - 0 \\cdot \\mu_2 + 0 \\cdot \\mu_3 - 1 \\cdot \\mu_4 \\\\ C_4 = \\mu_2 - \\mu_3 = 0 \\cdot \\mu_1 + 1 \\cdot \\mu_2 - 1 \\cdot \\mu_3 + 0 \\cdot \\mu_4 \\\\ C_5 = \\mu_2 - \\mu_4 = 0 \\cdot \\mu_1 + 1 \\cdot \\mu_2 + 0 \\cdot \\mu_3 - 1 \\cdot \\mu_4 \\\\ C_6 = \\mu_3 - \\mu_4 = 0 \\cdot \\mu_1 + 0 \\cdot \\mu_2 + 1 \\cdot \\mu_3 - 1 \\cdot \\mu_4 \\end{array}} \\right.\\] La matrice dei coefficienti è: \\[K = \\left[ {\\begin{array}{rrrr} 1 &amp; - 1 &amp; 0 &amp; 0\\\\ 1 &amp; 0 &amp; - 1 &amp; 0\\\\ 1 &amp; 0 &amp; 0 &amp; - 1\\\\ 0 &amp; 1 &amp; - 1 &amp; 0\\\\ 0 &amp; 1 &amp; 0 &amp; - 1\\\\ 0 &amp; 0 &amp; 1 &amp; - 1 \\end{array}} \\right]\\] Fortunatamente, non è necessario codificare la matrice \\(K\\) da zero; nel quadro sottostante mostriamo come si possa ottenere il confronto multiplo con la funzione contrast() (come sopra) e passando il valore ‘tukey’ o ‘dunnett’ all’argomento ‘method’. In questo secondo caso, R confronta tutte le tesi con metribuzin, che è il primo livello in ordine alfabetico, mentre noi avremmo preferito confrontare tutte le tesi con la miscela. Per ottenere questo risultato basta aggiungere l’argomento ‘ref’ ed assegnare il valore ‘2’, considerando che la miscela è la seconda tesi in ordine alfabetico: # Example 9.5 # Pairwise comparisons for the &#39;mixture&#39; data # Loading the packages library(statforbiology) library(multcomp) # Loading the data dataset &lt;- getAgroData(&quot;mixture&quot;) # Fitting a one-way ANOVA model model &lt;- lm(Weight ~ Treat, data=dataset) # Determining the least square means muj &lt;- emmeans(model, ~Treat) # All-pairwise comparisons (Tukey&#39;s method) contrast(muj, adjust=&quot;none&quot;, method=&quot;tukey&quot;) ## contrast estimate SE df t.ratio p.value ## Metribuzin__348 - Mixture_378 4.05 2.77 12 1.461 0.1697 ## Metribuzin__348 - Rimsulfuron_30 -7.68 2.77 12 -2.774 0.0168 ## Metribuzin__348 - Unweeded -17.60 2.77 12 -6.352 &lt;.0001 ## Mixture_378 - Rimsulfuron_30 -11.73 2.77 12 -4.235 0.0012 ## Mixture_378 - Unweeded -21.64 2.77 12 -7.813 &lt;.0001 ## Rimsulfuron_30 - Unweeded -9.91 2.77 12 -3.578 0.0038 ## Comparisons all-against-one (Dunnett&#39;s method) con &lt;- contrast(muj, adjust=&quot;none&quot;, method=&quot;dunnett&quot;, ref = 2) con ## contrast estimate SE df t.ratio p.value ## Metribuzin__348 - Mixture_378 4.05 2.77 12 1.461 0.1697 ## Rimsulfuron_30 - Mixture_378 11.73 2.77 12 4.235 0.0012 ## Unweeded - Mixture_378 21.64 2.77 12 7.813 &lt;.0001 ## Confidence intervals confint(con) ## contrast estimate SE df lower.CL upper.CL ## Metribuzin__348 - Mixture_378 4.05 2.77 12 -1.99 10.1 ## Rimsulfuron_30 - Mixture_378 11.73 2.77 12 5.70 17.8 ## Unweeded - Mixture_378 21.64 2.77 12 15.61 27.7 ## ## Confidence level used: 0.95 Il risultato delle elaborazioni sovrastanti mostra i contrasti con il loro errore standard e potrebbe essere interessante calcolare anche l’intervallo di confidenza per le differenze stimate. Ciò può esser fatto facilmente assegnando il risultato della funzione contrast() ad una variabile ed esplorando quest’ultima con il metodo confint(). 9.5.1 Display a lettere I risultati di un confronto multiplo a coppie possono essere presentati anche con un display a lettere, nel quale le medie seguite da lettere diverse sono significativamente diverse per un livello di probabilità di errore minore di quello dato. Realizzare un display a lettere manualmente è piuttosto facile, utilizzando la seguente procedura: ordinare le medie in senso crescente/decrescente partire dalla prima media e aggiungere la lettera A a tutte quelle che non sono significativamente diverse passare alla seconda media e aggiungere la lettera B a tutte quelle che non sono significativamente diverse procedere analogamente con tutte le medie successive, finche non vengono più individuate differenze significative. Con R si può sfruttare il package ‘emmeans’, utilizzando i comandi sottostanti. multcomp::cld(muj, adjust=&quot;none&quot;, Letters=LETTERS) ## Treat emmean SE df lower.CL upper.CL .group ## Mixture_378 5.13 1.96 12 0.86 9.4 A ## Metribuzin__348 9.18 1.96 12 4.91 13.4 A ## Rimsulfuron_30 16.86 1.96 12 12.59 21.1 B ## Unweeded 26.77 1.96 12 22.50 31.0 C ## ## Confidence level used: 0.95 ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. 9.5.2 Correzione per la molteplicità Operando nel modo anzidetto, ogni contrasto/confronto ha una probabilità di errore del 5% (\\(\\alpha_C = 0.05\\)). Se i contrasti/confronti sono più di uno (‘famiglia’ di n contrasti), la probabilità di sbagliarne almeno uno (maximum experimentwise error rate: \\(\\alpha_E\\)) è data da: \\[\\alpha_E = 1 - (1 - \\alpha_C)^n\\] Bisogna premettere che l’anzidetta formula vale quando i contrasti sono totalmente indipendenti tra loro, cosa che quasi mai avviene, dato che, anche in un semplice modello ANOVA, i contrasti condividono la stessa varianza d’errore e sono quindi più o meno correlati tra di loro. Con contrasti non indipendenti la formula anzidetta fornisce una sovrastima di \\(\\alpha_E\\) (per questo si parla di maximum experimentwise error rate). Il numero di confronti a coppie per esperimento può essere anche molto elevato: se ho k medie il numero dei confronti possibili è pari a \\(k \\cdot (k-1)/2\\). Di conseguenza, la probabilità di errore per esperimento (\\(\\alpha_E\\)) può essere molto più alta del valore \\(\\alpha_C\\) prefissato per confronto. Ad esempio, se ho 15 medie, ho \\((15 \\cdot 14)/2 = 105\\) confronti possibili. Se uso \\(\\alpha_C = 0.05\\) per ogni confronto, la probabilità di sbagliarne almeno uno è pari (in caso di confronti indipendenti) a \\(1 - (1 - 0.05)^105 = 0.995\\). Sostanzialmente, vi è pressoché la certezza che in questo esperimento qualcosa sia sbagliato! Per questo motivo, quando si elaborano i dati di un esperimento nel quale è necessario fare molti contrasti, o confronti, o, più in generale, molti test d’ipotesi simultanei, si potrebbe voler esprimere un giudizio globale (simultaneo) sull’intera famiglia di contrasti/confronti, minimizzando la possibilità che anche solo uno o pochi di essi siano sbagliati. In particolare, ciò potrebbe capitare quando: vogliamo trovare i migliori di k trattamenti, senza correre rischi di escluderne erroneamente qualcuno. In questa situazione, facendo ogni confronto con il 5% di probabilità di errore, la probabilità di escludere erroneamente anche solo un trattamento dal lotto dei migliori è molto più alta di quella prefissata, perché basta sbagliare anche uno solo dei k - 1 confronti con il migliore. Abbiamo utilizzato un display a lettere e intendiamo affermare che ‘i trattamenti seguiti da lettere diverse sono significativamente diversi’. In questo caso, stiamo tirando una conclusione basata sull’intera famiglia di confronti e non possiamo lecitamente riportare la probabilità di errore di un singolo confronto. In tutte le condizioni analoghe a quelle più sopra accennate si pone il problema di applicare un aggiustamento per la molteplicità, in modo da rispettare un certo livello prestabilito di protezione per esperimento (e non per confronto). La prima possibilità che abbiamo è quella di aggiustare il P-level per ogni confronto, in modo da diminuire la probabilità di errore per l’intera famiglia di sei confronti. Utilizzando la formula che lega la probabilità d’errore per esperimento (\\(\\alpha_E\\)) alla probabilità d’errore per confronto (\\(\\alpha_C\\); vedi sopra), possiamo prendere la sesta colonna del dataframe ‘con’, quella che contiene i P-levels non corretti, e trasformarla come segue: alphaC &lt;- as.data.frame(con)[,6] 1 - (1 - alphaC)^6 ## [1] 6.722991e-01 6.923077e-03 2.869757e-05 Più facilmente, possiamo arrivare allo stesso risultato con il package ‘emmeans’: contrast(muj, method = &quot;tukey&quot;, adjust = &quot;sidak&quot;) ## contrast estimate SE df t.ratio p.value ## Metribuzin__348 - Mixture_378 4.05 2.77 12 1.461 0.6723 ## Metribuzin__348 - Rimsulfuron_30 -7.68 2.77 12 -2.774 0.0968 ## Metribuzin__348 - Unweeded -17.60 2.77 12 -6.352 0.0002 ## Mixture_378 - Rimsulfuron_30 -11.73 2.77 12 -4.235 0.0069 ## Mixture_378 - Unweeded -21.64 2.77 12 -7.813 &lt;.0001 ## Rimsulfuron_30 - Unweeded -9.91 2.77 12 -3.578 0.0226 ## ## P value adjustment: sidak method for 6 tests Vediamo che il secondo confronto, che era significativo, non è più tale adottando la correzione di Sidak. Un’alternativa più nota (e semplice) è quella di utilizzare la diseguaglianza di Bonferroni: \\[\\alpha_E = \\alpha_C \\cdot k\\] Quest’ultima è un po’ più conservativa della precedente, nel senso che fornisce un P-level aggiustato leggermente più alto dell’altra. alphaC * 6 ## [1] 1.018071e+00 6.943132e-03 2.869792e-05 Oppure possiamo utilizzare la funzione contrast(): contrast(muj, method = &quot;pairwise&quot;, adjust = &quot;bonferroni&quot;) ## contrast estimate SE df t.ratio p.value ## Metribuzin__348 - Mixture_378 4.05 2.77 12 1.461 1.0000 ## Metribuzin__348 - Rimsulfuron_30 -7.68 2.77 12 -2.774 0.1010 ## Metribuzin__348 - Unweeded -17.60 2.77 12 -6.352 0.0002 ## Mixture_378 - Rimsulfuron_30 -11.73 2.77 12 -4.235 0.0069 ## Mixture_378 - Unweeded -21.64 2.77 12 -7.813 &lt;.0001 ## Rimsulfuron_30 - Unweeded -9.91 2.77 12 -3.578 0.0228 ## ## P value adjustment: bonferroni method for 6 tests Esistono altre procedure di aggiustamento del P-level (metodi di Holm, Hochberg, Hommel), ma nessuna di queste tiene conto della correlazione eventualmente esistente tra i contrasti e tutte quindi sono da definirsi più o meno ‘conservative’. Oltre che aggiustare il P-level, possiamo anche utilizzare altre procedure di aggiustamento, basate sulla distribuzione multivariata di t e in grado di tener conto dell’eventuale correlazione esistente tra i contrasti stessi. Una di queste procedure viene impiegata di default nella funzione contrast() nel package ‘emmeans’: #Confronti multipli a coppie, basati sul t multivariato contrast(muj, method=&quot;tukey&quot;) ## contrast estimate SE df t.ratio p.value ## Metribuzin__348 - Mixture_378 4.05 2.77 12 1.461 0.4885 ## Metribuzin__348 - Rimsulfuron_30 -7.68 2.77 12 -2.774 0.0698 ## Metribuzin__348 - Unweeded -17.60 2.77 12 -6.352 0.0002 ## Mixture_378 - Rimsulfuron_30 -11.73 2.77 12 -4.235 0.0055 ## Mixture_378 - Unweeded -21.64 2.77 12 -7.813 &lt;.0001 ## Rimsulfuron_30 - Unweeded -9.91 2.77 12 -3.578 0.0173 ## ## P value adjustment: tukey method for comparing a family of 4 estimates Possiamo notare che i P-levels sono leggermente più bassi di quelli ottenuti con Bonferroni, che conferma quindi di essere una procedura molto conservativa, mentre l’impiego del t multivariato consente di rispettare esattamente il tasso di errore ‘per esperimento’. Ovviamente la correzione per la molteplicità ed il conseguente innalzamento del P-level sono fortemente dipendenti dal numero di contrasti effettuati; se utilizziamo un set di confronti tipo ‘dunnett’ invece che tipo ‘pairwise’, avremo meno confronti e quindi una correzione più ‘leggera’. #Confronti multipli a coppie, basati sul t multivariato contrast(muj, method=&quot;dunnett&quot;) ## contrast estimate SE df t.ratio p.value ## Mixture_378 - Metribuzin__348 -4.05 2.77 12 -1.461 0.3711 ## Rimsulfuron_30 - Metribuzin__348 7.68 2.77 12 2.774 0.0442 ## Unweeded - Metribuzin__348 17.60 2.77 12 6.352 0.0001 ## ## P value adjustment: dunnettx method for 3 tests 9.5.3 Procedure ‘classiche’ di confronto multiplo In questo libro, i confronti a coppie sono inseriti nel contesto dei contrasti lineari, come, ad esempio, in Hsu (1996). In passato, i confronti multipli si basavano sulla determinazione di una differenza critica, in base alla quale due medie venivano considerate significativamente diverse quando la loro differenza superava la differenza critica. Nella letteratura scientifica si trovano molte procedure di questo tipo, tra le quali segnaliamo: Minima Differenza Significativa (MDS o LSD) Honest Significant Difference di Tukey Test di Dunnett Test di Duncan Test di Newman-Keuls Test di confronto multiplo di Tukey Il primo metodo corrisponde esattamente a quello che abbiamo utilizzato all’inizio, per fare confronti multipli ‘tutti contro tutti’, senza correzione per la molteplicità. Il secondo e il terzo metodo corrispondono rispettivamente al test di confronto ‘tutti verso tutti’ e ‘uno verso tutti’ indicati in precedenza, con correzione per la molteplicità. Non è necessario dettagliare gli altri test, in quanto, seppur siano ancora molto utilizzati, vengono ormai ritenuti obsoleti e sconsigliabili, da parecchi ricercatori. Chi vuole, trova altre informazioni nella letteratura indicata in fondo al capitolo; mostriamo solo come la HSD di Tukey HSD possa essere calcolata ed utilizzata per in confronto multiplo, utilizzando la funzione aov() per la stima del modello e la funzione TukeyHSD() per il confronto multiplo con correzione per la molteplicità (Code Box 9.13). # Esempio 9.5 [continuazione] # Tukey HSD per un modello lineare adattato con la funzione &#39;aov()&#39; mod2 &lt;- aov(Weight ~ Treat, data = dataset) TukeyHSD(mod2) ## Tukey multiple comparisons of means ## 95% family-wise confidence level ## ## Fit: aov(formula = Weight ~ Treat, data = dataset) ## ## $Treat ## diff lwr upr p adj ## Mixture_378-Metribuzin__348 -4.0475 -12.271978 4.176978 0.4884620 ## Rimsulfuron_30-Metribuzin__348 7.6850 -0.539478 15.909478 0.0698118 ## Unweeded-Metribuzin__348 17.5975 9.373022 25.821978 0.0001854 ## Rimsulfuron_30-Mixture_378 11.7325 3.508022 19.956978 0.0055015 ## Unweeded-Mixture_378 21.6450 13.420522 29.869478 0.0000247 ## Unweeded-Rimsulfuron_30 9.9125 1.688022 18.136978 0.0172572 Per concludere la sezione sui confronti multipli vogliamo dare alcuni consigli pratici di buon senso. Quando è possibile, pianificare gli esperimenti in modo da ottenere le risposte cercate con pochi contrasti di interesse. In questo modo il problema della molteplicità è minimizzato. Non usare mai contrasti con serie di dati quantitative. In questo caso la regressione è l’approccio corretto e ne parleremo in un prossimo capitolo. In generale, utilizzare i contrasti solo se sono coerenti con la logica dell’esperimento. Evitare di utilizzare i confronti multipli nei disegno fattoriale per confrontare tutte le combinazioni dei fattori sperimentali e preferire invece il confronto dei lvelli di un fattore all’interno dei livelli dell’altri. Pianificare esattamente il numero di contrasti necessari ed eseguirli, fornendo il valore del contrasto e il suo errore standard. Decidere è necessario aggiustare il p-level (e gli intervalli di confidenza) per la molteplicità (tasso di errore comparisonwise o experimentwise). Se si decide di aggiustare il p-level, considerare che le procedure di Bonferroni o Sidak possono essere eccessivamente protette. Preferire quindi le procedure di aggiustamento basate sulla distribuzione t multivariata, il che, a livello di confronto multiplo con dati bilanciati, è equivalente ad utilizzate la Tukey HSD o il test di Dunnett. Evitare le procedure di Duncan e Newmann-Keuls: non danno il livello di protezione cercato e, inoltre, non sono basate su una differenza critica costante (quindi sono difficili da discutere). 9.6 Esempio 9.6: confronti multipli con dati trasformati Un altro aspetto di cui tener conto è relativo al fatto che, nel caso in cui si fosse reso necessario qualche tipo di trasformazione stabilizzante, il test di confronto multiplo deve opportunamente adeguato. Per capire questo aspetto, possiamo riprendere in mano il dataset ‘insects.csv’ già esplorato nel capitolo precedente e relativo alle quindici piante trattate con tre insetticidi (cinque piante per insetticida), su ciascuna delle quali, alcune settimane dopo il trattamento, sono stati contati gli insetti presenti e vitali. Ricarichiamo il dataset e, tenendo conto dell’esigenza emerse nel capitolo precedente, analizziamo i dati previa trasformazione logaritmica. Quest’ultima viene eseguita direttamente nel corso del ‘model fitting’ e non nel dataset, per un motivo che sarà chiaro in seguito. fileName &lt;- &quot;https://www.casaonofri.it/_datasets/insects.csv&quot; dataset &lt;- read.csv(fileName, header = T) dataset$Insecticide &lt;- factor(dataset$Insecticide) mod &lt;- lm(log(Count) ~ Insecticide, data = dataset) A questo punto, possiamo calcolare le medie marginali attese, che, tuttavia, sono su scala logaritmica, come indicato nel codice sottostante. medie &lt;- emmeans(mod, ~Insecticide) medie ## Insecticide emmean SE df lower.CL upper.CL ## T1 6.34 0.178 12 5.96 6.73 ## T2 5.81 0.178 12 5.43 6.20 ## T3 3.95 0.178 12 3.56 4.34 ## ## Results are given on the log (not the response) scale. ## Confidence level used: 0.95 Presentare le medie su scala logaritmica, in molti casi, potrebbe non essere di immediata o facile lettura. Per questo, potremmo pensare di retro-trasformare le medie, utilizzando la trasformazione inversa di quella logaritmica, cioè l’antilogaritmo. Ad esempio, per la prima media: \\[e^{6.34} = 566.7963\\] In questo modo la nostra unità di misura ridiventa quella originale, anche se il valore ottenuto non coincide con la media dei dati originali; in effetti la trasformazione è non lineare e la media dei logaritmi non può coincidere con il logaritmo della media. Possiamo osservare che la media del trattamento A, sulla scala originale, è: mean(dataset[dataset$Insecticide == &quot;T1&quot;,&quot;Count&quot;]) ## [1] 589.8 e risulta più alta della media retro-trasformata. In realtà, se è vero che i logaritmi sono normalmente distribuiti, la media dei logaritmi (6.34) dovrebbe essere uguale alla mediana (ricordiamo che in una distribuzione normale media e mediana coincidono). La mediana è il valore centrale; dato che la retro-trasformazione è monotona, il valore centrale resta centrale, anche se io retro-trasformo. Quindi la media retro-trasformata è uno stimatore della mediana della popolazione originale, non della sua media. Questo non è uno svantaggio: infatti il QQ-plot suggerisce un’asimmetria positiva (vedi capitolo precedente) cosa che è confermata dal fatto che la mediana è minore della media. Se la distribuzione dei dati è asimmetrica, la mediana è un indicatore di tendenza centrale migliore della media, perché meno sensibile ai valori estremi, che sono più frequenti in caso di asimmetria. Il problema è che, se vogliamo utilizzare la media retro-trasformata, dobbiamo trovare un valore di errore standard per questo stima, con il quale esprimere la sua incertezza. In realtà, anche l’errore standard può essere retro-trasformato, con una tecnica detta metodo ‘delta’, che costituisce un estensione della legge di propagazione degli errori per le trasformazioni non-lineari. È inutile andare nel dettaglio; diciamo solo che la funzione emmeans() rende semplicissima l’implementazione del metodo delta, con il comando seguente: retroMedie &lt;- emmeans(mod, ~Insecticide, type = &quot;response&quot;) retroMedie ## Insecticide response SE df lower.CL upper.CL ## T1 568.6 101.01 12 386.1 837.3 ## T2 335.1 59.54 12 227.6 493.5 ## T3 51.9 9.22 12 35.2 76.4 ## ## Confidence level used: 0.95 ## Intervals are back-transformed from the log scale Con questo abbiamo tutto quello che ci serve: stime ed errori standard, che, ovviamente, sono diversi per le diverse medie retro-trasformate, coerentemente con la mancanza di omoscedasticità. Il test di confronto multiplo è, pertanto: library(multcomp) cld(retroMedie, Letters = LETTERS) ## Insecticide response SE df lower.CL upper.CL .group ## T3 51.9 9.22 12 35.2 76.4 A ## T2 335.1 59.54 12 227.6 493.5 B ## T1 568.6 101.01 12 386.1 837.3 B ## ## Confidence level used: 0.95 ## Intervals are back-transformed from the log scale ## P value adjustment: tukey method for comparing a family of 3 estimates ## Tests are performed on the log scale ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. La retrotrasformazione è immediata in quanto la funzione emmeans() è stata in grado di riconoscere la trasformazione stabilizzante applicata all’interno del ‘model fitting’. La situazione diviene più complessa se la trasformazione è applicata prima del ‘model fitting’ oppure se non viene automaticamente riconosciuta. Ad esempio, una trasformazione inversa non viene automaticamente riconosciuta e, di conseguenza, la retrotrasformazione non viene effettuata. mod2 &lt;- lm(1/Count ~ Insecticide, data = dataset) emmeans(mod2, ~Insecticide, type = &quot;response&quot;) ## Insecticide emmean SE df lower.CL upper.CL ## T1 0.00182 0.00279 12 -0.00426 0.00789 ## T2 0.00317 0.00279 12 -0.00291 0.00924 ## T3 0.02120 0.00279 12 0.01513 0.02727 ## ## Confidence level used: 0.95 In questo caso, dobbiamo eseguire la trasformazione prima del ‘model fitting’ e poi cambiare la griglia di riferimento per il modello (update(ref_grid(mod2), ....)) specificando la trasformazione effettuata (tran = \"inverse\"). La griglia così modificata viene passata al posto del modello alla funzione emmeans(), come indicato di seguito. dataset$InvCount &lt;- 1/dataset$Count mod3 &lt;- lm(InvCount ~ Insecticide, data = dataset) updGrid &lt;- update(ref_grid(mod3), tran = &quot;inverse&quot;) emmeans(updGrid, ~Insecticide, type = &quot;response&quot;) ## Insecticide response SE df lower.CL upper.CL ## T1 550.9 845.9 12 126.8 Inf ## T2 315.8 278.0 12 108.2 Inf ## T3 47.2 6.2 12 36.7 66 ## ## Confidence level used: 0.95 ## Intervals are back-transformed from the inverse scale Questo metodo si può utilizzare con numerose funzioni, come, ad esempio “identity”, “1/mu^2”, “inverse”, “reciprocal”, “log10”, “log2”, “asin.sqrt” e “asinh.sqrt”. Un approccio analogo può essere utilizzato se vogliamo effettuare la trasformazione di Box-Cox nella sua forma semplificata (\\(W = Y^{\\lambda}\\)), utilizzando un valore \\(\\lambda\\) diverso da quelli ‘semplici’ (cioè diverso da 1, 0, 0.5 o -1). Ad esempio, se vogliamo utilizzare \\(\\lambda = 0.25\\), dobbiamo operare in modo simile a quello descritto in precedenza, utilizzando la funzione make.tran(), come evidenziato nel box seguente. dataset$lCount &lt;- dataset$Count^0.25 mod4 &lt;- lm(lCount ~ Insecticide, data = dataset) updGrid &lt;- update(ref_grid(mod4), tran = make.tran(&quot;power&quot;, 0.25)) emmeans(updGrid, ~Insecticide, type = &quot;response&quot;) ## Insecticide response SE df lower.CL upper.CL ## T1 573.5 78.7 12 420.3 765.3 ## T2 340.5 53.2 12 238.5 472.1 ## T3 53.1 13.2 12 29.6 88.3 ## ## Confidence level used: 0.95 ## Intervals are back-transformed from the mu^0.25 scale 9.7 Esempio 9.7: Previsioni e previsioni inverse Per i modelli di regressione lineare o non lineare, lavorare con le medie è solitamente irrilevante, mentre può essere necessario utilizzare il modello per fare previsioni, ovvero per calcolare la risposta attesa con un certo valore della variabile indipendente oppure per calcolare quale valore di una variabile indipendente consente di ottenere la risposta voluta (previsione inversa). Anche le previsioni possono essere considerate combinazioni lineari o non lineari dei parametri del modello e possono essere calcolate con R, utilizzando una delle numerose funzioni disponibili, come predict(), emmeans(), glht() e gnlht(). A titolo di esempio, possiamo considerare i dati ‘Ammi94’, relativi a un esperimento per definire la relazione tra la densità di Ammi majus (un’importante infestante di diverse colture primaverili nell’Italia centrale) espressa come numero di piante per metro quadrato e la resa del girasole in tonnellate per ettaro. Le diverse densità delle infestanti sono state ottenute con semina mauale, mentre i dati di resa rappresentano la media di quattro repliche (Onofri et al., 1994). Il dataset è disponibile nel pacchetto statforbiology e nel riquadro successivo, si vede come venga adattato un semplice modello di regressione lineare e le due stime (intercetta e pendenza, ovvero \\(\\beta_0\\) e \\(\\beta_1\\)) vengono recuperate e visualizzate. # Example 9.7 # Predictions and inverse predictions for linear regression # Weed density/Yield relationship for Ammi majus # Loading the packages library(statforbiology) library(multcomp) library(emmeans) # Loading the data dataset &lt;- getAgroData(&quot;Ammi94&quot;) dataset ## Density Yield ## 1 0 2.4866 ## 2 16 2.1806 ## 3 21 1.8456 ## 4 36 1.8412 ## 5 49 1.6486 # Fitting a regression model mod &lt;- lm(Yield ~ Density, data = dataset) summary(mod) ## ## Call: ## lm(formula = Yield ~ Density, data = dataset) ## ## Residuals: ## 1 2 3 4 5 ## 0.08403 0.04167 -0.21094 0.03182 0.05342 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.402566 0.108697 22.103 0.000203 *** ## Density -0.016477 0.003667 -4.494 0.020567 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.138 on 3 degrees of freedom ## Multiple R-squared: 0.8707, Adjusted R-squared: 0.8275 ## F-statistic: 20.19 on 1 and 3 DF, p-value: 0.02057 In un esperimento del genere, vi sono due interessi fondamentali: Prevedere la resa con misurazioni precoci della densità delle infestanti (previsione); Determinare la densità delle infestanti che provoca un certo livello di perdita di resa (previsione inversa). Queste stime possono essere ottenute come combinazioni lineari o non lineari. Ad esempio, immaginiamo di voler determinare il livello di resa previsto con 10 piante di Ammi majus per metro quadrato. Ci sono tre possibilità: Utilizzare la funzione glht() per adattare un contrasto \\(C = 1 \\times \\beta_0 + 10 \\times \\beta_1\\), dove i parametri \\(\\beta_0\\) e \\(\\beta_1\\) sono, rispettivamente, l’intercetta e la pendenza del modello lineare; Utilizzare la funzione predict() e passare un dataframe (non un vettore!) contenente il livello di densità per la previsione (argomento ‘newdata’); Utilizzare la funzione emmeans(), passando il livello di densità come dataframe all’argomento ‘at’. Tutte e tre le possibilità sono illustrate nel riquadro sottostante; i risultati sono, ovviamente, del tutto equivalenti. # Example 9.7 [continuation] # Three methods for predictions # 1.Fitting with &#39;glht()&#39;################## # Setting a contrast matrix K &lt;- matrix(c(1, 10), nrow = 1, ncol = 2) summary(glht(mod, linfct = K)) ## ## Simultaneous Tests for General Linear Hypotheses ## ## Fit: lm(formula = Yield ~ Density, data = dataset) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## 1 == 0 2.23779 0.08123 27.55 0.000105 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) # 2.Fitting with &#39;predict()&#39; ################ predict(mod, newdata = data.frame(Density= c(10)), se.fit = T) ## $fit ## 1 ## 2.237793 ## ## $se.fit ## [1] 0.08123191 ## ## $df ## [1] 3 ## ## $residual.scale ## [1] 0.1380352 # 3.Fitting with &#39;emmeans()&#39; #################### emmeans(mod, ~Density, at = data.frame(Density= c(10))) ## Density emmean SE df lower.CL upper.CL ## 10 2.24 0.0812 3 1.98 2.5 ## ## Confidence level used: 0.95 Immaginiamo ora di voler stimare il livello di densità delle malerbe che provoca una riduzione della resa del 10%. Considerando che la resa senza malerbe è di 2.403 tonnellate per ettaro (l’intercetta stimata più sopra), una riduzione della resa del 10% corrisponde all’ottenimento di un livello di resa pari a \\(2.403 - 0.1 \\times 2.403 = 2.163\\), che è pari a \\((2,163 - \\beta_0)/\\beta_1\\). Quest’ultima equazione è intrinsecamente non lineare; pertanto, si deve utilizzare la funzione gnlht(), come mostrato qui sotto. # Example 9.7 [continuation] # Inverse prediction with gnlht() gnlht(mod, func = list(~(21.53 - b0)/b1), parameterNames = c(&quot;b0&quot;, &quot;b1&quot;)) ## Form Estimate SE t-value p-value ## 1 (21.53 - b0)/b1 -1160.835 263.7767 4.400825 0.0217523 9.8 Altre letture Bretz F, Hothorn T, Westfall P (2011) Multiple Comparisons Using R. CRC Press, Boca Raton, FL Chew V (1976) Comparing treatment means: a compendium. Hortscience 11(4):348–357 Cousens R (1988) Misinterpretetion of results in weed research through inappropriate use of statistics. Weed Res 28:281–289 Hsu JC (1996) Multiple Comparisons: Theory and Methods. Chapman &amp; Hall, London Lenth RV (2016) Least-squares means: the R package lsmeans. J Stat Softw 69(1). https://doi.org/10.18637/jss.v069.i01. Onofri A, Tei F (1994) Competitive ability and threshold levels for three broadleaf weed species in sunflower. Weed Res 34:471–479 Onofri A, Carbonell EA, Piepho HP, Mortimer AM, Cousens RD (2010) Current statistical issues in Weed Research. Weed Res 50(1):5–24 Piepho HP (2004) An algorithm for a letter-based representation of all-pairwise comparisons. J Comput Graph Stat 13(2):456–466 Weisberg S (2005) Applied Linear Regression, 3rd edn. Wiley, Hoboken 9.9 Esercizi Considerare gli esercizi da 5 a 7 nel Capitolo 4. Per tutti questi esercizi, dopo essersi accertati se è necessaria una trasformazione per soddisfare le ipotesi di base per i modelli lineari, eseguire il test di confronto multiplo, adottando una correzione appropriata per la molteplicità. vedi: ↩︎ Chi fosse interessato può trovare informazioni sul nel blog associato, all’indirizzo \\url{https://www.statforbiology.com/2024/stat_general_thedeltamethod_edit/↩︎ "],["ricomponiamo-il-puzzle.html", "Capitolo 10 Ricomponiamo il ‘puzzle’ 10.1 Esempio 10.1: Confronto tra erbicidi in un esperimento a blocchi randomizzati 10.2 Esempio 10.2: confronto tra co-adiuvanti in un esperimento a quadrato latino 10.3 Esempio 10.3: interazione tra genotipo e concimazione azotata 10.4 Esempio 10.4: confronto tra incroci in un disegno fattoriale gerarchico 10.5 Esempio 10.5: un esperimento di germinazione ripetuto due volte 10.6 Altre letture 10.7 Esercizi", " Capitolo 10 Ricomponiamo il ‘puzzle’ È giunto ormai il momento di riunire tutti gli strumenti presentati nei capitoli precedenti e sviluppare un piano di lavoro per eseguire analisi dei dati corrette, produrre risultati affidabili e giungere a conclusioni pienamente supportate dai dati a nostra disposizione. Il piano di lavoro proposto non deve essere preso troppo alla lettera: è solo uno dei possibili approcci all’analisi dei dati e deve essere inteso solo come punto di partenza per ‘principianti’. Il piano di lavoro è il seguente: Caricare i dati ed eseguire le eventuali trasformazioni che si rendano necessarie (ad es. le trasformazioni delle variabili numeriche in ‘factors’ oppure le trasformazioni stabilizzanti). Descrivere i dati, calcolando almeno un indicatore di tendenza centrale (media) e un indicatore di variabilità (deviazione standard) come indicato nel Capitolo 3. Se necessario, utilizzare grafici per scoprire le caratteristiche principali del dataset in studio, scoprire pattern e individuare valori anomali: lasciare che i dati parlino da soli e “ascoltare” ciò che hanno da dire. Questa fase preliminare è definita Analisi Esplorativa dei Dati (EDA) ed è una parte fondamentale dell’analisi dei dati, prima dell’adattamento del modello, dell’inferenza e del test d’ipotesi. Specificare il modello descrittivo più opportuno a stimarne i parametri con R. Controllare il fitting per il rispetto delle assunzioni di base. Se necessario, trasformare i dati e ripetere il fitting Calcolare gli errori standard e/o gli intervalli di confidenza e aggiungerli a tutte le stime puntuali. Verificare la significatività di tutti gli effetti tramite il test di F nell’ANOVA. Utilizzare combinazioni lineari o non lineari dei parametri o delle medie per testare ulteriori ipotesi di interesse e rispondere a tutti i quesiti di ricerca. Presentare i risultati sotto forma di grafici e tabelle, in modo conciso e assicurandosi di evidenziare tutte le caratteristiche chiave di interesse per il set di dati in questione. In questo capitolo mostreremo come questo piano di lavoro possa essere messo in pratica, lavorando su alcuni dataset reali, relativi ad esperimenti agronomici di pieno campo. 10.1 Esempio 10.1: Confronto tra erbicidi in un esperimento a blocchi randomizzati Consideriamo un esperimento di campo per confrontare otto genotipi di frumento, disegnato a blocchi randomizzati con tre repliche, nella collina Umbra durante la stagione di semina 2002 (Ciriciofolo, 2004; pubblicato in Belocchi et al. 2003). La variabile di risposta è la resa (in tonnellate per ettaro) e il set di dati è disponibile come “WinterWheat2002” nel package statforbiology. La variabile “blocco” deve essere trasformata in un fattore prima dell’analisi, altrimenti, R stimerebbe erroneamente un modello di regressione lineare (mentre i blocchi sono classi nominali e non ordinate). Anche la variabile “genotipo” può essere trasformata in un fattore, sebbene ciò sia facoltativo, poiché i genotipi non sono rappresentati con numeri. L’EDA rivela che i genotipi, ad eccezione di Simeto, sono relativamente simili in termini di resa media. Allo stesso tempo, esistono alcune differenze in termini di deviazione standard, che potrebbero giustificare un attento controllo di eteroschedasticità. # Example 10.1 # A genotype experiment in blocks # Loading the packages library(statforbiology) library(MASS) library(car) library(emmeans) library(multcomp) # Loading the &#39;WinterWheat2002&#39; dataset and performing an EDA dataset &lt;- getAgroData(&quot;WinterWheat2002&quot;) head(dataset) ## Plot Block Genotype Yield ## 1 57 A COLOSSEO 4.31 ## 2 61 B COLOSSEO 4.73 ## 3 11 C COLOSSEO 5.64 ## 4 60 A CRESO 3.99 ## 5 10 B CRESO 4.82 ## 6 42 C CRESO 4.17 dataset$Block &lt;- factor(dataset$Block) dataset$Genotype &lt;- factor(dataset$Genotype) with(dataset, data.frame(Mean = tapply(Yield, Genotype, mean), SD = tapply(Yield, Genotype, sd))) ## Mean SD ## COLOSSEO 4.893333 0.6798774 ## CRESO 4.326667 0.4366158 ## DUILIO 4.240000 0.1400000 ## GRAZIA 4.340000 0.3764306 ## IRIDE 4.963333 0.1892969 ## SANCARLO 4.503333 0.2250185 ## SIMETO 3.340000 0.3915354 ## SOLEX 4.790000 0.2645751 La produzione di ogni unità sperimentale (parcella) è determinata da: il genotipo in essa coltivato; il blocco di cui fa parte; altri effetti non conoscibile e puramente casuale (residuo). Quindi, possiamo stimare un modello con due predittori nominali, come mostrato nell’Esempio 4.3 del Capitolo 4. Le analisi grafiche dei residui mostrano alcuni lievi segni di eteroschedasticità (Figura 10.1, sinistra), ma nessuna chiara evidenza di mancanza di normalità. La funzione leveneTest() non può essere utilizzata con dati provenienti da esperimenti a blocchi randomizzati, ma possiamo adattarla eseguendola sui residui in valore assoluto (Bhandary e Dai 2013; vedi riquadro sottostante); questo test non è significativo e il grafico di Box-Cox (non mostrato) conferma che non è necessaria alcuna trasformazione dei dati. Di conseguenza, concludiamo che non ci sono deviazioni significative dalle assunzioni di base e procediamo esaminando la tabella ANOVA. Il controllo preliminare dei gradi di libertà conferma che il modello è stato specificato correttamente (vale a dire, i DF sono uguali, rispettivamente, al numero di blocchi meno uno e al numero di genotipi meno uno) e, in base al P-value, rigettiamo l’ipotesi nulla concludendo che esistono differenze significative tra i genotipi. # Example 10.1 [continuation] # Model fitting with two nominal predictors mod &lt;- lm(Yield ~ Block + Genotype, data = dataset) # Inspection of plots (not run) # par(mfrow=c(2,2)) # plot(mod, which = 1) # plot(mod, which = 2) # boxcox(mod) # Levene test (modified version for RCBDs) leveneTest(abs(residuals(mod)) ~ Genotype, data = dataset) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 7 0.7932 0.6037 ## 16 # Variance partitioning anova(mod) ## Analysis of Variance Table ## ## Response: Yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Block 2 0.7977 0.39883 3.8502 0.0465178 * ## Genotype 7 5.6305 0.80436 7.7651 0.0006252 *** ## Residuals 14 1.4502 0.10359 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Figura 10.1: Analisi grafica dei residui per la prova di confronto varietale a blocchi randomizzati Le stime dei parametri del modello sono relativamente poco interessanti in questo caso, mentre i confronti a coppie possono essere utili per la raccomandazione varietale. Con otto genotipi e, quindi, \\((8 \\times 7)/2 = 28\\) contrasti, è necessaria una correzione per la molteplicità. Oltre ai confronti a coppie con i relativi intervalli di confidenza, riportiamo una tabella delle medie in ordine decrescente di resa, con le lettere di significanza. La conclusione è che Simeto è risultato significativamente peggiore di tutti gli altri genotipi, ad eccezione di Duilio. # Example 10.1 [continuation] # Multiple comparisons meds &lt;- emmeans(mod, ~Genotype) confint(contrast(meds, method = &quot;pairwise&quot;)) ## contrast estimate SE df lower.CL upper.CL ## COLOSSEO - CRESO 0.5667 0.263 14 -0.3606 1.494 ## COLOSSEO - DUILIO 0.6533 0.263 14 -0.2740 1.581 ## COLOSSEO - GRAZIA 0.5533 0.263 14 -0.3740 1.481 ## COLOSSEO - IRIDE -0.0700 0.263 14 -0.9973 0.857 ## COLOSSEO - SANCARLO 0.3900 0.263 14 -0.5373 1.317 ## COLOSSEO - SIMETO 1.5533 0.263 14 0.6260 2.481 ## COLOSSEO - SOLEX 0.1033 0.263 14 -0.8240 1.031 ## CRESO - DUILIO 0.0867 0.263 14 -0.8406 1.014 ## CRESO - GRAZIA -0.0133 0.263 14 -0.9406 0.914 ## CRESO - IRIDE -0.6367 0.263 14 -1.5640 0.291 ## CRESO - SANCARLO -0.1767 0.263 14 -1.1040 0.751 ## CRESO - SIMETO 0.9867 0.263 14 0.0594 1.914 ## CRESO - SOLEX -0.4633 0.263 14 -1.3906 0.464 ## DUILIO - GRAZIA -0.1000 0.263 14 -1.0273 0.827 ## DUILIO - IRIDE -0.7233 0.263 14 -1.6506 0.204 ## DUILIO - SANCARLO -0.2633 0.263 14 -1.1906 0.664 ## DUILIO - SIMETO 0.9000 0.263 14 -0.0273 1.827 ## DUILIO - SOLEX -0.5500 0.263 14 -1.4773 0.377 ## GRAZIA - IRIDE -0.6233 0.263 14 -1.5506 0.304 ## GRAZIA - SANCARLO -0.1633 0.263 14 -1.0906 0.764 ## GRAZIA - SIMETO 1.0000 0.263 14 0.0727 1.927 ## GRAZIA - SOLEX -0.4500 0.263 14 -1.3773 0.477 ## IRIDE - SANCARLO 0.4600 0.263 14 -0.4673 1.387 ## IRIDE - SIMETO 1.6233 0.263 14 0.6960 2.551 ## IRIDE - SOLEX 0.1733 0.263 14 -0.7540 1.101 ## SANCARLO - SIMETO 1.1633 0.263 14 0.2360 2.091 ## SANCARLO - SOLEX -0.2867 0.263 14 -1.2140 0.641 ## SIMETO - SOLEX -1.4500 0.263 14 -2.3773 -0.523 ## ## Results are averaged over the levels of: Block ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 8 estimates # Letter display cld(meds, Letters = LETTERS, reverse = T) ## Genotype emmean SE df lower.CL upper.CL .group ## IRIDE 4.96 0.186 14 4.56 5.36 A ## COLOSSEO 4.89 0.186 14 4.49 5.29 A ## SOLEX 4.79 0.186 14 4.39 5.19 A ## SANCARLO 4.50 0.186 14 4.10 4.90 A ## GRAZIA 4.34 0.186 14 3.94 4.74 A ## CRESO 4.33 0.186 14 3.93 4.73 A ## DUILIO 4.24 0.186 14 3.84 4.64 AB ## SIMETO 3.34 0.186 14 2.94 3.74 B ## ## Results are averaged over the levels of: Block ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 8 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. 10.2 Esempio 10.2: confronto tra co-adiuvanti in un esperimento a quadrato latino Consideriamo un esperimento a quadrato latino con quattro repliche, finalizzato a confrontare tre possibili co-adiuvanti per l’erbicida rimsulfuron (Onofri, 1990; dati non pubblicati). I risultati di questo esperimento sono disponibili nel dataset ‘adjuvantsLS’, nel package statforbiology; la colonna ‘Yield’ è la risposta, la colonna ‘Adjuvant’ il predittore nominale, mentre le colonne ‘Row’ and ‘Column’ rappresentano le righe e le colonne della griglia a quadrato latino e costituiscono i due fattori di raggruppamento da inserire nel modello. Le tre variabili indipendenti dovranno essere trasformate in fattori prima dell’analisi, sebbene ciò sia strettamente necessario solo per le righe e le colonne, che sono caratterizzate da codifica numerica. Invece di trasformare le tre variabili una alla volta (come nell’esempio 10.1), possiamo utilizzare la funzione transform(), passandole il ‘dataframe’ come primo argomento e l’elenco delle trasformazioni da eseguire all’interno di tale ‘dataframe’ (vedere il codice più sotto). L’EDA si basa sull’analisi delle medie aritmetiche e delle deviazioni standard (DS) dei diversi trattamenti: la media per il tensioattivo sembra essere più alta rispetto alle altre medie. Allo stesso tempo, non ci sono evidenti differenze tra i co-adiuvanti in termini di deviazioni standard. # Example 10.2 # Comparing adjuvants on a latin square # Loading the packages library(statforbiology) library(MASS) library(emmeans) library(multcomp) # Loading and transforming the data dataset &lt;- getAgroData(&quot;adjuvantsLS&quot;) dataset &lt;- transform(dataset, Adjuvant = factor(Adjuvant), Row = factor(Row), Column = factor(Column)) head(dataset[,c(2, 6, 7, 24)]) ## Adjuvant Column Row Yield ## 1 AmmoniumSulphate 1 3 58.23 ## 2 AmmoniumSulphate 2 1 47.98 ## 3 AmmoniumSulphate 3 4 92.39 ## 4 AmmoniumSulphate 4 2 85.97 ## 5 MineralOil 1 2 73.99 ## 6 MineralOil 2 4 92.97 # EDA with(dataset, data.frame(Mean = tapply(Yield, Adjuvant, mean), SD = tapply(Yield, Adjuvant, sd))) ## Mean SD ## AmmoniumSulphate 71.1425 21.40518 ## MineralOil 101.1475 23.00979 ## None 80.5525 30.51889 ## Surfactant 115.4250 20.69268 In questo esempio, abbiamo un trattamento sperimentale e due effetti ‘blocco’ che debbono necessariamente essere inclusi nel modello (Jensen et al., 2018). Di conseguenza, il modello causa-effetto può essere così definito: \\[Y_{ijk} = \\mu + \\gamma_k + \\beta_j + \\alpha_i + \\varepsilon_{ijk}\\] dove \\(\\mu\\) è l’intercetta, \\(\\gamma\\) è l’effetto della k-esima riga, \\(\\beta\\) è l’effetto della j-esima colonna e \\(\\alpha\\) è l’effetto dell’i-esimo coadiuvante. L’elemento \\(\\varepsilon_{ijk}\\) rappresenta la componente random individuale, di ogni osservazione e si assume normalmente distribuita, con media 0 e deviazione standard \\(\\sigma\\). Dopo il ‘fitting’, estraiamo i residui e li sottoponiamo ad analisi grafica, che non rivela problemi di alcun tipo (Figura 10.2), mentre il grafico di Box-Cox conferma che non è necessaria alcuna trasformazione (non mostrato). Pertanto, possiamo procedere all’ANOVA per testare la significatività di tutti i fattori sperimentali. # Example 10.2 [continuation] # Fitting the model mod &lt;- lm(Yield ~ Adjuvant + Row + Column, data = dataset) # checking the residuals (not run here) # plot(mod, which = 1) # plot(mod, which = 2) # boxcox(mod) # Variance partitioning anova(mod) ## Analysis of Variance Table ## ## Response: Yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Adjuvant 3 4793.9 1597.96 14.9051 0.003458 ** ## Row 3 375.8 125.28 1.1685 0.396678 ## Column 3 6022.6 2007.53 18.7253 0.001893 ** ## Residuals 6 643.3 107.21 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Figura 10.2: Analisi grafica dei residui per la prova di confronto tra metodi costruttivi La differenza tra i co-adiuvanti è significativa (valore P = 0,0035) e la procedura di confronto multiplo rivela che il tensioattivo ha migliorato significativamente le prestazioni dell’erbicida, rispetto a quando è stato utilizzato da solo, mentre la resa con olio minerale non è stata significativamente inferiore a quella ottenuta col tensioattivo. # Example 10.2 [continuation] # Multiple comparisons avgs &lt;- emmeans(mod, ~Adjuvant) confint(contrast(avgs, method = &quot;pairwise&quot;)) ## contrast estimate SE df lower.CL upper.CL ## AmmoniumSulphate - MineralOil -30.00 7.32 6 -55.35 -4.66 ## AmmoniumSulphate - None -9.41 7.32 6 -34.75 15.93 ## AmmoniumSulphate - Surfactant -44.28 7.32 6 -69.63 -18.94 ## MineralOil - None 20.59 7.32 6 -4.75 45.94 ## MineralOil - Surfactant -14.28 7.32 6 -39.62 11.07 ## None - Surfactant -34.87 7.32 6 -60.22 -9.53 ## ## Results are averaged over the levels of: Row, Column ## Confidence level used: 0.95 ## Conf-level adjustment: tukey method for comparing a family of 4 estimates cld(avgs, Letters = LETTERS, reversed = TRUE) ## Adjuvant emmean SE df lower.CL upper.CL .group ## Surfactant 115.4 5.18 6 102.8 128.1 A ## MineralOil 101.1 5.18 6 88.5 113.8 AB ## None 80.6 5.18 6 67.9 93.2 BC ## AmmoniumSulphate 71.1 5.18 6 58.5 83.8 C ## ## Results are averaged over the levels of: Row, Column ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 4 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. 10.3 Esempio 10.3: interazione tra genotipo e concimazione azotata Quindici genotipi di frumento sono stati confrontati a due diversi livelli di fertilizzazione azotata, utilizzando un disegno a blocchi randomizzati con tre repliche. L’esperimento mirava a valutare se la raccomandazione varietale cambiasse al cambiare del livello di concimazione azotata. Il set di dati è stato generato tramite simulazione Monte Carlo, a partire dai risultati riportati in (Stagnari et al., 2003) ed è disponibile come ‘NGenotypeFull’ nel package statforbiology. In questo esperimento, la resa è determinata da quattro effetti: blocco genotipo livello di azoto interazione tra genotipo e livello di azoto Di conseguenza, il modello mostrato può essere codificato come nell’Esempio 4.4 (Capitolo 4), aggiungendo l’effetto blocco. Per stimare questo modello, possiamo caricare i dati e trasformare i predittori numerici in fattori. Per questa trasformazione, nel riquadro sottostante abbiamo utilizzato la funzione lapply() invece della funzione transform(), che avevamo utilizzato in un esempio precedente. Con lapply(), le variabili da trasformare vengono recuperate utilizzando gli indici di colonna, vengono trasformate utilizzando la funzione factor() (passata come secondo argomento) e riassegnate alle stesse posizioni che avevano in precedenza nel ‘dataframe’. Per brevità, saltiamo l’EDA e passiamo direttamente alla stima del modello; L’analisi grafica dei residui produce i risultati mostrati nella Figura \\(\\ref{fig:figName133}\\), dove non osserviamo deviazioni evidenti rispetto agli assunti di base per i modelli lineari; pertanto, procediamo con l’ANOVA. # Example 10.3 # Genotype by Nitrogen Interactions # Loading the packages library(statforbiology) library(MASS) library(car) library(emmeans) library(multcomp) # Loading and transforming the data dataset &lt;- getAgroData(&quot;NGenotypeFull&quot;) dataset[,1:3] &lt;- lapply(dataset[,1:3], factor) head(dataset) ## Block Genotype N Yield ## 1 1 A 1 2.146 ## 2 2 A 1 2.433 ## 3 3 A 1 2.579 ## 4 1 A 2 2.362 ## 5 2 A 2 2.919 ## 6 3 A 2 2.912 # Model fitting mod &lt;- lm(Yield ~ Block + Genotype * N, data=dataset) # Model checking (not run) # plot(mod, which = 1) # plot(mod, which = 2) # boxcox(mod) # Variance partitioning anova(mod) ## Analysis of Variance Table ## ## Response: Yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Block 2 0.0944 0.04721 1.3310 0.2721536 ## Genotype 14 10.5408 0.75291 21.2297 &lt; 2.2e-16 *** ## N 1 1.6246 1.62463 45.8092 7.175e-09 *** ## Genotype:N 14 1.6061 0.11472 3.2349 0.0008204 *** ## Residuals 58 2.0570 0.03547 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Figura 10.3: Analisi grafiche dei residui per l’esperimento fattoriale di confronto tra genotipi a due dosi di azoto (Esempio 10.3). La lettura della tabella ANOVA per un esperimento a due vie richiede una certa attenzione ed è fondamentale procedere dal basso verso l’alto, considerando che un’interazione cross-over significativa potrebbe nascondere gli effetti dei fattori principali (vedere Capitolo 4). In generale, ogniqualvolta l’interazione sia significativa, dovremmo sempre riportare e commentare le medie delle combinazioni tra i livelli dei fattori sperimentali. D’altra parte, se l’interazione non fosse significativa, potremmo invece riassumere i risultati riportando e commentando solo le medie degli effetti principali. In questo esempio, l’interazione è significativa e la conclusione è che la raccomandazione varietale non può essere univoca, ma deve cambiare a seconda del livello di fertilizzazione azotata. Pertanto, è necessario riportare e separatamente le medie dei genotipi per ciascun livello di azoto; in questa situazione i confronti a coppie tra genotipi potrebbero essere effettuati in due modi: confrontando tutti i genotipi, anche se concimati in modo diverso; confrontando tra loro solo i genotipi concimati nello stesso modo. Il primo approccio è molto flessibile, ma implica un numero elevato di contrasti \\((10 x 9) / 2 = 45\\) contrasti); di conseguenza, implica anche un forte aggiustamento per la molteplicità, quindi una potenza ridotta e maggiori rischi di errori di II specie. Tale approccio è da raccomandare solo se strettamente necessario e, in questo caso, la codifica R per la funzione emmeans() deve utilizzare l’operatore : (ad esempio: emmeans(mod, ~Genotype:N)). Il secondo approccio implica invece un numero inferiore di confronti (\\(2 x [5 x 4)/2 = 20\\) confronti] e, in questo caso, appare più logico e sensato, da un punto di vista agronomico. Nel riquadro sottostante questo approccio viene implementato utilizzando l’operatore di ‘condizionamento’ (|). # Example 10.3 [continuation] # Pairwise comparisons within Nitrogen levels GNmeans2 &lt;- emmeans(mod, ~Genotype|N) cld(GNmeans2, Letters=LETTERS) ## N = 1: ## Genotype emmean SE df lower.CL upper.CL .group ## A 2.39 0.109 58 2.17 2.60 A ## M 2.43 0.109 58 2.21 2.65 AB ## C 2.53 0.109 58 2.32 2.75 ABC ## G 2.61 0.109 58 2.39 2.83 ABCD ## H 2.69 0.109 58 2.47 2.91 ABCD ## I 2.77 0.109 58 2.55 2.99 ABCDE ## B 2.92 0.109 58 2.70 3.13 ABCDEF ## D 2.96 0.109 58 2.74 3.17 BCDEF ## N 2.99 0.109 58 2.77 3.21 CDEFG ## O 3.00 0.109 58 2.78 3.22 CDEFG ## F 3.06 0.109 58 2.85 3.28 CDEFG ## J 3.10 0.109 58 2.88 3.31 DEFG ## E 3.26 0.109 58 3.04 3.47 EFG ## K 3.40 0.109 58 3.18 3.61 FG ## L 3.52 0.109 58 3.31 3.74 G ## ## N = 2: ## Genotype emmean SE df lower.CL upper.CL .group ## C 2.19 0.109 58 1.97 2.41 A ## I 2.63 0.109 58 2.41 2.85 AB ## A 2.73 0.109 58 2.51 2.95 ABC ## M 2.99 0.109 58 2.77 3.21 BCD ## H 3.02 0.109 58 2.80 3.24 BCD ## F 3.11 0.109 58 2.90 3.33 BCDE ## G 3.13 0.109 58 2.91 3.34 BCDEF ## B 3.24 0.109 58 3.02 3.46 CDEF ## D 3.35 0.109 58 3.13 3.56 DEF ## O 3.35 0.109 58 3.13 3.57 DEF ## E 3.47 0.109 58 3.25 3.68 DEF ## L 3.53 0.109 58 3.32 3.75 DEF ## J 3.62 0.109 58 3.40 3.83 EF ## K 3.62 0.109 58 3.40 3.83 EF ## N 3.67 0.109 58 3.45 3.89 F ## ## Results are averaged over the levels of: Block ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 15 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. 10.4 Esempio 10.4: confronto tra incroci in un disegno fattoriale gerarchico L’esempio precedente era relativo ad un disegno fattoriale completamente incrociato, dato che i livelli delle lavorazioni erano gli stessi per ogni livello di diserbo. In alcuni casi possiamo trovare disegni innestati, dove i livelli di un fattore cambiano al cambiare dei livelli dell’altro fattore. Nell’esempio seguente abbiamo considerato tre linee pure impollinanti di mais (A1, A2 ed A3), che abbiamo incrociato con tre linee pure portaseme, diverse per ogni impollinante (B1, B2, B3 per A1, B4, B5, B6 per A2 e B7, B8, B9 per A3). Alla fine abbiamo nove ibridi in tre gruppi, a seconda della linea impollinante. L’esperimento è stato disegnato in blocchi randomizzati completi con 4 repliche (36 osservazioni in totale) e i risultati sono disponibili come ‘crosses’ nel package statforbiology. In questo esperimento, la produzione del mais dipende dal blocco e dall’effetto paterno, mentre l’effetto materno può essere solo determinato entro ogni linea impollinante. Si dice che l’effetto materno è innestato entro l’effetto paterno, come mostrato in Figura 10.4. Pertanto, il modello lineare risulta così definito: \\[Y_{ijk} = \\mu + \\gamma_k + \\alpha_i + \\delta_{ij} + \\varepsilon_{ijk}\\] dove \\(\\gamma_k\\) è l’effetto del blocco \\(k\\), \\(\\alpha_i\\) è l’effetto dell’impollinante \\(i\\) e \\(\\delta_{ij}\\) è l’effetto del portaseme \\(j\\) entro ogni linea impollinante \\(i\\). La componente random \\(\\varepsilon\\) viene assunta, come al solito, gaussiana e omoscedastica, con media 0 e deviazione standard uguale a \\(\\sigma\\). La differenza con un modello ANOVA completamente incrociato dovrebbe essere chiara: in quest’ultimo caso abbiamo due effetti, A, B e la loro interazione A:B, mentre in un modello innestato abbiamo solo l’effetto A e l’effetto B entro A, mentre l’effetto principale B manca, in quanto non esiste in pratica. Figura 10.4: Struttura di un disegno sperimentale gerarchico In R, questo modello gerarchico può essere codificato utilizzando l’operatore di nesting /, come mostrato nel riquadro sottostante. Le analisi grafiche dei residui consentono di escludere qualsiasi deviazione significativa rispetto agli assunti di base (non mostrate) e la tabella ANOVA mostra che tutti gli effetti sono significativi e, pertanto, possiamo esaminare e confrontare le medie dei diversi ibridi, anche considerando che l’effetto paterno è relativamente poco importante, dato che le linee impollinanti sono incrociate con linee portaseme diverse. Il confronto multiplo viene lasciato al lettore come esercizio. # Example 10.4 # Comparing crosses in a nested factorial design # Loading the packages library(statforbiology) library(MASS) # Loading the data and fitting a model with a nested effect dataset &lt;- getAgroData(&quot;crosses&quot;) dataset[,1:3] &lt;- lapply(dataset[,1:3], factor) head(dataset, 5) ## Male Female Block Yield ## 1 A1 B1 1 9.984718 ## 2 A1 B1 2 13.932663 ## 3 A1 B1 3 12.201312 ## 4 A1 B1 4 1.916661 ## 5 A1 B2 1 8.928465 # Model fitting and parameter estimation mod &lt;- lm(Yield ~ Block + Male/Female, data = dataset) # Analyses of residuals (not shown) # plot(mod, which = 1) # plot(mod, which = 2) # boxcox(mod) # Variance partitioning anova(mod) ## Analysis of Variance Table ## ## Response: Yield ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Block 3 383.75 127.917 44.355 6.051e-10 *** ## Male 2 134.76 67.378 23.363 2.331e-06 *** ## Male:Female 6 575.16 95.860 33.239 1.742e-10 *** ## Residuals 24 69.21 2.884 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 In conclusione, vediamo che l’analisi dei disegni con due fattori innestati è piuttosto simile a quella per due fattori incrociati, con l’unica eccezione che l’effetto principale per il fattore innestato non è incluso nel modello. 10.5 Esempio 10.5: un esperimento di germinazione ripetuto due volte Nonostante possano essere molto precisi e significativi, i risultati di un singolo esperimento in agricoltura sono solitamente considerati abbastanza deboli, se non sono confermati in altri esperimenti simili. Infatti, un singolo esperimento può essere influenzato da ‘disturbi’ di ogni tipo, errori di misurazione, eventi imprevisti o intrusioni; inoltre, un risultato anche significativo può essere valido solo nelle condizioni in cui è stato osservato, senza essere necessariamente riproducibile in altre condizioni (vedi Capitolo 1). Per queste ragioni, in agricoltura siamo soliti ripetere gli esperimenti in più anni e/o in più località, oppure, nel caso di esperimenti in condizioni controllate, con materiale vegetale diverso. Quando gli esperimenti vengono ripetuti, oltre ad analizzare i dati di ciascun esperimento separatamente, è molto utile tentare un’analisi finale aggregata, per saggiare l’ipotesi che le prove sperimentali non differiscano significativamente l’una dall’altra. Consideriamo un esperimento per confrontare la germinazione di tre genotipi di colza (Pace et al., 2012), organizzato in cella climatica, secondo uno schema a blocchi randomizzati con sei repliche. Le unità sperimentali erano piastre Petri da 50 semi ciascuna e i blocchi erano i diversi scaffali (variabile ‘shelf’) di una cella climatica, mantenuta a 20°C per l’intera durata dell’esperimento. Per confermare i risultati, l’esperimento è stato ripetuto indipendentemente in un altro forno alla stessa temperatura (variabile ‘run’); in entrambi gli esperimenti, dopo 15 giorni dall’inizio, è stato contato il numero di semi germinati ed i conteggi sono stati espressi come proporzione rispetto al numero di semi posti a germinare (Final Germinated Proportion; FGP). I risultati di questi due esperimenti sono disponibili nel dataset ‘FGP_rape’, contenuto nel package statforbiology; dopo aver caricato i dati, è necessario trasformare i predittori numerici (‘run’ e ‘shelf’) in fattori (vedi il codice più sotto). In questa situazione, l’EDA dovrebbe includere le analisi separate per ogni esperimento, al fine di garantire che non vi siano outliers o violazioni degli assunti di base in nessuno degli esperimenti. Inoltre, è necessario assicurarsi che le varianze dei residui dei diversi esperimenti siano simili (omoschedasticità tra esperimenti). Per effettuare le analisi separate, è possibile semplificare il codice utilizzando la strategia split-apply-combine (Wickham, 2011), basata sulle funzioni by() e lapply(). La prima opera sui sottoinsiemi del dataset selezionato, suddivisi in base a una variabile di classificazione (in questo caso la variabile run) e produce una lista con i risultati della funzione lm() applicata a ciascun sottoinsieme. Questa lista può essere analizzata con la funzione lapply(), che permette di applicare le funzioni leveneTest() e shapiro.test() a ciascun elemento della lista. Possiamo vedere che nessuno dei due test indica significative deviazioni rispetto agli assunti di base. Per verificare l’omoschedasticità tra esperimenti, si può utilizzare il test F max di Hartely (Hartley, 1950), che consiste nel calcolare il rapporto tra la varianza residua massima e minima tra quelle osservate, che, in questo caso però, sono solo due. La significatività del test può essere ottenuta grazie alla distribuzione pmaxFratio(), che è contenuta nel package SuppDists (Wheeler, 2024). In questo caso, il P-value non è sufficientemente basso per il rifiuto dell’ipotesi nulla, il che conferma l’omoschedasticità tra esperimenti. Le analisi sono riportate nel riquadro sottostante # Example 10.5 # A germination experiment in two runs # Loading packages library(statforbiology) library(car) library(SuppDists) library(MASS) library(emmeans) library(multcomp) # Loading and transforming the data dataset &lt;- getAgroData(&quot;FGP_rape&quot;) dataset[,1:5] &lt;- lapply(dataset[,1:5], factor) head(dataset) ## Dish Run Shelf Species Genotype FGP ## 1 1 1 1 OilseedRape A 0.81 ## 2 13 1 1 OilseedRape B 0.81 ## 3 25 1 1 OilseedRape C 0.74 ## 4 2 1 2 OilseedRape A 0.91 ## 5 14 1 2 OilseedRape B 0.92 ## 6 26 1 2 OilseedRape C 0.76 # Fitting linear models to the two runs, separately lmFits &lt;- by(dataset, dataset$Run, function(df) lm(FGP ~ Genotype + Shelf, data = df) ) # Check for within-experiments homoscedasticity # Modified Levene&#39;s test for RCBDs (see Code box 10.2) levTest &lt;- by(dataset, dataset$Run, function(df) leveneTest(abs(residuals(lm(FGP ~ Genotype + Shelf, data = df))), df$Genotype)) levTest ## dataset$Run: 1 ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 0.2779 0.7612 ## 15 ## ---------------------------------------------------- ## dataset$Run: 2 ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 2 1.5841 0.2376 ## 15 lapply(lmFits, function(mods) shapiro.test(residuals(mods))) ## $`1` ## ## Shapiro-Wilk normality test ## ## data: residuals(mods) ## W = 0.90201, p-value = 0.06229 ## ## ## $`2` ## ## Shapiro-Wilk normality test ## ## data: residuals(mods) ## W = 0.93221, p-value = 0.2124 # Check for homoscedasticity of errors across runs # by the Hartley Fmax test mses &lt;- unlist( lapply(lmFits, function(mods) summary(mods)$sigma^2)) Fmax &lt;- max(mses)/min(mses) pmaxFratio(Fmax, 15, 2, lower.tail = FALSE) ## [1] 0.7404869 # Variance partitioning lapply(lmFits, function(mods) anova(mods)) ## $`1` ## Analysis of Variance Table ## ## Response: FGP ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Genotype 2 0.033011 0.0165056 15.6864 0.000825 *** ## Shelf 5 0.019911 0.0039822 3.7846 0.034871 * ## Residuals 10 0.010522 0.0010522 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## $`2` ## Analysis of Variance Table ## ## Response: FGP ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Genotype 2 0.042544 0.0212722 16.9876 0.0006081 *** ## Shelf 5 0.001761 0.0003522 0.2813 0.9129498 ## Residuals 10 0.012522 0.0012522 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 L’EDA dimostra che non ci sono problemi con le assunzioni di base e che l’effetto del trattamento è stato significativo in entrambi gli esperimenti. Passando alle analisi del dataset aggregato, possiamo notare che esso è totalmente simile a quello derivante da un qualunque esperimento fattoriale a due vie, con l’unica differenza che l’effetto blocco non è incrociato, ma ‘innestato’ all’interno degli esperimento, poiché i ripiani sono diversi nei diversi esperimenti, che sono stati eseguiti in celle climatiche diverse. Di conseguenza, il modello finale è: \\[y_{ijk} = \\mu + \\gamma_{ik} + \\alpha_i + \\beta_j + \\alpha\\beta_{ij} + \\varepsilon_{ijk}\\] dove \\(y\\) è la risposta per l’i-esimo esperimento, il j-esimo genotipo e il k-esimo scaffale, \\(\\mu\\) è l’intercetta, \\(\\gamma_{ik}\\) è l’effetto del k-esimo scaffale nell’i-esimo esperimento, \\(\\alpha_i\\) è l’effetto dell’i-esimo esperimento, \\(\\beta_j\\) è l’effetto del j-esimo genotipo, \\(\\alpha\\beta_{ij}\\) è l’interazione ‘genotipo per esperimento’, mentre \\(\\varepsilon_{ijk}\\) è il residuo per ciascuna osservazione, che si presume distribuito normalmente e omoschedastico (\\(\\epsilon_{ijk} \\sim N(0, \\sigma_{\\varepsilon})\\)). # Example 10.5 [continuation] # Pooled analyses: model fitting mod &lt;- lm(FGP ~ Genotype * Run + Run:Shelf, data = dataset) # model checking (not shown) # plot(mod, which = 1) # plot(mod, which = 2) # boxcox(mod) # Variance partitioning anova(mod) ## Analysis of Variance Table ## ## Response: FGP ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Genotype 2 0.074289 0.037144 32.2372 5.534e-07 *** ## Run 1 0.003025 0.003025 2.6254 0.1208 ## Genotype:Run 2 0.001267 0.000633 0.5497 0.5856 ## Run:Shelf 10 0.021672 0.002167 1.8809 0.1100 ## Residuals 20 0.023044 0.001152 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 L’analisi della tabella ANOVA per un insieme di esperimenti ripetuti fornisce un’idea della riproducibilità dei risultati. È possibile riscontrare le seguenti situazioni: L’interazione “esperimento per trattamento” è significativa. In questo caso, dovremmo concludere che gli effetti dei trattamenti e, probabilmente, la loro graduatoria, sono cambiati nei diversi esperimenti. Di conseguenza, l’aggregazione dei risultati non è possibile e dovremmo visualizzare e confrontare solo le medie dei trattamenti all’interno di ciascun esperimento. L’interazione non è significativa, ma l’effetto principale del trattamento lo è. Dovremmo quindi concludere che gli effetti dei trattamenti e degli esperimenti sono stati indipendenti e additivi; di conseguenza, le medie dei trattamenti sono cambiate nei diversi esperimenti, ma la loro graduatoria (e quindi il giudizio di merito) è risultato pienamente riproducibile. Spetta al ricercatore decidere se sia appropriato calcolare e visualizzare le medie generali dei trattamenti o mantenerle separate per i diversi esperimenti. Né l’interazione né gli effetti principali sono significativi. La conclusione è che i risultati degli esperimenti ripetuti sono pienamente riproducibili e di solito è sufficiente riportare solo le medie generali dei trattamenti. Nel nostro esempio, osserviamo che è significativo solo l’effetto del genotipo, il che significa che i risultati sono stati pienamente riproducibili. Pertanto, calcoliamo le medie generali dei genotipi e le sottoponiamo a confronto multiplo. # Example 10.5 [continuation] # Multiple comparisons for pooled data cld(emmeans(mod, ~ Genotype), Letters = LETTERS) ## Genotype emmean SE df lower.CL upper.CL .group ## C 0.781 0.0098 20 0.760 0.801 A ## A 0.871 0.0098 20 0.850 0.891 B ## B 0.882 0.0098 20 0.862 0.903 B Prima di concludere, è necessario sottolineare che il metodo di analisi dei dati proposto per questo esempio è sempre appropriato, sebbene in alcuni casi, soprattutto quando il numero di esperimenti è molto elevato, potrebbe essere opportuno impiegare un altro metodo, di cui verrà fornito un esempio nel Capitolo 12. 10.6 Altre letture Belocchi A, Fornara M, Ciriciofolo E, Biancolatte V, Gosparini E, Piccioni C, Desiderio E (2003) Grano duro: Risultati 2002–03 della Rete Nazionale. Lazio e Umbria. L’Informatore Agrario 19(Suppl.1):41–44 Bhandary M, Dai H (2013) An alternative test for the equality of variances for several populations in randomised complete block design. Stat Methodol 11:22–35. https://doi.org/10.1016/j. stamet.2012.08.002. https://linkinghub.elsevier.com/retrieve/pii/S1572312712000482 Hartley HO (1950) The Maximum F-ratio as a short-cut test for heterogeneity of vari- ance. Biometrika 37(3/4):308. https://doi.org/10.2307/2332383. https://www.jstor.org/stable/ 2332383?origin=crossref Jensen SM, Schaarschmidt F, Onofri A, Ritz C (2018) Experimental design matters for statistical analysis: how to handle blocking: experimental design matters for statistical analysis. Pest Manag Sci 74(3):523–534. https://doi.org/10.1002/ps.4773. http://doi.wiley.com/10.1002/ps. 4773 Kuehl RO (2000) Design of Experiments: Statistical Principles of Research Design and Analysis. Duxbury Press, Pacific Grove Le Clerg EL, Leonard WH, Clark AG (1962) Field Plot Technique. Burgess Publishing Company, Minneapolis Onofri A, Tei F (1994) Influence of application timing on the effectiveness of rimsulfuron against rhizome Sorghum halepense (L.) Pers. In: Tei F, Onofri A (eds) Weed Control in Sustainable Agriculture in the Mediterranean Area. Proceedings 5th EWRS Mediterranean Symposium, Università degli Studi di Perugia, Reprints, pp 105–111 Pace R, Benincasa P, Ghanem ME, Quinet M, Lutts S (2012) Germination of untreated and primed seeds in rapeseed (brassica napus var oleifera del.) under salinity and low matric potential. Exp Agricul 48(02):238–251. https://doi.org/10.1017/S0014479711001189. http:// www.journals.cambridge.org/abstract_S0014479711001189 Stagnari F, Onofri A, Codianni P, Pisante M (2013) Durum wheat varieties in N-deficient environments and organic farming: a comparison of yield, quality and stability performances. Plant Breed 132:266–275 Wheeler B (2024) SuppDists: Supplementary Distributions. https://CRAN.R-project.org/package= SuppDists, r package version 1.1-9.8 White JW, Boote KJ, Kimball BA, Porter C, Salmeron M, Shelia V, Thorp KR, Hoogenboom G (2025) From field to analysis: strengthening reproducibility and confirmation in research for sustainable agriculture. npj Sustain Agricul 3(1):27. https://doi.org/10.1038/s44264-025- 00067-z. https://www.nature.com/articles/s44264-025-00067-z Wickham H (2011) The split-apply-combine strategy for data analysis. J Stat Softw 40(1):1–29. https://doi.org/10.18637/jss.v040.i01. http://www.jstatsoft.org/v40/i01/ 10.7 Esercizi Per tutti gli esercizi che seguono, utilizzate il piano di lavoro proposto all’inizio di questo capitolo e cercate di giungere a conclusioni attendibili. Tutti i dataset sono disponibili nel package statforbiology e sono accessibili tramite la funzione getAgroData(). Il nome del dataset è specificato per ogni esercizio. È stato condotto un esperimento con un disegno completamente randomizzato per confrontare la resa di 5 genotipi di grano. I risultati (in bushel per acro) sono riportati nella tabella seguente: determinare il genotipo migliore e trarre conclusioni attendibili. L’esempio è tratto da Le Clerg (1962) e il dataset è disponibile come “LeClerg”. Variety 1 2 3 A 32.4 34.3 37.3 B 20.2 27.5 25.9 C 29.2 27.8 30.2 D 12.8 12.3 14.8 E 21.7 24.5 23.4 Colture cellulari di pomodoro sono state allevate su tre tipi di substrato, ottenuti aggiungendo al testimone una certa quantità di glucosio, fruttosio o saccarosio. L’esperimento è stato condotto con un disegno completamente randomizzato con 5 repliche, osservando la crescita delle cellule su ogni unità sperimentale. Determinare quale substrato ha prodotto la crescita cellulare più elevata e commentare i risultati. Il dataset è mostrato nella tabella sottostante ed è disponibile come “sugarsMedia”. Control Glucose Fructose Sucrose 5.285 4.020 3.705 4.776 5.737 3.648 3.714 3.771 5.320 3.861 3.110 4.742 6.050 4.098 3.522 4.246 5.705 3.919 3.957 4.212 È stata valutata la durata di un impianto di riscaldamento (in ore prima del guasto), a seconda della temperatura di esercizio. L’esperimento è stato organizzato includendo quattro diverse temperature ed è stato disegnato con randomizzazione completa e 6 repliche. Considerare la temperatura come un fattore e determinare la temperatura di esercizio ottimale per massimizzare la durata dell’impianto. I risultati sono mostrati di seguito e sono disponibili come ‘failureTimes’. SUGGERIMENTO: in questo esercizio è necessaria una trasformazione stabilizzante, che non viene riconosciuta automaticamente dalla funzione emmeans(). Pertanto, la retro-trasformazione richiederà il processo descritto alla fine della Sezione 9.6. Temp 1 2 3 4 5 6 1520 1953 2135 2471 4727 6134 6314 1620 1190 1286 1550 2125 2557 2845 1660 651 837 848 1038 1361 1543 1708 511 651 651 652 688 729 Un entomologo ha contato il numero di uova deposte da un lepidottero su tre substrati diversi, in un esperimento a randomizzazione completa 15 repliche. Identificare il substrato con la più bassa ovideposizione. I risultati sono riportati di seguito e sono disponibili come ‘lepidopteraEggs’. Rep A B C 1 456 118 72 2 411 213 99 3 594 74 24 4 280 26 20 5 664 163 89 6 379 76 47 7 444 240 32 8 436 75 29 9 294 108 1 10 431 68 33 11 476 108 20 12 382 153 22 13 413 98 27 14 485 120 39 15 440 126 12 È stato condotto un esperimento in un aranceto nel Sud Italia, comprendente 5 sistemi di irrigazione in 5 blocchi completi. Le rese osservate (in tonnellate per ettaro) sono riportate nella tabella sottostante e sono disponibili come ‘orangeIrrigation’. Qual è il sistema di irrigazione che ha offerto le migliori prestazioni? Method 1 2 3 4 5 Localised 26.7 27.9 51.2 29.0 34.8 Surface 46.4 47.7 33.9 32.7 21.7 Sprinkler 38.5 29.1 33.6 11.8 27.6 Sprinker+localised 41.3 33.9 31.3 5.8 12.1 Submersion 35.2 46.9 19.8 27.9 26.7 È stata condotta una prova di fertilizzazione, con cinque trattamenti e un disegno a blocchi randomizzati con cinque repliche. Per circostanze casuali impreviste, è venuto a mancare un dato per il trattamento “50N” nel secondo blocco. I dati osservati sono i contenuti percentuali di P2O5 nei campioni di foglie raccolte in ogni parcella e sono disponibili come ‘missingVal’. Analizzando i dati rispondete alle seguenti domande. È conveniente fertilizzare? È conveniente arrivare a 100 kg/ha con fertilizzazione azotata? L’aggiunta di P2O5 è una pratica conveniente? SUGGERIMENTO: considerare il valore mancante e assicurarsi che l’approccio utilizzato per l’ANOVA sia corretto Fert 1 2 3 4 5 100N 6.9 9.6 5.6 7.4 8.2 100N+75P 9.6 9.3 12.0 10.6 11.6 50N 7.3 NA 7.7 7.7 7.0 50N+75P 10.8 9.2 8.8 9.9 9.4 Unfertilised 5.6 6.1 5.3 5.9 7.4 È stato eseguito un esperimento a quadrato latino, per valutare l’effetto di quattro diversi fertilizzanti sulla resa della lattuga. I dati osservati sono disponibili come ‘lettuceLS’ e sono riportati nella tabella seguente. Qual è il fertilizzante migliore? Fertiliser Row Column Yield A 1 1 155.5 B 1 2 128.4 C 1 3 105.5 D 1 4 182.4 A 2 4 185.4 B 2 3 163.8 C 2 1 178.4 D 2 2 238.3 A 3 3 173.1 B 3 4 170.0 C 3 2 198.6 D 3 1 213.3 A 4 2 185.7 B 4 1 198.9 C 4 4 191.7 D 4 3 231.6 È stato eseguito un esperimento in vaso per valutare il momento migliore per l’applicazione di un erbicida (rimsulfuron) contro Sorghum halepense da rizoma. Sono state confrontate cinque epoche d’intervento (2-3, 4-5, 6-7 e 8-9 foglie, oltre ad un intervento doppio a 3-4 e 8-9 foglie) e il controllo non trattato. Per comprendere se l’applicazione sia efficace contro piante provenienti da rizomi di diverse dimensioni, è stato incluso nell’esperimento un secondo fattore sperimentale, ovvero la dimensione del rizoma (2, 4, 6 nodi). Il disegno sperimentale era un fattoriale a due vie, completamente incrociato, con trattamenti completamente randomizzati con quattro repliche. I risultati (peso delle piante tre settimane dopo l’applicazione dell’erbicida) sono tratti da (Onofri, 1994b} e sono disponibili come ‘johnsongrass’. In quale momento l’erbicida è più efficace? Il doppio trattamento risulta più efficace dei trattamenti singoli? La raccomandazione per gli agricoltori può essere considerata univoca ed indipendente dalla dimensione del rizoma? Sizes / Timings 2-3 4-5 6-7 8-9 3-4/8-9 Untreated 2-nodes 34.03 0.10 30.91 33.21 2.89 41.63 22.31 6.08 35.34 43.44 19.06 22.96 21.70 3.73 24.23 44.06 0.10 52.14 14.90 9.15 28.27 35.34 0.68 59.81 4-nodes 42.19 14.86 52.34 39.06 8.62 68.15 51.06 36.03 43.17 61.59 0.05 42.75 43.77 21.85 57.28 48.89 0.10 57.77 31.74 8.71 29.71 49.14 9.65 44.85 6-nodes 20.84 11.37 55.00 41.77 9.80 43.20 26.12 2.24 28.46 37.38 0.10 40.68 35.24 14.17 21.81 39.55 1.42 34.11 13.32 23.93 60.72 48.37 6.83 32.21 "],["modelli-di-regressione-avanzati.html", "Capitolo 11 Modelli di regressione ‘avanzati’", " Capitolo 11 Modelli di regressione ‘avanzati’ Da fare …. "],["breve-introduzione-ai-modelli-misti.html", "Capitolo 12 Breve introduzione ai modelli misti 12.1 Esempio 12.1: un esperimento di lavorazione a split-plot 12.2 Esempio 12.2: un esperimento di ‘recropping’ a strip-plot 12.3 Esempio 12.3: confronto varietale con blocchi ‘random’ 12.4 Esempio 12.4: blocchi randomizzati con sub-campionamento 12.5 Esempio 12.5: confronto varietale ripetuto in più anni 12.6 Esempio 12.6: misure ripetute nelle colture poliennali 12.7 Fattori di raggruppamento nei modelli di regressione 12.8 Altre letture", " Capitolo 12 Breve introduzione ai modelli misti In questo libro abbiamo affrontato le questioni più rilevanti in relazione all’attività di ricerca e sperimentazione, almeno quelle che dovrebbero far parte del bagaglio culturale di ogni laureato in agraria o altre discipline biologiche. La trattazione non è affatto esaustiva e quindi, se si avesse l’intenzioni intraprendere una carriera professionale nel mondo dell’analisi dei dati, non si potrebbe prescindere dalla lettura di altri testi di approfondimento, che sono stati via via segnalati. Ci sembra comunque opportuno, in questo capitolo e quello successivo, dare almeno alcune informazioni di base su altri modelli un po’ più complessi, il cui impiego è abbastanza comune nella sperimentazione di pieno campo. In particolare, in questo libro abbiamo finora considerato i cosidetti modelli fissi, cioè contenenti solo fattori fissi oltre al residuo stocastico. I fattori fissi, identificabili per le seguenti caratteristiche: i livelli sono selezionati appositamente (non campionati); i livelli sono ripetibili (potremmo effettuare un nuovo esperimento con gli stessi livelli); gli effetti attesi sono deterministici ed espressi come differenze (aumenti o diminuzioni) rispetto ad un valore di base. Esempi di fattore fisso sono il genotipo, le ferrtilizzazioni, le epoche di semina, ecc. Oltre ai fattori fissi, i modelli in agricoltura e biologia possono richiedere l’inclusione di fattori random che presentano le seguenti caratteristiche: i livelli non sono interessanti di per sé, ma sono campionati da una popolazione più ampia di possibili livelli; i livelli non sono ripetibili, nel senso che se l’esperimento venisse ripetuto, è molto probabile che sarebbero scelti altri livelli, senza che l’esperimento perda il suo significato biologico; gli effetti attesi sono casuali e cambiano ad ogni campionamento; i livelli rappresentano unità di randomizzazione a cui vengono assegnati i livelli del trattamento, attraverso un processo di randomizzazione (ad esempio, le parcelle). Come conseguenza di quanto detto sopra, l’interesse primario per i fattori casuali non è stimare gli effetti di ciascun livello incluso nell’esperimento, ma stimare la quantità complessiva di varianza (componente di varianza) che inducono nella risposta sperimentale. Ad esempio, nel caso dell’elemento casuale \\(\\varepsilon\\) che abbiamo trovato in tutti i modelli fin qui trattati, non vi è alcun interesse nel valore esatto di ciascun residuo, poiché questi valori si verificano casualmente e, ripetendo l’esperimento, si otterrebbero valori diversi. Invece, i residui sono stati determinati solo per poterne calcolare la relativa varianza, che è l’unico elemento di nostro interesse, da utilizzare per diversi scopi, come, ad esempio, al denominatore del test F. Oltre ai residui, per comprendere meglio cosa è un fattore random, possiamo considerare un esperimento di confronto tra genotipi, che viene ripetuto in diversi campi scelti a caso all’interno di un certo macroambiente. In questo caso, i ‘campi’ non sono, di per se’, interessanti, ma vengono campionati per quantificare la variabilità della resa all’interno dell’intero macroambiente. Il fattore ‘campo’ nell’esempio precedente costituisce un tipico esempio di grouping factor (fattore di raggruppamento; vedi Capitolo 2); altri esempi includono i blocchi nei disegni a blocchi completi randomizzati, le righe e le colonne nei disegni a quadrato latino e le main-plots nei disegni a split-plot. Tutti questi fattori di raggruppamento creano spesso problemi perché raramente sono interessanti di per sé e quindi vengono spesso trascurati in fase di analisi dei dati. Si tratta di un grave errore, poichè l’effetto di questi fattori di raggruppamento, se trascurato, finisce per essere incluso nei residui, che risulteranno quindi non indipendenti, ma saranno invece accomunati dalla eventuale cappartenenza allo stesso gruppo e dalla conseguente condisione dello stesso effetto di gruppo. Ad esempio, in un disegno a split-plot, se una main-plot è più fertile di un’altra, tutte le misurazioni effettuate su di essa condivideranno lo stesso effetto positivo e saranno quindi più simili tra di loro che non le misurazioni effettuate su main-plots diverse. Insomma, con uno schema a split-plot, i dati ottenuti sulla stessa main-plot non sono indipendenti, ma sono in qualche modo ‘apparentati’; più propriamente, si parla di correlazione intra-classe, un concetto simile, ma non totalmente coincidente con quello di correlazione di Pearson. Insomma, se l’effetto prodotto dalle main-plots o dagli altri grouping factors non viene incluso nel modello statistico descrittivo, esso rimane tra gli effetti non spiegati e, di conseguenza, viene incluso nei residui, che, pertanto, saranno correlati e quindi non indipendenti tra di loro. Posto che i grouping factors debbano essere inclusi nel modello, la domanda è: dobbiamo considerare questi fattori come fissi o random? Nella maggior parte dei casi, la decisione spetta al ricercatore, che dovrebbe fornire motivazioni convincenti a sostegno della sua scelta; in altri casi, come accennato in precedenza per il fattore ‘campo’, un fattore di raggruppamento deve obbnligatoriamente essere random, ovvero quando i suoi livelli diventano unità di randomizzazione e ricevono l’allocazione dei livelli di un fattore o di una combinazione di fattori, tramite un processo di randomizzazione (Piepho et al., 2003). Si considerino i seguenti esempi: in un disegno a blocchi randomizzati, i blocchi raggruppano le unità in base al loro posizionamento rispetto al ‘gradiente’ di fertilità; tuttavia, non sono unità di randomizzazione nel senso che i livelli di trattamento sono allocati alle parcelle all’interno di ciascun blocco, non ai blocchi stessi. Di conseguenza, il fattore blocco può essere considerato random o fisso, a seconda delle circostanze; in un disegno a split-plot, le main-plots raggruppano le sub-plots e sono anche unità di randomizzazione perché ricevono l’llocazione dei livelli del fattore principale. Di conseguenza, il fattore main-plot deve essere necessariamente random. Il motivo per cui le main-plots e le altre unità di randomizzazione devono essere considerate fattori random è legato al loro ruolo nell’esperimento: secondo Ronald Fisher, la differenza tra le unità sperimentali trattate allo stesso modo è la misura più appropriata dell’errore sperimentale e, di conseguenza, la differenza tra, ad esempio, le main-plots trattate allo stesso modo diviene una misura dell’errore sperimentale, il che significa che l’effetto delle main-plots è, in effetti, random. Considerando le premesse precedenti, ne consegue che diversi esperimenti comuni in agricoltura, come i disegni split-plot, strip-plot, misure ripetute e sottocampionamento, contengono fattori di raggruppamento e potrebbero richiedere l’inclusione di effetti random nel modello, oltre al residuo. I modelli che contengono più di un effetto random oltre agli eventuali effetti fissi sono chiamati modelli misti e, a partire dagli anni ’80, sono diventati una classe di modelli molto diffusa. Fornire dettagli sui modelli misti va ben oltre lo scopo di questo libro e i lettori interessati sono invitati a consultare il libro di (Galecki e Burzicoski, 2013). Per tutti gli altri lettori, i seguenti esempi concreti dimostrano come i modelli misti possano essere applicati per analizzare i dati provenienti da esperimenti split-plot, strip-plot e altri tipi comuni nella ricerca agricola. 12.1 Esempio 12.1: un esperimento di lavorazione a split-plot Consideriamo nuovamente l’esempio presentato nel capitolo 2, nel quale avevamo due fattori sperimentali a confronto: il diserbo, con due livelli (totale o localizzato sulla fila) e la lavorazione, con tre livelli (aratura profonda, aratura superficiale e minimum tillage). Questo esperimento è stato disegnato a split-plot, come indicato in Figura 2.9, ovvero con le lavorazioni allocate a random alle main-plots e il diserbo allocato a caso alle sub-plot, all’interno di ogni main-plot. I risultati di questo esperimento sono disponibili nel dataset ‘beet’, all’interno del package statforbiology. Il modello ANOVA per un disegno a split-plot è simile a quello dell’ANOVA fattoriale, fatta salva la presenza di un effetto aggiuntivo, cioè quello delle parcelle principali, che costituiscono un elemento di raggruppamento delle osservazioni: \\[Y_{ijk} = \\mu + \\gamma_k + \\alpha_i + \\theta_{ik} + \\beta_j + \\alpha\\beta_{ij} + \\varepsilon_{ijk}\\] dove \\(\\gamma\\) è l’effetto del blocco \\(k\\), \\(\\alpha\\) è l’effetto della lavorazione \\(i\\), \\(\\beta\\) è l’effetto del diserbo \\(j\\), \\(\\alpha\\beta\\) è l’effetto dell’interazione per la specifica combinazione della lavorazione \\(i\\) e del diserbo \\(j\\). Abbiamo incluso anche \\(\\theta\\) che è l’effetto della main-plot; dato che ogni parcella principale è identificata univocamente dal blocco \\(k\\) a cui appartiene e dalla lavorazione \\(i\\) in essa eseguita, abbiamo utilizzato i pedici corrispondenti. Nel precedente modello vi sono due fattori di raggruppamento, cioè il blocco e la main-plot. Mentre il blocco non costituisce un’unità di randomizzazione e quindi il suo effetto potrebbe essere considerato o fisso o casuale (ma lo considereremo fisso, come abbiamo sempre fatto finora), le main-plots costituiscono delle unità di randomizzazione e quindi gli effetti che producono debbono essere considerati random, con distribuzione normale, media pari a 0 e deviazione standard pari a \\(\\sigma_{\\theta}\\). Allo stesso modo, il residuo \\(\\varepsilon\\) è casuale, con distribuzione normale, media 0 a deviazione standard pari a \\(\\sigma\\). Stimare un modello misto in R non è molto diverso dallo stimare un modello a effetti fissi. Innanzitutto, dobbiamo creare una nuova variabile per identificare in modo univoco le main-plots, il che può essere fatto creando un nuovo fattore che combini i livelli di blocco e lavorazione, come accennato in precedenza. Successivamente, è necessario abbandonare la funzione lm(), che non permette di inserire effetti random, ed utilizzare un’altra funzione che abbia questa capacità. Tra quelle disponibili, in questo libro proporremo la funzione lmer(), che si trova all’interno del package lme4 (Bates et al. 2015), da utilizzare assieme al package lmerTest (Kuznetsova et al. 2017), che fornisce alcune utili funzionalità aggiuntive ed, in particolare, consente di migliorare la leggibilità della tabella ANOVA. La sintassi della funzionelmer()è simile a quella della funzionelm(); l'effetto random deve essere inserito utilizzando l'operatore1|e posto tra parentesi, per distinguerlo meglio dagli effetti fissi (riquadro sottostante). In questo capitolo, introduciamo anche l'uso dell'operatore \"pipe\" (|&gt;`), che serve a scrivere codice più chiaro e riceve il valore restituito dalla funzione precedente, passandolo alla successiva come primo argomento (riquadro sottostante; vedi anche l’Appendice A). # Example 12.1 # A split-plot tillage experiment # Loading the packages library(statforbiology) library(lme4) library(lmerTest) # Loading and transforming the data dataset &lt;- getAgroData(&quot;beet&quot;) |&gt; transform(Tillage = factor(Tillage), WeedControl = factor(WeedControl), Block = factor(Block), mainPlot = factor(Block):factor(Tillage)) # Mixed-Model fitting mod.split &lt;- lmer(Yield ~ Block + Tillage * WeedControl + (1|mainPlot), data=dataset) ## boundary (singular) fit: see help(&#39;isSingular&#39;) Per quanto riguarda le assunzioni di base, i modelli misti sono sempre e comunque modelli linear e quindi fanno le stesse assunzioni di moscedasticità e normalità dei residui. L’ispezione grafica di questi ultimi può essere condotta nel modo usuale, se non che la funzione plot() restituisce solo il grafico dei residui verso i valori attesi (quello corrispondente all’argomento ‘which = 1’ in lm()), mentre l’argomento ‘which’ non funziona. Pertanto, il QQ-plot dovrebbe essere prodotto utilizzando le funzioni generiche qqnorm() e qqline(), come mostrato nel riquadro sottostante. Questi due grafici presentano alcune lievi deviazioni rispetto agli assunti di normalità ed omoschedasticità (Fig. 12.1), ma il test di Shapiro-Wilk non sembra sollevare particolari preoccupazioni, per cui possiamo procedere con le operazioni di inferenza statistica. # Example 12.1 [continuation] # Check for the basic assumptions for the &#39;beet&#39; data # Graphical analyses (not run) # plot(mod.split) # Analogous to &#39;which = 1&#39; for linear models # qqnorm(resid(mod.split)) # QQ-plot # qqline(resid(mod.split), lty = 2) # Shapiro-Wilk&#39;s test shapiro.test(residuals(mod.split)) ## ## Shapiro-Wilk normality test ## ## data: residuals(mod.split) ## W = 0.93838, p-value = 0.1501 Figura 12.1: Analisi grafiche dei residui per l’esperimento a split-plot relativo all’esempio 12.1, ove il model fitting è stato eseguito con la funzione lmer() L’oggetto che risulta dalla stima del modello misto può essere esplorato con i metodi usuali, anche se è necessario ricordare che le stime dei parametri debbono essere ottenuto con la funzione fixef() al posto di coef(). L’ANOVA viene sempre prodotta con l’usuale funzione anova(), che fornisce però un output leggermente diverso dal solito. Come secondo argomento è necessario indicare il metodo prescelto per la stima dei gradi di libertà, che non è così semplice come nel caso dei modelli lineari generali. Consigliamo il metodo ‘Kenward-Roger’ che, pur fornendo comunque un’approssimazione, ha dimostrato ottima affidabilità, superiore a quella del metodo ‘Sattertwhaite’, che verrebbe utilizzato di default (Kuznetsova et al. 2017). # Example 12.1 [continuation] # Variance partitioning for the ’beet’ data anova(mod.split, ddf=&quot;Kenward-Roger&quot;) ## Type III Analysis of Variance Table with Kenward-Roger&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## Block 3.6596 1.2199 3 6 0.6521 0.61016 ## Tillage 23.6565 11.8282 2 6 6.3228 0.03332 * ## WeedControl 3.3205 3.3205 1 9 1.7750 0.21552 ## Tillage:WeedControl 19.4641 9.7321 2 9 5.2023 0.03152 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 L’interazione tra lavorazione del terreno e controllo delle erbe infestanti è significativa; pertanto, possiamo esplorare e confrontare le medie relative alle combinazioni ‘lavorazione \\(\\times\\) diserbo’, utilizzando l’usuale funzione emmeans(). Questa parte di lavoro viene lasciata al lettore come esercizio. 12.2 Esempio 12.2: un esperimento di ‘recropping’ a strip-plot In alcune circostanze, soprattutto nelle prove di diserbo chimico, potrebbe trovare applicazione un altro tipo di schema sperimentale, nel quale ogni blocco viene diviso in tante righe quanti sono i livelli di un fattore sperimentale e tante colonne quanti sono i livelli dell’altro. In questo modo, i livelli del primo fattore sperimentale vengono applicati ad ognuna delle righe, mentre i livelli dell’altro trattamento ad ognuna delle colonne, in ordine casuale, che cambia per ogni blocco (esperimento a strip-plot). Consideriamo l’esperimento fattoriale a due vie descritto nel Capitolo 2 e finalizzato a determinare l’intervallo di risemina per un erbicida sulfonilureico. In questo esperimento, sono stati considerati due tesi di diserbo, cioè: rimsulfuron applicato alla dose raccomandata su terreno nudo e testimone non diserbato. Quaranta giorni dopo il trattamento, sono state seminate tre colture, cioè barbabietola da zucchero, colza e soia, sia sulle parcelle trattate che su quelle non trattate e, quattro settimane dopo la semina, è stato determinato il peso delle piante su un metro quadrato di ogni parcella. L’esperimento è stato disegnato a strip-plot, in quattro blocchi completi (Fig. 2.10); in ogni blocco, i trattamenti erbicidi (rimsulfuron e controllo non trattato) sono stati assegnati casualmente a ciascuna di due colonne, mentre le tre colture sono state assegnate casualmente a ciascuna di tre righe (Onofri, dati non pubblicati). Il dataset relativo ai risultati di questo esperimento è disponibile come “recropS” nel package statforbiology. In questo esperimento, ci sono tre fattori di raggruppamento I blocchi Le righe all’interno di ciascun blocco (tre righe per blocco) Le colonne all’interno di ciascun blocco (due colonne per blocco) Le righe e le colonne sono anche unità di randomizzazione, poiché hanno ricevuto i trattamenti sperimentali attraverso un processo di randomizzazione, analogo alle main-plots nell’Esempio 12.1. Di conseguenza, entrambi gli effetti sono da considerare random. Analogamente a quanto abbiamo visto per lo split-plot, le 12 righe sono univocamente definite da un livello di lavorazione e un blocco, mentre le 8 colonne sono definite da un livello di diserbo e un blocco, per cui l’effetto \\(\\zeta\\) porta i pedici \\(j\\) e \\(k\\). per cui anche questo è un modello ‘misto’, con tre effetti random. Iniziamo le analisi caricando il dataset e operando le necessarie trasformazioni dei dati, come abbiamo visto negli esempi precedenti. # Example 12.2 # A strip-plot recropping experiment # Loading packages library(statforbiology) library(lme4) library(lmerTest) # Loading and transforming the data dataset &lt;- getAgroData(&quot;recropS&quot;) |&gt; transform(Herbicide = factor(Herbicide), Crop = factor(Crop), Block = factor(Block), Rows = factor(Crop):factor(Block), Columns = factor(Herbicide):factor(Block)) Un modello adatto a descrivere i risultati di questo esperimento è il seguente: \\[Y_{ijk} = \\mu + \\gamma_k + \\alpha_i + \\theta_{ik} + \\beta_j + \\zeta_{jk} + \\alpha\\beta_{ij} + \\varepsilon_{ijk}\\] In questo modello, \\(\\mu\\) è l’intercetta, \\(\\gamma_k\\) sono gli effetti blocco, \\(\\alpha_i\\) sono gli effetti delle colture, \\(\\theta_ik\\) sono gli effetti ‘riga’, \\(\\beta_j\\) sono gli effetti degli erbicidi/testimone, \\(\\zeta_{jk}\\) sono gli effetti ‘colonna’, \\(\\alpha\\beta_{ij}\\) sono gli effetti di interazione ‘coltura-erbicida’ e \\(\\varepsilon_ijk\\) è residuo casuale. I tre effetti random (‘riga’, ‘colonna’ e residuo) sono assunti come gaussiani, con media pari a zero e deviazioni standard rispettivamente pari a \\(\\sigma_{\\theta}\\), \\(\\sigma_{\\zeta}\\) e \\(\\sigma\\). Il codice da utilizzare è analogo a quello precedentemente esposto per il disegno a split-plot e prevede l’introduzione degli effetti random ‘riga’ e ‘colonna’, che vengono inseriti tra parentesi e con l’operatore ‘1|’, come indicato nel box sottostante. L’analisi grafica dei residui può essere eseguita con la stessa tecnica illustrata per l’Esempio 12.1 e viene lasciata al lettore per esercizio. # Example 12.2 [continuation] # Model fitting mod.strip &lt;- lmer(CropBiomass ~ Block + Herbicide*Crop + (1|Rows) + (1|Columns), data = dataset) # Variance partitioning anova(mod.strip, ddf = &quot;Kenward-Roger&quot;) ## Type III Analysis of Variance Table with Kenward-Roger&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## Block 21451 7150.3 3 4.1367 2.5076 0.19387 ## Herbicide 148 147.9 1 3.0000 0.0519 0.83450 ## Crop 43874 21936.9 2 6.0000 7.6932 0.02208 * ## Herbicide:Crop 12549 6274.4 2 6.0000 2.2004 0.19198 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 La tabella ANOVA mostra che solo l’effetto della coltura è significativo, mentre non vi è alcuna differenza tra i trattamenti erbicidi (trattato vs. non trattato) all’interno di ciascuna coltura. Pertanto, gli effetti fitotossici possono essere considerati negligibili. Il calcolo delle medie e i confronti multipli possono essere eseguiti con la tecnica usuale, indicata nei capitoli precedenti e sono lasciati al lettore per esercizio. 12.3 Esempio 12.3: confronto varietale con blocchi ‘random’ Riconsideriamo l’Esempio 10.1, che descrive un esperimento di campo con otto genotipi di frumento in tre blocchi completi, eseguito sulle colline dell’Italia centrale nel 2002 (Belocchi et al. 2003). Sebbene i blocchi non rappresentino unità di randomizzazione, a volte si suggerisce di considerare il loro effetto come random, cosa che è molto conveniente per recuperare le informazioni inter-blocco, nei disegni a blocchi incompleti (Dixon 2016). In questo caso, trattandosi di un disegno a blocchi completi, considerare l’effetto del blocco come random non è conveniente, perchè non vi sono informazioni inter-blocco da recuperare. Tuttavia, ci è sembrato utile mostrare qual è il codice R da utilizzare quando si vogliono considerare i blocchi come effetti casuali. # Example 12.3 # A genotype experiment with random blocks # Loading the packages library(statforbiology) library(lme4) library(emmeans) library(multcomp) # Loading and transforming the data dataset &lt;- getAgroData(&quot;WinterWheat2002&quot;) |&gt; transform(Block = factor(Block), Genotype = factor(Genotype)) # Model fitting (with random blocks) modmix &lt;- lmer(Yield ~ (1|Block) + Genotype, data = dataset) meds &lt;- emmeans(modmix, ~Genotype) multcomp::cld(meds, Letters = LETTERS, reverse = T) ## Genotype emmean SE df lower.CL upper.CL .group ## IRIDE 4.96 0.216 10.8 4.49 5.44 A ## COLOSSEO 4.89 0.216 10.8 4.42 5.37 A ## SOLEX 4.79 0.216 10.8 4.31 5.27 A ## SANCARLO 4.50 0.216 10.8 4.03 4.98 A ## GRAZIA 4.34 0.216 10.8 3.86 4.82 A ## CRESO 4.33 0.216 10.8 3.85 4.80 A ## DUILIO 4.24 0.216 10.8 3.76 4.72 AB ## SIMETO 3.34 0.216 10.8 2.86 3.82 B ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 8 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. 12.4 Esempio 12.4: blocchi randomizzati con sub-campionamento Il sub-campionamento può verificarsi ogni qual volta in cui vengano prese, in ogni parcella, due o più misure casuali, che non possono essere considerate repliche vere, poiché non hanno ricevuto il trattamento sperimentale in modo indipendente l’una dall’altra. Consideriamo ad esempio i dati nel dataset ‘TKW’, disponibile nel package statforbiology. Questi dati derivano da un esperimento con 30 genotipi di frumento in tre blocchi, nel quale è stato determinato il peso di mille semi (Thousand Kernel Weight; TKW), in tre sub-campioni di granella per parcella (Ciriciofolo, dati non pubblicati). Dopo aver caricato i dati, è necessario trasformare tutti i predittori in fattori nominali (‘Genotype’, ‘Block’ e ‘Plot’); è importante notare che questo dataset include anche la variabile ‘Plot’, che identifica in modo univoco tutte le parcelle e funge da variabile di raggruppamento per i tre sub-campioni di ciascuna parcella. A scopo di confronto, nel riquadro sottostante, mostriamo la stima di un modello errato, che non fa alcuna distinzione tra repliche vere e sub-repliche (pseudo-repliche) e, di conseguenza, considera l’esperimento come se avesse 9 repliche vere. La deviazione standard dei residui è 2.71, il test F per il genotipo è altamente significativo e ci sono 225 confronti a coppie significativi tra i 30 genotipi. # Example 12.4 # A RCBD with sub-sampling # Loading the packages library(statforbiology) library(nlme) library(car) library(emmeans) library(lme4) library(lmerTest) # Loading and transforming the data TKW &lt;- getAgroData(&quot;TKW&quot;) |&gt; transform(Plot = factor(Plot), Block = factor(Block), Genotype = factor(Genotype)) head(TKW) ## Plot Block Genotype Sample TKW ## 1 1 1 Meridiano 1 28.6 ## 2 2 1 Solex 1 33.3 ## 3 3 1 Liberdur 1 22.3 ## 4 4 1 Virgilio 1 28.1 ## 5 5 1 PR22D40 1 26.7 ## 6 6 1 Ciccio 1 34.2 # WRONG ANALYSIS!!!! # no distinction is made between true replicates and sub-replicates # Fitting a &#39;naive&#39; model mod &lt;- lm(TKW ~ Block + Genotype, data=TKW) anova(mod) ## Analysis of Variance Table ## ## Response: TKW ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Block 2 110.3 55.169 7.510 0.0006875 *** ## Genotype 29 7224.7 249.129 33.913 &lt; 2.2e-16 *** ## Residuals 238 1748.4 7.346 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Residual standard deviation summary(mod)$sigma ## [1] 2.710373 ## [1] 2.710373 # Number of significant pairwise comparisons between genotype means pairwise &lt;- as.data.frame(pairs(emmeans(mod, ~Genotype))) sum(pairwise$p.value &lt; 0.05) ## [1] 225 L’analisi illustrata qui sopra è semplice e allettante, ma è anche totalmente sbagliata: mettere sullo stesso piano repliche vere e pseudo-repliche trascura il fatto che le 270 osservazioni sono raggruppate per parcella e che le osservazioni nella stessa parcella sono più simili che quelle in pacelle diverse, poiché condividono la stessa ‘origine’ (mancanza di indipendenza dei residui). Inoltre, il grado di precisione è troppo elevato: i tre sottocampioni sono correlati e non forniscono tre ‘pezzi’ di informazione completi. Un modello corretto per questa circostanza dovrebbe includere un termine aggiuntivo per le parcelle, che sono unità di “raggruppamento” e sono anche unità di randomizzazione: \\[Y_{ijs} = \\mu + \\alpha_i + \\gamma_j + \\delta_{ij} + \\varepsilon_{ijs}\\] In questo modello, \\(Y_{ijs}\\) è il peso di mille semi per l’i-esimo genotipo, il j-esimo blocco, la k-esima pacella e il s-esimo sub-campione, \\(\\alpha_i\\) è l’effetto dell’i-esimo genotipo, \\(\\gamma_j\\) è l’effetto del j-esimo blocco, \\(\\delta_{ij}\\) è l’effetto della parcella identificata dall’i-esimo genotipo e dal j-esimo blocco e \\(\\varepsilon_{ijs}\\) è l’effetto del s-esimo sottocampione, nella parcella identificata come precedentemente menzionato. La presenza dell’elemento \\(\\delta\\) spiega le differenze tra le parcelle, in modo da ripristinare l’indipendenza dei residui del modello. Dato che la parcella anche un’unità di randomizzazione, perchè riceve i livelli del trattamento in modo randomizzato, deve essere considerata come effetto random. Di conseguenza, si tratta di un modello misto: le due componenti della varianza sono \\(\\sigma^2_{\\delta}\\) e \\(\\sigma^2_{\\varepsilon}\\), e la seconda dovrebbe essere molto più piccola, in quanto non contiene importanti fonti di errore sperimentale, come la variabilità dovuta al suolo o alle pratiche colturali. Ovviamente, alla prima componente deve essere assegnato il peso appropriato quando si costruisce il termine di errore corretto per testare l’effetto del genotipo. Questo modello misto può essere stimato utilizzando la funzione lmer() nel pacchetto lme4 (Codice 12.8). La verifica delle assunzioni di base, effettuata come spiegato per gli esempi precedenti, non fornisce alcun sospetto di possibili deviazioni e, pertanto, è possibile visualizzare le componenti della varianza e la tabella ANOVA. Si può confermare che l’effetto del genotipo è significativo, sebbene gli errori standard delle medie siano molto più alti rispetto all’analisi errata mostrata in precedenza (1.75 contro 0.903) e il numero di confronti significativi sia sceso a 91. Per brevità, non vengono mostrati i risultati completi dei confronti a coppie. # Example 12.4 [continuation] # CORRECT ANALYSES!!! # True replicates and sub-replicates are parted # Fitting a mixed model with the random &#39;plot&#39; term mod.mix &lt;- lmer(TKW ~ Block + Genotype + (1|Plot), data=TKW) # Check for basic assumptions (not run) # plot(mod.mix) # qqnorm(resid(mod.mix)) # QQ-plot # qqline(resid(mod.mix), lty = 2) leveneTest(lm(residuals(mod.mix) ~ Genotype, data=TKW)) ## Levene&#39;s Test for Homogeneity of Variance (center = median) ## Df F value Pr(&gt;F) ## group 29 1.0143 0.4507 ## 240 shapiro.test(residuals(mod.mix)) ## ## Shapiro-Wilk normality test ## ## data: residuals(mod.mix) ## W = 0.99277, p-value = 0.2141 # Printing the variance components print(VarCorr(mod.mix), comp = &quot;Variance&quot;) ## Groups Name Variance ## Plot (Intercept) 8.89201 ## Residual 0.84526 # Variance partitioning anova(mod.mix, ddf = &quot;Kenward-Roger&quot;) ## Type III Analysis of Variance Table with Kenward-Roger&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## Block 3.389 1.6944 2 58 2.0046 0.1439 ## Genotype 221.892 7.6515 29 58 9.0522 9.944e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Number of significant pairwise comparisons between genotype means pairwise &lt;- as.data.frame(pairs(emmeans(mod.mix, ~Genotype))) sum(pairwise$p.value &lt; 0.05) ## [1] 91 Il metodo di analisi dei dati illustrato nel riquadro sovrastante è fortemente raccomandato, sebbene, qualora il numero di sub-campioni sia lo stesso per tutte le parcelle, possiamo ottenere risultati corretti anche con un’analisi in due fasi: nella prima fase, calcoliamo le medie dei sub-campioni per ciascuna parcella e, nella seconda fase, utilizziamo queste medie per stimare un modello che include il genotipo e il blocco come fattori fissi. Il riquadro sottostante mostra che questa tecnica in due fasi produce gli stessi risultati, senza la necessità di disporre di un software avanzato per la stima di un modello misto. # Example 12.4 [continuation] # Fitting in two-steps without a mixed model # Only correct when the number of sub-samples is the # same for all plots! # First step TKWm &lt;- aggregate(TKW ~ Block + Genotype, data = TKW, mean) # Second step mod2step &lt;- lm(TKW ~ Genotype + Block, data = TKWm) anova(mod2step) ## Analysis of Variance Table ## ## Response: TKW ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Genotype 29 2408.24 83.043 9.0522 9.943e-13 *** ## Block 2 36.78 18.390 2.0046 0.1439 ## Residuals 58 532.08 9.174 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 12.5 Esempio 12.5: confronto varietale ripetuto in più anni In questo libro, abbiamo più volte menzionato l’importanza di ripetere più volte gli esperimenti, cosa che è del tutto assodata per le prove varietali, che coinvolgono spesso ampie reti di istituti di ricerca, in molte regioni e/o paesi. In genere, le reti varietali utilizzano un nucleo di genotipi comuni e lo stesso disegno sperimentale (ad esempio, blocchi completi randomizzati con 3-4 repliche), mentr, nel corso del tempo, vengono via via inseriti i genotipi più innovativi , mentre quelli obsoleti sono progressivamente abbandonati (Annichiarico 2002). Consideriamo un esperimento varietale con otto genotipi di frumento, in tre blocchi completi, ripetuto per 7 anni e finalizzato a fornire raccomandazioni varietali agli agricoltori. I risultati sono tratti da Onofri e Ciriciofolo (2007) e sono disponibili nel dataset ‘WinterWheat’, all’interno del package statforbiology. Per questo dataset è possibile utilizzare il modello seguente: \\[y_{ijk} = \\mu + \\gamma_{ik} + \\alpha_i + \\beta_j + \\alpha\\beta_{ij} + \\varepsilon_{ijk}\\] In questo modello, \\(y\\) è la produzione nell’iesimo anno, j-esimo genotipo e k-esimo blocco, \\(\\mu\\) è l’intercetta, \\(\\gamma_{ik}\\) è l’effetto del k-esimo blocco nell’i-esimo anno, \\(\\alpha_i\\) è l’effetto dell’i-esimo anno, \\(\\beta_j\\) è l’effetto del j-esimo genotipo, \\(\\alpha\\beta_{ij}\\) è l’effetto dell’interazione ‘genotipo x anno’ e \\(\\varepsilon_{ijk}\\) è il residuo, che assumiamo sia distribuito normalmente e omoschedastico (\\(\\epsilon_{ijk} \\sim N(0, \\sigma_{\\varepsilon})\\)). Con gli esperimenti ripetuti, di qualunque genere essi siano, è necessario prendere una decisione sulla natura dell’effetto di ripetizione, cioè l’anno (in questo caso), la località oppure, in genere, la ‘serie’. In particolare, è necessario decidere se considerare questo effetto “fisso” o “random”. Tale decisione è specifica per ogni esperimento e spetta al ricercatore, che dovrebbe fornire solide motivazioni a supporto. Come regola generale, si possono dare i seguenti suggerimenti: ogni volta che l’esperimento viene ripetuto un numero limitato di volte (ad esempio 2 o 3), l’effetto “ripetizione” potrebbe essere preferibilmente considerato fisso, come abbiamo mostrato nella Sezione 10.5; infatti, una stima affidabile delle componenti della varianza richiede che il numero di livelli per il fattore random sia sufficientemente elevato (almeno 4, approssimativamente). Con esperimenti di campo ripetuti in un numero relativamente elevato di anni, quest’ultimo effetto potrebbe essere ragionevolmente considerato casuale, per almeno una buona ragione: sebbene gli anni non siano campionati (non possiamo campionare gli anni, possiamo solo prenderli nelll’ordine in cui si presentano), gli effetti che producono non sono ripetibili e sono chiaramente di natura casuale. Con esperimenti sul campo ripetuti in un numero relativamente elevato di località, la natura di quest’ultimo effetto è più dubbia: in alcuni casi, le località sono scelte appositamente e sono interessanti di per sè, senza rappresentare nessun macro-ambiente. In questo caso, l’effetto ‘località’ può essere ragionevolmente preso come fisso. In altri casi, le località sono campionate per rappresentare un macroambiente e, pertanto, il loro effetto è da considerare random. Quando gli ‘anni/località/ambienti’ sono considerati random, essi costituiscono una sorta di “super-repliche”, che inducono un’ulteriore fonte di variabilità (la variabilità tra prove), che si aggiunge alla consueta variabilità entro prova. Separare queste due fonti di variabilità è estremamente rilevante, ad esempio, per scopi di selezione varietale. Nel dataset ‘WinterWheat’, il numero di anni è relativamente elevato e, poiché l’effetto anno è intrinsecamente di natura casuale e irripetibile, non avrebbe senso condizionare la raccomandazione varietale ad uno specifico anno; pertanto, l’effetto anno può essere preferibilmente considerato come random, con distribuzione gaussiana, media pari a 0 e deviazione standard pari a \\(\\sigma_E\\): \\[\\alpha_i \\sim N(0, \\sigma_E)\\] L’elemento \\(\\sigma^2_E\\) è la cosiddetta “componente di varianza” per l’effetto anno. Se l’anno è random, anche gli effetti “genotipo x anno” e “blocco entro anno” sono casuali e sono definiti come: \\[\\alpha\\beta_{ij} \\sim N(0, \\sigma_{GE})\\] \\[\\gamma_{ik} \\sim N(0, \\sigma_{EB})\\] Una volta caricato il dataset e aver eseguito le trasformazioni necessarie (ovvero, le variabili “Block”, “Year” e “Genotype” devono essere trasformate in fattori), è necessaria un’attenta analisi EDA, che implica un esame approfondito di ogni singolo esperimento, per assicurarsi che i dati di tutti gli anni siano validi e che le varianze dei residui dei diversi anni siano simili (vedere anche Sezione 10.5). Il riquadro sottostante non evidenzia problemi rilevanti, sebbene i risultati non siano mostrati per brevità. # Example 12.5 # A multi-year winter wheat experiment # Loading the packages library(statforbiology) library(nlme) library(car) library(emmeans) library(multcomp) library(lme4) library(lmerTest) library(SuppDists) # Loading and transforming the data WinterWheat &lt;- getAgroData(&quot;WinterWheat&quot;) |&gt; transform(Block = factor(Block), Year = factor(Year), Genotype = factor(Genotype)) # Model fitting for each year fits &lt;- by(WinterWheat, WinterWheat$Year, function(group) lm(Yield ~ Block + Genotype, data = group)) # Levene&#39;s test for each year: fit a reduced model with # only the Genotype in each year and use the &#39;leveneTest&#39; function fits2 &lt;- by(WinterWheat, WinterWheat$Year, function(group) leveneTest(residuals(lm(Yield ~ Block + Genotype, data = group)) ~ Genotype, data = group )) lev.test &lt;- unlist( lapply(fits2, function(mod) mod$`Pr(&gt;F)`[1] )) lev.test ## 1996 1997 1998 1999 2000 2001 2002 ## 0.9606223 0.9227674 0.8272382 0.7615624 0.9400817 0.8875930 0.7361952 # Shapiro-Wilks&#39; test for each year norm.tests &lt;- unlist( lapply(fits, function(mod) shapiro.test(residuals(mod))$p.value )) norm.tests ## 1996 1997 1998 1999 2000 2001 ## 0.43238842 0.24363110 0.70103762 0.98820729 0.85707740 0.46985800 ## 2002 ## 0.03322886 # Retrieve the residual variance for each year mses &lt;- unlist( lapply(fits, function(mod) summary(mod)$sigma^2) ) mses ## 1996 1997 1998 1999 2000 2001 ## 0.16178095 0.20184048 0.07198333 0.10116845 0.12620893 0.27505952 ## 2002 ## 0.10358631 # Hartley&#39;s Fmax test Fmax &lt;- max(mses)/min(mses) pmaxFratio(Fmax, 15, 7, lower.tail = F) ## [1] 0.1573404 Prima di stimare un modello misto, potrebbe essere una buona idea adattare un modello fisso, per una valutazione preliminare dei residui e per confrontare i risultati con quelli del un modello misto (riquadro sottostante). # Example 12.5 [continuation] # Pooled analyses: fitting a preliminary fixed model modfix &lt;- lm(sqrt(Yield) ~ Year/Block + Genotype * Year, data = WinterWheat) # Checking the residuals (not run) # plot(modfix, which= 1) # plot(modfix, which = 2) # boxcox(modfix) # No problems with the assumptions, thus proceed to ANOVA anova(modfix) ## Analysis of Variance Table ## ## Response: sqrt(Yield) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Year 6 6.8527 1.14212 192.5546 &lt; 2.2e-16 *** ## Genotype 7 0.4760 0.06799 11.4633 1.488e-10 *** ## Year:Block 14 0.1657 0.01183 1.9949 0.02568 * ## Year:Genotype 42 1.1627 0.02768 4.6671 1.804e-10 *** ## Residuals 98 0.5813 0.00593 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Il riquadro precedente conferma l’assenza di problemi con le assunzioni di base e la tabella ANOVA mostra che l’interazione “genotipo per anno” è significativa, il che consentirebbe solo raccomandazioni varietali specifiche per anno (e, quindi, piuttosto inutili). È chiaro che le raccomandazioni per un determinato sito dovrebbero essere formulate tenendo conto dell’intera gamma di condizioni meteorologiche che potrebbero verificarsi. In quest’ottica, possiamo stimare un modello misto con anni random tramite la funzione lmer(); le stime delle componenti della varianza vengono prodotte utilizzando il metodo REML (Restricted Maximum Likelyhood) (Pinheiro e Bates, 2000) e possono essere visualizzate utilizzando la funzione VarCorr() (riquadro sottostante). Queste componenti della varianza mostrano che la variabilità complessiva della produzione è dovuta principalmente all’effetto anno (variabilità tra anni: \\(\\sigma^2_E = 1,07\\)), seguito dall’interazione genotipo-anno (\\(\\sigma^2_{GE} = 0,170\\)), dalla variabilità tra parcelle entro anno (termine di errore residuo \\(\\sigma^2 = 0,149\\)) e, infine, dalla variabilità tra blocchi entro anno (\\(\\sigma^2_{EB} = 0,016\\)). Queste componenti vengono utilizzate per costruire test F ed errori standard. # Example 12.5 [continuation] # Pooled analyses: fitting a mixed model with random years modmix &lt;- lmer(Yield ~ (1|Year) + (1|Year:Block) + Genotype + (1|Year:Genotype), data = WinterWheat) # Variance components print( VarCorr(modmix), comp=c(&quot;Variance&quot;, &quot;Std.Dev.&quot;) ) ## Groups Name Variance Std.Dev. ## Year:Genotype (Intercept) 0.170341 0.41272 ## Year:Block (Intercept) 0.016418 0.12813 ## Year (Intercept) 1.073146 1.03593 ## Residual 0.148804 0.38575 # ANOVA table anova(modmix, ddf = &quot;Kenward-Roger&quot;) ## Type III Analysis of Variance Table with Kenward-Roger&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## Genotype 2.6033 0.3719 7 42 2.4993 0.03058 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The ANOVA table shows that the F-ratio is still significant, but it is smaller than that of the fixed model fit. Indeed, at the denominator, apart from the residual error term, it is necessary to also consider the specific variability of each genotype across years (i.e., the genotype-by-year interaction). Infine, vengono derivate e confrontate le medie complessive dei genotipi, ma non vengono evidenziate differenze significative tra i genotipi. Infatti, i modelli misti consentono di considerare tutte le possibili fonti di variabilità della resa (all’interno degli anni e tra gli anni), consentendo inferenze sull’intera popolazione di possibili anni (inferenza ‘broad space’). # Example 12.5 [continuation] # Multiple comparisons for a mixed model with random years cld(emmeans(modmix, ~Genotype), Letters = letters) ## Genotype emmean SE df lower.CL upper.CL .group ## SIMETO 5.93 0.431 8.23 4.94 6.91 a ## CRESO 5.97 0.431 8.23 4.99 6.96 a ## GRAZIA 6.08 0.431 8.23 5.09 7.07 a ## SANCARLO 6.22 0.431 8.23 5.23 7.21 a ## SOLEX 6.23 0.431 8.23 5.24 7.22 a ## COLOSSEO 6.41 0.431 8.23 5.43 7.40 a ## DUILIO 6.59 0.431 8.23 5.60 7.58 a ## IRIDE 6.70 0.431 8.23 5.71 7.68 a ## ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 8 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. 12.6 Esempio 12.6: misure ripetute nelle colture poliennali Con le colture poliennali, le misure vengono effettuate ripetutamente nelle stesse parcelle nel corso degli anni. Per questo motivo, sebbene il dataset assomigli molto a quello dell’esperimento precedente su frumento ripetuto in diversi anni, deve essere analizzato in modo completamente diverso. In particolare, non dobbiamo trascurare che, a differenza dell’Esempio 12.5, le osservazioni non sono indipendenti, ma sono raggruppate all’interno delle stesse parcelle. La situazione appare simile a quella di un esperimento con sub-campionamento (vedi Sezione 12.4), con un’importante differenza: mentre i sub-campioni sono scelti casualmente all’interno di ciascuna parcella, con l’unico scopo di valutare la loro variabilità, le misure ripetute vengono eseguite specificamente per valutare l’andamento temporale della risposta. Consideriamo un set di dati relativo alla resa di diversi genotipi di erba medica in tre anni consecutivi, prelevati dalle stesse parcelle in un singolo esperimento della durata di tre anni. Nel riquadro sottostante, il set di dati viene caricato e vengono eseguite alcune trasformazioni necessarie. Abbiamo anche creato una nuova variabile per identificare in modo univoco ogni parcella, il che è semplice, considerando che i valori di resa presi per lo stesso genotipo nello stesso blocco devono essere stati presi nella stessa parcella. # Example 12.6 # Repeated measures in a perennial crop # Loading the packages library(statforbiology) library(lme4) library(lmerTest) library(emmeans) library(multcomp) # Loading and transforming the data dataset &lt;- getAgroData(&quot;alfalfa3years&quot;) |&gt; transform(Block = factor(Block), Genotype = factor(Genotype), Year = factor(Year)) head(dataset) ## Plot Block Genotype Year Yield ## 1 1 1 4cascine 2006 6.631775 ## 2 25 2 4cascine 2006 6.705397 ## 3 60 3 4cascine 2006 6.499588 ## 4 63 4 4cascine 2006 7.087686 ## 5 7 1 casalina 2006 8.033558 ## 6 33 2 casalina 2006 8.265165 # Reference the plots (not necessary in this instance) # dataset$Plot &lt;- dataset$Block:dataset$Genotype Per i disegni a misure ripetute, i modelli possono essere costruiti utilizzando le regole di Piepho et al. (2004): Considerare un singolo anno e costruire il modello per i trattamenti Considerare un singolo anno e costruire il modello per i fattori di raggruppamento Includere il fattore anno nel modello e combinare l’anno con tutti gli effetti nel modello dei trattamento, incrociando o annidando a seconda dei casi. Considerare che il fattore “plot” nel modello dei fattori di raggruppamento fa riferimento alle unità di randomizzazione, ovvero quelle unità che hanno ricevuto i genotipi tramite un processo di randomizzazione. Assegnare quindi a questo fattore ‘plot’ un effetto casuale. Escludendo i termini per le unità di randomizzazione, annidare l’anno in tutti gli altri termini del modello dei fattori di raggruppamento. Combinare gli effetti casuali per le unità di randomizzazione con il fattore ripetuto, utilizzando l’operatore due punti, al fine di derivare i termini di errore corretti per gestire le strutture di correlazione. I modelli nelle diverse fasi sono i seguenti (con notazione R): modello dei trattamenti: RESA ~ GENOTIPO modello dei fattori di raggruppamento: RESA ~ BLOCCO + BLOCCO:PLOT modello di trattamento: RESA ~ GENOTIPO * ANNO modello a blocchi: RESA ~ BLOCCO + (1|BLOCCO:GRAFICO) modello a blocchi: RESA ~ BLOCCO + BLOCCO:ANNO + (1|BLOCCO:GRAFICO) modello a blocchi: RESA ~ BLOCCO + BLOCCO:ANNO + (1|BLOCCO:GRAFICO) + (1|BLOCCO:GRAFICO:ANNO) In questo caso, considerando che l’erba medica dura in media tre anni e segue uno specifico schema di resa in questi anni, si è deciso che gli effetti di blocco, anno e genotipo siano fissi e, quindi, il modello finale, con notazione R, è: RESA ~ BLOCCO + BLOCCO:ANNO + GENOTIPO * ANNO + (1|BLOCK:PLOT) + (1|BLOCK:PLOT:YEAR) dove l’ultimo termine (i residui) non deve essere inserito, poiché viene inserito di default. # Example 12.6 [continuation] # Mixed model analysis for the &#39;alfalfa3years&#39; dataset mod &lt;- lmer(Yield ~ Block + Block:Year + Genotype*Year + (1|Block:Plot), data = dataset) anova(mod, ddf = &quot;Kenward-Roger&quot;) ## Type III Analysis of Variance Table with Kenward-Roger&#39;s method ## Sum Sq Mean Sq NumDF DenDF F value Pr(&gt;F) ## Block 3.96 1.32 3 57 2.1389 0.105316 ## Genotype 54.00 2.84 19 57 4.6024 3.75e-06 *** ## Year 2602.53 1301.27 2 114 2107.3223 &lt; 2.2e-16 *** ## Block:Year 14.14 2.36 6 114 3.8176 0.001667 ** ## Year:Genotype 31.83 0.84 38 114 1.3563 0.111546 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Multiple comparisons cld(emmeans(mod, ~Genotype), Letters = LETTERS, reverse = TRUE) ## NOTE: Results may be misleading due to involvement in interactions ## Genotype emmean SE df lower.CL upper.CL .group ## casalina 12.46 0.315 57 11.83 13.1 A ## FDL0101 12.22 0.315 57 11.59 12.9 A ## LaBellaCampagnola 12.17 0.315 57 11.54 12.8 A ## PicenaGR 12.12 0.315 57 11.49 12.8 A ## Selene 12.11 0.315 57 11.48 12.7 A ## robot 12.11 0.315 57 11.48 12.7 A ## Zenith 11.94 0.315 57 11.31 12.6 A ## prosementi 11.79 0.315 57 11.15 12.4 A ## marina 11.76 0.315 57 11.13 12.4 A ## garisenda 11.76 0.315 57 11.13 12.4 A ## dimitra 11.75 0.315 57 11.12 12.4 A ## PR57Q53 11.70 0.315 57 11.07 12.3 A ## classe 11.59 0.315 57 10.96 12.2 AB ## 4cascine 11.59 0.315 57 10.96 12.2 AB ## PR56S82 11.56 0.315 57 10.93 12.2 AB ## LaTorre 11.36 0.315 57 10.73 12.0 ABC ## linfa 11.23 0.315 57 10.60 11.9 ABC ## Palladiana 10.89 0.315 57 10.26 11.5 ABC ## RivieraVicentina 9.98 0.315 57 9.35 10.6 BC ## costanza 9.89 0.315 57 9.26 10.5 C ## ## Results are averaged over the levels of: Block, Year ## Degrees-of-freedom method: kenward-roger ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 20 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. Si dimostra che l’interazione “genotipo x anno” non è significativa, quindi è possibile derivare e confrontare le medie complessive dei genotipi negli anni. Il gruppo dei migliori, in media sui tre anni, contiene tutti i genotipi tranne Riviera Vicentina e Costanza. Prima di concludere, è necessario ribadire l’idea che se questo set di dati venisse analizzato come nell’Esempio 12.5, tutte le inferenze e i test di ipotesi sarebbero invalidi perché l’assunto di base di indipendenza dei residui verrebbe violato, come accade quando i fattori di raggruppamento non sono inclusi nel modello. Un’altra avvertenza è che l’analisi del modello misto proposta in precedenza nel riquadro precedente considera il disegno come uno “split-plot nel tempo”, il che non è necessariamente corretto. Infatti, tale analisi presuppone che la correlazione entro parcella rimanga la stessa per tutte le coppie di osservazioni, indipendentemente dalla loro distanza temporale. In effetti, sarebbe ragionevole aspettarsi che la correlazione sia maggiore per misure molto vicine nel tempo e diminuisca per misure prese a distanze temporali elevate. Pertanto, soprattutto quando il numero di anni è elevato, potrebbero essere necessarie ulteriori analisi per valutare se l’adozione di strutture di correlazione seriale sia giustificata (Piepho et al., 2004). Tuttavia, questo aspetto esula dallo scopo di questo libro introduttivo; informazioni utili sono reperibili in Littel et al. (2006). Infine, vale la pena notare che si possono trovare disegni in cui le misurazioni non vengono ripetute nel tempo ma piuttosto nello spazio, ad esempio in posizioni diverse (vedi Capitolo 2) o a profondità variabili. Sebbene il termine “split-plot nel tempo” possa non essere appropriato per queste situazioni, il set di dati risultante può comunque essere analizzato utilizzando gli stessi metodi mostrati in questo esempio. 12.7 Fattori di raggruppamento nei modelli di regressione Si prevedeva (Capitolo 11) che i fattori di raggruppamento dovessero sempre essere adeguatamente referenziati nel modello, il che vale anche per i modelli di regressione. Per questi ultimi modelli, in particolare per i modelli non lineari, è spesso preferibile considerare l’effetto del fattore di raggruppamento come casuale, supponendo che tutti i parametri del modello (o parte di essi) cambino casualmente da un gruppo all’altro. Di conseguenza, ad esempio, per i modelli di regressione lineare semplici, è possibile definire modelli con intercetta casuale o modelli con pendenza casuale o modelli con intercetta e pendenza casuali. Questo è un aspetto spesso trascurato e, pertanto, è sembrato opportuno menzionarlo qui, sebbene sia troppo avanzato per un libro introduttivo. I lettori interessati possono consultare per ulteriori informazioni. Inoltre, diversi post sono dedicati a questo aspetto nel blog allegato a questo libro. 12.8 Altre letture Annichiarico P (2002) Genotype x Environment Interactions - Challenges and Opportunities for Plant Breeding and Cultivar Recommendations, Plant Production and Protection Paper, vol 1. FAO, MET Bates D, Mächler M, Bolker B, Walker S (2015) Fitting linear mixed-effects models using lme4. J Stat Softw 67(1):1–48. https://doi.org/10.18637/jss.v067.i01 Belocchi A, Fornara M, Ciriciofolo E, Biancolatte E, Del Puglia S, Olimpieri G, Vecchiarelli V, Gosparini E, Piccioni C, Desiderio E (2003) Grano duro: Risultati 2002-03 della Rete Nazionale. Lazio e Umbria. L’Informatore Agrario 19(Suppl. 1):41–44 Dixon P (2016) Should blocks be fixed or random? In: Conference on Applied Statistics in Agri- culture. https://doi.org/10.4148/2475-7772.1474. https://newprairiepress.org/agstatconference/ 2016/proceedings/4 Gałecki A, Burzykowski T (2013) Linear Mixed-Effects Models Using R: A Step-by-Step Approach. Springer, Berlin Gerhard D, Ritz C (2018) medrc: Mixed effect dose-response curves. https://github.com/doseResponse/medrc, r package version 1.1-0, commit bc36df514ad68d6e3f29ec4c740a563605231819 Kuznetsova A, Brockhoff PB, Christensen RHB (2017) lmerTest package: Tests in linear mixed effects models. J Stat Softw 82(13):1–26. https://doi.org/10.18637/jss.v082.i13 Ligabue M, Onofri A, Ruozzi F (2009) Le migliori varietà di erba medica da seme. Agricoltura 84:82–84 Littell RC, Milliken GA, Stroup WW, Wolfinger RD, Schabanberger O (2006) SAS for Mixed Models, 2nd edn. Books. SAS Publishing, Cary Onofri A, Ciriciofolo E (2007) Using R to perform the AMMI analysis on agriculture variety trials. R News 7:14–19. http://www.r-project.org Piepho HP, Büchse A, Emrich K (2003) A Hitchhiker’s Guide to mixed models for randomized experiments. J Agron Crop Sci 189(5):310–322. https://doi.org/10.1046/j.1439-037X.2003. 00049.x Piepho HP, Büchse A, Richter C (2004) A mixed modelling approach for randomized experiments with repeated measures. J Agron Crop Sci 190(4):230–247. http://dx.doi.org/10.1111/j.1439- 037X.2004.00097.x Pinheiro JC, Bates DM (2000) Mixed-Effects Models in S and S-Plus. Springer-Verlag Inc. edn. Springer, New York Stagnari F, Onofri A, Jemison J, Monotti M (2007) Improved multivariate analyses to discriminate the behaviour of faba bean varieties. Agron Sustain Develop 27(4):387–397 "],["appendice-a-breve-introduzione-ad-r.html", "Capitolo 13 Appendice A: Breve introduzione ad R Cosa è R? Installazione di R 13.1 Prima di iniziare 13.2 Oggetti e assegnazioni 13.3 Tipi di oggetti 13.4 Lavorare con gli oggetti 13.5 Espressioni, funzioni e argomenti 13.6 Funzioni di uso comune 13.7 Creazione di funzioni personalizzate 13.8 Uso di librerie aggiuntive 13.9 Workspace 13.10 Importare dati esterni 13.11 Cenni sulle funzionalità grafiche in R 13.12 Altre letture", " Capitolo 13 Appendice A: Breve introduzione ad R Cosa è R? R è un software cugino di S-PLUS, con il quale condivide la gran parte delle procedure ed una perfetta compatibilità. Rispetto al cugino più famoso, è completamente freeware (sotto la licenza GNU General Public Licence della Free Software Foundation) ed è nato proprio per mettere a disposizione degli utenti uno strumento gratuito, potente, che permette di lavorare in modo estremamente professionale, senza usare software di frodo. Inoltre, si tratta di un programma Open Source, cioè ognuno può avere accesso al suo codice interno ed, eventualmente, proporne modifiche o ampliarne le funzionalità programmando apposite librerie aggiuntive. A fronte di questi vantaggi, bisogna tuttavia considerare il fatto che R, almeno all’inizio, presenta alcune difficoltà legate al fatto che manca una vera e propria interfaccia grafica (Graphical User Interface: GUI) e, di conseguenza, ogni operazione deve essere eseguita digitando il codice necessario. Parte di queste difficoltà possono essere alleviate utilizzando R dall’interno di RStudio, un’interfaccia che garantisce una più facile digitazione del codice. Installazione di R Per iniziare, segui questi semplici passaggi: Installa R da: https://cran.r-project.org. Segui il link a CRAN (in alto a destra), seleziona uno dei mirror disponibili (puoi semplicemente selezionare il primo link in alto), seleziona il tuo sistema operativo (SO) e scarica la versione base. Installala utilizzando tutte le opzioni predefinite. Installa RStudio da: https://posit.co/download/rstudio-desktop/. Seleziona la versione desktop di RStudio, edizione open source e scaricala. Installala utilizzando tutte le opzioni predefinite. Avvia RStudio. 13.1 Prima di iniziare Ci sono alcune nozioni che è bene conoscere prima di mettersi al lavoro con R. Riassumiamole: Case sensitivity. Per evitare noiosi errori che possono essere molto comuni per chi è abituato a lavorare in ambiente WINDOWS, è bene precisare subito che R, come tutti i linguaggi di derivazione UNIX, è case sensitive, cioè distingue tra lettere maiuscole e lettere minuscole. Spazi. Gli spazi possono essere aggiunti ovunque nel codice per renderlo più leggibile. Tuttavia, non si possono aggiungere spazi all’interno dei nomi delle funzioni, dei nomi degli oggetti e degli operatori composti da più di un carattere. Pannelli. In RStudio, ci sono quattro pannelli e noi ne utilizzeremo prevalentemente due, denominati, rispettivamente SOURCE e CONSOLE. Il codice si scrive nel pannello SOURCE, che è un semplice editor di testi, salvabili con l’estensione ‘.R’. Il codice composto nel pannello SOURCE DEVE essere inviato alla console, dove viene eseguito, utilizzando i tasti ‘ctrl-r’ (Windows) oppure ‘ctrl-invio’ (Windows) o ‘cmd-invio’ (Mac). Se il codice non è inviato alla console non viene eseguito: è come scrivere un messaggio in Whattsapp, senza inviarlo al destinatario! Operatori. In informatica e programmazione, un operatore è un simbolo che specifica quale operazione applicare ad uno o più operandi, per generare un risultato. Si distinguono in (1) aritmetici (+, -, * e /); (2) di assegnazione (&lt;- oppure =); (3) logici (TRUE, FALSE, &amp; e |); (4) Condizionali (if); (5) di relazione (&lt;, &lt;=, ==, &gt;= e &gt;) 13.2 Oggetti e assegnazioni In R, si lavora creando ‘oggetti’ ed assegnando loro un nome, che identifica la porzione di memoria in cui questo oggetto viene collocato. Nel principio, questo è molto simile a quello che facciamo in un foglio elettronico, dove assegniamo un oggetto (lo memorizziamo) in una determinata cella. Ad esempio, il comando: y &lt;- 3 assegna al valore numerico 3 il nome y. Invece il comando: x &lt;- &quot;Biondo&quot; assegna al testo “Biondo” il nome x. I dati che possiamo includere in un oggetto sono di diverso tipo: numerici a doppia precisione; ‘integer’, cioè numeri senza parte decimale carattere (con virgolette, ad es. “Germinato”, “Non germinato”) valori logici (TRUE o FALSE, abbreviati in T o F). 13.3 Tipi di oggetti Gli oggetti che possiamo creare sono di diverso tipo, principalmente: costanti, vettori, matrici, dataframes. 13.3.1 Costanti e vettori Le costanti sono, ad esempio, quelle indicate in precedenza, ma, solitamente, in R si creano oggetti più organizzati, come i ‘vettori’, cioè degli elenchi di dati dello stesso tipo. Ad esempio, il codice segente crea un vettore di nome x, contenente i numeri 1, 2 e 3. Bisogna precisare che il ‘vettore’, in R, non ha alcun legame con la fisica o l’algebra, ed è semplicemente una collezione di elementi affini. x &lt;- c(1, 2, 3) Oltre che numerici, i vettori possono contenere testi alfanumerici. Ad esempio, nel codice sottostante abbiamo creato un vettore contenente nomi di persona. nomi &lt;- c(&quot;Andrea&quot;, &quot;Luca&quot;, &quot;Sandro&quot;, &quot;Mario&quot;) nomi ## [1] &quot;Andrea&quot; &quot;Luca&quot; &quot;Sandro&quot; &quot;Mario&quot; Un oggetto leggermente diverso è il fattore sperimentale (‘factor’), che contiene caratteri alfanumerici (come nel caso precedente), ma rappresenta una variabile qualitativa di classificazione in categorie. classe &lt;- factor(c(&quot;Uomo&quot;, &quot;Uomo&quot;, &quot;Donna&quot;, &quot;Donna&quot;, &quot;Donna&quot;)) classe ## [1] Uomo Uomo Donna Donna Donna ## Levels: Donna Uomo 13.3.2 Matrici Oltre ai vettori, in R possiamo definire le matrici. Ad esempio il comando: z &lt;- matrix(c(1, 2, 3, 4, 5, 6, 7, 8), nrow = 2, ncol = 4, byrow = TRUE) crea una matrice z a 2 righe e 4 colonne, contenente i numeri da 1 a 8. La matrice viene riempita per riga. 13.3.3 Dataframe Oltre a vettori e matrici, in R esiste un altro importante oggetto, cioè il dataframe, costituito da una tabella di dati con una o più colonne di variabili e una o più righe di dati. A differenza della matrice, il dataframe può essere utilizzato per memorizzare variabili di diverso tipo (numeri e caratteri). Un dataframe può essere creato unendo più vettori, come nell’esempio seguente; fare attenzione a non confondere il nome assegnato alla colonna, con il nome del vettore il cui contenuto viene immesso nella colonna stessa (nel codice sottostante, “Parc” = parcelle significa che la prima colonna della tabella si chiama “Parc” e contiene i dati del vettore ‘parcelle’). parcelle &lt;- c(1, 2, 3, 4, 5, 6) tesi &lt;- factor(c(&quot;A&quot;, &quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;C&quot;, &quot;C&quot;)) dati &lt;- c(12, 15, 16, 13, 11, 19) tabella &lt;- data.frame(&quot;Parc&quot; = parcelle, &quot;Tesi&quot; = tesi, &quot;Produzioni&quot; = dati) 13.4 Lavorare con gli oggetti 13.4.1 Visualizzazione Per visualizzare un oggetto basta invocare il suo nome: z ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 oppure: tabella ## Parc Tesi Produzioni ## 1 1 A 12 ## 2 2 A 15 ## 3 3 B 16 ## 4 4 B 13 ## 5 5 C 11 ## 6 6 C 19 13.4.2 Indicizzazione Vettori, matrici e dataframe sono oggetti organizzati caratterizzati da una o due dimensioni. Gli elementi che sono in essi contenuti possono essere identificati per mezzo di ‘indici’, un po’ come avviene nella battaglia navale. Gli indici sono inclusi tra parentesi quadre. Ad esempio, il secondo elemento del vettore ‘x’ creato in precedenza può essere richiamato in questo modo: x[2] ## [1] 2 Nel caso delle matrici e dei dataframes, che sono oggetti bidimensionali, gli indici sono due, uno per le righe e uno per le colonne, separati da virgole: tabella[2,1] ## [1] 2 Per questi oggetti bidimensionali, è possibile anche accedere agli elementi di un’intera riga o di un’intera colonna, lasciando vuoto l’indice relativo ad una delle due dimensioni. Ad esempio: tabella[,1] ## [1] 1 2 3 4 5 6 oppure: tabella[1,] ## Parc Tesi Produzioni ## 1 1 A 12 13.4.3 Estrazione di slots A volte gli oggetti contengono altri oggetti ai quali è possibile accedere con l’estrattore \\(*. Per esempio, si può accedere alle singole colonne di un dataframe, oltre che con l&#39;indicizzazione, anche utilizzando l&#39;estrattore *\\) seguito dal nome della colonna, ad esempio: tabella$Parc ## [1] 1 2 3 4 5 6 13.5 Espressioni, funzioni e argomenti Gli oggetti numerici possono essere creati e manipolati anche con opportune operazioni algebriche (espressioni), utilizzando gli operatori indicati in precedenza. Ad esempio: f &lt;- 2 * y f ## [1] 6 Le operazioni più complesse ed usuali sono implementate in apposite funzioni, che hanno un nome ed uno o più argomenti. Ad esempio, la funzione: abs(-5) ## [1] 5 restituisce il valore assoluto e richiede un solo argomento, cioè il numero di cui calcolare il valore assoluto. Al contrario, la funzione: log(100, 2) ## [1] 6.643856 Calcola il logaritmo in base 2 di 100 e richiede due argomenti, cioè il numero di cui calcolare il logaritmo e la base del logaritmo. A volte, gli argomenti hanno valori di default, per cui, se digitiamo: log(5) ## [1] 1.609438 otteniamo il logaritmo naturale di 5, in quanto il secondo argomento (la base) ha, per default, il valore \\(e\\) (operatore di Nepero). Quando sono necessari due o più argomenti essi debbono essere messi nell’ordine esatto in cui R se li aspetta (in questo caso prima il numero, poi la base), oppure possono essere specificati per nome. Ad esempio, i due comandi: log(x=100, base=2) ## [1] 6.643856 log(base=2, x=100) ## [1] 6.643856 restituiscono lo stesso risultato, al contrario dei due comandi seguenti: log(100, 2) ## [1] 6.643856 log(2, 100) ## [1] 0.150515 perchè il primo restituisce il logaritmo di 100 in base 2, mentre il secondo restituisce il logaritmo di 2 in base 100. Per conoscere gli argomenti di una funzione ed il loro ordine, si può digitare il nome della funzione preceduto dal punto interrogativo: ?log Come menzionato in precedenza, a volte le funzioni restituiscono diversi risultati, che vengono messi in appositi ‘slots’. Ad esempio, se vogliamo calcolare autovettori ed autovalori di una matrice, utilizziamo la funzione ‘eigen()’. Questa funzione restituisce una lista che, al suo interno, contiene i due oggetti, denominati, rispettivamente, ‘values’ (autovalori) e ‘vectors’ (autovettori). Per recuperare l’uno o l’altro dei due oggetti (autovettori o autovalori) si usa l’estrattore ‘$’, come abbiamo visto prima per le colonne dei dataframes: matrice &lt;- matrix(c(2,1,3,4),2,2) ev &lt;- eigen(matrice) ev$values ## [1] 5 1 ev$vectors ## [,1] [,2] ## [1,] -0.7071068 -0.9486833 ## [2,] -0.7071068 0.3162278 13.6 Funzioni di uso comune Nella pratica operativa, ci troviamo spesso nelle condizioni di creare una serie di numeri progressivi, utilizzando il comando seq(n, m, by=step), che genera una sequenza da \\(n\\) a \\(m\\) con passo pari a \\(step\\). Il codice sottostante crea una serie da 1 a 12. options(width = 55) parcelle &lt;- seq(1, 12, 1) parcelle ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 Altre volte, abbiamo la necessità di creare vettori, ripetendo più volte alcune categorie. Ad esempio, potremmo avere quattro osservazioni che appartengono alla varietà BAIO, quattro osservazioni che appartengono alla varietà DUILIO e quattro osservazioni che appartengono alla varietà PLINIO. Per creare velocemente questo vettore, possiamo utilizzare la funzione rep(), in questo modo: tesi &lt;- factor(c(&quot;BAIO&quot;, &quot;DUILIO&quot;, &quot;PLINIO&quot;)) tesi ## [1] BAIO DUILIO PLINIO ## Levels: BAIO DUILIO PLINIO rep(tesi, each=4) ## [1] BAIO BAIO BAIO BAIO DUILIO DUILIO DUILIO ## [8] DUILIO PLINIO PLINIO PLINIO PLINIO ## Levels: BAIO DUILIO PLINIO Notare l’uso della funzione factor() per creare un vettore di dati qualitativi (fattore sperimentale). Notare anche che il codice sottostante restituisce lo stesso risultato, ma ordinato in modo diverso, in quanto viene ripetuto l’intero vettore, non i singoli elementi che lo costituiscono: rep(tesi, times = 4) ## [1] BAIO DUILIO PLINIO BAIO DUILIO PLINIO BAIO ## [8] DUILIO PLINIO BAIO DUILIO PLINIO ## Levels: BAIO DUILIO PLINIO Un’altra funzione molto usata è ‘str()’ che permette di avere informazioni sulla struttura di un oggetto creato in R: str(tabella) ## &#39;data.frame&#39;: 6 obs. of 3 variables: ## $ Parc : num 1 2 3 4 5 6 ## $ Tesi : Factor w/ 3 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;: 1 1 2 2 3 3 ## $ Produzioni: num 12 15 16 13 11 19 R ci informa che l’oggetto ‘tabella’ è in realtà un dataframe composto da tre colonne, di cui la prima e la terza sono numeriche, mentre la seconda è una variabile qualitativa (fattore). Altre informazioni riassuntive su un oggetto possono essere ottenute con la funzione ‘summary()’, che fornisce un output diverso a seconda dell’oggetto che le viene passato come argomento: summary(nomi) ## Length Class Mode ## 4 character character summary(classe) ## Donna Uomo ## 3 2 summary(tabella) ## Parc Tesi Produzioni ## Min. :1.00 A:2 Min. :11.00 ## 1st Qu.:2.25 B:2 1st Qu.:12.25 ## Median :3.50 C:2 Median :14.00 ## Mean :3.50 Mean :14.33 ## 3rd Qu.:4.75 3rd Qu.:15.75 ## Max. :6.00 Max. :19.00 Tra le funzioni di uso comune, citiamo quelle che si impiegano per fare alcune semplici operazioni su un dataframe, come l’ordinamento o la selezione di records. Ad esempio, è possibile estrarre da un dataframe un subset di dati utilizzando la funzione ‘subset()’: tabella2 &lt;- subset(tabella, Tesi == &quot;A&quot; | Tesi == &quot;C&quot;) tabella2 ## Parc Tesi Produzioni ## 1 1 A 12 ## 2 2 A 15 ## 5 5 C 11 ## 6 6 C 19 Notare il carattere “|” che esprime la condizione logica OR. La condizione logica AND si esprime con il carattere “&amp;”. L’esempio seguente isola i record in cui le varietà sono A o C e, contemporaneamente, la produzione è minore di 19. tabella3 &lt;- subset(tabella, Tesi == &quot;A&quot; | Tesi == &quot;C&quot; &amp; Produzioni &lt; 19) tabella3 ## Parc Tesi Produzioni ## 1 1 A 12 ## 2 2 A 15 ## 5 5 C 11 Un vettore (numerico o carattere) può essere ordinato con la funzione ‘sort()’: y &lt;- c(12, 15, 11, 17, 12, 8, 7, 15) sort(y, decreasing = FALSE) ## [1] 7 8 11 12 12 15 15 17 z &lt;- c(&quot;A&quot;, &quot;C&quot;, &quot;D&quot;, &quot;B&quot;, &quot;F&quot;, &quot;L&quot;, &quot;M&quot;, &quot;E&quot;) sort(z, decreasing = TRUE) ## [1] &quot;M&quot; &quot;L&quot; &quot;F&quot; &quot;E&quot; &quot;D&quot; &quot;C&quot; &quot;B&quot; &quot;A&quot; Un dataframe può essere invece ordinato con la funzione order(), facendo attenzione al segno meno utilizzabile per l’ordinamento decrescente. dataset[order(dataset$z, dataset$y), ] dataset[order(dataset$z, -dataset$y), ] 13.7 Creazione di funzioni personalizzate Anche se R contiene tantissime funzioni, a volte ci troviamo nella necessità di creare una funzione personale, se questa non fosse già disponibile. Immaginiamo, ad esempio, di voler scrivere una funzione che, dato il valore della produzione rilevata in una parcella di orzo di 20 $ m^2 $ (in kg) e la sua umidità percentuale, calcoli automaticamente il valore della produzione secca in kg/ha. La funzione che dobbiamo implementare è: \\[ PS = PU \\cdot \\frac{100 - U}{100} \\cdot \\frac{10000}{20}\\] dove PS è la produzione secca in kg/ha e PU è la produzione in kg per 20 $ m^2 $ con l’umidità percentuale U. Il codice è: PS &lt;- function(PU, U) { PU*((100-U)/100)*(10000/20) } Notare l’uso delle parentesi graffe. Una volta creata ed inviata alla console, la funzione può essere utilizzata come ogni altre funzione di R: PS(PU = 20, U = 85) ## [1] 1500 13.8 Uso di librerie aggiuntive Le funzionalità di R possono essere anche estese installando librerie aggiuntive. Il comando è: install.packages(&quot;NomeLibreria&quot;) Un libreria si installa ‘una tantum’, ma va caricata ogni volta che la si vuole usare: library(&quot;NomeLibreria&quot;) 13.9 Workspace Gli oggetti creati durante una sessione di lavoro vengono memorizzati nel cosiddetto workspace (ambiente di lavoro). Per il salvataggio del workspace nella directory corrente si usa il menu (File/Save Workspace) oppure il comando: save.image(&#39;nomefile.RData&#39;) Il contenuto del workspace viene visualizzato con: ls() Il workspace viene richiamato da menu (File/Open Workspace) oppure con il comando: load(&#39;nomefile.RData&#39;) Per un lavoro efficiente in R è bene tenere il workspace molto pulito, eliminando gli oggetti non necessari. La completa eliminazione degli oggetti nel workspace si esegue con: rm(list=ls()) Uno o più oggetti specifici possono essere eliminati con: rm(oggetto1, oggetto2, .....) Gli oggetti possono anche essere richiamati in base alla loro posizione; ad esempio il comando: rm(list=ls()[3:4]) elimina il terzo e il quarto oggetto dal workspace. Un comando particolarmente utile è il seguente: rm(list=ls()[ls()!=&quot;oggetto1&quot;]) che permette di eliminare dal workspace ogni oggetto meno “oggetto1”. Si possono utilizzare anche clausole logiche più articolate come la seguente: rm(list=ls()[ls()!=&quot;oggetto1&quot; &amp; ls()!=&quot;oggetto2&quot;]) che elimina tutto meno “oggetto1” e “oggetto2”. 13.10 Importare dati esterni Oltre che immessi da tastiera, i dati possono essere importati in R da files esterni, ad esempio in formato EXCEL. Per essere importata, una tabella deve essere in formato ‘ordinato’ (tidy data), vale a dire: la prima riga dovrebbe contenere i nomi delle colonne ci dovrebbe essere una riga per ogni soggetto ci dovrebbe essere una colonna per ogni attributo dei soggetti Detto ciò, avremo bisogno di una libreria addizionale, che dovremo installare (‘una tantum’) e poi caricare in memoria, utilizzando il codice sottostante: # install.packages(&quot;readxl&quot;) # solo la prima volta library(readxl) A questo punto, in R, possiamo digitare il seguente comando, che permette di selezionare un file, tramite una ‘form’ di selezione e, da questo, importare il foglio di lavoro con il nome ‘Foglio1’. dati &lt;- read_xlsx(file.choose(), sheet = &quot;Foglio1&quot;) dati Per importare un file di testo (ad esempio in formato comma delineated, cioè .csv) si utilizza il seguente comando: dataset &lt;- read.csv(&quot;NomeFile.csv&quot;, sep = &quot;;&quot;, dec = &quot;,&quot;) dove gli argomenti ‘sep’ e ‘dec’ permettono di specificare, rispettivamente, il separatore di elenco e il separatore decimale. E’ possibile anche esportare un dataframe in un file di testo, con il codice seguente: write.table(nomeDataframe, file = &quot;residui.csv&quot;, row.names=FALSE, sep=&quot;;&quot;, dec = &quot;,&quot;) 13.11 Cenni sulle funzionalità grafiche in R R è un linguaggio abbastanza potente e permette di creare grafici interessanti. Ovviamente un trattazione esauriente esula dagli scopi di questo testo, anche se è opportuno dare alcune indicazioni che potrebbero essere utili in seguito. La funzione più utilizzata per produrre grafici è: plot(x, y, type, xlab, ylab, col) dove x ed y sono i vettori con le coordinate dei punti da disegnare, ‘type’ rappresenta il tipo di grafico (‘’p’’ produce un grafico a punti, ‘’l’’ un grafico a linee, ‘’b’’ disegna punti uniti da linee, ‘’h’’ disegna istogrammi), ‘xlab’ e ‘ylab’ le etichette degli assi, ‘col’ è il colore dei punti/linee. Per una descrizione più dettagliata si consiglia di consultare la documentazione on line. A titolo di esempio, i comandi mostrati qui sotto producono l’output in Figura 13.1. x &lt;- c(1, 2, 3, 4) y &lt;- c(10, 11, 13, 17) plot(x, y, type = &quot;p&quot;, col=&quot;red&quot;, xlab=&quot;Ascissa&quot;, ylab=&quot;Ordinata&quot;) Figura 13.1: Esempio di un semplice grafico a dispersione Per sovrapporre una seconda serie di dati alla prima possiamo utilizzare la funzione ‘plot()’, come sopra e, successivamente la funzione ‘points()’ per aggiungere la nuova serie. Il risultato è quello mostrato in Figura 13.2. y2 &lt;- c(17,13,11,10) plot(x, y, type = &quot;p&quot;, col=&quot;red&quot;, xlab=&quot;Ascissa&quot;, ylab=&quot;Ordinata&quot;) points(x, y2, col=&quot;blue&quot;) Figura 13.2: Esempio di grafico con due serie di dati Se avessimo voluto sovrapporre un grafico a linee avremmo potuto utilizzare la funzione ‘lines()’ al posto della funzione ‘points()’, ottenendo l’output in Figura 13.3. plot(x, y, &quot;p&quot;, col=&quot;red&quot;, xlab=&quot;Ascissa&quot;, ylab=&quot;Ordinata&quot;) points(x, y2, col=&quot;blue&quot;) lines(x, y2, col=&quot;blue&quot;) Figura 13.3: Esempio di grafico con due serie di dati, con linee e punti Per disegnare una curva si può utilizzare la funzione ‘curve()’ ottenendo, ad esempio, l’output in Figura 13.4. curve(5 + 4 * x + 2 * x^2, from = -15, to = 15, ylab = &quot;y&quot;) Figura 13.4: Esempio di una parabola Un grafico a barre può essere ottenuto con il codice indicato più sotto, che produce il grafico in Figura 13.5 e che è di facile interpretazione. Produzioni &lt;- c(10, 12, 13, 15, 17) Genotipo &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;, &quot;E&quot;) barplot(Produzioni, names.arg = Genotipo, ylab = &quot;Produzioni (t/ha)&quot;, main = &quot;Produzioni di diversi genotipi di mais&quot;) Figura 13.5: Esempio di grafico a barre L’ultima cosa che desideriamo menzionare è la possibilità di disegnare grafici a torta, utilizzando il comando: pie(vettoreNumeri, vettoreEtichette, vettoreColori) Ad esempio il comando sottostante, produce l’output in Figura 13.6. pie(c(20,35,45),label=c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), col=c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;)) Figura 13.6: Esempio di grafico a torta 13.12 Altre letture Maindonald J. Using R for Data Analysis and Graphics - Introduction, Examples and Commentary. (PDF, data sets and scripts are available at JM’s homepage. Oscar Torres Reina, 2013. Introductio to RStudio (v. 1.3). This homepage "],["appendice-b-statistica-descrittiva-per-le-variabili-nominali.html", "Capitolo 14 Appendice B: Statistica descrittiva per le variabili nominali 14.1 Distribuzioni di frequenze e classamento 14.2 Statistiche descrittive per le distribuzioni di frequenze 14.3 Rappresentazione grafica delle distribuzioni di frequenza 14.4 Distribuzioni di frequenza bivariate: le tabelle di contingenze 14.5 Connessione 14.6 Il chi quadro con R 14.7 Altre letture 14.8 Esercizi 14.9 Soluzioni", " Capitolo 14 Appendice B: Statistica descrittiva per le variabili nominali Nel capitolo 2 abbiamo visto che le variabili qualitative sono ottenute assegnando ogni soggetto di un collettivo ad una classe scelta tra due o più possibili opzioni. Al termine di questo processo di classificazione, di solito calcoliamo le frequenza assolute, cioè il numero di individui assegnato ad ogni classe. Ad esempio, se abbiamo esaminato 500 insetti rilevando l’ordine a cui appartengono, le frequenze assolute potrebbero essere: 100 ditteri, 200 imenotteri e 150 ortotteri. Oltre alle frequenze assolute, possiamo calcolare anche le frequenze relative, dividendo le frequenze assolute per il numero totale degli individui del collettivo. Nel caso precedentemente menzionato, la frequenza relativa dei ditteri è pari a \\(100/500 = 0.2\\). Se le classi possono essere logicamente ordinate, oltre alle frequenze assolute e relative, possiamo calcolare anche le cosiddette frequenze cumulate, che si ottengono cumulando le frequenze relative di una classe con quelle di tutte le classi precedenti. 14.1 Distribuzioni di frequenze e classamento Quando rappresentiamo, in un grafico o in una tabella, le frequenze (assolute, relative o cumulate) per tutte le classi e tutti gli individui del collettivo, otteniamo una distribuzione di frequenze. In R, il calcolo delle frequenze assolute può essere eseguito utilizzando la funzione table(), che può essere combinata con la funzione length() (restituisce il numero di elementi in un vettore) per il calcolo delle frequenze relative e con la funzione cumsum() per le frequenze cumulate. Ad esempio, se consideriamo il famoso database ‘mtcars’, relativo alle 32 auto storiche censite dalla rivista Motor Trends nel 1974, e analizziamo il numero delle marce, otteniamo la seguente distribuzione di frequenze assolute, relative e cumulate. abs &lt;- table(mtcars$gear) rel &lt;- table(mtcars$gear)/length(mtcars$gear) cum &lt;- cumsum(rel) dfr &lt;- data.frame( &quot;Gears&quot; = 3:5, &quot;Freq.ass&quot; = as.numeric(abs), &quot;Freq.rel&quot; = as.numeric(rel), &quot;Freq.cum&quot; = as.numeric(cum)) knitr::kable(dfr, digits = 32) Gears Freq.ass Freq.rel Freq.cum 3 15 0.46875 0.46875 4 12 0.37500 0.84375 5 5 0.15625 1.00000 Le distribuzioni di frequenze possono essere costruite anche per le variabili quantitative, tramite un’operazione di classamento, che consiste nel suddividere il campo di variazione dei dati in una serie di intervalli (esempio, da 10 a 20, da 20 a 40 e così via) e contare i soggetti in ogni classe. In questo modo, se le osservazioni sono molto numerose, la lettura delle informazioni risulta più semplice e più completa che non elencando tutti i valori o, d’altra parte, riportando solo la loro media e la loro deviazione standard. Ad esempio, possiamo prendere 1000 numeri casuali da una distribuzione uniforme nell’intervallo da 130 a 200 ed esprimere questi mille valori tramite una distribuzione di frequenze nelle sei classi: &lt;140, 140-150, 150-160, 160-170, 170-190, &gt;190. Per questo compito si utilizza la funzione cut(), che con l’argomento breaks() consente di specificare gli estremi inferiori delle classi, inclusi per default nella classe successiva (intervalli aperti a sinistra e chiusi a destra). Ad esempio, se l’estremo inferiore della prima classe è 129 e quello della classe successiva è 140, i valori eventualmente inferiori o uguali a 129 sarebbero esclusi, quelli strettamente maggiori di 129 e minori o uguali a 140 sarebbero inclusi nella seconda classe. set.seed(1234) vals &lt;- runif(1000, min = 130, max = 200) freq &lt;- table( cut(vals, breaks = c(129, 140,150,160,170,190,200)) ) freq ## ## (129,140] (140,150] (150,160] (160,170] (170,190] ## 141 140 141 141 283 ## (190,200] ## 154 14.2 Statistiche descrittive per le distribuzioni di frequenze Per una distribuzione di frequenze, il più semplice indicatore di tendenza centrale è la moda, cioè il valore della classe che presenta la maggior frequenza. Ovviamente, se la variabile è quantitativa ed è stata sottoposta a classamento, si considera come moda il punto centrale della classe con maggior frequenza. L’individuazione della moda è banale e non richiede calcoli di sorta. In alcune condizioni (distribuzioni di frequenze per caratteri qualitativi ordinabili o quantitativi sottoposti a classamento), oltre alla moda possiamo calcolare la mediana e gli altri percentili, nonché la media e le altre statistiche descrittive indicate per i caratteri quantitativi. Tuttavia, si tratta di una situazione più tipica delle scienze economiche e sociali che non delle scienze agrarie e biologiche e, per questo motivo, non la prenderemo in ulteriore considerazione. 14.3 Rappresentazione grafica delle distribuzioni di frequenza Una distribuzione di frequenze può essere rappresentata con un grafico a torta, che, in R, può essere disegnato con ggplot, producendo un grafico a barre, con segmenti sovrapposti e ruotando il sistema di coordinate, come mostrato nel box sottostante. In questo caso il grafico è banale, in quanto le classi sono più o meno di ampiezza equivalente, dato che abbiamo utilizzato un campionamento da una distribuzione uniforme. library(ggplot2) dfr &lt;- data.frame(&quot;Class&quot; = names(freq), &quot;Freq&quot; = as.numeric(freq)) ggplot(data = dfr) + geom_bar(aes(x = NA, y = Freq, fill = Class), stat=&quot;identity&quot;, position = &quot;fill&quot;) + coord_polar(&quot;y&quot;, start=0) + theme_void() # remove background, grid, numeric labels 14.4 Distribuzioni di frequenza bivariate: le tabelle di contingenze In alcuni casi, in ciascuna unità sperimentale del collettivo vengono studiati due (o più) caratteri qualitativi, che possiamo rappresentare in una tabella di contingenze. Si tratta di tabelle a due (o più) entrate, nelle quali ogni valore rappresenta la frequenza assoluta per una particolare combinazione dei caratteri rilevati. Ad esempio, potremmo aver valutato la germinabilità di cariossidi di frumento sottoposte a due tipi di illuminazione, rossa o blu. Per ogni cariosside abbiamo quindi due informazioni, il trattamento a cui è stata sottoposta (luce rossa o blu) e se è germinata oppure no, per un totale di quattro possibili combinazioni (Rosso-si, Rosso-no, Blu-si, Blu-no). Supponendo di aver osservato 95 cariossidi germinate su 110 testate con luce rossa e 67 germinate su 120 testate con luce blu, possiamo definire la tabella di contingenze riportata di seguito. SI NO ROSSO 95 15 BLU 67 53 Ogni riga della tabella sovrastante costituisce una distribuzione di frequenze per la germinabilità, data una certa tipologia di luce (distribuzione di frequenze condizionate). 14.5 Connessione Se guardiamo le due distribuzioni condizionate per la luce rossa e blu, possiamo notare che esiste una certa differenza e che la germinabilità pare maggiore con luce rossa. Potremmo chiederci quindi se una certa modalità del carattere luce (rossa o blue) influenzi il presentarsi di una particolare modalità del carattere germinabilità (si o no). Se così fosse, potremmo parlare di dipendenza o connessione, mentre, nel caso contrario, si dovrebbe parlare di indipendenza dei caratteri. Come si fa a stabilire se i caratteri sono indipendenti o connessi? Il punto di partenza è pensare che, se i caratteri fossero indipendenti, la germinabilità dovrebbe essere la stessa con entrambi i trattamenti; in totale, abbiamo osservato 230 semi, di cui 162 sono germinati e 68 non lo sono e, di conseguenza, la proporzione di semi germinati è stata pari a 162/230 = 0.704. Ebbene, questa proporzione la si dovrebbe riscontrare con entrambi i trattamenti. In cifre, il numero di semi germinati con luce rossa dovrebbe essere pari a \\(110 \\times 0.704 = 77.44\\), mentre il numero di semi germinati con luce blu dovrebbe essere pari a \\(120 \\times 0.704 = 84.48\\). Rispettando i totali marginali (cioè il numero totale di semi saggiati con luce rossa e blu dovrebbe essere pari, rispettivamente a 110 e 120), possiamo costruire la tabella delle frequenze assolute attese, nell’ipotesi di indipendenza completa tra i due caratteri. SI NO ROSSO 77.44 32.56 BLU 84.48 35.52 A questo punto possiamo costruire un indice statistico di connessione, detto \\(\\chi^2\\), che misuri la discrepanzatra le due tabelle, quella delle frequenze osservate e quella delle frequenze teoriche che si sarebbero dovute osservare nell’ipotesi di indipendenza perfetta: \\[\\chi ^2 = \\sum \\left[ \\frac{\\left( {f_o - f_a } \\right)^2 }{f_a } \\right]\\] dove \\(f_o\\) sta per frequenza osservata ed \\(f_a\\) sta per frequenza attesa nel caso indipendenza. Questo indice assume valore pari a zero nel caso di indipendenza completa (le frequenze osservate sono uguali a quelle attese) ed assume un valore positivo tanto più alto quanto maggiore è la connessione tra i due caratteri. Nel nostro esempio: \\[\\chi^2 = \\frac{\\left( {95 - 77.44 } \\right)^2 }{77.44 } + \\frac{\\left( {15 - 32.56 } \\right)^2 }{32.56 } + \\frac{\\left( {67 - 84.48 } \\right)^2 }{84.48 } + \\frac{\\left( {53 - 35.52 } \\right)^2 }{35.52 } = 25.67\\] Se i caratteri fossero veramente indipendenti, la tabella delle frequenze osservate dovrebbe essere uguale a quella delle frequenze atteso, il che implicherebbe \\(\\chi^2 = 0\\). Il valore da noi osservato è maggiore di 0 e quindi possiamo dire che esiste un certo grado di connessione, ma non sappiamo dire quanto questa sia elevata. Qual è il \\(\\chi^2\\) massimo possibile? Intuitivamente, possiamo immaginare che la connessione potrebbe essere la più elevata possibile quando con uno dei due trattamenti i semi sono tutti germinati, mentre con l’altro non ne è germinato nessuno, come indicato nella tabella seguente: SI NO ROSSO 110 0 BLU 0 120 Se calcoliamo il valore di \\(\\chi^2\\) per la tabella sovrastante otteniamo 230, che è appunto il massimo valore possibile nella nostra condizione. Più in generale, il \\(\\chi^2\\) massimo è dato dal prodotto del numero degli individui per il valore minimo tra il numero di righe meno una e il numero di colonne meno una: \\[\\max \\chi ^2 = n \\cdot \\min (r - 1,\\,c - 1)\\] Possiamo concludere che la connessione tra i due caratteri è pari all’11% circa di quello massima (\\(25.67/230 = 0.112\\)). 14.6 Il chi quadro con R Consideriamo il dataset ‘HairEyeColor’, disponibile nell’installazione di base di R e relativo al colore degli occhi e dei capelli di 520 studenti di statistica. La tabella delle contingenze, per le femmine, è la seguente: data(HairEyeColor) tab &lt;- HairEyeColor[,,2] tab ## Eye ## Hair Brown Blue Hazel Green ## Black 36 9 5 2 ## Brown 66 34 29 14 ## Red 16 7 7 7 ## Blond 4 64 5 8 Se vogliamo sapere se il colore degli occhi è legato a quello dei capelli, possiamo utilizzare la funzione as.table() per trasformare l’oggetto tab in una tabella di contingenze (in questo caso non sarebbe necessario, visto che ‘tab’ è già una tabella di contingenze) ed applicare la funzione summary(). Oltre al chi quadro, l’output fornisce anche il P-value relativo all’ipotesi nulla che non vi sia connessione tra i due caratteri. summary(as.table (tab)) ## Number of cases in table: 313 ## Number of factors: 2 ## Test for independence of all factors: ## Chisq = 106.66, df = 9, p-value = 7.014e-19 ## Chi-squared approximation may be incorrect Nell’output si legge che l’approssimazione del chi quadro potrebbe non essere corretta in quanto, quando ci sono meno di 25-30 soggetti, l’impiego di una distribuzione continua come quella di chi quadro potrebbe non essere ottimale. Nelle tabelle ‘2 x 2’ si preferisce utilizzare la funzione chisq.test(), che fornisce, per default, la correzione di Yates per la continuità. In questo caso, la stessa funzione permette di calcolare il P-value con una simulazione di Monte Carlo, evitando il problema della mancanza di continuità. chisq.test(tab, simulate.p.value = T) ## ## Pearson&#39;s Chi-squared test with simulated ## p-value (based on 2000 replicates) ## ## data: tab ## X-squared = 106.66, df = NA, p-value = 0.0004998 14.7 Altre letture F. Crivellari (2006). Analisi statistica dei dati con R. Apogeo, Milano. G. Leti e L. Cerbara (2009). Elementi di statistica descrittiva. Il Mulino Editore, Bologna. 14.8 Esercizi Quali statistiche descrittive possono essere utilizzate con le variabili categoriche e ordinali? Illustrare brevemente e discutere Un ricercatore ha confrontato il rapporto tra maschi e femmine in una popolazione di insetti sottoposta a due trattamenti sperimentali diversi e si chiede se maschi e femmine manifestino una diversa sensibilità al trattamento in studio. Considerando che i maschi e le femmine osservati sono, rispettivamente 275 e 175 con il trattamento A e 326 e 297 con il trattamento B, valutare il grado di dipendenza tra i due caratteri (sesso e trattamento), in rapporto al valore minimo e massimo possibile per l’indicatore prescelto. Caricare il datasets ‘students’ disponibile al link: ‘https://www.casaonofri.it/_datasets/students.csv’. In questo file potete trovare una database relativo alla valutazione degli studenti in alcune materie del primo anno di Agraria. Ogni record rappresenta un esame, con il relativo voto, la materia e la scuola di provenienza dello studente. Determinare la frequenza assoluta e relativa dei diversi voti (da 18 a 30). È possibile calcolare le frequenze cumulate? Con un uso appropriato delle tabelle di contingenza e del chi quadro, valutare se il voto dipende dalla materia e dalla scuola di provenienza dello studente. 14.9 Soluzioni ## ## Pearson&#39;s Chi-squared test with Yates&#39; ## continuity correction ## ## data: tab ## X-squared = 7.8289, df = 1, p-value = 0.005142 "],["appendice-c-intervalli-di-confidenza-per-una-proporzione.html", "Capitolo 15 Appendice C: Intervalli di confidenza per una proporzione 15.1 Popolazioni gaussiane e non 15.2 Cosa fare se il teorema centrale del limite non funziona?", " Capitolo 15 Appendice C: Intervalli di confidenza per una proporzione 15.1 Popolazioni gaussiane e non Nel capitolo 6 abbiamo imparato come costruire intervalli di confidenza per stime la cui sampling distribution è, almeno approssimativamente normale. Abbiamo anche visto che questa approssimazione è buona quando (1) gli errori sono gaussiani e quando (2) i soggetti sono molto numerosi. In altre circostanze DA RIVEDERE casi potrebbe non essere così. Ad esempio, immaginiamo di avere una popolazione di insetti, nella quale il rapporto tra maschi e femmine è ignoto. Campioniamo 40 insetti e contiamo 14 femmine. Qual è la proporzione di femmine nella popolazione originaria? Stiamo studiando una grandezza che, almeno nel principio, non può essere gaussiana, ma, nonostante questo, grazie al teorema centrale del limite, possiamo utilizzare la stessa tecnica per la stima dell’intervallo di confidenza; basta sapere che la proporzione osservata è \\(p = 14/40 = 0.375\\), mentre la deviazione standard di una proporzione (che non abbiamo finora incontrato) è pari a \\(\\sigma = \\sqrt{0.375 \\times (1 - 0.375)} = 0.484\\) (Snedecor e Cochran, 1989). L’errore standard è \\(0.484 / \\sqrt{40} = 0.077\\) e l’intervallo di confidenza, considerando che il campione è molto numeroso, potrà essere approssimato come: 0.375 - 2 * 0.077 ## [1] 0.221 0.375 + 2 * 0.077 ## [1] 0.529 15.2 Cosa fare se il teorema centrale del limite non funziona? Nel caso precedente, avevamo a che fare con una distribuzione non gaussiana, ma avevamo comunque un campione numeroso, oltre ad una formula per il calcolo dell’errore standard. In altri casi, non abbiamo nessuno di questi elementi e quindi non possiamo calcolare l’intervallo di confidenza classico, come suggerito da Neyman. L’esempio tipico è la varianza, per la quale non sappiamo come calcolare un errore standard attendibile (anche se sono disponibili in letteratura alcune formule di uso comune). Ad esempio, immaginiamo di avere un campione di 30 soggetti, la cui media è pari a 7.0 e la cui varianza è 0.5. Possiamo dire che la media della popolazione che ha generato il campione è presumibilmente compresa tra: 7 - qt(0.975, 29) * sqrt(0.5)/sqrt(30) ## [1] 6.735962 e 7 + qt(0.975, 29) * sqrt(0.5)/sqrt(30) ## [1] 7.264038 Invece, in relazione alla varianza della popolazione, possiamo solo dire che la stima puntuale è pari a 0.5, ma non abbiamo una formula attendibile per stimare l’errore standard e quindi per calcolare l’intervallo di confidenza. In questo caso, possiamo determinare una sampling distribution empirica, con una simulazione di Monte Carlo, come indicato nel codice sottostante: # Simulazione Monte Carlo - Varianza set.seed(1234) result &lt;- rep(0, 100000) for (i in 1:100000){ sample &lt;- rnorm(30, 7, sqrt(0.5)) result[i] &lt;- var(sample) } mean(result) ## [1] 0.5004283 sd(result) ## [1] 0.1313021 Vediamo che la sampling distribution empirica ha media pari a 0.5 circa (questo non ci sorprende) e che l’errore standard è pari a 0.131. Possiamo anche calcolare il 2.5-esimo e il 97.5-esimo percentile ed utilizzarli come margini dell’intervallo di confidenza, che comprende al suo interno il 95% dei valori: quantile(result, probs = c(0.025, 0.975)) ## 2.5% 97.5% ## 0.2770264 0.7871032 Questo intervallo di confidenza empirico funziona piuttosto bene ed ha campi di impiego abbastanza vasti, anche quando il teorema centrale del limite non vale; tuttavia, l’intervallo di confidenza così ottenuto può non essere simmetrico rispetto alla media, il che non dovrebbe stupire, dato che la sampling distribution non è gaussiana e può essere più o meno asimmetrica. "],["appendice-e-confronto-di-due-proporzioni.html", "Capitolo 16 Appendice E: Confronto di due proporzioni 16.1 Il test di ‘chi quadro’ 16.2 Confronto tra due proporzioni con simulazione di Monte Carlo 16.3 Esercizi", " Capitolo 16 Appendice E: Confronto di due proporzioni Il test di t, con tutte le sue varianti, è fondamentalmente basato sul rapporto tra una stima ed il suo errore standard, la cui sampling distribution è approssimativamente gaussiana o, più precisamente, segue la distribuzione di ‘t di Student’. Tuttavia, io posso testare ipotesi di ogni tipo, mi basta avere una qualunque statistica che descriva l’andamento dell’esperimento e conoscere la sua sampling distribution, assumendo che l’ipotesi nulla sia vera. Questa sampling distribution può essere empirica (cioè ottenuta per simulazione Monte Carlo) o meglio teorica, scelta in base a considerazioni di natura statistico-matematica; su di essa, vado a cercare la probabilità di trovare valori per la statistica in studio che siano tanto estremi o più estremi di quello da noi riscontrato. 16.1 Il test di ‘chi quadro’ Ad esempio, immaginiamo che io abbia una stima pari a 22 ed immaginiamo che la sampling distribution per questa stima, assumendo vera l’ipotesi nulla, segua la distribuzione di \\(\\chi^2\\) con 10 gradi di libertà (per menzionare una qualunque distribuzione che non conosciamo ancora). Allora io posso ottenere un P-level per l’ipotesi nulla andandomi a guardare la probabilità di osservare un valore altrettanto estremo o più estremo di 22 (test ad una coda), come indicato nel box sottostante. pchisq(22, 10, lower.tail = F) ## [1] 0.0151046 Il test di \\(\\chi^2\\) funziona esattamente in questo modo ed è utilizzato per valutare la significatività della connessione tra due caratteri qualitativi, per i quali sia stata costruita una tabella delle contingenze (ricordate il Capitolo 3?). Ad esempio, immaginiamo un esperimento per verificare se un coadiuvante aumenta l’efficacia di un insetticida. In questo esperimento, utilizziamo l’insetticida da solo e miscelato con il coadiuvante su due gruppi di insetti diversi. Nel primo gruppo (trattato con insetticida) contiamo 56 morti su 75 insetti trattate, mentre nel secondo gruppo (trattato con insetticida e coadiuvante) otteniamo 48 morti su 50 insetti trattati. Nel capitolo 3 abbiamo visto come costruire una tabella di contingenze e come calcolare il \\(\\chi^2\\) per misurare l’entità della connessione: counts &lt;- c(56, 19, 48, 2) tab &lt;- matrix(counts, 2, 2, byrow = T) row.names(tab) &lt;- c(&quot;I&quot;, &quot;IC&quot;) colnames(tab) &lt;- c(&quot;M&quot;, &quot;V&quot;) tab ## M V ## I 56 19 ## IC 48 2 summary( as.table(tab) ) ## Number of cases in table: 125 ## Number of factors: 2 ## Test for independence of all factors: ## Chisq = 9.768, df = 1, p-value = 0.001776 Il valore di \\(\\chi^2\\) osservato è pari a 9.768, il che indica un certo grado di connessione, in quanto è diverso dal valore atteso in assenza di connessione che sarebbe zero (Capitolo 3). Tuttavia, noi non siamo interessati solo ai 125 insetti osservati, ma siamo interessati a trarre conclusioni generali e valide per l’intera popolazione che ha generato il nostro campione. A questo fine abbiamo bisogno di un test d’ipotesi formale; se non esiste connessione, la proporzione di insetti controllati dal trattamento dovrebbe la stessa, indipendentemente dalla presenza del coadiuvante. Cioè: \\[H_o :\\pi_1 = \\pi_2 = \\pi\\] Vediamo che, come negli altri esempio, l’ipotesi nulla riguarda i parametri delle popolazioni (\\(\\pi_1\\) e \\(\\pi_2\\)), non quelli dei campioni (\\(p_1\\) e \\(p_2\\)). Ci chiediamo: se l’ipotesi nulla fosse vera (\\(\\pi_1 = \\pi_2\\)), quale sarebbe la sampling distribution per \\(\\chi^2\\)? E soprattutto, quanto sarebbe probabile ottenere un valore alto come il nostro o più alto? Karl Pearson ha dimostrato che il valore di \\(\\chi^2\\), quando l’ipotesi nulla è vera, segue la distribuzione di \\(\\chi^2\\), con un numero di gradi di libertà pari a quelli della tabelle delle contingenze (bisogna prendere il minimo valore tra il numero di righe meno una e il numero di colonne meno una; vedi il Capitolo 3). Il box sottostante mostra come utilizzare la funzione ‘pchi()’ per il calcolo del P-level (in questo caso il test è ad una coda, perché la connessione implica valori di \\(\\chi^2\\) alti e non bassi). pchisq(9.768, df = 1, lower.tail = F) ## [1] 0.001775755 Vediamo che questo P-level era già disponibile nell’output della funzione summary(); essendo inferiore a 0.05, ci consente di rigettare l’ipotesi nulla, affermando che esiste una differenza significativa tra l’effetto dell’insetticida quando è utilizzato da solo e quando è utilizzando in abbinamento con un coadiuvante. Allo stesso risultato, ma in modo più semplice, è possibile pervenire utilizzando la funzione chisq.test(), applicata alla tabella di contingenza: chisq.test(tab, correct = F) ## ## Pearson&#39;s Chi-squared test ## ## data: tab ## X-squared = 9.768, df = 1, p-value = 0.001776 L’opzione ‘correct = F’ permette di evitare la correzione per la continuità (correzione di Yates), che è invece necessaria quando il numero dei soggetti è piccolo (minore di 30, grosso modo). 16.2 Confronto tra due proporzioni con simulazione di Monte Carlo Vi sono situazioni nelle quali non vi è una chiara indicazione su quale sia la distribuzione di probabilità/densità più opportuna per descrivere la sampling distribution di una statistica sotto l’ipotesi nulla. Ciò è vero anche per il test di \\(\\chi^2\\) appena esposto, per il quale la distribuzione di \\(\\chi^2\\) è cosniderata solo una buona approssimazione. In queste situazioni è possibile costruire una sampling distribution empirica analogamente a quanto abbiamo fatto in precedenza per il test di t di Student. Nel caso del test di \\(\\chi^2\\), possiamo utilizzare la funzione r2dtable(), che, partendo da una situazione in cui l’ipotesi nulla è vera (cioè \\(\\pi_1 = \\pi_2\\)) e quindi i due caratteri sono indipendenti, produce tante tabelle di contingenza (nel nostro caso 10’000), rispettando i totali marginali della nostra tabella di partenza. Le tabelle prodotte sono restituite come lista, quindi possiamo utilizzare la funzione lapply() per applicare ad ogni elemento della lista la funzione che restituisce il \\(\\chi^2\\) (‘chiSim’). chiSim &lt;- function(x) summary(as.table(x))$stat set.seed(1234) tabs &lt;- r2dtable(10000, apply(tab, 1, sum), apply(tab, 2, sum)) chiVals &lt;- as.numeric( lapply( tabs, chiSim) ) length(chiVals[chiVals &gt; 9.768]) ## [1] 19 Vediamo che vi sono 19 valori so 10’000 più alti di quello da noi osservato, quindi il P-value è 0.0019, molto simile a quello osservato con il test formale. 16.3 Esercizi Uno sperimentatore ha impostato un esperimento per verificare l’effetto di un fungicida (A) in confronto al testimone non trattato (B), in base al numero di colonie fungine sopravvissute. Il numero delle colonie trattate è di 200 con 20 sopravvissute, mentre il numero di quelle non trattate è di 100, con 50 sopravvissute. Stabilire se i risultati possono essere considerati significativamente diversi, per un livello di probabilità del 5%. Immaginate di aver riscontrato che, in determinate condizioni ambientali, 60 olive su 75 sono attaccate da Daucus olee (mosca dell’olivo). Nelle stesse condizioni ambientali, diffondendo in campo un insetto predatore siamo riusciti a ridurre il numero di olive attaccate a 12 su 75. Si tratta di una oscillazione casuale del livello di attacco o possiamo concludere che l’insetto predatore è stato un mezzo efficace di lotta biologica alla mosca dell’olivo? Sono stati osservati 153 calciatori registrando la dominanza della mano e quella del piede e sono state riscontrate le seguenti frequenze: 26 con dominanza di mano e piede sinistro, 11 con dominanza mano sinistra e piede destro, 21 con dominanza mano destra e piede sinistro e 95 con dominanza di mano e piede destro. Sulla base di questi dati, possiamo concludere che esiste una dipendenza tra la dominanza della mano e del piede? Un botanico ha valutato il numero di semi germinati per colza sottoposto a due diversi regimi termici dopo l’imbibizione (15 e 25°C). Per la temperatura più bassa, su 400 semi posti in prova, ne sono germinati 358. Alla temperatura più alta, su 380 semi in prova, ne sono germinati 286. Descrivere i due campioni, in termini di proporzione di semi germinati. Inferire la proporzione di germinati nell’intera popolazione di semi da cui è stato estratto il nostro campione casuale di 780 semi. Utilizzare opportunamente un intervallo di confidenza, sapendo che la varianza di una proporzione è una quantità fissa, che si calcola come \\(p ( 1- p)\\) (dove ‘p’ è la proporzione osservata. Esiste una differenza significativa tra le proporzioni delle due popolazioni? Esplicitare l’ipotesi nulla e calcolare la probabilità di errore relativa al suo rifiuto. "],["appendice-f-alcuni-problemi-collegati-con-le-deviazioni-rispetti-agli-assunti-di-base.html", "Capitolo 17 Appendice F: Alcuni problemi collegati con le deviazioni rispetti agli assunti di base", " Capitolo 17 Appendice F: Alcuni problemi collegati con le deviazioni rispetti agli assunti di base Nel codice sottostante abbiamo immaginato di campionare residui da distribuzioni normali con la stessa media, ma diverse deviazioni standard per ognuno dei quattro trattamenti sperimentali. Abbiamo quindi ottenuti 100’000 datasets nei quali l’ipotesi nulla è vera (nessuna differenza tra le medie), ma non sussiste l’omogeneità delle varianze. Sottoponendo questi datasets ad ANOVA, notiamo che la sampling distribution per F non può essere descritta con la curva di densità F di Fisher e, soprattutto, che quest’ultima funzione, nella coda destra, produce una chiara sottostima della probabilità reale e, quindi del P-value. In altre parole, quando non vi è omoscedasticità, si può incorrere in un incremento del rischio di rifiutare erroneamente l’ipotesi nulla, il che rende le nostre conclusioni molto meno attendibili. Fvals &lt;- c() set.seed(1234) Treat &lt;- factor(rep(1:4, each = 4)) for(i in 1:100000){ # Ysim &lt;- rnorm(16, 14.48375, 3.9177) # Omoscedasticità Ysim1 &lt;- rnorm(4, 14.48375, 0.39177) Ysim2 &lt;- rnorm(4, 14.48375, 3.9177) Ysim3 &lt;- rnorm(4, 14.48375, 6.9177) Ysim4 &lt;- rnorm(4, 14.48375, 9.9177) Ysim &lt;- c(Ysim1, Ysim2, Ysim3, Ysim4) mod &lt;- lm(Ysim ~ Treat) Fvals[i] &lt;- anova(mod)$F[1] } # b &lt;- seq(0, 65, by=0.1) # hist(Fvals, breaks = b, xlim = c(0, 6), freq = F, # xlab = &quot;F&quot;, ylab = &quot;Density&quot;, main = &quot;&quot;) # curve(df(x, 3, 12), add=T, col=&quot;blue&quot;) knitr::include_graphics(&quot;_images/SamplingDistribF_false.png&quot;) Figura 17.1: Sampling distribution empirica per F, in caso di disomogeneità delle varianze. Vediamo che, in questo caso, la funzione di densità F di Fisher non costituisce un buon riferimento per il calcolo del P-level. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
