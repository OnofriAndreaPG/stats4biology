<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Metodologia sperimentale per le scienze agrarie</title>
  <meta name="description" content="Appunti dai corsi S.I.A.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Metodologia sperimentale per le scienze agrarie" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Appunti dai corsi S.I.A." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Metodologia sperimentale per le scienze agrarie" />
  
  <meta name="twitter:description" content="Appunti dai corsi S.I.A." />
  

<meta name="author" content="Andrea Onofri e Dario Sacco">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="appendix-2-richiami-di-statistica-descrittiva.html">

<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global Site Tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131792052-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-131792052-1');
  </script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduzione</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#organizzazione-del-testo"><i class="fa fa-check"></i>Organizzazione del testo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#gli-autori"><i class="fa fa-check"></i>Gli autori</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#pre-requisiti"><i class="fa fa-check"></i>Pre-requisiti</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#package-aggiuntivi"><i class="fa fa-check"></i>Package aggiuntivi</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html"><i class="fa fa-check"></i><b>1</b> Scienza e pseudo-scienza</a><ul>
<li class="chapter" data-level="1.0.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#cosa-e-quindi-una-prova-scientifica"><i class="fa fa-check"></i><b>1.0.1</b> Cosa è quindi una prova scientifica?</a></li>
<li class="chapter" data-level="1.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#esperimenti-buoni-e-cattivi"><i class="fa fa-check"></i><b>1.1</b> Esperimenti buoni e cattivi!</a><ul>
<li class="chapter" data-level="1.1.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#lerrore-sperimentale"><i class="fa fa-check"></i><b>1.1.1</b> L’errore sperimentale</a></li>
<li class="chapter" data-level="1.1.2" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#il-campionamento"><i class="fa fa-check"></i><b>1.1.2</b> Il campionamento</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#scienza-metodo"><i class="fa fa-check"></i><b>1.2</b> Scienza = metodo</a></li>
<li class="chapter" data-level="1.3" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#chi-valuta-se-un-esperimento-e-attendibile"><i class="fa fa-check"></i><b>1.3</b> Chi valuta se un esperimento è attendibile?</a></li>
<li class="chapter" data-level="1.4" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#il-metodo-sperimentale"><i class="fa fa-check"></i><b>1.4</b> Il metodo sperimentale</a></li>
<li class="chapter" data-level="1.5" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#metodi-sperimentali-validi-ed-invalidi"><i class="fa fa-check"></i><b>1.5</b> Metodi sperimentali validi ed invalidi</a><ul>
<li class="chapter" data-level="1.5.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#primo-esperimento"><i class="fa fa-check"></i><b>1.5.1</b> Primo esperimento</a></li>
<li class="chapter" data-level="1.5.2" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#secondo-esperimento"><i class="fa fa-check"></i><b>1.5.2</b> Secondo esperimento</a></li>
<li class="chapter" data-level="1.5.3" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#terzo-esperimento"><i class="fa fa-check"></i><b>1.5.3</b> Terzo esperimento</a></li>
<li class="chapter" data-level="1.5.4" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#quarto-esperimento-quello-buono"><i class="fa fa-check"></i><b>1.5.4</b> Quarto esperimento: quello buono</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#incertezza-residua"><i class="fa fa-check"></i><b>1.6</b> Incertezza residua</a></li>
<li class="chapter" data-level="1.7" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#il-ruolo-della-statistica"><i class="fa fa-check"></i><b>1.7</b> Il ruolo della statistica</a></li>
<li class="chapter" data-level="1.8" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#conclusioni"><i class="fa fa-check"></i><b>1.8</b> Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html"><i class="fa fa-check"></i><b>2</b> Esperimenti validi ed invalidi</a><ul>
<li class="chapter" data-level="2.1" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#definizioni"><i class="fa fa-check"></i><b>2.1</b> Definizioni</a></li>
<li class="chapter" data-level="2.2" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#elementi-fondamentali-del-disegno-sperimentale"><i class="fa fa-check"></i><b>2.2</b> Elementi fondamentali del disegno sperimentale</a><ul>
<li class="chapter" data-level="2.2.1" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#primo-elemento-controllo-degli-errori"><i class="fa fa-check"></i><b>2.2.1</b> Primo elemento: controllo degli errori</a></li>
<li class="chapter" data-level="2.2.2" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#secondo-elemento-replicazione"><i class="fa fa-check"></i><b>2.2.2</b> Secondo elemento: replicazione</a></li>
<li class="chapter" data-level="2.2.3" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#terzo-elemento-randomizzazione"><i class="fa fa-check"></i><b>2.2.3</b> Terzo elemento: randomizzazione</a></li>
<li class="chapter" data-level="2.2.4" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#esperimenti-non-validi"><i class="fa fa-check"></i><b>2.2.4</b> Esperimenti non validi</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#conclusione"><i class="fa fa-check"></i><b>2.3</b> Conclusione</a></li>
<li class="chapter" data-level="2.4" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#per-approfondimenti"><i class="fa fa-check"></i><b>2.4</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html"><i class="fa fa-check"></i><b>3</b> Progettare un esperimento</a><ul>
<li class="chapter" data-level="3.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#ipotesi-scientifica-rightarrow-obiettivo-dellesperimento"><i class="fa fa-check"></i><b>3.1</b> Ipotesi scientifica <span class="math inline">\(\rightarrow\)</span> obiettivo dell’esperimento</a></li>
<li class="chapter" data-level="3.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#identificazione-dei-fattori-sperimentali"><i class="fa fa-check"></i><b>3.2</b> Identificazione dei fattori sperimentali</a><ul>
<li class="chapter" data-level="3.2.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esperimenti-multifattoriali"><i class="fa fa-check"></i><b>3.2.1</b> Esperimenti (multi)fattoriali</a></li>
<li class="chapter" data-level="3.2.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#aggiungere-un-controllo"><i class="fa fa-check"></i><b>3.2.2</b> Aggiungere un controllo?</a></li>
<li class="chapter" data-level="3.2.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#fattori-sperimentali-di-trattamento-e-di-blocco"><i class="fa fa-check"></i><b>3.2.3</b> Fattori sperimentali di trattamento e di blocco</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#identificazione-delle-unita-sperimentali"><i class="fa fa-check"></i><b>3.3</b> Identificazione delle unità sperimentali</a><ul>
<li class="chapter" data-level="3.3.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#cornice-di-campionamento"><i class="fa fa-check"></i><b>3.3.1</b> Cornice di campionamento</a></li>
<li class="chapter" data-level="3.3.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#scelta-delle-unita-sperimentali"><i class="fa fa-check"></i><b>3.3.2</b> Scelta delle unità sperimentali</a></li>
<li class="chapter" data-level="3.3.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#unita-sperimentali-in-campo-le-parcelle"><i class="fa fa-check"></i><b>3.3.3</b> Unità sperimentali in campo: le parcelle</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#allocazione-dei-trattamenti-e-disegno-sperimentale"><i class="fa fa-check"></i><b>3.4</b> Allocazione dei trattamenti e disegno sperimentale</a><ul>
<li class="chapter" data-level="3.4.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#disegni-completamente-randomizzati"><i class="fa fa-check"></i><b>3.4.1</b> Disegni completamente randomizzati</a></li>
<li class="chapter" data-level="3.4.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#disegni-a-blocchi-randomizzati"><i class="fa fa-check"></i><b>3.4.2</b> Disegni a blocchi randomizzati</a></li>
<li class="chapter" data-level="3.4.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#disegni-a-quadrato-latino"><i class="fa fa-check"></i><b>3.4.3</b> Disegni a quadrato latino</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#scelta-delle-variabili-da-rilevare"><i class="fa fa-check"></i><b>3.5</b> Scelta delle variabili da rilevare</a><ul>
<li class="chapter" data-level="3.5.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-nominali-categoriche"><i class="fa fa-check"></i><b>3.5.1</b> Variabili nominali (categoriche)</a></li>
<li class="chapter" data-level="3.5.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-ordinali"><i class="fa fa-check"></i><b>3.5.2</b> Variabili ordinali</a></li>
<li class="chapter" data-level="3.5.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-quantitative-discrete"><i class="fa fa-check"></i><b>3.5.3</b> Variabili quantitative discrete</a></li>
<li class="chapter" data-level="3.5.4" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-quantitative-continue"><i class="fa fa-check"></i><b>3.5.4</b> Variabili quantitative continue</a></li>
<li class="chapter" data-level="3.5.5" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#rilievi-visivi-e-sensoriali"><i class="fa fa-check"></i><b>3.5.5</b> Rilievi visivi e sensoriali</a></li>
<li class="chapter" data-level="3.5.6" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-di-confondimento"><i class="fa fa-check"></i><b>3.5.6</b> Variabili di confondimento</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#impianto-delle-prove"><i class="fa fa-check"></i><b>3.6</b> Impianto delle prove</a></li>
<li class="chapter" data-level="3.7" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#scrivere-un-progettoreport-di-ricerca-semplici-indicazioni"><i class="fa fa-check"></i><b>3.7</b> Scrivere un progetto/report di ricerca: semplici indicazioni</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html"><i class="fa fa-check"></i><b>4</b> Come si generano le osservazioni sperimentali?</a><ul>
<li class="chapter" data-level="4.1" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#verita-vera-e-modelli-deterministici"><i class="fa fa-check"></i><b>4.1</b> Verità ‘vera’ e modelli deterministici</a><ul>
<li class="chapter" data-level="4.1.1" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#qualche-esempio-di-modello-deterministico"><i class="fa fa-check"></i><b>4.1.1</b> Qualche esempio di modello deterministico</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#genesi-deterministica-delle-osservazioni-sperimentali"><i class="fa fa-check"></i><b>4.2</b> Genesi deterministica delle osservazioni sperimentali</a></li>
<li class="chapter" data-level="4.3" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#errore-sperimentale-e-modelli-stocastici"><i class="fa fa-check"></i><b>4.3</b> Errore sperimentale e modelli stocastici</a><ul>
<li class="chapter" data-level="4.3.1" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#funzioni-di-probabilita"><i class="fa fa-check"></i><b>4.3.1</b> Funzioni di probabilità</a></li>
<li class="chapter" data-level="4.3.2" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#funzioni-di-densita"><i class="fa fa-check"></i><b>4.3.2</b> Funzioni di densità</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#la-distribuzione-normale-curva-di-gauss"><i class="fa fa-check"></i><b>4.4</b> La distribuzione normale (curva di Gauss)</a></li>
<li class="chapter" data-level="4.5" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#modelli-a-due-facce"><i class="fa fa-check"></i><b>4.5</b> Modelli ‘a due facce’</a><ul>
<li class="chapter" data-level="4.5.1" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#esercizio-1"><i class="fa fa-check"></i><b>4.5.1</b> Esercizio 1</a></li>
<li class="chapter" data-level="4.5.2" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#esercizio-2"><i class="fa fa-check"></i><b>4.5.2</b> Esercizio 2</a></li>
<li class="chapter" data-level="4.5.3" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#esercizio-3"><i class="fa fa-check"></i><b>4.5.3</b> Esercizio 3</a></li>
<li class="chapter" data-level="4.5.4" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#esercizio-4"><i class="fa fa-check"></i><b>4.5.4</b> Esercizio 4</a></li>
<li class="chapter" data-level="4.5.5" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#esercizio-5"><i class="fa fa-check"></i><b>4.5.5</b> Esercizio 5</a></li>
<li class="chapter" data-level="4.5.6" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#esercizio-6"><i class="fa fa-check"></i><b>4.5.6</b> Esercizio 6</a></li>
<li class="chapter" data-level="4.5.7" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#esercizio-7"><i class="fa fa-check"></i><b>4.5.7</b> Esercizio 7</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#altri-modelli-stocastici-di-interesse-per-lo-sperimentatore"><i class="fa fa-check"></i><b>4.6</b> Altri modelli stocastici di interesse per lo sperimentatore</a></li>
<li class="chapter" data-level="4.7" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#e-allora"><i class="fa fa-check"></i><b>4.7</b> E allora?</a></li>
<li class="chapter" data-level="4.8" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#le-simulazioni-monte-carlo"><i class="fa fa-check"></i><b>4.8</b> Le simulazioni Monte Carlo</a></li>
<li class="chapter" data-level="4.9" data-path="come-si-generano-le-osservazioni-sperimentali.html"><a href="come-si-generano-le-osservazioni-sperimentali.html#analisi-dei-dati-e-model-fitting"><i class="fa fa-check"></i><b>4.9</b> Analisi dei dati e ‘model fitting’</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html"><i class="fa fa-check"></i><b>5</b> Stime ed incertezza</a><ul>
<li class="chapter" data-level="5.1" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#lanalisi-dei-dati-gli-ingredienti-fondamentali"><i class="fa fa-check"></i><b>5.1</b> L’analisi dei dati: gli ‘ingredienti’ fondamentali</a></li>
<li class="chapter" data-level="5.2" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#esempio-una-soluzione-erbicida"><i class="fa fa-check"></i><b>5.2</b> Esempio: una soluzione erbicida</a><ul>
<li class="chapter" data-level="5.2.1" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#il-modello-dei-dati"><i class="fa fa-check"></i><b>5.2.1</b> Il modello dei dati</a></li>
<li class="chapter" data-level="5.2.2" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#analisi-dei-dati-stima-dei-parametri"><i class="fa fa-check"></i><b>5.2.2</b> Analisi dei dati: stima dei parametri</a></li>
<li class="chapter" data-level="5.2.3" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#la-sampling-distribution"><i class="fa fa-check"></i><b>5.2.3</b> La ‘sampling distribution’</a></li>
<li class="chapter" data-level="5.2.4" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#lerrore-standard"><i class="fa fa-check"></i><b>5.2.4</b> L’errore standard</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#riepilogo-1-caratterizzare-lincertezza-di-un-esperimento"><i class="fa fa-check"></i><b>5.3</b> Riepilogo 1: Caratterizzare l’incertezza di un esperimento</a></li>
<li class="chapter" data-level="5.4" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#lintervallo-di-confidenza"><i class="fa fa-check"></i><b>5.4</b> L’intervallo di confidenza</a></li>
<li class="chapter" data-level="5.5" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#qual-e-il-senso-dellintervallo-di-confidenza"><i class="fa fa-check"></i><b>5.5</b> Qual è il senso dell’intervallo di confidenza?</a></li>
<li class="chapter" data-level="5.6" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#come-presentare-i-risultati-degli-esperimenti"><i class="fa fa-check"></i><b>5.6</b> Come presentare i risultati degli esperimenti</a></li>
<li class="chapter" data-level="5.7" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#alcune-precisazioni"><i class="fa fa-check"></i><b>5.7</b> Alcune precisazioni</a><ul>
<li class="chapter" data-level="5.7.1" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#campioni-numerosi-e-non"><i class="fa fa-check"></i><b>5.7.1</b> Campioni numerosi e non</a></li>
<li class="chapter" data-level="5.7.2" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#popolazioni-gaussiane-e-non"><i class="fa fa-check"></i><b>5.7.2</b> Popolazioni gaussiane e non</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#analisi-statistica-dei-dati-riassunto-del-percorso-logico"><i class="fa fa-check"></i><b>5.8</b> Analisi statistica dei dati: riassunto del percorso logico</a></li>
<li class="chapter" data-level="5.9" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#da-ricordare"><i class="fa fa-check"></i><b>5.9</b> Da ricordare</a></li>
<li class="chapter" data-level="5.10" data-path="stime-ed-incertezza.html"><a href="stime-ed-incertezza.html#esercizi"><i class="fa fa-check"></i><b>5.10</b> Esercizi</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html"><i class="fa fa-check"></i><b>6</b> Breve introduzione al test d’ipotesi</a><ul>
<li class="chapter" data-level="6.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-una-media-osservata-e-una-media-teorica"><i class="fa fa-check"></i><b>6.1</b> Confronto tra una media osservata e una media teorica</a><ul>
<li class="chapter" data-level="6.1.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#simulazione-monte-carlo"><i class="fa fa-check"></i><b>6.1.1</b> Simulazione Monte Carlo</a></li>
<li class="chapter" data-level="6.1.2" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#soluzione-formale"><i class="fa fa-check"></i><b>6.1.2</b> Soluzione formale</a></li>
<li class="chapter" data-level="6.1.3" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#interpretazione-del-p-level"><i class="fa fa-check"></i><b>6.1.3</b> Interpretazione del P-level</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-medie-il-test-t-di-student"><i class="fa fa-check"></i><b>6.2</b> Confronto tra due medie: il test t di Student</a></li>
<li class="chapter" data-level="6.3" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-proporzioni-il-test-chi2"><i class="fa fa-check"></i><b>6.3</b> Confronto tra due proporzioni: il test <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="6.4" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#conclusioni-1"><i class="fa fa-check"></i><b>6.4</b> Conclusioni</a></li>
<li class="chapter" data-level="6.5" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#riepilogo"><i class="fa fa-check"></i><b>6.5</b> Riepilogo</a></li>
<li class="chapter" data-level="6.6" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#esercizi-1"><i class="fa fa-check"></i><b>6.6</b> Esercizi</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html"><i class="fa fa-check"></i><b>7</b> Modelli ANOVA ad una via</a><ul>
<li class="chapter" data-level="7.1" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#caso-studio-confronto-tra-erbicidi-in-vaso"><i class="fa fa-check"></i><b>7.1</b> Caso-studio: confronto tra erbicidi in vaso</a></li>
<li class="chapter" data-level="7.2" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#descrizione-del-dataset"><i class="fa fa-check"></i><b>7.2</b> Descrizione del dataset</a></li>
<li class="chapter" data-level="7.3" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#definizione-di-un-modello-lineare"><i class="fa fa-check"></i><b>7.3</b> Definizione di un modello lineare</a></li>
<li class="chapter" data-level="7.4" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#parametrizzazione-del-modello"><i class="fa fa-check"></i><b>7.4</b> Parametrizzazione del modello</a><ul>
<li class="chapter" data-level="7.4.1" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#vincolo-sul-trattamento"><i class="fa fa-check"></i><b>7.4.1</b> Vincolo sul trattamento</a></li>
<li class="chapter" data-level="7.4.2" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#vincolo-sulla-somma"><i class="fa fa-check"></i><b>7.4.2</b> Vincolo sulla somma</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#assunzioni-di-base"><i class="fa fa-check"></i><b>7.5</b> Assunzioni di base</a></li>
<li class="chapter" data-level="7.6" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#stima-dei-parametri"><i class="fa fa-check"></i><b>7.6</b> Stima dei parametri</a><ul>
<li class="chapter" data-level="7.6.1" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#coefficienti-del-modello"><i class="fa fa-check"></i><b>7.6.1</b> Coefficienti del modello</a></li>
<li class="chapter" data-level="7.6.2" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#residui"><i class="fa fa-check"></i><b>7.6.2</b> Residui</a></li>
<li class="chapter" data-level="7.6.3" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#stima-di-sigma"><i class="fa fa-check"></i><b>7.6.3</b> Stima di <span class="math inline">\(\sigma\)</span></a></li>
<li class="chapter" data-level="7.6.4" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#sem-e-sed"><i class="fa fa-check"></i><b>7.6.4</b> SEM e SED</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#scomposizione-della-varianza"><i class="fa fa-check"></i><b>7.7</b> Scomposizione della varianza</a></li>
<li class="chapter" data-level="7.8" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#analisi-della-varianza"><i class="fa fa-check"></i><b>7.8</b> Analisi della varianza</a></li>
<li class="chapter" data-level="7.9" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#test-dipotesi"><i class="fa fa-check"></i><b>7.9</b> Test d’ipotesi</a></li>
<li class="chapter" data-level="7.10" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#operazioni-con-r"><i class="fa fa-check"></i><b>7.10</b> Operazioni con R</a></li>
<li class="chapter" data-level="7.11" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#medie-marginali-attese"><i class="fa fa-check"></i><b>7.11</b> Medie marginali attese</a></li>
<li class="chapter" data-level="7.12" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#per-concludere"><i class="fa fa-check"></i><b>7.12</b> Per concludere …</a></li>
<li class="chapter" data-level="7.13" data-path="modelli-anova-ad-una-via.html"><a href="modelli-anova-ad-una-via.html#per-approfondimenti-1"><i class="fa fa-check"></i><b>7.13</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html"><i class="fa fa-check"></i><b>8</b> La verifica delle assunzioni di base</a><ul>
<li class="chapter" data-level="8.1" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#procedure-diagnostiche"><i class="fa fa-check"></i><b>8.1</b> Procedure diagnostiche</a></li>
<li class="chapter" data-level="8.2" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#analisi-grafica-dei-residui"><i class="fa fa-check"></i><b>8.2</b> Analisi grafica dei residui</a><ul>
<li class="chapter" data-level="8.2.1" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#grafico-dei-residui-contro-i-valori-attesi"><i class="fa fa-check"></i><b>8.2.1</b> Grafico dei residui contro i valori attesi</a></li>
<li class="chapter" data-level="8.2.2" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#qq-plot"><i class="fa fa-check"></i><b>8.2.2</b> QQ-plot</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#strumenti-diagnostici-formali"><i class="fa fa-check"></i><b>8.3</b> Strumenti diagnostici formali</a></li>
<li class="chapter" data-level="8.4" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#risultati-contraddittori"><i class="fa fa-check"></i><b>8.4</b> Risultati contraddittori</a></li>
<li class="chapter" data-level="8.5" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#terapia"><i class="fa fa-check"></i><b>8.5</b> ‘Terapia’</a><ul>
<li class="chapter" data-level="8.5.1" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#correzionerimozione-degli-outliers"><i class="fa fa-check"></i><b>8.5.1</b> Correzione/Rimozione degli outliers</a></li>
<li class="chapter" data-level="8.5.2" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#correzione-del-modello"><i class="fa fa-check"></i><b>8.5.2</b> Correzione del modello</a></li>
<li class="chapter" data-level="8.5.3" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#trasformazione-della-variabile-indipendente"><i class="fa fa-check"></i><b>8.5.3</b> Trasformazione della variabile indipendente</a></li>
<li class="chapter" data-level="8.5.4" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#impiego-di-metodiche-statistiche-avanzate"><i class="fa fa-check"></i><b>8.5.4</b> Impiego di metodiche statistiche avanzate</a></li>
<li class="chapter" data-level="8.5.5" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#trasformazioni-stabilizzanti"><i class="fa fa-check"></i><b>8.5.5</b> Trasformazioni stabilizzanti</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#esempio"><i class="fa fa-check"></i><b>8.6</b> Esempio</a></li>
<li class="chapter" data-level="8.7" data-path="la-verifica-delle-assunzioni-di-base.html"><a href="la-verifica-delle-assunzioni-di-base.html#altre-letture"><i class="fa fa-check"></i><b>8.7</b> Altre letture</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html"><i class="fa fa-check"></i><b>9</b> Contrasti e confronti multipli</a><ul>
<li class="chapter" data-level="9.1" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#esempio-1"><i class="fa fa-check"></i><b>9.1</b> Esempio</a></li>
<li class="chapter" data-level="9.2" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#i-contrasti"><i class="fa fa-check"></i><b>9.2</b> I contrasti</a><ul>
<li class="chapter" data-level="9.2.1" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#varianza-del-contrasto-e-test-dipotesi"><i class="fa fa-check"></i><b>9.2.1</b> Varianza del contrasto e test d’ipotesi</a></li>
<li class="chapter" data-level="9.2.2" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#i-contrasti-con-r"><i class="fa fa-check"></i><b>9.2.2</b> I contrasti con R</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#i-confronti-multipli-a-coppie-pairwise-comparisons"><i class="fa fa-check"></i><b>9.3</b> I confronti multipli a coppie (pairwise comparisons)</a></li>
<li class="chapter" data-level="9.4" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#display-a-lettere"><i class="fa fa-check"></i><b>9.4</b> Display a lettere</a></li>
<li class="chapter" data-level="9.5" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#problemi-di-molteplicita-tassi-di-errore-per-confronto-e-per-esperimento"><i class="fa fa-check"></i><b>9.5</b> Problemi di molteplicità: tassi di errore per confronto e per esperimento</a><ul>
<li class="chapter" data-level="9.5.1" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#correzione-per-la-molteplicita"><i class="fa fa-check"></i><b>9.5.1</b> Correzione per la molteplicità</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#e-le-classiche-procedure-di-confronto-multiplo"><i class="fa fa-check"></i><b>9.6</b> E le classiche procedure di confronto multiplo?</a></li>
<li class="chapter" data-level="9.7" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#consigli-pratici"><i class="fa fa-check"></i><b>9.7</b> Consigli pratici</a></li>
<li class="chapter" data-level="9.8" data-path="contrasti-e-confronti-multipli.html"><a href="contrasti-e-confronti-multipli.html#referenze-bibliografiche"><i class="fa fa-check"></i><b>9.8</b> Referenze bibliografiche</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html"><i class="fa fa-check"></i><b>10</b> Modelli ANOVA con fattori di blocco</a><ul>
<li class="chapter" data-level="10.1" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html#caso-studio-confronto-tra-erbicidi-in-campo"><i class="fa fa-check"></i><b>10.1</b> Caso-studio: confronto tra erbicidi in campo</a></li>
<li class="chapter" data-level="10.2" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html#definizione-di-un-modello-lineare-1"><i class="fa fa-check"></i><b>10.2</b> Definizione di un modello lineare</a></li>
<li class="chapter" data-level="10.3" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html#stima-dei-parametri-1"><i class="fa fa-check"></i><b>10.3</b> Stima dei parametri</a><ul>
<li class="chapter" data-level="10.3.1" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html#coefficienti-del-modello-1"><i class="fa fa-check"></i><b>10.3.1</b> Coefficienti del modello</a></li>
<li class="chapter" data-level="10.3.2" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html#residui-e-devianze"><i class="fa fa-check"></i><b>10.3.2</b> Residui e devianze</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html#scomposizione-della-varianza-1"><i class="fa fa-check"></i><b>10.4</b> Scomposizione della varianza</a></li>
<li class="chapter" data-level="10.5" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html#disegni-a-quadrato-latino-1"><i class="fa fa-check"></i><b>10.5</b> Disegni a quadrato latino</a></li>
<li class="chapter" data-level="10.6" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html#caso-studio-confronto-tra-metodi-costruttivi"><i class="fa fa-check"></i><b>10.6</b> Caso studio: confronto tra metodi costruttivi</a></li>
<li class="chapter" data-level="10.7" data-path="modelli-anova-con-fattori-di-blocco.html"><a href="modelli-anova-con-fattori-di-blocco.html#definizione-di-un-modello-lineare-2"><i class="fa fa-check"></i><b>10.7</b> Definizione di un modello lineare</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html"><i class="fa fa-check"></i><b>11</b> Modelli ANOVA a due vie</a><ul>
<li class="chapter" data-level="11.1" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#il-concetto-di-interazione"><i class="fa fa-check"></i><b>11.1</b> Il concetto di ’interazione’</a></li>
<li class="chapter" data-level="11.2" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#tipi-di-interazione"><i class="fa fa-check"></i><b>11.2</b> Tipi di interazione</a></li>
<li class="chapter" data-level="11.3" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#caso-studio-interazione-tra-lavorazioni-e-diserbo-chimico"><i class="fa fa-check"></i><b>11.3</b> Caso-studio: interazione tra lavorazioni e diserbo chimico</a></li>
<li class="chapter" data-level="11.4" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#definizione-del-modello-lineare"><i class="fa fa-check"></i><b>11.4</b> Definizione del modello lineare</a></li>
<li class="chapter" data-level="11.5" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#stima-dei-parametri-2"><i class="fa fa-check"></i><b>11.5</b> Stima dei parametri</a></li>
<li class="chapter" data-level="11.6" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#verifica-delle-assunzioni-di-base"><i class="fa fa-check"></i><b>11.6</b> Verifica delle assunzioni di base</a></li>
<li class="chapter" data-level="11.7" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#scomposizione-delle-varianze"><i class="fa fa-check"></i><b>11.7</b> Scomposizione delle varianze</a></li>
<li class="chapter" data-level="11.8" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#funzioni-dei-parametri"><i class="fa fa-check"></i><b>11.8</b> Funzioni dei parametri</a><ul>
<li class="chapter" data-level="11.8.1" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#medie-delle-combinazioni-lavorazioni-x-diserbo"><i class="fa fa-check"></i><b>11.8.1</b> Medie delle combinazioni ‘lavorazioni x diserbo’</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#calcolo-degli-errori-standard-sem-e-sed"><i class="fa fa-check"></i><b>11.9</b> Calcolo degli errori standard (SEM e SED)</a></li>
<li class="chapter" data-level="11.10" data-path="modelli-anova-a-due-vie.html"><a href="modelli-anova-a-due-vie.html#contrasti-medie-attese-e-confronti-multipli-con-r"><i class="fa fa-check"></i><b>11.10</b> Contrasti, medie attese e confronti multipli con R</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html"><i class="fa fa-check"></i><b>12</b> La regressione lineare semplice</a><ul>
<li class="chapter" data-level="12.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#caso-studio-effetto-della-concimazione-azotata-al-frumento"><i class="fa fa-check"></i><b>12.1</b> Caso studio: effetto della concimazione azotata al frumento</a></li>
<li class="chapter" data-level="12.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#analisi-preliminari"><i class="fa fa-check"></i><b>12.2</b> Analisi preliminari</a></li>
<li class="chapter" data-level="12.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#definizione-del-modello-lineare-1"><i class="fa fa-check"></i><b>12.3</b> Definizione del modello lineare</a></li>
<li class="chapter" data-level="12.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#stima-dei-parametri-3"><i class="fa fa-check"></i><b>12.4</b> Stima dei parametri</a></li>
<li class="chapter" data-level="12.5" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-della-bonta-del-modello"><i class="fa fa-check"></i><b>12.5</b> Valutazione della bontà del modello</a><ul>
<li class="chapter" data-level="12.5.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-grafica"><i class="fa fa-check"></i><b>12.5.1</b> Valutazione grafica</a></li>
<li class="chapter" data-level="12.5.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#errori-standard-dei-parametri"><i class="fa fa-check"></i><b>12.5.2</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="12.5.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-mancanza-dadattamento"><i class="fa fa-check"></i><b>12.5.3</b> Test F per la mancanza d’adattamento</a></li>
<li class="chapter" data-level="12.5.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-bonta-di-adattamento-e-coefficiente-di-determinazione"><i class="fa fa-check"></i><b>12.5.4</b> Test F per la bontà di adattamento e coefficiente di determinazione</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#previsioni"><i class="fa fa-check"></i><b>12.6</b> Previsioni</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html"><i class="fa fa-check"></i><b>13</b> La regressione non-lineare</a><ul>
<li class="chapter" data-level="13.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#caso-studio-degradazione-di-un-erbicida-nel-terreno"><i class="fa fa-check"></i><b>13.1</b> Caso studio: degradazione di un erbicida nel terreno</a><ul>
<li class="chapter" data-level="13.1.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#scelta-della-funzione"><i class="fa fa-check"></i><b>13.1.1</b> Scelta della funzione</a></li>
<li class="chapter" data-level="13.1.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#stima-dei-parametri-4"><i class="fa fa-check"></i><b>13.1.2</b> Stima dei parametri</a></li>
<li class="chapter" data-level="13.1.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#la-regressione-non-lineare-con-r"><i class="fa fa-check"></i><b>13.1.3</b> La regressione non-lineare con R</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#verifica-della-bonta-del-modello"><i class="fa fa-check"></i><b>13.2</b> Verifica della bontà del modello</a><ul>
<li class="chapter" data-level="13.2.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#analisi-grafica-dei-residui-1"><i class="fa fa-check"></i><b>13.2.1</b> Analisi grafica dei residui</a></li>
<li class="chapter" data-level="13.2.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#test-f-per-la-mancanza-di-adattamento-approssimato"><i class="fa fa-check"></i><b>13.2.2</b> Test F per la mancanza di adattamento (approssimato)</a></li>
<li class="chapter" data-level="13.2.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#errori-standard-dei-parametri-1"><i class="fa fa-check"></i><b>13.2.3</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="13.2.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#coefficienti-di-determinazione"><i class="fa fa-check"></i><b>13.2.4</b> Coefficienti di determinazione</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#funzioni-lineari-e-nonlineari-dei-parametri"><i class="fa fa-check"></i><b>13.3</b> Funzioni lineari e nonlineari dei parametri</a></li>
<li class="chapter" data-level="13.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#previsioni-1"><i class="fa fa-check"></i><b>13.4</b> Previsioni</a></li>
<li class="chapter" data-level="13.5" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#gestione-delle-situazioni-patologiche"><i class="fa fa-check"></i><b>13.5</b> Gestione delle situazioni ‘patologiche’</a><ul>
<li class="chapter" data-level="13.5.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-del-modello"><i class="fa fa-check"></i><b>13.5.1</b> Trasformazione del modello</a></li>
<li class="chapter" data-level="13.5.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-dei-dati"><i class="fa fa-check"></i><b>13.5.2</b> Trasformazione dei dati</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#altre-letture-1"><i class="fa fa-check"></i><b>13.6</b> Altre letture</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html"><i class="fa fa-check"></i><b>14</b> Appendix 1: breve introduzione ad R</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#cosa-e-r"><i class="fa fa-check"></i>Cosa è R?</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#oggetti-e-assegnazioni"><i class="fa fa-check"></i>Oggetti e assegnazioni</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#costanti-e-vettori"><i class="fa fa-check"></i>Costanti e vettori</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#matrici"><i class="fa fa-check"></i>Matrici</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#dataframe"><i class="fa fa-check"></i>Dataframe</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#quale-oggetto-sto-utilizzando"><i class="fa fa-check"></i>Quale oggetto sto utilizzando?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#operazioni-ed-operatori"><i class="fa fa-check"></i>Operazioni ed operatori</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#funzioni-ed-argomenti"><i class="fa fa-check"></i>Funzioni ed argomenti</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#consigli-per-limmissione-di-dati-sperimentali"><i class="fa fa-check"></i>Consigli per l’immissione di dati sperimentali</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#immissione-manuale-di-dati"><i class="fa fa-check"></i>Immissione manuale di dati</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#immissione-di-numeri-progressivi"><i class="fa fa-check"></i>Immissione di numeri progressivi</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#immissione-dei-codici-delle-tesi-e-dei-blocchi"><i class="fa fa-check"></i>Immissione dei codici delle tesi e dei blocchi</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#leggere-e-salvare-dati-esterni"><i class="fa fa-check"></i>Leggere e salvare dati esterni</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#alcune-operazioni-comuni-sul-dataset"><i class="fa fa-check"></i>Alcune operazioni comuni sul dataset</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#selezionare-un-subset-di-dati"><i class="fa fa-check"></i>Selezionare un subset di dati</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#ordinare-un-vettore-o-un-dataframe"><i class="fa fa-check"></i>Ordinare un vettore o un dataframe</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#workspace"><i class="fa fa-check"></i>Workspace</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#script-o-programmi"><i class="fa fa-check"></i>Script o programmi</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#interrogazione-di-oggetti"><i class="fa fa-check"></i>Interrogazione di oggetti</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#altre-funzioni-matriciali"><i class="fa fa-check"></i>Altre funzioni matriciali</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#cenni-sulle-funzionalita-grafiche-in-r"><i class="fa fa-check"></i>Cenni sulle funzionalità grafiche in R</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#per-approfondimenti-2"><i class="fa fa-check"></i>Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html"><i class="fa fa-check"></i><b>15</b> Appendix 2: Richiami di statistica descrittiva</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#dati-quantitativi-analisi-chimiche-e-altre-misurazioni-fondamentali"><i class="fa fa-check"></i>Dati quantitativi: analisi chimiche e altre misurazioni fondamentali</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#indicatori-di-tendenza-centrale"><i class="fa fa-check"></i>Indicatori di tendenza centrale</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#indicatori-di-dispersione"><i class="fa fa-check"></i>Indicatori di dispersione</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#arrotondamenti"><i class="fa fa-check"></i>Arrotondamenti</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#descrizione-dei-sottogruppi"><i class="fa fa-check"></i>Descrizione dei sottogruppi</a></li>
<li class="chapter" data-level="15.0.1" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#relazioni-tra-variabili-quantitative-correlazione"><i class="fa fa-check"></i><b>15.0.1</b> Relazioni tra variabili quantitative: correlazione</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#dati-qualitativi-conteggi-e-frequenze"><i class="fa fa-check"></i>Dati qualitativi: conteggi e frequenze</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#distribuzioni-di-frequenze-e-classamento"><i class="fa fa-check"></i>Distribuzioni di frequenze e classamento</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#statistiche-descrittive-per-le-distribuzioni-di-frequenze"><i class="fa fa-check"></i>Statistiche descrittive per le distribuzioni di frequenze</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#distribuzioni-di-frequenza-bivariate-le-tabelle-di-contingenza"><i class="fa fa-check"></i>Distribuzioni di frequenza bivariate: le tabelle di contingenza</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#connessione"><i class="fa fa-check"></i>Connessione</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#esercizi-2"><i class="fa fa-check"></i>Esercizi</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#esercizio-1-1"><i class="fa fa-check"></i>Esercizio 1</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#esercizio-2-1"><i class="fa fa-check"></i>Esercizio 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html"><i class="fa fa-check"></i>Appendix 3: Per chi vuole approfondire un po’…</a><ul>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-3-progettare-un-esperimento"><i class="fa fa-check"></i>Capitolo 3: Progettare un esperimento</a><ul>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#organizzare-un-esperimento-di-diserbo-chimico"><i class="fa fa-check"></i>Organizzare un esperimento di diserbo chimico</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#organizzare-un-esperimento-di-confronto-varietale"><i class="fa fa-check"></i>Organizzare un esperimento di confronto varietale</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#organizzare-un-esperimento-fattoriale"><i class="fa fa-check"></i>Organizzare un esperimento fattoriale</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#organizzare-un-esperimento-con-una-coltura-poliennale"><i class="fa fa-check"></i>Organizzare un esperimento con una coltura poliennale</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#utilizzare-r-per-disegnare-gli-esperimenti"><i class="fa fa-check"></i>Utilizzare R per disegnare gli esperimenti</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-4-modelli-matematici-a-due-facce"><i class="fa fa-check"></i>Capitolo 4: Modelli matematici a ‘due facce’</a><ul>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#la-distribuzione-t-di-student"><i class="fa fa-check"></i>La distribuzione t di Student</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#la-distribuzione-f-di-fisher"><i class="fa fa-check"></i>La distribuzione F di Fisher</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#la-distribuzione-binomiale"><i class="fa fa-check"></i>La distribuzione binomiale</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-5-esperimenti-stime-ed-incertezza"><i class="fa fa-check"></i>Capitolo 5: Esperimenti stime ed incertezza</a><ul>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#e-realistico-lintervallo-di-confidenza"><i class="fa fa-check"></i>E’ realistico l’intervallo di confidenza?</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#che-cosa-non-significa-lintervallo-di-confidenza"><i class="fa fa-check"></i>Che cosa NON significa l’intervallo di confidenza?</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#popolazioni-non-gaussiane"><i class="fa fa-check"></i>Popolazioni non gaussiane</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-6.-introduzione-al-test-dipotesi"><i class="fa fa-check"></i>Capitolo 6. Introduzione al test d’ipotesi</a><ul>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#simulazione-monte-carlo-di-un-test-t-di-student"><i class="fa fa-check"></i>Simulazione Monte Carlo di un test t di Student</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#tipologie-alternative-di-test-t-di-student"><i class="fa fa-check"></i>Tipologie alternative di test t di Student</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#simulazione-di-un-test-di-chi-quadro"><i class="fa fa-check"></i>Simulazione di un test di chi quadro</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#errori-di-prima-e-di-seconda-specie"><i class="fa fa-check"></i>Errori di prima e di seconda specie</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-7-anova-ad-una-via"><i class="fa fa-check"></i>Capitolo 7: ANOVA ad una via</a><ul>
<li class="chapter" data-level="15.0.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#perche-il-vincolo-sulla-somma-e-preferibile-per-i-calcoli-manuali"><i class="fa fa-check"></i><b>15.0.2</b> Perchè il vincolo sulla somma è preferibile per i calcoli manuali</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#lanova-a-mano"><i class="fa fa-check"></i>L’ANOVA ‘a mano’</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-8-verifica-delle-assunzioni"><i class="fa fa-check"></i>Capitolo 8: verifica delle assunzioni</a><ul>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#il-qq-plot"><i class="fa fa-check"></i>Il QQ-plot</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#correzione-dati-mancantiaberranti"><i class="fa fa-check"></i>Correzione dati mancanti/aberranti</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-9-contrasti-e-confronti-multipli"><i class="fa fa-check"></i>Capitolo 9: Contrasti e confronti multipli</a><ul>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#intervallo-di-confidenza-di-un-contrasto"><i class="fa fa-check"></i>Intervallo di confidenza di un contrasto</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#correzione-per-la-molteplicita-1"><i class="fa fa-check"></i>Correzione per la molteplicità</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#intervalli-di-confidenza-simultanei"><i class="fa fa-check"></i>Intervalli di confidenza simultanei</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#e-le-classiche-procedure-di-confronto-multiplo-1"><i class="fa fa-check"></i>E le classiche procedure di confronto multiplo?</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#consigli-pratici-per-il-confronto-multiplo"><i class="fa fa-check"></i>Consigli pratici per il confronto multiplo</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-10-modelli-con-fattori-di-blocco"><i class="fa fa-check"></i>Capitolo 10: modelli con fattori di blocco</a><ul>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#anova-a-due-vie-senza-repliche-i-calcoli-manuali"><i class="fa fa-check"></i>ANOVA a due vie senza repliche: i calcoli manuali</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-11-anova-a-due-vie"><i class="fa fa-check"></i>Capitolo 11: ANOVA a due vie</a><ul>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#anova-a-due-vie-scomposizione-manuale-della-varianza"><i class="fa fa-check"></i>Anova a due vie: scomposizione ‘manuale’ della varianza</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#disegni-incrociati-e-gerarchici"><i class="fa fa-check"></i>Disegni incrociati e gerarchici</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#disegni-a-split-plot"><i class="fa fa-check"></i>Disegni a split-plot</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#disegni-a-split-block"><i class="fa fa-check"></i>Disegni a split-block</a></li>
<li class="chapter" data-level="" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#disegni-a-split-split-plot"><i class="fa fa-check"></i>Disegni a split-split-plot</a></li>
</ul></li>
<li class="chapter" data-level="15.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-12-regressione-lineare"><i class="fa fa-check"></i><b>15.1</b> Capitolo 12: Regressione lineare</a></li>
<li class="chapter" data-level="15.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-13-regressione-non-lineare"><i class="fa fa-check"></i><b>15.2</b> Capitolo 13: Regressione non-lineare</a><ul>
<li class="chapter" data-level="15.2.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#riparametrizzazione-delle-funzioni"><i class="fa fa-check"></i><b>15.2.1</b> Riparametrizzazione delle funzioni</a></li>
<li class="chapter" data-level="15.2.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#modelli-ancova"><i class="fa fa-check"></i><b>15.2.2</b> Modelli ANCOVA</a></li>
<li class="chapter" data-level="15.2.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#confronto-tra-modelli-alternativi"><i class="fa fa-check"></i><b>15.2.3</b> Confronto tra modelli alternativi</a></li>
<li class="chapter" data-level="15.2.4" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#confronto-tra-modelli-non-nested"><i class="fa fa-check"></i><b>15.2.4</b> Confronto tra modelli non-nested</a></li>
<li class="chapter" data-level="15.2.5" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#il-package-drc"><i class="fa fa-check"></i><b>15.2.5</b> Il package ‘drc’</a></li>
<li class="chapter" data-level="15.2.6" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#altre-statistiche"><i class="fa fa-check"></i><b>15.2.6</b> Altre statistiche</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Metodologia sperimentale per le scienze agrarie</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendix-3-per-chi-vuole-approfondire-un-po" class="section level1 unnumbered">
<h1>Appendix 3: Per chi vuole approfondire un po’…</h1>
<p>[Intro da fare]</p>
<div id="capitolo-3-progettare-un-esperimento" class="section level2 unnumbered">
<h2>Capitolo 3: Progettare un esperimento</h2>
<div id="organizzare-un-esperimento-di-diserbo-chimico" class="section level3 unnumbered">
<h3>Organizzare un esperimento di diserbo chimico</h3>
<p>Si suppone che gli erbicidi A, B e C siano più efficaci di D, E ed F verso <em>Solanum nigrum</em>, una comune pianta infestante delle colture di pomodoro. L’obiettivo generale della ricerca sarà quello di trovare un’efficace soluzione per l’eliminazione di <em>Solanum nigrum</em> dal pomodoro. Gli obiettivi specifici saranno:</p>
<ol style="list-style-type: decimal">
<li>valutare l’efficacia erbicida di A, B e C, confrontandola con quella di D, E ed F</li>
<li>valutare la selettività degli anzidetti erbicidi verso il pomodoro</li>
</ol>
<p>Il fattore sperimentale oggetto di studio sarà il diserbo del pomodoro, con 5 livelli inseriti in prova (6 trattamenti sperimentali): A, B, C, D, E ed F. Inoltre, si ritiene opportuno inserire in prova un testimone non trattato (NT), che ci permetterà di quantificare la percentuale di malerbe controllate. In totale, avremo quindi sette tesi sperimentali.</p>
<p>Questo esperimento verrà eseguito in vaso e, di conseguenza, potremo realizzare sei repliche con un disegno sperimentale a randomizzazione completa. La variabile rilevata, tre settimane dopo il trattamento, sarà il peso della biomassa presente in ogni vasetto.</p>
</div>
<div id="organizzare-un-esperimento-di-confronto-varietale" class="section level3 unnumbered">
<h3>Organizzare un esperimento di confronto varietale</h3>
<p>L’ipotesi è che le varietà di girasole A, B e C non abbiano la stessa base genetica e quindi non siano tutte ugualmente produttive. L’obiettivo generale è quello di capire quale tra A, B e C sia più adatta alle condizioni pedoclimatiche della collina Umbra. Gli obiettivi specifici sono quelli di valutare:</p>
<ol style="list-style-type: decimal">
<li>produttività di A, B e C</li>
<li>stabilità produttiva di A, B e C</li>
</ol>
<p>Il fattore sperimentale in studio sarà la varietà di girasole con 3 livelli inclusi in prova (varietà A, B e C). Come testimone, inseriremo la varietà di riferimento per la zona (D). Dato che eseguiremo questa prova su un terreno nel quale vi sono due chiari gradienti di fertilità, disegneremo l’esperimento considerando due fattori di blocco: trasversale e longitudinale (spiego meglio tra poco…). Poiché dobbiamo valutare la stabilità produttiva, dovremo ripetere l’esperimento più volte (es. in tre anni diversi) e quindi avremo un secondo fattore sperimentale, incrociato con il primo.</p>
<p>Questo esperimento verrà realizzato in pieno campo, su parcelle di dimensioni 2 m x 8 m, seguendo uno schema sperimentale a quadrato latino con quattro repliche. Dovendo misurare la stabilità produttiva, cioè l’oscillazione di produzione da un ambiente all’altro, questa prova dovrà essere ripetuta in più anni (es. tre anni).</p>
<p>Per ognuno degli anni di prova, la mappa contiene una griglia 4 x 4, nella quale possiamo identificare quattro colonne e quattro righe. Dato che abbiamo presupposto l’esistenza di un gradiente trasversale e lungitudinale (tra righe e tra colonne), l’allocazione dei trattamenti dovrà esser fatta in modo che ognuno di essi si trovi su ogni riga e ogni colonna (<strong>Quadrato latino</strong>). Un’aspetto fondamentale è comunque quello di <strong>definire una diversa randomizzazione in ogni anno/località</strong>, per evitare che le stesse varietà siano sempre nelle stesse posizioni, che potrebbe dare origine a dubbi di confounding. La definizione delle randomizzazioni per il secondo e terzo anno è lasciata per esercizio.</p>
<p>Anche in questo caso potremo chiedere ad R di aiutarci a trovare la combinazione corretta (anche se questo potrebbe essere comodamente fatto a mano).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(agricolae)
trt &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="st">&quot;D&quot;</span>)
designLS &lt;-<span class="st"> </span><span class="kw">design.lsd</span>(trt, <span class="dt">seed=</span><span class="dv">543</span>, <span class="dt">serie=</span><span class="dv">2</span>)
designLS<span class="op">$</span>book
##    plots row col trt
## 1    101   1   1   C
## 2    102   1   2   A
## 3    103   1   3   B
## 4    104   1   4   D
## 5    201   2   1   D
## 6    202   2   2   B
## 7    203   2   3   C
## 8    204   2   4   A
## 9    301   3   1   B
## 10   302   3   2   D
## 11   303   3   3   A
## 12   304   3   4   C
## 13   401   4   1   A
## 14   402   4   2   C
## 15   403   4   3   D
## 16   404   4   4   B</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName35"></span>
<img src="_images/Mappa2LS.png" alt="Schema sperimentale a quadrato latino per l'Esempio 2 (un anno)" width="65%" />
<p class="caption">
Figure 15.4: Schema sperimentale a quadrato latino per l’Esempio 2 (un anno)
</p>
</div>
<p>Un’altro aspetto da considerare è la metodica impiegata per la determinazione del peso di 1000 semi. Abbiamo già visto che, per aumentare la precisione e la rappresentatività, da tutta la granella raccolta da una parcella preleviamo quattro lotti da 1000 semi, di cui determinare il peso. In questo modo, per ogni trattamento avremo 16 valori (quattro repliche x quattro lotti per replica). Ovviamente non possiamo affermare di avere 16 repliche, in quanto solo le parcelle sono da considerare repliche, in quanto ricevono il trattamento (varietà) in modo indipendente. I quattro lotti raccolti da ogni parcella sono unità osservazionali (perché ne viene rilevato il peso), ma non unità sperimentali, perché appartengono alla stessa parcella e non sono indipendenti. I quattro lotti si dicono <strong>sub-repliche</strong>, quindi il disegno ha quattro repliche e quattro sub-repliche per replica (<strong>disegno a quadrato latino con sottocampionamento</strong>). I due strati di errore (variabilità tra repliche e variabilità tra sub-repliche entro replica), devono essere mantenuti separati in fase di analisi, altrimenti l’analisi è invalida, perché è condotta come se avessimo un più alto grado di precisione (16 repliche) rispetto a quello che abbiamo effettivamente (una sorta di millantato credito!).</p>
<p>[Inserire immagine]</p>
<p>Al termine del ciclo colturale, si misurerà il peso di mille semi. Per questo, prenderemo dalla produzione di granella di ogni parcella, quattro sub-campioni da mille semi, da sottoporre a pesate.</p>
</div>
<div id="organizzare-un-esperimento-fattoriale" class="section level3 unnumbered">
<h3>Organizzare un esperimento fattoriale</h3>
<p>Nella barbabietola da zucchero, il diserbo localizzato lungo la fila consente di diminuire l’impiego di erbicidi. Tuttavia, se la coltura precedente ha prodotto semi e se non abbiamo effettuato una lavorazione profonda per interrarli, la coltura sarà più infestata e quindi sarà più difficile ottenere una buona produttività con il diserbo parziale. Su questa ipotesi costruiamo un esperimento volto a valutare l’interazione tra lavorazione del terreno e diserbo chimico. Per raggiungere questo obiettivo generale, proveremo a valutare se:</p>
<ol style="list-style-type: decimal">
<li>il diserbo parziale consente di ottenere produzioni comparabili a quelle del diserbo totale</li>
<li>l’effetto erbicida è indipendente dalla lavorazione prescelta</li>
</ol>
<p>In questo caso avremo due fattori sperimentali incrociati: il diserbo, con due livelli (totale o parziale, localizzato sulla fila) e la lavorazione, con tre livelli (aratura profonda, aratura superficiale e <em>minimum tillage</em>). Non vi è la necessità di un testimone, ma avremo la necessità di un fattore di blocco. In totale, avremo sei tesi sperimentali.</p>
<p>In questo caso abbiamo un disegno fattoriale con due livelli a blocchi randomizzati. Nel principio, questo disegno non ha nulla di diverso da quello relativo all’esempio 1, fatto salvo un minor numero di trattamenti (solo 6). Anche in questo caso, ci facciamo aiutare da R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trt &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">2</span>) <span class="co"># factorial 3x2</span>
design2way &lt;-<span class="kw">design.ab</span>(trt, <span class="dt">r=</span><span class="dv">4</span>, <span class="dt">serie=</span><span class="dv">2</span>,
  <span class="dt">design=</span><span class="st">&quot;rcbd&quot;</span>, <span class="dt">seed=</span><span class="dv">777</span>)
book &lt;-<span class="st"> </span>design2way<span class="op">$</span>book
<span class="kw">levels</span>(book<span class="op">$</span>A) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;PROF&quot;</span>, <span class="st">&quot;SUP&quot;</span>, <span class="st">&quot;MIN&quot;</span>)
<span class="kw">levels</span>(book<span class="op">$</span>B) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;TOT&quot;</span>, <span class="st">&quot;PARZ&quot;</span>)
book
##    plots block    A    B
## 1    101     1  SUP PARZ
## 2    102     1 PROF PARZ
## 3    103     1 PROF  TOT
## 4    104     1  MIN  TOT
## 5    105     1  SUP  TOT
## 6    106     1  MIN PARZ
## 7    107     2  MIN  TOT
## 8    108     2  SUP  TOT
## 9    109     2  MIN PARZ
## 10   110     2 PROF  TOT
## 11   111     2  SUP PARZ
## 12   112     2 PROF PARZ
## 13   113     3  MIN  TOT
## 14   114     3  SUP  TOT
## 15   115     3 PROF PARZ
## 16   116     3  MIN PARZ
## 17   117     3  SUP PARZ
## 18   118     3 PROF  TOT
## 19   119     4  MIN PARZ
## 20   120     4 PROF  TOT
## 21   121     4 PROF PARZ
## 22   122     4  MIN  TOT
## 23   123     4  SUP  TOT
## 24   124     4  SUP PARZ</code></pre></div>
<p>La mappa risultante è visibile più sotto.</p>
<div class="figure" style="text-align: center"><span id="fig:figName36"></span>
<img src="_images/Mappa3FATT.png" alt="Schema sperimentale fattoriale a blocchi randomizzati per l'Esempio 3" width="65%" />
<p class="caption">
Figure 15.5: Schema sperimentale fattoriale a blocchi randomizzati per l’Esempio 3
</p>
</div>
<p>Questo disegno è totalmente appropriato, ma ci costringe a lasciare parecchio spazio tra una parcella e l’altra, per poter manovrare con la macchina per la lavorazione del terreno. Sarebbe utile raggruppare le parcelle caratterizzate dalla stessa lavorazione, in modo da poter lavorare su superfici più ampie. Ne guadagnerebbe l’uniformità dell’esperimento e l’accuratezza dei risultati. Possiamo quindi immaginare un disegno a un fattore, con parcelle di dimensione doppia (<strong>main-plots</strong>), sulle quali eseguire, in modo randomizzato le lavorazioni del terreno. Succesivamente, ogni main-plot può essere suddivisa in due e, su ognuna delle due metà, possono essere allocati in modo random i due trattamenti di diserbo. In questo modo ci troviamo ad operare con parcelle di due dimensioni diverse: le main-plots per le lavorazioni e le sub-plots per il diserbo. Questo tipo di schema prende il nome di <strong>parcella suddivisa</strong> (<strong>split-plot</strong>), ed è piuttosto comune nella sperimentazione di pieno campo.</p>
<p>Proviamo ad utilizzare R per redigere il piano sperimentale.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lavorazione &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;PROF&quot;</span>, <span class="st">&quot;SUP&quot;</span>, <span class="st">&quot;MIN&quot;</span>)
diserbo &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;TOT&quot;</span>, <span class="st">&quot;PARZ&quot;</span>)
designSPLIT &lt;-<span class="st"> </span><span class="kw">design.split</span>(lavorazione, diserbo,
  <span class="dt">r=</span><span class="dv">4</span>, <span class="dt">serie=</span><span class="dv">2</span>, <span class="dt">seed=</span><span class="dv">777</span>)
book &lt;-<span class="st"> </span>designSPLIT<span class="op">$</span>book
book
##    plots splots block lavorazione diserbo
## 1    101      1     1         SUP    PARZ
## 2    101      2     1         SUP     TOT
## 3    102      1     1        PROF     TOT
## 4    102      2     1        PROF    PARZ
## 5    103      1     1         MIN    PARZ
## 6    103      2     1         MIN     TOT
## 7    104      1     2         SUP    PARZ
## 8    104      2     2         SUP     TOT
## 9    105      1     2         MIN     TOT
## 10   105      2     2         MIN    PARZ
## 11   106      1     2        PROF     TOT
## 12   106      2     2        PROF    PARZ
## 13   107      1     3         MIN     TOT
## 14   107      2     3         MIN    PARZ
## 15   108      1     3         SUP     TOT
## 16   108      2     3         SUP    PARZ
## 17   109      1     3        PROF     TOT
## 18   109      2     3        PROF    PARZ
## 19   110      1     4        PROF    PARZ
## 20   110      2     4        PROF     TOT
## 21   111      1     4         MIN     TOT
## 22   111      2     4         MIN    PARZ
## 23   112      1     4         SUP    PARZ
## 24   112      2     4         SUP     TOT</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName37"></span>
<img src="_images/Mappa3split.png" alt="Schema sperimentale split-plot a blocchi randomizzati per l'Esempio 3" width="65%" />
<p class="caption">
Figure 15.6: Schema sperimentale split-plot a blocchi randomizzati per l’Esempio 3
</p>
</div>
<p>In alcune circostanze, soprattutto nelle prove di diserbo chimico, potrebbe trovare applicazione un altro tipo di schema sperimentale, nel quale, in ogni blocco, un trattamento viene applicato a tutte le parcelle di una riga e l’altro trattamento a tutte le parcelle di una colonna. Ad esempio, il disegno sottostante mostra una prova nella quale il terreno è stato diserbato in una striscia nel senso della lunghezza e, dopo il diserbo, le colture sono state seminate in striscia, nel senso della larghezza. Questo disegno è detto <strong>strip-plot</strong> ed è molto comodo perché consente di lavorare velocemente.</p>
<div class="figure" style="text-align: center"><span id="fig:figName38"></span>
<img src="_images/MappaStrip.png" alt="Schema sperimentale a strip-plot" width="90%" />
<p class="caption">
Figure 15.7: Schema sperimentale a strip-plot
</p>
</div>
</div>
<div id="organizzare-un-esperimento-con-una-coltura-poliennale" class="section level3 unnumbered">
<h3>Organizzare un esperimento con una coltura poliennale</h3>
<p>Vogliamo porre a confronto tre varietà di erba medica (A, B e C) e, considerando che l’erba medica è una coltura poliennale, vogliamo capire se il giudizio di merito è indipendente dall’anno di coltivazione. I nostri obiettivi specifici saranno:</p>
<ol style="list-style-type: decimal">
<li>valutare la produttività media delle varietà in prova</li>
<li>valutare le oscillazione nei quattro anni di durata del cotico erboso</li>
</ol>
<p>Il fattore sperimentale in studio sarà la varietà di erba medica con 3 livelli inclusi in prova (varietà A, B e C) ai quali aggiungiamo il riferimento di zona (D) come testimone. Come nel caso del girasole, dovremo valutare la stabilità produttiva negli anni, ma, dato che abbiamo una coltura poliennale, non avremo bisogno di ripetere la prova, ma potremo ripetere le osservazioni per quattro anni sulla stessa prova.</p>
<p>La prova di erba medica è fondamentalmente un esperimento a blocchi randomizzati, il cui piano è riportato più sotto. Tuttavia, si tratta di una coltura poiliennale nella quale ripeteremo le misurazioni ogni anno sulle stesse parcelle. le misure ripetute non sono randomizzate (non possono esserlo), ma seguono una metrica temporale. Proprio per questo sviluppo lungo la scala del tempo, i dati che si raccolgono in questi esperimenti a misure ripetute sono detti <strong>dati longitudinali</strong>. Guardando bene il disegno si capisce anche per si parla di <strong>split-plot nel tempo</strong>. Esempi affini sono relativi all’analisi di accrescimento con misure non distruttive (esempio l’altezza) oppure i prelievi di terreno a profondità diverse, anche se, in quest’ultimo caso, la metrica delle misure ripetute è spaziale, non temporale.</p>
<p>Si può notare una certa analogia con il sottocampionamento illustrato più sopra, nel senso che vengono prese più misure per parcella. Tuttavia, bisogna tener presente che nel sottocampionamento le diverse misure sono solo repliche e non vi è nessuna esigenza di distinguere tra quelle prese nella stessa parcella. Invece, nel caso delle misure ripetute ognuna di esse ha interesse individuale, in quanto espressione di un’anno particolare.</p>
<div class="figure" style="text-align: center"><span id="fig:figName39"></span>
<img src="_images/Mappa4.png" alt="Schema sperimentale a blocchi randomizzati con misure ripetute (split-plot in time)" width="55%" />
<p class="caption">
Figure 15.8: Schema sperimentale a blocchi randomizzati con misure ripetute (split-plot in time)
</p>
</div>
</div>
<div id="utilizzare-r-per-disegnare-gli-esperimenti" class="section level3 unnumbered">
<h3>Utilizzare R per disegnare gli esperimenti</h3>
<p>Negli esperimenti più semplici lo schema sperimentale può essere pianificato a mano. Per esperimenti complessi potremo invece utilizzare il computer; in R, potremo utilizzare, ad esempio, il package <em>agricolae</em> <span class="citation">(de Mendiburu <a href="#ref-de-Mendiburu:2019aa">2019</a>)</span>, seguento il codice che troverete nei paragrafi seguenti.</p>
<p>[Spostare qui gli esempi, lasciando sopra gli schemi]</p>
</div>
</div>
<div id="capitolo-4-modelli-matematici-a-due-facce" class="section level2 unnumbered">
<h2>Capitolo 4: Modelli matematici a ‘due facce’</h2>
<div id="la-distribuzione-t-di-student" class="section level3 unnumbered">
<h3>La distribuzione t di Student</h3>
<p>La distribuzione t di Student è analoga per forma ad una distribuzione normale con media 0 e deviazione standard 1. Rispetto a questa, la dispersione è un po’ più ampia, nel senso la probabilità di avere valori lontani dalla media è più alta. In realtà, non esiste una sola distribuzione t di Student, ma ne esistono molte, caratterizzate da un diverso numero di gradi di libertà (<span class="math inline">\(\nu\)</span>); maggiore è <span class="math inline">\(\nu\)</span>, minore la sovradispersione; se il numero di gradi di libertà è infinito, la distribuzione t di Student è identica alla normale standardizzata (distribuzione normale con media 0 e deviazione standard uguale ad 1).</p>
<p>Per verificare l’entità della sovradispersione, proviamo a disegnare su un grafico una curva normale standardizzata ed una serie di curve di t, con 2, 6 e 24 gradi di libertà.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x),<span class="op">-</span><span class="dv">3</span>, <span class="op">+</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;Black&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Densità&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">2</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">6</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">24</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-177-1.png" /><!-- --></p>
</div>
<div id="la-distribuzione-f-di-fisher" class="section level3 unnumbered">
<h3>La distribuzione F di Fisher</h3>
<p>La distribuzione F di Fisher è definita solo per valori positivi ed è fortemente asimmetrica. Anche in questo caso, abbiamo una famiglia di distribuzioni, che differiscono tra di loro per due parametri (gradi di libertà) <span class="math inline">\(\nu_1\)</span> e <span class="math inline">\(\nu_2\)</span>. Solitamente questa distribuzione viene utilizzata per descrivere il rapporto tra le varianze di coppie di campioni estratti da un distribuzione normale standardizzata, per cui <span class="math inline">\(\nu_1\)</span> e <span class="math inline">\(\nu_2\)</span> sono i gradi di libertà del numeratore e del denominatore.</p>
<p>Col codice che segue, possiamo disegnare la distribuzione di F con <span class="math inline">\(\nu_1 = \nu_2 = 3\)</span> e possiamo calcolare la probabilità di estrarre da questa distribuzione un valore pari o superiore a 5. Inoltre, calcoliamo anche il 95° percentile, utilizzando le apposite funzioni in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">df</span>(x, <span class="dv">3</span>, <span class="dv">3</span>), <span class="dv">0</span>, <span class="op">+</span><span class="dv">3</span>,<span class="dt">col=</span><span class="st">&quot;Black&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Densità&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-178-1.png" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>(<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dt">lower.tail =</span> F)
## [1] 0.109551
<span class="kw">qf</span>(<span class="fl">0.95</span>, <span class="dv">3</span>, <span class="dv">3</span>)
## [1] 9.276628</code></pre></div>
</div>
<div id="la-distribuzione-binomiale" class="section level3 unnumbered">
<h3>La distribuzione binomiale</h3>
<p>Ogni esperimento per il quale ci sono solo due esiti possibili (successo ed insuccesso) e una certa probabilità di successo, viene detto <strong>esperimento Bernoulliano</strong>. Il tipico esempio è il lancio della moneta, nel quale possiamo ottenere solo testa o croce, con una probabilità di 0.5 (se la moneta non è truccata). In alcuni casi, potremmo avere una serie di esperimenti Bernoulliani indipendenti, con probabilità di successo costante (ad esempio, lanciare la moneta 10 volte) e potremmo essere interessati a conoscere la probabilità di ottenere <em>k</em> successi su <em>n</em> prove. Questa probabilità può essere descritta attraverso la <strong>funzione di probabilità binomiale</strong>.</p>
<p>Poniamo di sapere che in una Facoltà di Agraria con un numero molto elevato di studenti il rapporto tra maschi e femmine sia pari a 0.7 e quindi che la probabilità di incontrare un maschio sia pari a <span class="math inline">\(p = 0.7\)</span> (evento semplice). Deve essere estratto a sorte un viaggio studio per quattro studenti e, per una questione di pari opportunità, si preferirebbe che fossero premiati in ugual misura maschi e femmine (cioè si vogliono premiare due femmine). Qual è la probabilità che un simile evento si realizzi?</p>
<p>La probabilità cercata si può ottenere pensando che abbiamo un evento “estrazione” che può dare due risultati possibili (maschio o femmina) e che deve essere ripetuto quattro volte. Se consideriamo “successo” estrarre una femmina, allora la probabilità di successo in ogni estrazione è <span class="math inline">\(p = 0.3\)</span> mentre quella di insuccesso (evento complementare) è pari a <span class="math inline">\(1 - p = q = 0.7\)</span>. Facciamo attenzione! Quanto abbiamo detto è vero solo se la popolazione è sufficientemente numerosa da pensare che la singola estrazione non cambia la probabilità degli eventi nelle successive (eventi indipendenti). La probabilità che su quattro estrazioni si abbiano 2 successi (due femmine) e due insuccessi (due maschi) è data da (teorema della probabilità composta):</p>
<p><span class="math display">\[0.3 \cdot 0.3 \cdot 0.7 \cdot 0.7 = 0.3^2 \cdot 0.7^2\]</span></p>
<p>In generale, data una popolazione molto numerosa, nella quale gli individui si presentano con due modalità possibili (in questo caso maschio e femmina) e posto di sapere che la frequenza con cui si presenta la prima modalità è pari a <span class="math inline">\(p\)</span> (in questo caso la frequenza delle femmine è pari a 0.3), mentre la frequenza della seconda modalità è pari a <span class="math inline">\(q = 1 - p\)</span>, se vogliamo estrarre da questa popolazione <span class="math inline">\(n\)</span> elementi, la probabilità che <span class="math inline">\(k\)</span> di questi presentino la prima modalità (successo) è data da:</p>
<p><span class="math display">\[p^k \cdot q^{(n-k)}\]</span></p>
<p>La formula di cui sopra, tuttavia, non risolve il nostro problema, in quanto noi vogliamo che vengano estratte due femmine, indipendentemente dall’ordine con cui esse vengono estratte (prima, seconda, terza o quarta estrazione), mentre la probabilità che abbiamo appena calcolato è quella relativa all’evento in cui le due femmine sono estratte al primo e secondo posto.</p>
<p>Di conseguenza (teorema della probabilità totale) alla probabilità dell’evento indicato in precedenza (estrazione di due femmine in prima e seconda posizione) dobbiamo sommare la probabilità di tutti gli altri eventi utili (due femmine in seconda e terza posizione, oppure in terza e seconda, oppure in terza e quarta e così via). Il numero delle combinazioni possibili per 2 femmine in quattro estrazioni (combinazione di 4 elementi di classe 2) è dato dal coefficiente binomiale:</p>
<p><span class="math display">\[\left( {\begin{array}{*{20}c}
n  \\
k  \\
\end{array}} \right) = \frac{n!}{(n - k)!k!} \]</span></p>
<p>Moltiplicando le due equazioni date in precedenza otteniamo la funzione di probabilità binomiale:</p>
<p><span class="math display">\[P(X = x_i ) = \frac{{n!}}{{(n - k)!k!}} \cdot p^k \cdot q^{(n - k)} \]</span></p>
<p>Nel caso specifico otteniamo il risultato:</p>
<p><span class="math display">\[P(X = 2) = \frac{4!}{(4 - 2)!2!} \cdot 0.3^2 \cdot 0.7^{(4 - 2)}  = 0.2646 \]</span></p>
<p>che è appunto la probabilità cercata.</p>
<p>In R, utilizziamo la funzione ‘dbinom(successi, prove, probabilità semplice)’ per calcolare la probabilità di ottenere <span class="math inline">\(k\)</span> successi in <span class="math inline">\(n\)</span> prove:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="fl">0.3</span>)
## [1] 0.2646</code></pre></div>
<p>La funzione binomiale è un modello stocastico e si può dimostrare che il valore atteso (media) è uguale ad <span class="math inline">\(n\cdot p\)</span>, mentre la varianza è pari a <span class="math inline">\(n\cdot p \cdot q\)</span>:</p>
<p>La funzione di ripartizione (probabilità cumulata) si calcola in R con la funzione ‘pbinom(successi, prove, probabilità semplice)’. Nell’esempio, se vogliamo sapere la probabilità totale di estrarre meno di tre femmine (2 femmine o meno), possiamo operare in questo modo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pbinom</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
## [1] 0.9163</code></pre></div>
<p>Che risulta anche dalla somma della probabilità di estrarre 0, 1, 2 femmine:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">zero &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
uno &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
due &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
zero <span class="op">+</span><span class="st"> </span>uno <span class="op">+</span><span class="st"> </span>due
## [1] 0.9163</code></pre></div>
<p>La funzione di ripartizione può anche essere utilizzata al contrario, per determinare i quantili, cioè il numero di successi che corrispondono ad una probabilità cumulata pari ad alfa:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qbinom</span>(<span class="fl">0.9163</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
## [1] 2</code></pre></div>
<div id="esercizio" class="section level4 unnumbered">
<h4>Esercizio</h4>
<p>Da una popolazione di insetti che ha un rapporto tra maschi e femmine pari a 0.5, qual è la probabilità di campionare casualmente 2 maschi e 8 femmine?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.5</span>)
## [1] 0.04394531</code></pre></div>
</div>
<div id="esercizio-8" class="section level4 unnumbered">
<h4>Esercizio</h4>
<p>Riportare su un grafico la funzione di ripartizione binomiale, per p=0.5 e n=5. Costruire anche la densità di frequenza, utilizzando le opportune funzioni R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prob &lt;-<span class="st"> </span><span class="fl">0.5</span>
n &lt;-<span class="st"> </span><span class="dv">5</span>
<span class="kw">barplot</span>(<span class="kw">dbinom</span>(<span class="kw">seq</span>(<span class="dv">0</span>, n, <span class="dt">by=</span><span class="dv">1</span>), <span class="dt">size=</span>n, <span class="dt">prob=</span>prob),
          <span class="dt">xlab=</span><span class="st">&quot;Successi&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Probabilità&quot;</span>,
          <span class="dt">names.arg=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName53"></span>
<img src="_main_files/figure-html/figName53-1.png" alt="Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)" width="90%" />
<p class="caption">
Figure 15.9: Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">barplot</span>(<span class="kw">pbinom</span>(<span class="kw">seq</span>(<span class="dv">0</span>, n, <span class="dt">by=</span><span class="dv">1</span>), <span class="dt">size=</span>n, <span class="dt">prob=</span>prob),
          <span class="dt">xlab=</span><span class="st">&quot;Successi&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Probabilità&quot;</span>,
          <span class="dt">names.arg=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName53"></span>
<img src="_main_files/figure-html/figName53-2.png" alt="Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)" width="90%" />
<p class="caption">
Figure 15.9: Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)
</p>
</div>
<p>Allo stesso modo possiamo immaginare di estrarre 20 insetti a caso da una popolazione in cui il rapporto tra i sessi è 1:1. Questo esperimento può essere simulato con:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">prob =</span> <span class="fl">0.5</span>)
Y
## [1] 10</code></pre></div>
<p>Assumendo che il ‘successo’ sia ottenere una femmina, il computer ci restituisce il numero delle femmine.</p>
</div>
</div>
</div>
<div id="capitolo-5-esperimenti-stime-ed-incertezza" class="section level2 unnumbered">
<h2>Capitolo 5: Esperimenti stime ed incertezza</h2>
<div id="e-realistico-lintervallo-di-confidenza" class="section level3 unnumbered">
<h3>E’ realistico l’intervallo di confidenza?</h3>
<p>Abbiamo visto che un metodo semplice per costruire un intervallo di confidenza è utilizzare il doppio dell’errore standard. Questo intervallo, se viene utilizzato come misura di precisione/incertezza, è sempre accettabile. Tuttavia, da un punto di vista strettamente probabilistico, è lecito chiedersi: ma è proprio vero che se io ripeto l’esperimento molte volte e calcolo sempre l’intervallo di confidenza, riesco a centrare la media <span class="math inline">\(\mu\)</span> nel 95% dei casi?</p>
<p>Proviamo a rispondere a questa domanda con una simulazione Monte Carlo. Prendiamo la nostra popolazione (<span class="math inline">\(\mu = 120\)</span> e <span class="math inline">\(\sigma = 12\)</span>) ed estraiamo centomila campioni. Per ogni campione calcoliamo l’intervallo di confidenza della media (P = 0.95) considerando il doppio dell’errore standard. Verifichiamo poi se questo intervallo contiene il valore 120: se si, assegniamo al campionamento il valore 1 (successo), altrimenti assegniamo il valore 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">-</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="dv">2</span>
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.81656</code></pre></div>
<p>La simulazione mostra che la risposta alla domanda precedente è no: il nostro intervallo di confidenza non è riuscito a centrare la media nel 95% dei casi; ciò è avvenuto in poco più dell’80% dei casi. In realtà, possiamo facilmente verificare, con altre simulazioni di Monte Carlo, che la copertura effettiva dell’intervallo di confidenza si avvicina al 95% solo se abbiamo un numero di repliche superiori a 15-20 circa.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  n &lt;-<span class="st"> </span><span class="dv">15</span>
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">-</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span>
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.93591</code></pre></div>
<p>Insomma, quando gli esperimenti sono piccoli, con poche repliche, dovremmo trovare un metodo di calcolo un po’ più affidabile, se veramente vogliamo ottenere un grado di copertura pari a quello nominale (P = 0.95).</p>
<p>Il problema nasce dal fatto che, nella statistica T che abbiamo introdotto nel capitolo 5:</p>
<p><span class="math display">\[T = \frac{m - \mu}{\sigma_m}\]</span> <span class="math inline">\(\sigma_m\)</span> viene sostituito con <span class="math inline">\(s_m\)</span>, cioè il valore di deviazione standard stimato nel campione. Come tutte le stime, anche <span class="math inline">\(s\)</span> è ’soggetto ad incertezza, il che aggiunge un elemento ulteriore di imprecisione nella sampling distribution di T. Insomma ci chiediamo, la <em>sampling distribution</em> di T, calcolata con <span class="math inline">\(s\)</span> invece che <span class="math inline">\(\sigma\)</span> è ancora normale? Verifichiamo questo aspetto empiricamente, con una nuova simulazione Monte Carlo. Questa volta facciamo la seguente operazione:</p>
<ol style="list-style-type: decimal">
<li>campioniamo tre individui</li>
<li>Calcoliamo il valore di T con la statistica precedente, utilizzando la deviazione standard del campione e lo salviamo</li>
<li>Con un po’ di pazienza, ripetiamo il tutto 100’000 volte.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#SIMULAZIONE MONTE CARLO - t di Student</span>
<span class="kw">set.seed</span>(<span class="dv">435</span>)
result &lt;-<span class="st"> </span><span class="kw">c</span>()
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample3 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  Ti &lt;-<span class="st"> </span>(<span class="kw">mean</span>(sample3) <span class="op">-</span><span class="st"> </span><span class="dv">120</span>) <span class="op">/</span><span class="st"> </span>(<span class="kw">sd</span>(sample3)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>))
  result[i] &lt;-<span class="st"> </span>Ti
  }</code></pre></div>
<p>Se riportiamo i valori ottenuti su una distribuzione di frequenze otteniamo il grafico sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Plot sampling distribution</span>
b &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">600</span>, <span class="dv">600</span>, <span class="dt">by=</span><span class="fl">0.2</span>)
<span class="kw">hist</span>(result, <span class="dt">breaks =</span> b, <span class="dt">freq=</span>F, <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(m)), <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.4</span>), <span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">2</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-188-1.png" /><!-- --></p>
<p>Vediamo che la <em>sampling distribution</em> di T calcolato utilizzando <span class="math inline">\(s\)</span> invece che <span class="math inline">\(\sigma\)</span> è solo approssimativamente normale. E’ facile vedere che questa approssimazione è sufficientemente buona solo se la numerosità del campione diviene abbastanza grande (es. <span class="math inline">\(n &gt; 30)\)</span>, ma non certamente quando <span class="math inline">\(n\)</span> = 3 (ve lo lascio per esercizio). In questo caso, la sampling distribution che osserviamo è più ‘dispersa’ di quella normale, con un maggior numero di valori sulle code.</p>
<p>Neyman scoprì che la sampling distribution di T poteva essere perfettamente descritta utilizzando la distribuzione t di Student, con un numero di gradi di libertà pari a quelli del campione (in questo caso 2), come vediamo nella figura sovrastante. In realtà questa conclusione era stata già raggiunta da William Sealy Gosset (1876 - 1937), uno statistico impiegato presso la fabbrica londinese della famosa birra Guinness, dove elaborava i dati relativi all’andamento del processo di maltazione. Egli, avendo definito questa nuova funzione di densità, per aggirare il divieto di pubblicazione imposto dal suo datore di lavoro, pubblicò i risultati sotto lo pseudonimo Student, da cui deriva il nome della distribuzione di densità.</p>
<p>Quindi, quando i campioni sono piccoli, il modo giusto di calcolare l’intervallo di confidenza è quello di utilizzare l’espressione seguente:</p>
<p><span class="math display">\[P \left( m + \textrm{qt}(0.025,n - 1) \cdot s_m \le \mu  \le m + \textrm{qt}(0.975,n - 1) \cdot s_m \right) = 0.95\]</span></p>
<p>dove <span class="math inline">\(\textrm{qt}(0.025,n - 1)\)</span> e <span class="math inline">\(\textrm{qt}(0.975,n - 1)\)</span> sono rispettivamente il 2.5-esimo e il 97.5-esimo percentile della distribuzione t di Student, con n-1 gradi di libertà.</p>
<p>Nel capitolo 5 abbiamo utilizzato un esempio in cui abbiamo eseguito tre analisi chimiche da una soluzione erbicida di concentrazione pari a 120 mg/l, con uno strumento caratterizzato da un coefficiente di variabilità del 10%, che quindi, in assenza di errori sistematici, produce misure distribuite normalmente con media uguale a 120 e deviazione standard uguale a 12. Il campione osservato era</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
Y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
Y
## [1] 125.1584 114.7349 105.6998</code></pre></div>
<p>le statistiche descrittive sono:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">mean</span>(Y)
s &lt;-<span class="st"> </span><span class="kw">sd</span>(Y)
m; s
## [1] 115.1977
## [1] 9.737554</code></pre></div>
<p>I valori della distribuzione t di Student che lasciano al loro esterno il 5% delle varianti (2.5% per coda) sono:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>)
## [1] -4.302653
<span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>)
## [1] 4.302653</code></pre></div>
<p>Gli intervalli di confidenza sono pertanto:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>s<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>)
## [1] 91.00824
m <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>s<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>)
## [1] 139.3871</code></pre></div>
<p>E’ facile osservare che, se l’intervallo di confidenza è calcolato in questo modo, il suo <em>coverage</em><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> Operiamo con una simulazione Monte Carlo analoga a quella utilizzata nel capitolo 5.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>) 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>) 
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.94992</code></pre></div>
<p>Ovviamente possiamo calcolare anche gli intervalli di confidenza al 99% di proababilità o qualunque altro intervallo di confidenza rilevante per il nostro studio.</p>
</div>
<div id="che-cosa-non-significa-lintervallo-di-confidenza" class="section level3 unnumbered">
<h3>Che cosa NON significa l’intervallo di confidenza?</h3>
<p>Abbiamo già detto che l’intervallo di confidenza, calcolato su una serie di campionamenti ripetuti, contiene al suo interno la media vera e ignota della popolazione (<span class="math inline">\(\mu\)</span>) con una probabilità pari a 0.95.</p>
<p>Tuttavia, la formula di Neyman si presta a cattive letture, che sono insensate da un punto di vista probabilistico, ma tuttavia molto frequenti nella pratica operativa. Ad esempio:</p>
<ol style="list-style-type: decimal">
<li><strong>NON E’ VERO CHE:</strong> c’è il 95% di probabilità che la media ‘vera’ della popolazione si trovi tra 91.0082383 e 139.3870891. La media vera della popolazione è sempre fissa e pari a 120 e non cambia affatto tra un campionamento e l’altro.</li>
<li><strong>NON E’ VERO CHE:</strong> ripetendo l’esperimento, il 95% delle stime che otteniamo cadono nell’intervallo 91.0082383 e 139.3870891. Una semplice simulazione mostra che quasi tutte le medie campionate cadono in quell’intervallo:</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  <span class="cf">if</span> (<span class="kw">mean</span>(sample) <span class="op">&lt;=</span><span class="st"> </span><span class="fl">156.15</span> <span class="op">&amp;</span><span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">&gt;=</span><span class="st"> </span><span class="fl">92.13</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.99996</code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>NON E’ VERO CHE:</strong> c’è il 95% di probabilità che l’affermazione ’la media vera è compresa tra 91.0082383 e 139.3870891 sia vera. Nelle normali condizioni sperimentali la media vera è ignota e non sapremo mai nulla su di essa: il nostro intervallo di confidenza può catturarla o no. Nel nostro esempio lo ha fatto, ed è tutto quello che possiamo dire.</li>
</ol>
<p>Insomma, l’intervallo di confidenza vale per la sampling distribution e non vale per ogni singolo campionamento (esperimento). Pertanto, affermazioni del tipo: ”c’è il 95% di probabilità che <span class="math inline">\(\mu\)</span> è compreso nell’intervallo di confidenza” oppure ”il valor più probabile di <span class="math inline">\(\mu\)</span> è…” non sono corrette e anzi non hanno senso nella statistica tradizionale.</p>
<p>In altre parole, l’intervallo di confidenza è una sorta di polizza assicurativa che ci garantisce che, se operiamo continuativamente con le procedure indicate, al termine della nostra carriera avremo sbagliato in non più del 5% dei casi.</p>
</div>
<div id="popolazioni-non-gaussiane" class="section level3 unnumbered">
<h3>Popolazioni non gaussiane</h3>
<p>Nel capitolo 5 abbiamo presentato un esempio in cui avevamo campionato da una distribuzione normale, riscontrando una <em>sampling distribution</em> per la media campionaria anch’essa normale. Ma che succede se la distribuzione di partenza è non-normale? La <em>sampling distribution</em> di uno stimatore è ancora normale? Vediamo un nuovo esempio.</p>
<p>Immaginiamo di avere 4’000’000 di semi ben mischiati (in modo che non ci siano raggruppamenti non casuali di qualche tipo), che costituiscono la nostra popolazione di partenza. Vogliamo appurare la frequenza relativa (p) dei semi dormienti. Questa informazione, nella realtà, esiste (<span class="math inline">\(\pi\)</span> = 0.25), ma non è nota.</p>
<p>Dato l’elevato numero di ‘soggetti’, non possiamo testare la germinabilità di tutti i semi, ma dobbiamo necessariamente prelevare un campione casuale di 40 soggetti; ogni seme viene saggiato e, dato che la popolazione è molto numerosa, l’estrazione di un seme non modifica sensibilmente la proporzione di quelli dormienti nella popolazione (esperimenti indipendenti).</p>
<div id="il-modello-dei-dati-1" class="section level4 unnumbered">
<h4>Il modello dei dati</h4>
<p>Dopo aver descritto la popolazione e l’esperimento, ci chiediamo quale sia il modello matematico che genera i nostri dati (numero di successi su 40 semi estratti). Il disegno sperimentale ci assicura che ogni estrazione è totalmente indipendente dalla precedente e dalla successiva ed ha due soli risultati possibili, cioè successo (seme dormiente), o insuccesso (seme germinabile). Di conseguenza, ogni singola estrazione si configura come un esperimento Bernoulliano, con probabilità di successo pari a <span class="math inline">\(\pi\)</span>, il cui valore ‘vero’ esiste, è fisso, pre-determinato (esiste ancor prima di organizzare l’esperimento), anche se incognito e inconoscibile, a meno di non voler/poter esaminare tutti i semi disponibili. L’insieme delle 40 estrazioni (40 esperimenti Bernoulliani) può produrre un ventaglio di risultati possibili, da 40 successi a 40 insuccessi, per un totale di 41 possibili ‘outcomes’.</p>
<p>E’ evidente che i 41 possibili risultati non sono ugualmente probabili e si può dimostrare che la probabilità di ottenere <em>k</em> successi (con <em>k</em> che va da 0 ad <em>n</em>; <em>n</em> è al numero delle estrazioni) dipende da <span class="math inline">\(\pi\)</span> ed è descrivibile matematicamente con la distribuzione binomiale <span class="math inline">\(\phi\)</span>:</p>
<p><span class="math display">\[\phi(k, n, p) = \frac{n!}{(n-k)!k!} p^k (1 - p)^{(n-k)}\]</span></p>
<p>Abbiamo quindi definito il modello matematico che descrive la probabilità di tutti i possibili risultati del nostro esperimento e quindi può in qualche modo essere considerato il ‘meccanismo’ che ‘genera’ i dati sperimentali osservati. Si tratta di un meccanismo puramente ‘stocastico’ nel quale è solo il caso che, attraverso il campionamento, determina il risultato dell’esperimento.</p>
<p>Con queste informazioni, possiamo simulare un esperimento con R, ottenendo i seguenti risultati:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">23456789</span>)
<span class="kw">rbinom</span>(<span class="dv">1</span>, <span class="dv">40</span>, <span class="fl">0.25</span>)
## [1] 10</code></pre></div>
<p>Abbiamo ottenuto 9 successi su 40, cioè 9 semi dormienti su 40 saggiati.</p>
</div>
<div id="stima-dei-parametri-5" class="section level4 unnumbered">
<h4>Stima dei parametri</h4>
<p>Dovendo stimare la quantità <span class="math inline">\(\pi\)</span>, la statistica tradizionale trascura totalmente le nostre aspettative sul fenomeno e utilizza soltanto i risultati dell’esperimento. Chiamiamo <em>p</em> la quantità stimata e, dato che abbiamo contato nove semi dormienti, concludiamo che p = 0.225, in quanto questa, con le informazioni che abbiamo, è la cosa più verosimile. Anche in questo caso vi è chiara discrasia tra la verità ‘vera’ e l’osservazione sperimentale (tra <span class="math inline">\(\pi\)</span> e <span class="math inline">\(p\)</span>).</p>
</div>
<div id="sampling-distribution" class="section level4 unnumbered">
<h4>Sampling distribution</h4>
<p>Cosa succede se ripetiamo l’esperimento? Come abbiamo imparato a fare, possiamo cercare una risposta attraverso la simulazione Monte Carlo, ricorrendo ad un generatore di numeri casuali da una distribuzione binomiale con n = 40 e <span class="math inline">\(\pi\)</span> = 0.25 (in R si usa la funzione ‘rbinom(numeroDatiCasuali, n, p)’). Il codice è più semplice, in quanto non è necessario impostare un ciclo iterativo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
result &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">10000000</span>, <span class="dv">40</span>, <span class="fl">0.25</span>)</code></pre></div>
<p>Esploriamo i risultati ottenuti:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result_p &lt;-<span class="st"> </span>result<span class="op">/</span><span class="dv">40</span>
<span class="kw">mean</span>(result_p)
## [1] 0.2500129
<span class="kw">sd</span>(result_p)
## [1] 0.0684611</code></pre></div>
<p>Osserviamo subito che, anche se i singoli esperimenti portano a stime diverse da <span class="math inline">\(\pi\)</span>, la media di <span class="math inline">\(p\)</span> tende ad essere uguale a <span class="math inline">\(\pi\)</span>. L’errore standard (deviazione standard della <em>sampling distribution</em>) è 0.0685. Fino a qui, non vie è nulla di diverso dall’esempio precedente, se teniamo presente che la deviazione standard della popolazione originale (che è binomiale) è pari a <span class="math inline">\(\sqrt{p \times (1 - p)}\)</span>, quindi l’errore standard è <span class="math inline">\(\sqrt{0.25 \times 0.75 / 40} = 0.0685\)</span>.</p>
<p>Rimane da stabilire se la <em>sampling distribution</em> di <span class="math inline">\(p\)</span> è normale. Possiamo utilizzare i 10’000’000 di valori ottenuti per costruire una distribuzione empirica di frequenze, come nel codice sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">breaks &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">0.7</span>, <span class="dt">by=</span><span class="fl">0.025</span>)
freqAss &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( <span class="kw">table</span>(<span class="kw">cut</span>(result_p, breaks) ) ) 
freqRel &lt;-<span class="st"> </span>freqAss<span class="op">/</span><span class="kw">length</span>(result_p)
density &lt;-<span class="st"> </span>freqRel<span class="op">/</span><span class="fl">0.025</span>
p_oss &lt;-<span class="st"> </span>breaks[<span class="dv">2</span><span class="op">:</span><span class="kw">length</span>(breaks)]

<span class="kw">plot</span>(density <span class="op">~</span><span class="st"> </span>p_oss, <span class="dt">type =</span> <span class="st">&quot;h&quot;</span>,
     <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">bar</span>(p))),
     <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, 
    <span class="dt">main=</span><span class="st">&quot;Sampling distribution per p&quot;</span>, 
    <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.6</span>) )

<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="fl">0.25</span>, <span class="fl">0.0685</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-198-1.png" /><!-- --></p>
<p>Vediamo che <em>sampling distribution</em> è approssimativamente normale con media pari a 0.25 e deviazione standard pari a 0.0685. Lo percepiamo chiaramente dal grafico soprastante, ma c’è una spiegazione scientifica per questo, basata sul <strong>TEOREMA DEL LIMITE CENTRALE</strong>:</p>
<ol style="list-style-type: decimal">
<li>La sampling distribution di una statistica ottenuta da campioni casuali e indipendenti è approssimativamente normale, indipendentemente dalla distribuzione della popolazione da cui i campioni sono stati estratti.</li>
<li>La media della sampling distribution è uguale al valore della statistica calcolata sulla popolazione originale, la deviazione standard della sampling distribution (errore standard) è pari alla deviazione standard della popolazione originale divisa per la radice quadrata della numerosità di un campione.</li>
</ol>
</div>
</div>
</div>
<div id="capitolo-6.-introduzione-al-test-dipotesi" class="section level2 unnumbered">
<h2>Capitolo 6. Introduzione al test d’ipotesi</h2>
<div id="simulazione-monte-carlo-di-un-test-t-di-student" class="section level3 unnumbered">
<h3>Simulazione Monte Carlo di un test t di Student</h3>
<p>La sampling distribution per T potrebbe essere ottenuta empiricamente, utilizzando una simulazione MONTE CARLO ed immaginando di estrarre numerose coppie di campioni, dalla stessa distribuzione normale, analogamente a quanto abbiamo fatto nell’esempio precedente. Se l’ipotesi nulla è vera, possiamo immaginare che questa distribuzione gaussiana abbia una media pari a (70.2 + 85.4)/2 = 77.8 e una deviazione standard pari alla deviazione standard delle dieci osservazioni (tutte insieme, senza distinzioni di trattamento), cioè 5.71.</p>
<p>Il codice da utilizzare in R per le simulazioni è il seguente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">A &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">65</span>, <span class="dv">68</span>, <span class="dv">69</span>, <span class="dv">71</span>, <span class="dv">78</span>)
P &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">80</span>, <span class="dv">81</span>, <span class="dv">84</span>, <span class="dv">88</span>, <span class="dv">94</span>)
media &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">c</span>(A, P))
devSt &lt;-<span class="st"> </span><span class="kw">sd</span>(<span class="kw">c</span>(A, P))
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">5</span>, media, devSt)
  sample2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">5</span>, media, devSt)
  SED &lt;-<span class="st"> </span><span class="kw">sqrt</span>( (<span class="kw">sd</span>(sample1)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> <span class="op">+</span>
<span class="st">                 </span>(<span class="kw">sd</span>(sample2)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> )
  result[i] &lt;-<span class="st"> </span>(<span class="kw">mean</span>(sample1) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(sample2)) <span class="op">/</span><span class="st"> </span>SED
}</code></pre></div>
<p>I risultati delle 100’000 simulazioni sono riportati nel grafico sottostante. Possiamo notare che, dei 100’000 valori di T osservati assumendo vera l’ipotesi nulla, solo l’un per mille sono superiori a quello da noi osservato e altrettanti sono inferiori a -4.5217. In totale, la probabilità di osservare un valore di T così alto in valore assoluto e dello 0.21 %.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SED_obs &lt;-<span class="st"> </span><span class="kw">sqrt</span>( (<span class="kw">sd</span>(A)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> <span class="op">+</span>
<span class="st">                   </span>(<span class="kw">sd</span>(P)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> )
T_obs &lt;-<span class="st"> </span>(<span class="kw">mean</span>(A) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(P))<span class="op">/</span>SED_obs
(<span class="kw">length</span>(result[result <span class="op">&lt;</span><span class="st"> </span>T_obs]) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">length</span>(result[result <span class="op">&gt;</span><span class="st"> </span><span class="op">-</span><span class="st"> </span>T_obs])) <span class="op">/</span><span class="dv">100000</span>
## [1] 0.00164</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Codice Grafico </span>
b &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">12</span>, <span class="dv">12</span>, <span class="dt">by=</span><span class="fl">0.25</span>)
<span class="kw">hist</span>(result, <span class="dt">breaks =</span> b, <span class="dt">freq=</span>F, <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(m)), <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.45</span>), <span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x), <span class="dt">add=</span>T, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">8</span>), <span class="dt">add=</span>T, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="fl">4.52</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="op">-</span><span class="fl">4.52</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">text</span>(<span class="dv">5</span>, <span class="fl">0.4</span>, <span class="dt">label=</span><span class="st">&quot;4.52&quot;</span>, <span class="dt">adj=</span><span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
<span class="kw">text</span>(<span class="op">-</span><span class="dv">5</span>, <span class="fl">0.4</span>, <span class="dt">label=</span><span class="st">&quot;-4.52&quot;</span>, <span class="dt">adj=</span><span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-201-1.png" /><!-- --></p>
</div>
<div id="tipologie-alternative-di-test-t-di-student" class="section level3 unnumbered">
<h3>Tipologie alternative di test t di Student</h3>
<p>Il test t può essere di tre tipi:</p>
<ol style="list-style-type: decimal">
<li>Appaiato. In questo caso le misure sono prese a coppia sullo stesso soggetto e non sono quindi indipendenti.</li>
<li>Omoscedastico. Le misure sono prese su soggetti diversi (indipendenti) e possiamo suppore che i due campioni provengano da due popolazioni con la stessa varianza.</li>
<li>Eteroscedastico. Le misure sono prese su soggetti diversi, ma le varianze non sono omogenee.</li>
</ol>
<p>Nel nostro esempio vediamo che le varianze dei campioni sono piuttosto simili e quindi adottiamo un test t omoscedastico (‘var.equal = T’).</p>
<p>Se dovessimo supporre che i due campioni provengono da popolazioni con varianze diverse, allora si porrebbe il problema di stabilire il numero di gradi di libertà del SEM. Abbiamo visto che se le varianze dei due campioni sono uguali (o meglio, sono due stime della stessa varianza), la varianza della somma/differenza ha un ha un numero di gradi di libertà pari alla somma dei gradi di libertà delle due varianze. Se le varianze fossero diverse, il numero di gradi di libertà della loro combinazione lineare (somma o differenza) si dovrebbe approssimare con la formula di Satterthwaite:</p>
<p><span class="math display">\[DF_s \simeq \frac{ \left( s^2_1 + s^2_2 \right)^2 }{ \frac{(s^2_1)^2}{DF_1} + \frac{(s^2_2)^2}{DF_2} }\]</span></p>
<p>Vediamo che se le varianze e i gradi di libertà sono uguali, la formula precedente riduce a:</p>
<p><span class="math display">\[DF_s = 2 \times DF\]</span></p>
<p>Nel nostro caso, se fosse <span class="math inline">\(s^2_1 \neq s^2_2\)</span> avremmo un numero frazionario di gradi di libertà:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dfS &lt;-<span class="st"> </span>(<span class="kw">var</span>(A) <span class="op">+</span><span class="st"> </span><span class="kw">var</span>(P))<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>
<span class="st">  </span>((<span class="kw">var</span>(A)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span> <span class="op">+</span><span class="st"> </span>(<span class="kw">var</span>(P)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span>)
dfS
## [1] 7.79772</code></pre></div>
<p>Il risultato può essere riscontrato con:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(A, P, <span class="dt">var.equal=</span>F)
## 
##  Welch Two Sample t-test
## 
## data:  A and P
## t = -4.5217, df = 7.7977, p-value = 0.002076
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -22.986884  -7.413116
## sample estimates:
## mean of x mean of y 
##      70.2      85.4</code></pre></div>
<p>Se invece avessimo rilevato le misure accoppiate su quattro individui avremmo solo 4 gradi di libertà:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(A, P, <span class="dt">var.equal=</span>T, <span class="dt">paired=</span>T)
## 
##  Paired t-test
## 
## data:  A and P
## t = -22.915, df = 4, p-value = 2.149e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -17.04169 -13.35831
## sample estimates:
## mean of the differences 
##                   -15.2</code></pre></div>
</div>
<div id="simulazione-di-un-test-di-chi-quadro" class="section level3 unnumbered">
<h3>Simulazione di un test di chi quadro</h3>
<p>La simulazione di un test di <span class="math inline">\(\chi^2\)</span> può esser fatta utilizzando la funzione ‘r2dtable()’ che produce il numero voluto di tabelle di contingenza, con righe e colonne indipendenti r rispettando i totali marginali voluti. Le tabelle prodotte (nel nostro caso 10’000) sono restituite come lista, quindi possiamo utilizzare la funzione ‘lapply()’ per applicare ad ogni elemento della lista la funzione che restituisce il <span class="math inline">\(\chi^2\)</span> (‘chiSim’).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">counts &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">56</span>, <span class="dv">19</span>, <span class="dv">48</span>, <span class="dv">2</span>)
tab &lt;-<span class="st"> </span><span class="kw">matrix</span>(counts, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">byrow =</span> T)
<span class="kw">row.names</span>(tab) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;E&quot;</span>, <span class="st">&quot;EC&quot;</span>)
<span class="kw">colnames</span>(tab) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;M&quot;</span>, <span class="st">&quot;V&quot;</span>)
tab
##     M  V
## E  56 19
## EC 48  2
chiSim &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">summary</span>(<span class="kw">as.table</span>(x))<span class="op">$</span>stat
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
tabs &lt;-<span class="st"> </span><span class="kw">r2dtable</span>(<span class="dv">10000</span>, <span class="kw">apply</span>(tab, <span class="dv">1</span>, sum), <span class="kw">apply</span>(tab, <span class="dv">2</span>, sum))
chiVals &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( <span class="kw">lapply</span>( tabs, chiSim) )
<span class="kw">length</span>(chiVals[chiVals <span class="op">&gt;</span><span class="st"> </span><span class="fl">9.768</span>])
## [1] 22</code></pre></div>
<p>Vediamo che vi sono 19 valori più alti di quello da noi osservato (p = 0.0019).</p>
</div>
<div id="errori-di-prima-e-di-seconda-specie" class="section level3 unnumbered">
<h3>Errori di prima e di seconda specie</h3>
<p>[da fare]</p>
</div>
</div>
<div id="capitolo-7-anova-ad-una-via" class="section level2 unnumbered">
<h2>Capitolo 7: ANOVA ad una via</h2>
<div id="perche-il-vincolo-sulla-somma-e-preferibile-per-i-calcoli-manuali" class="section level3">
<h3><span class="header-section-number">15.0.2</span> Perchè il vincolo sulla somma è preferibile per i calcoli manuali</h3>
</div>
<div id="lanova-a-mano" class="section level3 unnumbered">
<h3>L’ANOVA ‘a mano’</h3>
<p>Nel capitolo 7 ci siamo trovati di fronte ad un dataset relativo ad un esperimento in vaso, nel quale erano stati utilizzati utilizzato quattro trattamenti erbicidi (Metribuzin, Rimsulfuron, Metribuzin + rimsulfuron e un testimone non trattato), con lo scopo di verificare quale di questi fosse più efficace dei due componenti utilizzati separatamente. L’esperimento era a randomizzazione completa ed il dataset era quello riportato nella Tabella</p>
</div>
</div>
<div id="capitolo-8-verifica-delle-assunzioni" class="section level2 unnumbered">
<h2>Capitolo 8: verifica delle assunzioni</h2>
<div id="il-qq-plot" class="section level3 unnumbered">
<h3>Il QQ-plot</h3>
<p>[da fare]</p>
</div>
<div id="correzione-dati-mancantiaberranti" class="section level3 unnumbered">
<h3>Correzione dati mancanti/aberranti</h3>
<p>La correzione dei dati aberranti era una pratica tipica di qualche decennio fa, quando le metodiche di calcolo non erano sufficientemente sofisticate per consentire l’analisi dei dati sbilanciati. Se il disegno sperimentale era a randomizzazione completa, il dato mancante veniva sostituito con la media delle altre repliche. Se invece il disegno era a blocchi randomizzati, allora si teneva conto non solo della media del trattamento di cui il dato mancante faceva parte, ma anche delle media del blocco nel quale esso si trovava. La formula era la seguente:</p>
<p><span class="math display">\[Y = \frac{tT + rR - G}{(t - 1)(r - 1)}\]</span></p>
<p>dove <em>t</em> è il numero delle tesi, <em>r</em> è il numero delle repliche, <em>T</em> è la somma dei dati relativi alla tesi che contiene il dato mancante (ovviamente escluso quest’ultimo), <em>R</em> è la somma dei dati relativi al blocco che contiene il dato mancante (sempre escluso quest’ultimo), <em>G</em> è il totale generale (escluso il dato mancante).</p>
<p>Un aspetto da non trascurare è che, imputando un dato, si rimuove lo sbilanciamento, ma non si recuperano le informazioni mancanti. Infatti il dato imputato non fornisce informazioni aggiuntive, perché è ottenuti come combinazione lineare degli altri. Di conseguenza, per ogni dato imputato, è necessario ridurre di un’unità il numero dei gradi di libertà della varianza residua, e ricalcolare F, SEM e SED di conseguenza.</p>
<p>Possiamo comunque ritenere che, oggigiorno, le tecniche di imputing dei dati aberranti/mancanti sono da ritenersi obsolete.</p>
</div>
</div>
<div id="capitolo-9-contrasti-e-confronti-multipli" class="section level2 unnumbered">
<h2>Capitolo 9: Contrasti e confronti multipli</h2>
<div id="intervallo-di-confidenza-di-un-contrasto" class="section level3 unnumbered">
<h3>Intervallo di confidenza di un contrasto</h3>
<p>Nel capitolo 9 abbiamo abbiamo lavorato con questo dataset:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">yield &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">20</span>,<span class="dv">21</span>,<span class="dv">23</span>,<span class="dv">22</span>,<span class="dv">19</span>,<span class="dv">20</span>,<span class="dv">12</span>,<span class="dv">15</span>,<span class="dv">13</span>,<span class="dv">19</span>,<span class="dv">18</span>,<span class="dv">16</span>)
fert &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">rep</span>(<span class="kw">c</span>(<span class="st">&quot;Minerale&quot;</span>, <span class="st">&quot;Minerale lento&quot;</span>, 
          <span class="st">&quot;Non concimato&quot;</span>, <span class="st">&quot;Organico&quot;</span>), <span class="dt">each=</span><span class="dv">3</span>))
dataset &lt;-<span class="st"> </span><span class="kw">data.frame</span>(yield, fert)
<span class="kw">rm</span>(yield, fert)
dataset
##    yield           fert
## 1     20       Minerale
## 2     21       Minerale
## 3     23       Minerale
## 4     22 Minerale lento
## 5     19 Minerale lento
## 6     20 Minerale lento
## 7     12  Non concimato
## 8     15  Non concimato
## 9     13  Non concimato
## 10    19       Organico
## 11    18       Organico
## 12    16       Organico</code></pre></div>
<p>ed abbiamo eseguito l’ANOVA, calcolando le medie delle tesi sperimentali, con la funzione ‘emmeans()’ nel package ‘emmeans’:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(yield <span class="op">~</span><span class="st"> </span>fert, <span class="dt">data=</span>dataset)
<span class="kw">anova</span>(model)
## Analysis of Variance Table
## 
## Response: yield
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## fert       3 115.000  38.333  16.429 0.0008821 ***
## Residuals  8  18.667   2.333                      
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
<span class="kw">library</span>(emmeans)
medie &lt;-<span class="st"> </span><span class="kw">emmeans</span>(model, <span class="op">~</span>fert)
medie
##  fert             emmean        SE df lower.CL
##  Minerale       21.33333 0.8819171  8 19.29963
##  Minerale lento 20.33333 0.8819171  8 18.29963
##  Non concimato  13.33333 0.8819171  8 11.29963
##  Organico       17.66667 0.8819171  8 15.63296
##  upper.CL
##  23.36704
##  22.36704
##  15.36704
##  19.70037
## 
## Confidence level used: 0.95</code></pre></div>
<p>Da un punto di vista biologico, abbiamo ritenuto rilevanti i seguenti contrasti:</p>
<ol style="list-style-type: decimal">
<li>non concimato vs concimato (in media)</li>
<li>concime organico vs. concimi minerali (in media)</li>
<li>concime minerale tradizionale vs. concime a lento rilascio.</li>
</ol>
<p>Li abbiamo eseguiti e abbiamo testato l’ipotesi nulla che ognuno di essi fosse significativamente diverso da 0. I risultati erano:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">3</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>,  <span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span><span class="op">/</span><span class="dv">3</span>)
m2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.5</span>, <span class="dv">0</span>, <span class="op">-</span><span class="dv">1</span>)
m3 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>)
<span class="kw">contrast</span>(medie, <span class="dt">method=</span><span class="kw">list</span>(<span class="dt">C1=</span>m1, <span class="dt">C2=</span>m2, <span class="dt">C3=</span>m3), 
           <span class="dt">adjust=</span><span class="st">&quot;none&quot;</span>)
##  contrast estimate       SE df t.ratio p.value
##  C1       6.444444 1.018350  8   6.328  0.0002
##  C2       3.166667 1.080123  8   2.932  0.0189
##  C3       1.000000 1.247219  8   0.802  0.4458</code></pre></div>
<p>Testare la significatività di un contrasto, secondo Tukey (1991), è sciocco (‘foolish’) almeno per due motivi:</p>
<ol style="list-style-type: decimal">
<li>la domanda non è realistica: due trattamenti diversi o due gruppi di trattamenti diversi non possono che dare risultati diversi, magari in modo impercettibile, ma pur sempre diversi;</li>
<li>l’eventuale rifiuto dell’ipotesi nulla non ci da nessuna informazione sulla rilevanza biologica della differenza, che è indipendente dalla sua significatività.</li>
</ol>
<p>Pertanto, sempre secondo Tukey, è molto più rilevante parlare di <em>effect size</em>, cioè di ampiezza dell’effetto, da quantificare tramite un intervallo di confidenza. Le formule sono quelle usuali, tramite i quantili della distribuzione t di Student, con un numero di gradi di libertà pari a quello del residuo ANOVA. Ad esempio, per il primo contrasto, l’intervallo di confidenza è:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">limSup &lt;-<span class="st"> </span><span class="fl">6.4467</span> <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">8</span>) <span class="op">*</span><span class="st"> </span><span class="fl">1.018277</span>
limInf &lt;-<span class="st"> </span><span class="fl">6.4467</span> <span class="op">-</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">8</span>) <span class="op">*</span><span class="st"> </span><span class="fl">1.018277</span>
limInf; limSup
## [1] 4.098549
## [1] 8.794851</code></pre></div>
<p>Con R, possiamo utilizzare la funzione ‘confint()’, passandole l’oggetto ‘medie’, ottenuto come output della funzione ‘emmeans()’:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(<span class="kw">contrast</span>(medie, <span class="dt">method=</span><span class="kw">list</span>(<span class="dt">C1=</span>m1, <span class="dt">C2=</span>m2, <span class="dt">C3=</span>m3), 
           <span class="dt">adjust=</span><span class="st">&quot;none&quot;</span>))
##  contrast estimate       SE df   lower.CL upper.CL
##  C1       6.444444 1.018350  8  4.0961248 8.792764
##  C2       3.166667 1.080123  8  0.6758975 5.657436
##  C3       1.000000 1.247219  8 -1.8760925 3.876092
## 
## Confidence level used: 0.95</code></pre></div>
<p>L’uso degli intervalli di confidenza può essere preferibile al test d’ipotesi formale perché ci fa vedere l’entità degli effetti; ad esempio, possiamo vedere che la differenza tra il concime tradizionale e quello a lento rilascio (contrasto C3), anche se non significativa, potrebbe essere rilevante da un punto di vista agronomico (3.88 q/ha).</p>
</div>
<div id="correzione-per-la-molteplicita-1" class="section level3 unnumbered">
<h3>Correzione per la molteplicità</h3>
<p>Quando si elaborano i dati di un esperimento nel quale è necessario fare molti contrasti, o confronti, o, più in generale, molti test d’ipotesi simultanei, si potrebbe voler esprimere un giudizio globale (simultaneo) sull’intera famiglia di contrasti/confronti, minimizzando la possibilità che anche solo uno o pochi di essi siano sbagliati. Vediamo alcuni esempi di quando questo potrebbe capitare.</p>
<ol style="list-style-type: decimal">
<li>Non vogliamo correre rischi di escludere erroneamente alcun trattamento dal lotto dei migliori. Infatti, poniamo di voler trovare i migliori di <em>k</em> trattamenti, intendendo con ciò quelli che non sono significativamente inferiori a nessun altro. In questa situazione, facendo ogni confronto con il 5% di probabilità di errore, la probabilità di escludere erroneamente anche solo un trattamento dal lotto dei migliori è molto più alta di quella prefissata, perché basta sbagliare anche uno solo dei <em>k - 1</em> confronti con il migliore.</li>
<li>Abbiamo utilizzato un display a lettere e intendiamo affermare che ‘i trattamenti seguiti da lettere diverse sono significativamente diversi’. In questo caso, stiamo tirando una conclusione basata sull’intera famiglia di confronti e non possiamo lecitamente riportare la probabilità di errore di un singolo confronto.</li>
</ol>
<p>In tutte le condizioni analoghe a quelle più sopra accennate si pone il problema di aggiustare il p-level) di ogni contrasto in modo da rispettare un certo livello prestabilito di errore per esperimento (e non per confronto).</p>
<p>Per aggiustare il p-level e correggere quindi per la molteplicità abbiamo parecchie possibilità. La prima è quella di utilizzare la formula precedente (metodo di Sidak). Ad esempio, nel caso del terzo dei sei confronti a coppie illustrati in precedenza (Minerale - Organico = 3.667; p = 0.018713), la correzione del p-level per la molteplicità è:</p>
<p><span class="math display">\[ \alpha_E = 1 - (1 - 0.018713)^6 = 0.1051546 \]</span></p>
<p>Con R possiamo utilizzare il seguente comando:</p>

<pre><code>contrast(medie, method=&quot;pairwise&quot;, adjust=&quot;sidak&quot;)</code></pre>

<p>Vediamo che alcuni confronti che prima erano significativi, ora non lo sono più.</p>
<p>Un’alternativa più nota (e semplice) è quella di utilizzare la diseguaglianza di Bonferroni:</p>
<p><span class="math display">\[\alpha_E = \alpha_C \cdot k\]</span></p>
<p>Quest’ultima è un po’ più conservativa della precedente, nel senso che fornisce un p-level aggiustato leggermente più alto dell’altra.</p>
<p><span class="math display">\[\alpha_E = 0.018713 \cdot 6 = 0.112278 \]</span></p>
<p>Con R:</p>

<pre><code>contrast(medie, method=&quot;pairwise&quot;, adjust=&quot;bonferroni&quot;)</code></pre>

<p>Sono possibili altre procedure di aggiustamento del p-level (metodi di Holm, Hochberg, Hommel), ma nessuna di queste tiene conto della correlazione eventualmente esistente tra i contrasti e tutte quindi sono da definirsi più o meno ‘conservative’.</p>
<p>Invece che aggiustare il p-level con uno dei metodi indicati più sopra è possibile considerare che, nel caso di contrasti e/o confronti, ogni singolo test d’ipotesi consiste in un rapporto tra una stima e il suo errore standard e segue la distribuzione di t univariata (vedi sopra). Di conseguenza, una famiglia di confronti/contrasti segue la distribuzione di t multivariato, con una matrice di correlazione che deducibile dal contesto, come indicato da Bretz et al., (2011), pag. 73. In altre parole, noto che sia il valore di t di ogni contrasto/confronto, posso desumere la relativa probabilità dalla distribuzione di t multivariata, invece che da quella univariata. Ovviamente il calcolo manuale è complesso e dovremo affidarci al software, come esemplificato più sotto. Questo tipo di correzione è quella di default in R, come si può desumere dal fatto che in tutti i frammenti di codice dati finora abbiamo dovuto specificare esplicitamente ‘correct=“none”’.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Confronti multipli a coppie, basati sul t multivariato</span>
<span class="kw">contrast</span>(medie, <span class="dt">method=</span><span class="st">&quot;pairwise&quot;</span>)
##  contrast                        estimate       SE df
##  Minerale - Minerale lento       1.000000 1.247219  8
##  Minerale - Non concimato        8.000000 1.247219  8
##  Minerale - Organico             3.666667 1.247219  8
##  Minerale lento - Non concimato  7.000000 1.247219  8
##  Minerale lento - Organico       2.666667 1.247219  8
##  Non concimato - Organico       -4.333333 1.247219  8
##  t.ratio p.value
##    0.802  0.8518
##    6.414  0.0009
##    2.940  0.0724
##    5.612  0.0022
##    2.138  0.2203
##   -3.474  0.0342
## 
## P value adjustment: tukey method for comparing a family of 4 estimates
<span class="kw">contrast</span>(medie, <span class="dt">method=</span><span class="st">&quot;dunnett&quot;</span>)
##  contrast                   estimate       SE df
##  Minerale lento - Minerale -1.000000 1.247219  8
##  Non concimato - Minerale  -8.000000 1.247219  8
##  Organico - Minerale       -3.666667 1.247219  8
##  t.ratio p.value
##   -0.802  0.7516
##   -6.414  0.0006
##   -2.940  0.0479
## 
## P value adjustment: dunnettx method for 3 tests</code></pre></div>

<p>Possiamo notare che i p-levels sono leggermente più bassi di quelli ottenuti con Bonferroni, che conferma quindi di essere una procedura molto conservativa, mentre l’impiego del t multivariato consente di rispettare esattamente il tasso di errore ‘per esperimento’familywise’.</p>
</div>
<div id="intervalli-di-confidenza-simultanei" class="section level3 unnumbered">
<h3>Intervalli di confidenza simultanei</h3>
<p>Nell’ottica esposta in precedenza, che prevede l’uso preferenziale degli intervalli di confidenza al posto del test d’ipotesi, è molto più interessante creare degli intervalli di confidenza <em>familywise</em>. Nel caso più semplice dei confronti a coppie nell’ANOVA per disegni ortogonali (bilanciati), si può utilizzare al posto del valore <span class="math inline">\(t_{\alpha/2, \nu}\)</span> il valore ottenuto dalla distribuzione t multivariata, che, per nostra fortuna, si può facilmente desumere dalle tabelle dello ‘Studentised Range’, in funzione del numero di trattamenti in prova. Ad esempio, si può consultare <a href="http://davidmlane.com/hyperstat/sr_table.html">questo link</a>, da dove desumiamo che lo Studentised Range per 4 medie e 8 gradi di libertà dell’errore è 4.529. Di conseguenza, se consideriamo ancora il terzo dei sei confronti a coppie illustrati in precedenza (Organico vs Minerale; SE = 1.247), l’intervallo di confidenza non corretto sarebbe:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">limSup &lt;-<span class="st"> </span><span class="fl">3.667</span> <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">8</span>) <span class="op">*</span><span class="st"> </span><span class="fl">1.247</span>
limInf &lt;-<span class="st"> </span><span class="fl">3.667</span> <span class="op">-</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">8</span>) <span class="op">*</span><span class="st"> </span><span class="fl">1.247</span>
limInf; limSup
## [1] 0.7914128
## [1] 6.542587</code></pre></div>
<p>Mentre l’intervallo di confidenza corretto sarebbe :</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">limSup &lt;-<span class="st"> </span><span class="fl">3.667</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="fl">4.529</span> <span class="op">*</span><span class="st"> </span><span class="fl">1.247</span>
limInf &lt;-<span class="st"> </span><span class="fl">3.667</span> <span class="op">-</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span>) <span class="op">*</span><span class="st"> </span><span class="fl">4.529</span> <span class="op">*</span><span class="st"> </span><span class="fl">1.247</span>
limSup; limInf
## [1] 7.660501
## [1] -0.3265008</code></pre></div>
<p>Possiamo osservare che lo Studentised Range viene diviso per <span class="math inline">\(\sqrt{2}\)</span>. Con R possiamo ottenere lo stesso risultato:</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(<span class="kw">contrast</span>(medie, <span class="dt">method=</span><span class="st">&quot;pairwise&quot;</span>))
##  contrast                        estimate       SE df
##  Minerale - Minerale lento       1.000000 1.247219  8
##  Minerale - Non concimato        8.000000 1.247219  8
##  Minerale - Organico             3.666667 1.247219  8
##  Minerale lento - Non concimato  7.000000 1.247219  8
##  Minerale lento - Organico       2.666667 1.247219  8
##  Non concimato - Organico       -4.333333 1.247219  8
##   lower.CL   upper.CL
##  -2.994035  4.9940347
##   4.005965 11.9940347
##  -0.327368  7.6607013
##   3.005965 10.9940347
##  -1.327368  6.6607013
##  -8.327368 -0.3392987
## 
## Confidence level used: 0.95 
## Conf-level adjustment: tukey method for comparing a family of 4 estimates</code></pre></div>

<p>Nel caso dei confronti tutti contro uno (tipo Dunnet), l’intervallo di confidenza può essere analogamente calcolato con la distribuzione t-multivariato. Le tabelle da consultare in questo caso sono diverse, perché, a parità di numero di medie, il numero di confronti è inferiore. Segnaliamo <a href="http://www.stat.ufl.edu/~winner/tables/dunnett-2side.pdf">questo link</a>. A titolo di esempio, il valore tabulato per 4 medie e 8 gradi di libertà è pari a 2.8826 e, di conseguenza, l’intervallo di confidenza per l’ultimo dei tre confronti tutti verso uno è pari a:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">limSup &lt;-<span class="st"> </span><span class="fl">4.333333</span> <span class="op">+</span><span class="st"> </span><span class="fl">2.88</span> <span class="op">*</span><span class="st"> </span><span class="fl">1.247</span>
limInf &lt;-<span class="st"> </span><span class="fl">4.333333</span> <span class="op">-</span><span class="st"> </span><span class="fl">2.88</span> <span class="op">*</span><span class="st"> </span><span class="fl">1.247</span>
limSup; limInf
## [1] 7.924693
## [1] 0.741973</code></pre></div>
<p>che è più o meno uguale a quello ottenuto con R (anche se vi sono alcune differenza, che lasciano pensare a qualche piccolo bug nel programma).</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">confint</span>(<span class="kw">contrast</span>(medie, <span class="dt">method=</span><span class="st">&quot;dunnett&quot;</span>))
##  contrast                   estimate       SE df
##  Minerale lento - Minerale -1.000000 1.247219  8
##  Non concimato - Minerale  -8.000000 1.247219  8
##  Organico - Minerale       -3.666667 1.247219  8
##    lower.CL    upper.CL
##   -4.630378  2.63037782
##  -11.630378 -4.36962218
##   -7.297044 -0.03628885
## 
## Confidence level used: 0.95 
## Conf-level adjustment: dunnettx method for 3 estimates</code></pre></div>

<p>Sono possibili altre procedure di correzione più avanzate (Shaffer, Westfall), che tuttavia sono valide in presenza di alcune assunzioni aggiuntive e debbono quindi essere valutate con attenzione.</p>
</div>
<div id="e-le-classiche-procedure-di-confronto-multiplo-1" class="section level3 unnumbered">
<h3>E le classiche procedure di confronto multiplo?</h3>
<p>Il confronto multiplo tradizionale è basato sul calcolo di una differenza critica minima, da utilizzare come base per il confronto tra due medie. In pratica, due medie sono considerate significativamente diverse quando la loro differenza supera la differenza critica. In questo modo possiamo solo sapere su un confronto è significativo oppure no, per P &lt; 0.05 o per qualche altro livello <span class="math inline">\(\alpha\)</span> prefissato, venendo così a mancare ogni altra informazione sull’<em>effect size</em> e sulla vera probabilità d’errore di I specie. Per questi motivi, i confronti basati sulla sola differenza critica sono considerati sub-ottimali, e dovrebbero essere evitati, anche se sono tuttora molto diffusi.</p>
<p>La differenza critica più utilizzata (almeno nel passato) è la Minima Differenza significativa, che è basata sul tasso di errore per confronto. Per l’esperimento in esempio, la MDS è pari a:</p>
<p><span class="math display">\[ MDS = 2.306 \times 1.247 = 2.875582\]</span></p>
<p>dove 2.306 è il valore critico della distribuzione di t, per una probabilità del 5% (a due code) e 8 gradi di libertà.</p>
<p>Un’altra differenza critica molto utilizzata è la <em>Honest Significant Difference</em> di Tukey (per i confronti a coppie), che utilizza, invece della distribuzione t univariata, la distribuzione t multivariata. Dovendola calcolare a mano, possiamo utilizzare lo Studentised range, ancora diviso per <span class="math inline">\(\sqrt{2}\)</span>:</p>
<p><span class="math display">\[ HSD = 4.529 \times \frac{1}{\sqrt{2}} \times 1.247 = 3.9935 \]</span></p>
<p>La HSD garantisce un tasso di errore <em>experimentwise</em> e può essere utilizzata per ottenere intervalli di confidenza simultanei (vedi sopra).</p>
<p>Un’altra procedura molto importante è quella di Dunnett, che consente di confrontare tutte le medie con un testimone (o con il migliore/peggiore dei trattamenti). Per dati bilanciati, la differenza critica in questo caso è (si vedano le tabelle indicate in precedenza per gli intervalli di confidenza):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="fl">2.88</span> <span class="op">*</span><span class="st"> </span><span class="fl">1.247</span>
## [1] 3.59136</code></pre></div>
<p>ed assicura il tasso d’errore prefissato per esperimento, anche se la differenza critica è più piccola della HSD, perché viene effettuato un minor numero di confronti.</p>
<p>Se volessimo confrontare tutte le medie con la media più alta (o più bassa) potremmo utilizzare il test di Dunnett ad una coda, che utilizza appunto un valore critico tabulato leggermente inferiore (si veda a: <a href="http://www.watpon.com/table/dunnetttest.pdf" class="uri">http://www.watpon.com/table/dunnetttest.pdf</a>, facendo però attenzione alla lettura della tabella, che, a differenza della precedente, richiede il numero di medie da confrontare escluso il controllo).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="fl">2.42</span> <span class="op">*</span><span class="st"> </span><span class="fl">1.247</span>
## [1] 3.01774</code></pre></div>
<p>Esistono almeno altre tre procedure classiche di confronto multiplo, che elenchiamo di seguito:</p>
<ol style="list-style-type: decimal">
<li>Test di Duncan;</li>
<li>Test di Newman-Keuls;</li>
<li>Test di confronto multiplo di Tukey.</li>
</ol>
<p>In genere queste procedure sono sconsigliabili, per i seguenti motivi:</p>
<ol style="list-style-type: decimal">
<li>sono basate su differenze critiche multiple (crescenti al crescere della distanza dei trattamenti in graduatoria) e quindi non consentono la definizione di un’intervallo di confidenza. Di conseguenza, tra le domande ‘biologiche’ alle quali si cerca la risposta con i confronti multipli (si veda all’inizio) sono in grado di rispondere solo alla prima e non alla seconda e alla terza (non consentono il calcolo di un intervallo di confidenza).</li>
<li>Non danno protezione ne’ per un tasso di errore per confronto ne’ per esperimento, ma rimangono a metà strada, in modo imprecisato (quindi il p level non è effettivamente noto, né a livello di singolo confronto né a livello di esperimento).</li>
</ol>
</div>
<div id="consigli-pratici-per-il-confronto-multiplo" class="section level3 unnumbered">
<h3>Consigli pratici per il confronto multiplo</h3>
<p>La cosa fondamentale è muoversi in coerenza con le finalità dell’esperimento. Si consiglia di:</p>
<ol style="list-style-type: decimal">
<li>Quando è possibile, pianificare gli esperimenti in modo da ottenere le risposte cercate con pochi contrasti di interesse. In questo modo il problema della molteplicità è minimizzato.</li>
<li>Non usare mai contrasti con serie di dati quantitative. In questo caso la regressione è l’approccio corretto. In generale, utilizzare i contrasti solo se sono coerenti con la logica dell’esperimento.</li>
<li>Pianificare esattamente il numero di contrasti necessari ed eseguirli, fornendo il valore del contrasto e il suo errore standard.</li>
<li>Decidere è necessario aggiustare il p-level (e gli intervalli di confidenza) per la molteplicità (tasso di errore <em>comparisonwise</em> o <em>experimentwise</em>).</li>
<li>Se si decide di aggiustare il p-level, considerare che le procedure di Bonferroni o Sidak possono essere eccessivamente protette. Preferire quindi le procedure di aggiustamento basate sulla distribuzione t multivariata, il che, a livello di confronto multiplo con dati bilanciati, è equivalente ad utilizzate la Tukey HSD o il test di Dunnett.</li>
<li>Evitare le procedure di Duncan e Newmann-Keuls: non danno il livello di protezione cercato e, inoltre, non sono basate su una differenza critica costante (quindi sono difficili da discutere).</li>
</ol>
</div>
</div>
<div id="capitolo-10-modelli-con-fattori-di-blocco" class="section level2 unnumbered">
<h2>Capitolo 10: modelli con fattori di blocco</h2>
<div id="anova-a-due-vie-senza-repliche-i-calcoli-manuali" class="section level3 unnumbered">
<h3>ANOVA a due vie senza repliche: i calcoli manuali</h3>
</div>
</div>
<div id="capitolo-11-anova-a-due-vie" class="section level2 unnumbered">
<h2>Capitolo 11: ANOVA a due vie</h2>
<div id="anova-a-due-vie-scomposizione-manuale-della-varianza" class="section level3 unnumbered">
<h3>Anova a due vie: scomposizione ‘manuale’ della varianza</h3>
<p>Anche nel caso dell’ANOVA a due vie, illustriamo i calcoli necessari per la scomposizione ‘manuale’ della varianza. Il punto di partenza, come al solito, sono le medie per i livelli di ogni fattore sperimentale e per le loro combinazioni, che sono date più sotto, in forma di matrici (ma nessuna paura, è solo per comodità!).</p>
<p>Le medie delle combinazioni ‘lavorazioni <span class="math inline">\(\times\)</span> diserbo’ sono:</p>
<p><span class="math display">\[ \bar{Y}_{ij.} = \left[ {\begin{array}{rr}
5.99500 &amp; 8.98275 \\
10.62875 &amp; 9.20675 \\
8.47525  &amp; 9.14125 \\
\end{array}} \right]\]</span></p>
<p>Per le lavorazioni e per i diserbi abbiamo:</p>
<p><span class="math display">\[ \bar{Y}_{i..} = \left[ {\begin{array}{r}
7.488875 \\
9.917750 \\
8.808250
\end{array}} \right]\]</span></p>
<p><span class="math display">\[ \bar{Y}_{.j.} = \left[ {\begin{array}{r}
7.488875 \\
9.917750 \\
8.808250
\end{array}} \right]\]</span></p>
<p>Le medie dei blocchi, sono, invece:</p>
<p><span class="math display">\[ \bar{Y}_{..k} = \left[ {\begin{array}{r}
9.385500 \\
8.347500 \\
8.557833 \\
8.662333
\end{array}} \right]\]</span></p>
<p>La media generale è <span class="math inline">\(\bar{Y}_{...} = 8.738292\)</span>.</p>
<p>Per calcolare le devianze degli effetti principali (blocchi, lavorazioni e diserbi), come primo passaggio, calcoliamo gli scostamenti tra le medie e la media generale e, quindi, sottraiamo da ogni media la media generale. Ricordiamo che questi scarti non sono altro che gli effetti dei trattamenti e, nel caso in cui si sia adottata un vincolo sulla somma, questi coincidono con i parametri di un modello lineare. Per cui:</p>
<p><span class="math display">\[\bar{Y}_{i..} - \bar{Y}_{...} = \alpha_i = \left[ {\begin{array}{r}
-1.24941667 \\
1.17945833 \\
0.06995833
\end{array}} \right]\]</span></p>
<p><span class="math display">\[ \bar{Y}_{.j.} - \bar{Y}_{...} = \beta_j = \left[ {\begin{array}{r}
-0.3719583 \\
0.3719583
\end{array}} \right]\]</span></p>
<p><span class="math display">\[ \bar{Y}_{..k} - \bar{Y}_{...} = \gamma_k = \left[ {\begin{array}{r}
0.6472083\\
-0.3907917\\
-0.1804583\\
-0.07595833
\end{array}} \right]\]</span></p>
<p>Per quanto riguarda la devianza di blocchi, lavorazioni e diserbo, basta calcolare il quadrato degli scarti e sommare i valori ottenuti, moltiplicando per il numero di osservazioni che abbiamo per ogni blocco/lavorazione/diserbo. In questo modo, considerando che, in un blocco, abbiamo 6 osservazioni, la devianza dei blocchi è:</p>
<p><span class="math display">\[SS_b = 6 \times \left( 0.6472083^2 + 0.3907917^2 + 0.1804583^2 + 0.07595833 ^ 2 \right) = 3.65959\]</span></p>
<p>La devianza delle lavorazioni, considerando che, per ognuna, abbiamo 8 valori, è:</p>
<p><span class="math display">\[ SS_l = 8 \times \left(1.24941667^2 + 1.17945833^2  + 0.06995833^2 \right) = 23.65647  \]</span></p>
<p>Per il diserbo:</p>
<p><span class="math display">\[ SS_l = 12 \times \left(0.3719583^2 + 0.3719583 ^ 2 \right) = 3.320472  \]</span></p>
<p>Per l’interazione, non possiamo procedere nello stesso modo, in quanto la variabilità esistente tra le medie delle sei combinazioni è il risultato, non solo dell’eventuale interazione, ma anche degli effetti principali. Infatti, se ricordiamo il modello lineare per un disegno a due vie, risulta che il valore atteso per una combinazione è:</p>
<p><span class="math display">\[ \bar{Y}_{ij.} = \mu + \alpha_i + \beta_j + \alpha\beta_{ij}\]</span></p>
<p>Se abbiamo utilizzato il vincolo sulla somma, <span class="math inline">\(\mu\)</span> è la media generale, <span class="math inline">\(\alpha_i\)</span> sono gli effetti delle lavorazioni (l’ultima colonna della tabella sovrastante), <span class="math inline">\(\beta_j\)</span> sono gli effetti dei diserbi (ultima riga della tabella sovrastante). Di conseguenza, gli effetti dell’interazione sono:</p>
<p><span class="math display">\[ \alpha\beta_{ij} = \bar{Y}_{ij.} - \bar{Y}_{...} - \alpha_i - \beta_j \]</span></p>
<p>Ora, siccome</p>
<p><span class="math display">\[\alpha_i = \bar{Y}_{i..} - \bar{Y}_{...}\]</span> e</p>
<p><span class="math display">\[\beta_j = \bar{Y}_{.j.} - \bar{Y}_{...}\]</span></p>
<p>possiamo scrivere:</p>
<p><span class="math display">\[ \alpha\beta_{ij} = \bar{Y}_{ij.} - \bar{Y}_{...} - \bar{Y}_{i..} + \bar{Y}_{...} - \bar{Y}_{.j.} + \bar{Y}_{...} = \bar{Y}_{ij.} - \bar{Y}_{i..} - \bar{Y}_{.j.} + \bar{Y}_{...}\]</span></p>
<p>Ad esempio:</p>
<p><span class="math display">\[ \alpha\beta_{11} = 5.995 - 7.488875 - 8.366333 + 8.738292 = - 1.121916\]</span></p>
<p>Completando i calcoli:</p>
<p><span class="math display">\[ \alpha\beta_{ij} = \left[ {\begin{array}{rr}
-1.1219 &amp;  1.1219 \\
1.0830 &amp; -1.0830 \\
0.0390 &amp; -0.0390\\
\end{array}} \right]\]</span></p>
<p>Elevando al quadrato, sommando e moltiplicando per quattro otteniamo la devianza dell’interazione, pari a:</p>
<p><span class="math display">\[ SS_{ld} = 4 \times \left(1.1219^2+ 1.1219^2 +1.0830^2 +1.0830^2 + 0.0390^2 +0.0390^2 \right)= 19.46456\]</span></p>
</div>
<div id="disegni-incrociati-e-gerarchici" class="section level3 unnumbered">
<h3>Disegni incrociati e gerarchici</h3>
<p>Nel capitolo 11 abbiamo presentato un esperimento fattoriale ‘incrociato’ (crossed), nel quale i livelli di A sono gli stessi per ogni livello di B (e viceversa). In alcune situazioni, i disegni fattoriali possono essere gerarchici (nested), cioè i livelli di un fattore cambiano al cambiare dei livelli dell’altro fattore.</p>
<p>Ad esempio, potremmo prendere tre linee pure impollinanti di mais (A1, A2 e A3) e incrociarle con tre linee portaseme, diverse per ogni linea impollinante (B1, B2 e B3 incrociate con A1, B4, B5 e B6 incrociate con A2 e B7, B8 e B9 incrociate con A3). In questo modo verremmo a misurare le produzioni di 9 ibridi, divisi in tre gruppi, in base alle linee impollinanti. Se immaginiamo di impiantare in campo un esperimento del genere, utilizzando uno schema a blocchi randomizzati con quattro repliche, alla fine ci troviamo con 36 dati, come quelli riportati nel dataset ‘Crosses.csv’, che è disponibile su gitHub, e al solito, può essere caricato con il codice indicato di seguito.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">path1 &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/OnofriAndreaPG/&quot;</span>
path2 &lt;-<span class="st"> &quot;aomisc/master/data/&quot;</span>
name &lt;-<span class="st"> &quot;Crosses.csv&quot;</span>
pathName &lt;-<span class="st"> </span><span class="kw">paste</span>(path1, path2, name, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
dataset &lt;-<span class="st"> </span><span class="kw">read.csv</span>(pathName, <span class="dt">header=</span>T)
<span class="kw">head</span>(dataset, <span class="dv">15</span>)
##    Male Female Block     Yield
## 1    A1     B1     1  9.984718
## 2    A1     B1     2 13.932663
## 3    A1     B1     3 12.201312
## 4    A1     B1     4  1.916661
## 5    A1     B2     1  8.928465
## 6    A1     B2     2 10.513908
## 7    A1     B2     3 10.035964
## 8    A1     B2     4  2.375822
## 9    A1     B3     1 21.511028
## 10   A1     B3     2 21.859852
## 11   A1     B3     3 17.626284
## 12   A1     B3     4 13.966646
## 13   A2     B4     1 17.483089
## 14   A2     B4     2 19.480893
## 15   A2     B4     3 12.838792</code></pre></div>
<div id="definizione-di-un-modello-lineare-3" class="section level4 unnumbered">
<h4>Definizione di un modello lineare</h4>
<p>In un esperimento simile, abbiamo un effetto blocco (<span class="math inline">\(\gamma\)</span>) e un effetto ‘paterno’ (<span class="math inline">\(\alpha\)</span>). Invece, l’effetto ‘materno’ (<span class="math inline">\(\delta\)</span>) può essere individuato solo entro ogni linea impollinante, dato che le linee portaseme sono diverse per ogni linea impollinante. In altre parole, l’effetto ‘materno’ è gerarchicamente inferiore all’effetto ‘paterno’, come evidenziato nella Figura <a href="appendix-3-per-chi-vuole-approfondire-un-po.html#fig:figNameA3113">15.10</a>.</p>
<p>Per descrivere il meccanismo di generazione delle osservazioni, possiamo utilizzare questo modello:</p>
<p><span class="math display">\[ Y_{ijk} = \mu + \gamma_k + \alpha_i + \delta_{ij} + \varepsilon_{ijk}\]</span></p>
<p>dove <span class="math inline">\(\gamma_k\)</span> è l’effetto del blocco (con <span class="math inline">\(k\)</span> che va da 1 a 4), <span class="math inline">\(\alpha_i\)</span> è l’effetto dell’impollinante (con <span class="math inline">\(i\)</span> che va da 1 a 3) e <span class="math inline">\(\delta_{ij}\)</span> è l’effetto del portaseme (con <span class="math inline">\(j\)</span> che va da 1 a 9) entro ogni impollinante <span class="math inline">\(i\)</span>. Ancora, <span class="math inline">\(\varepsilon\)</span> è il residuo, assunto normalmente distribuito, con media zero e deviazione standard <span class="math inline">\(\sigma\)</span> (omoscedasticità). Vediamo subito la principale differenza con un disegno fattoriale incrociato: mentre per quest’ultimo disegno il modello contiene i due fattori sperimentali A e B, insieme all’interazione A:B, nel modello per un disegno innestato abbiamo solo il fattore A ed il fattore B entro A (abbreviato come A/B), mentre manca l’effetto principale B, che, di fatto, non può esistere.</p>
<div class="figure" style="text-align: center"><span id="fig:figNameA3113"></span>
<img src="_main_files/figure-html/figNameA3113-1.png" alt="Struttura di un disegno sperimentale gerarchico" width="70%" />
<p class="caption">
Figure 15.10: Struttura di un disegno sperimentale gerarchico
</p>
</div>
</div>
<div id="stima-dei-parametri-6" class="section level4 unnumbered">
<h4>Stima dei parametri</h4>
<p>Per la stima dei parametri, utilizziamo R ed il metodo dei minimi quadrati, attraverso l’ormai usuale funzione ‘lm()’.</p>

<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model &lt;-<span class="st"> </span><span class="kw">lm</span>(Yield <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(Block) <span class="op">+</span><span class="st"> </span>Male <span class="op">+</span><span class="st"> </span>Male<span class="op">:</span>Female, <span class="dt">data =</span> dataset)
<span class="kw">summary</span>(model)
## 
## Call:
## lm(formula = Yield ~ factor(Block) + Male + Male:Female, data = dataset)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.95836 -1.14888  0.04749  1.08992  2.64592 
## 
## Coefficients: (18 not defined because of singularities)
##                 Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)      11.3625     0.9805  11.589 2.56e-11
## factor(Block)2    1.1476     0.8005   1.434   0.1646
## factor(Block)3   -1.2472     0.8005  -1.558   0.1323
## factor(Block)4   -7.3151     0.8005  -9.138 2.78e-09
## MaleA2           -0.7878     1.2008  -0.656   0.5180
## MaleA3            0.5975     1.2008   0.498   0.6233
## MaleA1:FemaleB2  -1.5453     1.2008  -1.287   0.2104
## MaleA2:FemaleB2       NA         NA      NA       NA
## MaleA3:FemaleB2       NA         NA      NA       NA
## MaleA1:FemaleB3   9.2321     1.2008   7.688 6.33e-08
## MaleA2:FemaleB3       NA         NA      NA       NA
## MaleA3:FemaleB3       NA         NA      NA       NA
## MaleA1:FemaleB4       NA         NA      NA       NA
## MaleA2:FemaleB4   6.4599     1.2008   5.380 1.59e-05
## MaleA3:FemaleB4       NA         NA      NA       NA
## MaleA1:FemaleB5       NA         NA      NA       NA
## MaleA2:FemaleB5   2.5073     1.2008   2.088   0.0476
## MaleA3:FemaleB5       NA         NA      NA       NA
## MaleA1:FemaleB6       NA         NA      NA       NA
## MaleA2:FemaleB6       NA         NA      NA       NA
## MaleA3:FemaleB6       NA         NA      NA       NA
## MaleA1:FemaleB7       NA         NA      NA       NA
## MaleA2:FemaleB7       NA         NA      NA       NA
## MaleA3:FemaleB7  10.0089     1.2008   8.335 1.52e-08
## MaleA1:FemaleB8       NA         NA      NA       NA
## MaleA2:FemaleB8       NA         NA      NA       NA
## MaleA3:FemaleB8   7.6209     1.2008   6.346 1.46e-06
## MaleA1:FemaleB9       NA         NA      NA       NA
## MaleA2:FemaleB9       NA         NA      NA       NA
## MaleA3:FemaleB9       NA         NA      NA       NA
##                    
## (Intercept)     ***
## factor(Block)2     
## factor(Block)3     
## factor(Block)4  ***
## MaleA2             
## MaleA3             
## MaleA1:FemaleB2    
## MaleA2:FemaleB2    
## MaleA3:FemaleB2    
## MaleA1:FemaleB3 ***
## MaleA2:FemaleB3    
## MaleA3:FemaleB3    
## MaleA1:FemaleB4    
## MaleA2:FemaleB4 ***
## MaleA3:FemaleB4    
## MaleA1:FemaleB5    
## MaleA2:FemaleB5 *  
## MaleA3:FemaleB5    
## MaleA1:FemaleB6    
## MaleA2:FemaleB6    
## MaleA3:FemaleB6    
## MaleA1:FemaleB7    
## MaleA2:FemaleB7    
## MaleA3:FemaleB7 ***
## MaleA1:FemaleB8    
## MaleA2:FemaleB8    
## MaleA3:FemaleB8 ***
## MaleA1:FemaleB9    
## MaleA2:FemaleB9    
## MaleA3:FemaleB9    
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.698 on 24 degrees of freedom
## Multiple R-squared:  0.9405, Adjusted R-squared:  0.9132 
## F-statistic: 34.48 on 11 and 24 DF,  p-value: 5.236e-12</code></pre></div>

<p>Per chi volesse comprendere l’output ottenuto e il significato biologico dei parametri, ricordiamo che R impiega, di default, il vincolo sul trattamento. Di conseguenza, <span class="math inline">\(\alpha_1 = 0\)</span> e <span class="math inline">\(\delta_{11} = 0\)</span>. Inoltre, visto che l’effetto materno deve essere definito per ogni impollinante, è necessario vincolare un valore di <span class="math inline">\(\delta\)</span> per ogni impollinante. Da questo punto di vista, la soluzione adottata da R non è molto intuitiva, in quanto questo software vincola l’ultimo livello di B per ogni livello di A; quindi pone i vincoli <span class="math inline">\(\delta_{26}=0\)</span> e <span class="math inline">\(\delta_{39} = 0\)</span>.</p>
<p>Con questi vincoli, <span class="math inline">\(\mu\)</span> è il valore atteso per l’ibrido ottenuto dal primo impollinante, primo portaseme (A1B1) nel primo blocco. I parametri <span class="math inline">\(\gamma_k\)</span> sono ottenuti analogamente a quanto illustrato nel capitolo sull’ANOVA fattoriale. Invece, i parametri <span class="math inline">\(\alpha_i\)</span> debbono essere ottenuti in modo diverso, in quanto non possiamo cambiare l’impollinante mantenendo costante il portaseme. Possiamo notare che:</p>
<p><span class="math display">\[ \bar{Y}_{111} = \mu + \alpha_1 + \delta_{11} = \mu\]</span></p>
<p>e (per il vincolo imposto):</p>
<p><span class="math display">\[ \bar{Y}_{261} = \mu + \alpha_2 + \delta_{26} = \mu + \alpha_2\]</span></p>
<p>Quindi:</p>
<p><span class="math display">\[ \alpha_2 = \bar{Y}_{261} - \bar{Y}_{111}\]</span></p>
<p>e, analogamente:</p>
<p><span class="math display">\[ \alpha_3 = \bar{Y}_{291} - \bar{Y}_{111}\]</span></p>
<p>La stima di <span class="math inline">\(\delta_{ij}\)</span> è più semplice, basta notare, ad esempio, che</p>
<p><span class="math display">\[ \bar{Y}_{121} = \mu + \alpha_1 + \delta_{12} = \mu + \delta_{12}\]</span></p>
<p>Quindi:</p>
<p><span class="math display">\[ \delta_{12} = \bar{Y}_{121} - \bar{Y}_{111}\]</span></p>
<p>e così via, per tutti gli altri parametri.</p>
</div>
<div id="scomposizione-della-varianza-2" class="section level4 unnumbered">
<h4>Scomposizione della varianza</h4>
<p>Per suddividere la devianza totale delle osservazioni nelle quote che competono ad ogni effetto, utilizziamo il solito metodo sequenziale. La devianza totale è ottenuto da un modello nullo, calcolando la somma dei quadrati degli scarti:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modNull &lt;-<span class="st"> </span><span class="kw">lm</span>(Yield <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data =</span> dataset)
TSS &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">residuals</span>(modNull)<span class="op">^</span><span class="dv">2</span>)
TSS
## [1] 1162.882</code></pre></div>
<p>Inseriamo ora il blocco, calcoliamo la devianza del residuo e, per sottrazione, otteniamo la devianza del blocco</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modBl &lt;-<span class="st"> </span><span class="kw">lm</span>(Yield <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(Block), <span class="dt">data =</span> dataset)
BlSS &lt;-<span class="st"> </span>TSS <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">residuals</span>(modBl)<span class="op">^</span><span class="dv">2</span>)
BlSS
## [1] 383.7506</code></pre></div>
<p>Successivamente, inseriamo gli altri effetti, nello stesso modo.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modA &lt;-<span class="st"> </span><span class="kw">lm</span>(Yield <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(Block) <span class="op">+</span><span class="st"> </span>Male, <span class="dt">data =</span> dataset)
ASS &lt;-<span class="st"> </span>TSS <span class="op">-</span><span class="st"> </span>BlSS <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">residuals</span>(modA)<span class="op">^</span><span class="dv">2</span>)
ASS
## [1] 134.7567
BSS &lt;-<span class="st"> </span>TSS <span class="op">-</span><span class="st"> </span>BlSS <span class="op">-</span><span class="st"> </span>ASS <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(<span class="kw">residuals</span>(model)<span class="op">^</span><span class="dv">2</span>)
BSS
## [1] 575.1607</code></pre></div>
<p>I gradi di libertà, per gli effetti immessi in sequenza, sono, rispettivamente, 3 (abbiamo quattro blocchi), 2 (abbiamo tre ‘parentali’) e 6 (abbiamo calcolato gli scostamenti rispetto alle medie degli impollinanti: quindi abbiamo, 2 gradi di libertà per ogni impollinante).</p>
<p>Più facilmente, arriviamo agli stessi risultati con la funzione ’anova(), in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(model)
## Analysis of Variance Table
## 
## Response: Yield
##               Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## factor(Block)  3 383.75 127.917  44.355 6.051e-10 ***
## Male           2 134.76  67.378  23.363 2.331e-06 ***
## Male:Female    6 575.16  95.860  33.239 1.742e-10 ***
## Residuals     24  69.21   2.884                      
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></div>
</div>
<div id="medie-e-sem" class="section level4 unnumbered">
<h4>Medie e SEM</h4>
<p>Il calcolo delle medie è banale, così come il calcolo degli errori standard. Dobbiamo solo ricordare che, per ogni parentale, vi sono 12 repliche (4 blocchi per 3 portaseme). Quindi</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sqrt</span>( <span class="kw">summary</span>(model)<span class="op">$</span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">12</span> )
## [1] 0.4902317</code></pre></div>
<p><span class="math display">\[SEM_A = \sqrt{\frac{MSE}{r b}} = \sqrt{\frac{2.079}{4 \times 3}} = 0.416\]</span></p>
<p>Al contrario, per ognuno dei 9 portaseme abbiamo 4 repliche</p>
<p><span class="math display">\[SEM_B = \sqrt{\frac{MSE}{r}} = \sqrt{\frac{2.079}{4}} = 0.721\]</span></p>
<p>Più in generale, possiamo calcolare le medie marginali attese con la funzione ‘emmeans()’</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(emmeans)
medie &lt;-<span class="st"> </span><span class="kw">emmeans</span>(model, <span class="op">~</span>Male)
medie
##  Male   emmean        SE df lower.CL upper.CL
##  A1   12.07111 0.4902317 24 11.05932 13.08290
##  A2   11.71013 0.4902317 24 10.69834 12.72192
##  A3   15.98291 0.4902317 24 14.97112 16.99470
## 
## Results are averaged over the levels of: Block, Female 
## Confidence level used: 0.95</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(emmeans)
medie &lt;-<span class="st"> </span><span class="kw">emmeans</span>(model, <span class="op">~</span>Male<span class="op">:</span>Female)
medie
##  Female Male    emmean        SE df  lower.CL
##  B1     A1    9.508839 0.8491062 24  7.756370
##  B2     A1    7.963540 0.8491062 24  6.211071
##  B3     A1   18.740953 0.8491062 24 16.988484
##  B4     A2   15.180952 0.8491062 24 13.428483
##  B5     A2   11.228376 0.8491062 24  9.475907
##  B6     A2    8.721060 0.8491062 24  6.968591
##  B7     A3   20.115204 0.8491062 24 18.362735
##  B8     A3   17.727215 0.8491062 24 15.974746
##  B9     A3   10.106318 0.8491062 24  8.353849
##   upper.CL
##  11.261308
##   9.716009
##  20.493422
##  16.933421
##  12.980845
##  10.473529
##  21.867673
##  19.479684
##  11.858787
## 
## Results are averaged over the levels of: Block 
## Confidence level used: 0.95</code></pre></div>
<p>Se necessario, contrasti e confronti multipli possono essere eseguiti come usuale.</p>
<p>Volevo concludere precisando che, specificatamente per questo esempio, un <em>plant breeder</em> potrebbe non essere interessato a valutare la significatività degli effetti con il test F o ad effettuare confronti tra le medie, ma potrebbe essere più interessato a valutare la variabilità delle produzioni legata alle linee materne e/o paterne, per ottenere alcuni indicatori noti come ‘componenti di varianza’, che sono fondamentali per studiare l’ereditabilità dei caratteri. Di conseguenza, per un <em>plant breeder</em>, la tabella ANOVA non è il punto di arrivo, ma solo il punto di partenza per altre valutazioni. Per questo rimandiamo alla letteratura specialistica.</p>
</div>
</div>
<div id="disegni-a-split-plot" class="section level3 unnumbered">
<h3>Disegni a split-plot</h3>
<p>Si parla di disegno a ‘split-plot’ (parcella suddivisa) quando un’unità sperimentale che ha subito (o è destinata a subire) un trattamento con il fattore sperimentale A, viene suddivisa in più sub-unità, alle quali vengono assegnati i diversi livelli di un altro fattore sperimentale (B), in modo randomizzato. Le sub-unità sperimentali non sono quindi indipendenti e viene a realizzarsi una sorta di raggruppamento tra di esse.</p>
<p>Un disegno a split-plot può rendersi necessario per i seguenti motivi:</p>
<ol style="list-style-type: decimal">
<li>un fattore richiede parcelle più grandi dell’altro. Ad esempio, le lavorazioni del terreno richiedono parcelle più grandi del diserbo. Le irrigazioni richiedono parcelle più grandi della concimazione. Le epoche di semina richiedono parcelle più grandi delle varietà. Di conseguenza si disegna l’esperimento per il fattore che richiede parcelle più grandi, che vengono poi suddivise per accomodare l’altro fattore sperimentale.</li>
<li>Uno dei due fattori sperimentali è più ‘difficile’ da assegnare rispetto all’altro e quindi è preferibile manipolare congiuntamente tutto il gruppo di unità sperimentali che deve riceverlo. Ad esempio, se vogliamo misurare la resistenza alla corrosione di barre d’acciaio con diversi rivestimenti e forgiate a diverse temperature, è evidente che la gestione della temperatura nella fornace è piuttosto complessa, perchè richiede tempi lunghi per essere resettata e raggiungere un nuovo equilibrio. Invece che preparare una fornace per ogni rivestimento (manipolazione indipendente delle unità sperimentali), si mettono nella stessa fornace tutte le unità sperimentali con i diversi rivestimenti.</li>
<li>Analogo al precedente, vi è il caso in cui uno dei fattori sperimentali si presenta naturalmente in lotti. Ad esempio, se vogliamo provare diverse miscele per torte (con vari ingredienti), e diversi tempi di cottura, non è agevole preparare una miscela diversa per ogni tempo di cottura, ma preferiamo preparare la miscela tutta insieme, per poi suddividerla tra i diversi tempi di cottura. Si possono fare altri esempi relativi alla sperimentazione di laboratorio, dove si utilizzano come parcelle principali gli armadi climatici e come sub-parcelle le capsule Petri in essi contenute.</li>
</ol>
<div id="la-mappa-di-campo" class="section level4 unnumbered">
<h4>La mappa di campo</h4>
<p>utilizziamo lo stesso esempio già visto nel capitolo 11 e relativo ad un esperimento organizzato per valutare l’effetto di tre tipi di lavorazione del terreno (lavorazione minima: LM; aratura superficiale: SUP; aratura profonda: PROF), e di due tipi di diserbo chimico (a tutta superficie: TOT; localizzato sulla fila della coltura: PARZ).</p>
<p>La Figura <a href="appendix-3-per-chi-vuole-approfondire-un-po.html#fig:figNameA3111">15.11</a> rappresenta la mappa di campo in campo, dove le lavorazioni (tesi di I ordine) sono randomizzate su parcelle più grandi (main-plots), suddivise in due parti (sub-plots), alle quali viene assegnato, in modo randomizzato, il metodo di controllo delle piante infestanti (tesi di II ordine).</p>
<div class="figure" style="text-align: center"><span id="fig:figNameA3111"></span>
<img src="_images/Split.jpg" alt="Esempio di un disegno a split-plot. L'esperimento prevede tre livelli di lavorazione (tesi di primo ordine, contraddistinte dai colori) e due livelli di diserbo chimico (tesi di secondo ordine)" width="75%" />
<p class="caption">
Figure 15.11: Esempio di un disegno a split-plot. L’esperimento prevede tre livelli di lavorazione (tesi di primo ordine, contraddistinte dai colori) e due livelli di diserbo chimico (tesi di secondo ordine)
</p>
</div>
<p>Osservando la mappa dell’esperimento, possiamo fare le seguenti considerazioni.</p>
<ol style="list-style-type: decimal">
<li>Lo split-plot introduce un vincolo alla randomizzazione, in quanto il fattore di II ordine non è randomizzato liberamente, ma la sua randomizzazione è vincolata al fatto che tutti i suoi livelli debbono essere inseriti nella stessa parcella principale.</li>
<li>Ogni ‘main plot’ funge da replica per le tesi di II ordine, ma non è vero il contrario. Ad esempio, se avessi un solo blocco, avrei tre repliche per il diserbo parziale e altrettante per il diserbo totale, ma avrei una e una sola replica per le levorazioni.</li>
<li>Per quanto riguarda le lavorazioni, il disegno può essere assimilato ad un blocco randomizzato che trova la sua unità sperimentale (replica vera) nella main-plot, in quanto è ad essa che sono stati allocati i trattamenti in modo indipendente. Per le lavorazioni, le sub-plots si comportano da sub-repliche, in quanto non sono trattate con le lavorazioni in modo indipendente l’una dall’altra (mentre i diserbi sono stati allocati in modo indipendente alle sub-plots).</li>
<li>La presenza delle main-plots non può mai essere dimenticata, in quanto essa da conto del fatto che due sub-parcelle nella stessa parcella principale sono più ‘simili’ di due sub-parcelle in due parcelle principali diverse. Insomma, se rimuoviamo la voce relativa alle parcelle principali rompiamo l’indipendenza degli errori sperimentali, venendo così a violare uno degli assunti fondamentali per l’ANOVA.</li>
</ol>
<p>I risultati ottenuti con questo esperimento sono disponibili nel file ‘beet.csv’, che può essere aperto direttamente da gitHub, con il codice sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">path1 &lt;-<span class="st"> &quot;https://raw.githubusercontent.com/OnofriAndreaPG/&quot;</span>
path2 &lt;-<span class="st"> &quot;aomisc/master/data/&quot;</span>
name &lt;-<span class="st"> &quot;beet.csv&quot;</span>
pathName &lt;-<span class="st"> </span><span class="kw">paste</span>(path1, path2, name, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
dataset &lt;-<span class="st"> </span><span class="kw">read.csv</span>(pathName, <span class="dt">header=</span>T)
<span class="kw">head</span>(dataset)
##   Lavorazione Diserbo Blocco   Prod
## 1         MIN     tot      1 11.614
## 2         MIN     tot      2  9.283
## 3         MIN     tot      3  7.019
## 4         MIN     tot      4  8.015
## 5         MIN    parz      1  5.117
## 6         MIN    parz      2  4.306</code></pre></div>
</div>
<div id="definizione-del-modello-lineare-2" class="section level4 unnumbered">
<h4>Definizione del modello lineare</h4>
<p>Il modello lineare per l’ANOVA a split-plot è simile a quello dell’ANOVA fattoriale, fatta salva la presenza delle parcelle principali (main-plots), che costituiscono un elemento di raggruppamento delle osservazioni. Ad esempio, se una main-plot è più fertile di un’altra, tutte le osservazioni prese nella prima main-plot saranno caratterizzate da un effetto positivo sulla produzione e, di conseguenza, saranno correlate tra di loro. In altre parole, la presenza di questo elemento comune, positivo o negativo che sia, rende le osservazioni prese su una main-plot più simili tra di loro che le osservazioni prese su main-plots diverse. Si parla, propriamente, di interazione intra-classe, un concetto simile, ma non totalmente coincidente con quello di correlazione di Pearson. E’evidente che l’effetto delle main-plots deve essere incluso nel modello, per evitare che finisca nel residuo e renda i residui correlati, cioè non indipendenti. Scriviamo quindi il modello:</p>
<p><span class="math display">\[Y_{ijk} = \mu + \gamma_k + \alpha_i + \theta_{ik} + \beta_j + \alpha\beta_{ij} + \varepsilon_{ijk}\]</span></p>
<p>dove <span class="math inline">\(\gamma\)</span> è l’effetto del blocco <span class="math inline">\(k\)</span>, <span class="math inline">\(\alpha\)</span> è l’effetto della lavorazione <span class="math inline">\(i\)</span>, <span class="math inline">\(\beta\)</span> è l’effetto del diserbo <span class="math inline">\(j\)</span>, <span class="math inline">\(\alpha\beta\)</span> è l’effetto dell’interazione per la specifica combinazione della lavorazione <span class="math inline">\(i\)</span> e del diserbo <span class="math inline">\(j\)</span>. Abbiamo incluso anche <span class="math inline">\(\theta\)</span> che è l’effetto della main-plot; dato che ogni parcella principale è identificata univocamente dal blocco <span class="math inline">\(k\)</span> a cui appartiene e dalla lavorazione <span class="math inline">\(i\)</span> in essa eseguita, abbiamo utilizzato i pedici corrispondenti.</p>
<p>Per la stima dei parametri, potremmo utilizzare il codice sottostante, anticipando però che è sbagliato, per i motivi che vedremo in seguito. Tuttavia, è importante notare che abbiamo definito le main-plots come combinazione tra Blocchi e Lavorazioni.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mainPlot &lt;-<span class="st"> </span><span class="kw">factor</span>(dataset<span class="op">$</span>Lavorazione)<span class="op">:</span><span class="kw">factor</span>(dataset<span class="op">$</span>Blocco)
mod.wrong &lt;-<span class="st"> </span><span class="kw">lm</span>(Prod <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(Blocco) <span class="op">+</span><span class="st"> </span>Lavorazione<span class="op">*</span>Diserbo <span class="op">+</span><span class="st"> </span>mainPlot, <span class="dt">data=</span>dataset)</code></pre></div>
</div>
<div id="la-natura-delleffetto-delle-main-plots" class="section level4 unnumbered">
<h4>La natura dell’effetto delle main-plots</h4>
<p>Abbiamo anticipato che il modello sovrastante è sbagliato. Il probema è sia concettuale, che pratico. Da un punto di vista concettuale, noi abbiamo incluso le main-plots come un effetto fisso, al pari delle lavorazioni o del diserbo. In realtà c’è una grossa differenza: mentre i livelli delle lavorazioni e del diserbo li abbiamo attentamente prescelti, perché eravamo specificatamente interessati ad essi, nel caso delle main plots non abbiamo nessun interesse specifico, le abbiamo selezionate come fossero le parcelle di un esperimento, in modo casuale da un universo più grosso, quello di tutte le main-plots possibili nel nostro appezzamento.</p>
<p>Insomma, stiamo dicendo che, mentre le lavorazioni ed il diserbo sono effetti cosiddetti fissi, le main-plots hanno un effetto di natura random, potremmo cambiarle a piacimento, senza che il nostro esperimento cambi o perda interesse. Cosa che non possiamo dire della lavorazione e del diserbo: se cambiamo i livelli inclusi nell’esperimento, cambia la finalità dello stesso.</p>
<p>Da un punto di vista pratico, se eseguiamo l’ANOVA con il modello sovrastante, tutti i test di F vengono effettuati utilizzando la varianza del residuo come denominatore. Tuttavia, per quanto riguarda le lavorazioni, i livelli sono stati allocati alle main-plots, non alle sub-plots e, pertanto, le repliche vere per questo fattore sperimentale sono le main-plots trattate con la stessa lavorazione, non le sub-plots. Ricordiamo che, secondo Fisher, l’errore sperimentale è definito come la variabilità tra repliche vere trattate allo stesso modo; di conseguenza, il residuo non è, e non può essere, la voce d’errore giusta per testare la significatività dell’effetto lavorazione.</p>
<p>In effetti, se per un attimo immaginassimo di escludere il diserbo chimico e pensassimo di aver fatto un’unica misura per ogni main-plot, ci troveremmo di fronte ad un esperimento a blocchi randomizzati, nel quale le main-plots assumono il ruolo delle parcelle. In questo esperimento, l’errore residuo, sul quale testare la significatività dell’effetto della lavorazione, sarebbe dato proprio dalla devianza tra main-plots trattate allo stesso modo. Ovviamente, lo stesso approccio dovrebbe essere mantenuto in un esperimento a split-plot.</p>
<p>Insomma, in un esperimento a split-plot, oltre ad includere le main-plots nel modello per assicurare l’indipendenza dei residui, è anche necessario trattare l’effetto main-plots come un effetto random, sul quale testare la significatività dell’effetto del fattore allocato alle main plots.</p>
</div>
<div id="scomposizione-della-varianza-3" class="section level4 unnumbered">
<h4>Scomposizione della varianza</h4>
<p>Tutte le devianze sono uguali a quelle calcolate per un modello ANOVA a due vie. Rimane il problema di calcolare la devianza delle main-plots. Intuitivamente possiamo pensare di calcolarle attraverso la devianza delle medie ottenute in main-plots diverse. Giusto, ma è necessario ricordare che queste medie sono anche determinate dalla lavorazione che è stata eseguita in ciascuna main-plot e dal blocco di cui la main-plot fa parte. Pertanto, dalla devianza delle main-plots deve essere scorporata la devianza dei blocchi e quella delle lavorazioni.</p>
<p>Le produzioni medie in ogni main-plot sono:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">medieMP &lt;-<span class="st"> </span><span class="kw">tapply</span>(dataset<span class="op">$</span>Prod, mainPlot, mean)
medieMP
##   MIN:1   MIN:2   MIN:3   MIN:4  PROF:1  PROF:2 
##  8.3655  6.7945  7.9795  6.8160 10.7940  9.7275 
##  PROF:3  PROF:4   SUP:1   SUP:2   SUP:3   SUP:4 
##  9.2470  9.9025  8.9970  8.5205  8.4470  9.2685</code></pre></div>
<p>La devianza, considerando che in ogni main-plot ci sono due osservazioni e considerando anche le devianze calcolate per l’ANOVA fattoriale a due vie, è quindi:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">sum</span>( (medieMP <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(dataset<span class="op">$</span>Prod))<span class="op">^</span><span class="dv">2</span> ) <span class="op">-</span><span class="st"> </span><span class="fl">3.65959</span> <span class="op">-</span><span class="st"> </span><span class="fl">23.65647</span>
## [1] 3.658419</code></pre></div>
<p>Questa devianza ha 6 gradi di libertà, in quanto abbiamo 12 main plots, quindi 11 gradi di libertà, meno 2 gradi di libertà per le lavorazioni e tre gradi di libertà per i blocchi.</p>
<p>Per il resto, nulla cambia rispetto all’ANOVA fattoriale, salvo il fatto che il residuo è più piccolo ed ha meno gradi di libertà, in quanto da esso è stato dedotto l’effetto delle main-plots.</p>
</div>
<div id="il-fitting-con-r" class="section level4 unnumbered">
<h4>Il fitting con R</h4>
<p>Il modello lineare per una disegno a split-plot ha due effetti random, cioè il residuo e l’effetto delle main-plots. Quando vi è più di un effetto random ed almeno un effetto fisso si parla di modelli misti (mixed models). In R ci sono molte funzioni avanzate per il fitting di questa classe di modelli, ma noi utilizzeremo la più semplice, anche se non necessariamente la più avanzata. Si tratta di ‘aov()’, nella quale l’effetto random delle main-plots viene immesso all’interno della funzione ‘Error()’ (notare la E maiuscola).</p>
<p>E’importante segnalare che la <strong>funzione ‘aov()’ fornisce risultati corretti solo quando il disegno è bilanciato</strong>, come in questo caso.</p>
<p>Il codice per il fitting è:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.split &lt;-<span class="st"> </span><span class="kw">aov</span>(Prod <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(Blocco) <span class="op">+</span><span class="st"> </span>Lavorazione<span class="op">*</span>Diserbo <span class="op">+</span><span class="kw">Error</span>(mainPlot), <span class="dt">data=</span>dataset)</code></pre></div>
<p>Le stime dei parametri non sono disponibili con questa funzione e la scomposizione della varianza può essere ottenuta con la funzione ‘anova()’ disponibile nel package ‘aomisc’, che deve essere installato e caricato. L’output presenta separatamente i due strati di errore, quello riferito alle main-plots e quello riferito alle sub-plots.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(aomisc)
<span class="kw">anova</span>(mod.split)
## 
## Error: mainPlot
##                Df Sum Sq Mean Sq F value Pr(&gt;F)   
## factor(Blocco)  3  3.660    1.22   2.001 0.2155   
## Lavorazione     2 23.656   11.83  19.399 0.0024 **
## Residuals       6  3.658    0.61                  
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Error: Within
##                     Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Diserbo              1   3.32   3.320   1.225 0.2972  
## Lavorazione:Diserbo  2  19.46   9.732   3.589 0.0714 .
## Residuals            9  24.40   2.711                 
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></div>
<p>Confrontando il risultato dell’analisi a split-plot con quella dell’analisi fattoriale esposta in una lezione precedente possiamo notare che l’interazione lavorazione x diserbo non è più significativa, mentre lo era nel caso del disegno fattoriale semplice. E’evidente che i dati vanno elaborati seguendo il disegno sperimentale utilizzato per generarli, anche se ciò può diminuire la potenza dei test di F, per il più basso numero di gradi di libertà del residuo.</p>
</div>
<div id="medie-e-sem-1" class="section level4 unnumbered">
<h4>Medie e SEM</h4>
<p>Le medie marginali attese si ottengono come al solito, tramite la funzione ‘emmeans()’</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(emmeans)
medieA &lt;-<span class="st"> </span><span class="kw">emmeans</span>(mod.split, <span class="op">~</span>Lavorazione)
## Warning in emm_basis.aovlist(object, ...): Some predictors are correlated with the intercept - results are biased.
## May help to re-fit with different contrasts, e.g. &#39;contr.sum&#39;
## <span class="al">NOTE</span>: Results may be misleading due to involvement in interactions
medieB &lt;-<span class="st"> </span><span class="kw">emmeans</span>(mod.split, <span class="op">~</span>Diserbo)
## Warning in emm_basis.aovlist(object, ...): Some predictors are correlated with the intercept - results are biased.
## May help to re-fit with different contrasts, e.g. &#39;contr.sum&#39;
## <span class="al">NOTE</span>: Results may be misleading due to involvement in interactions
medieAB &lt;-<span class="st"> </span><span class="kw">emmeans</span>(mod.split, <span class="op">~</span>Lavorazione<span class="op">:</span>Diserbo)
## Warning in emm_basis.aovlist(object, ...): Some predictors are correlated with the intercept - results are biased.
## May help to re-fit with different contrasts, e.g. &#39;contr.sum&#39;
medieA; medieB; medieAB
##  Lavorazione   emmean        SE    df lower.CL
##  MIN         9.584958 0.6637362 13.40 8.155375
##  PROF        9.808958 0.7700520 14.95 8.167149
##  SUP         9.743458 0.7700520 14.95 8.101649
##  upper.CL
##  11.01454
##  11.45077
##  11.38527
## 
## Results are averaged over the levels of: Blocco, Diserbo 
## Confidence level used: 0.95
##  Diserbo   emmean        SE    df lower.CL upper.CL
##  parz     9.34050 0.3904284  6.00 8.385156 10.29584
##  tot     10.08442 0.7773876 13.75 8.414228 11.75461
## 
## Results are averaged over the levels of: Blocco, Lavorazione 
## Confidence level used: 0.95
##  Lavorazione Diserbo    emmean        SE    df
##  MIN         parz     8.091083 0.3187835  6.00
##  PROF        parz    10.519958 0.5040409  6.00
##  SUP         parz     9.410458 0.5040409  6.00
##  MIN         tot     11.078833 1.2071927 10.31
##  PROF        tot      9.097958 1.2687587 12.05
##  SUP         tot     10.076458 1.2687587 12.05
##  lower.CL  upper.CL
##  7.311048  8.871118
##  9.286615 11.753302
##  8.177115 10.643802
##  8.400063 13.757604
##  6.334951 11.860966
##  7.313451 12.839466
## 
## Results are averaged over the levels of: Blocco 
## Confidence level used: 0.95</code></pre></div>
<p>Gli errori standard si calcolano in modo più complicato che non nel caso dell’ANOVA fattoriale semplice. Infatti, oltre che al numero di repliche degli effetti in gioco, è necessario fare attenzione alla scelta dell’a voce d’errore. In generale, il calcolo degli errori standard non è banale, in quanto dobbiamo tener presenti le componenti di varianza che agiscono su ogni strato di errore. Le formule da impiegare sono riportate più sotto; A è il fattore principale (lavorazione), B il fattore secondario (diserbo), <span class="math inline">\(r\)</span> il numero di repliche, <span class="math inline">\(a\)</span> il numero di livelli di A e <span class="math inline">\(b\)</span> il numero di livelli di B, MSE(1) è l’errore delle main plots ed MSE(2) è il residuo:</p>
<p><span class="math display">\[SEM_A = \sqrt{\frac{MSE(1)}{r b}} = \sqrt{\frac{0.61}{4 \times 2}} = 0.276\]</span></p>
<p><span class="math display">\[SEM_B = \sqrt{\frac{(b - 1) MSE(2) + MSE(1)}{r a b}} = \sqrt{ \frac{(2 - 1) \times 2.711 + 0.61}{4 \times 3 \times 2}} = 0.372\]</span></p>
<p><span class="math display">\[SEM_{A:B} = \sqrt{\frac{[(b - 1) MSE(2) + MSE(1)]}{r b}} =  \sqrt{ \frac{(2 - 1) \times 2.711 + 0.61}{4 \times 2}} = 0.644\]</span></p>
<p>I SEMs vengono utilizzati come misura di variabilità per le medie del primo fattore sperimentale, del secondo fattore sperimentale e delle combinazioni tra i due fattori sperimentali.</p>
<p>Bisogna tener presente che, a parte il fattore sperimentale di primo livello, per le altre medie i SEM sono costruiti operando una combinazione lineare di varianze. Pertanto, il numero di gradi di libertà potrà essere solo approssimato, come vedremo in seguito.</p>
</div>
<div id="sed-e-confronti-multipli" class="section level4 unnumbered">
<h4>SED e confronti multipli</h4>
<p>Nei disegni a split-plot abbiamo 4 tipi di differenze tra medie.</p>
<ol style="list-style-type: decimal">
<li>Differenze tra due medie del fattore principale A (per esempio tra MIN - SUP)</li>
<li>Differenze tra due medie del fattore B (TOT - PARZ)</li>
<li>Differenze tra due medie del fattore B per lo stesso livello di A (MIN:TOT - MIN:PARZ). Per questa situazione si parla di differenze tra B entro A, che si abbrevia B|A.</li>
<li>Differenze tra due medie del fattore B per un diverso livello di A (MIN:TOT - SUP:PARZ). In questo caso l’abbreviazione è B:A.</li>
</ol>
<p>Per ognuna di queste differenza vi è una voce di errore (Errore standard della differenza = SED), ottenuto con il termine appropriato nell’ANOVA.</p>
<p><span class="math display">\[SED_A = \sqrt{\frac{2 \times MSE(1)}{r b}}\]</span></p>
<p><span class="math display">\[SED_B = \sqrt{\frac{2 \times  MSE(2)}{r a}}\]</span></p>
<p><span class="math display">\[SED_{B|A} = \sqrt{\frac{2  \times MSE(2)}{r}}\]</span></p>
<p><span class="math display">\[SED_{A:B} = \sqrt{\frac{2 [(b - 1) MSE(2) + MSE(1)]}{r b}}\]</span></p>
<p>In questo caso, l’unico effetto significativo è quello relativo alla ‘lavorazione’, con un SED pari a:</p>
<p><span class="math display">\[SED_{LAV}  = \sqrt {\frac{{2 \times 0.6097}}{{4 \times 2}}}  = 0.3904\]</span></p>
<p>I SED sono utili per i test di confronto multiplo, che, tuttavia, possono essere eseguiti, come usuale, con R. In questo caso, solo l’effetto lavorazione è significativo, quindi operiamo il confronto multiplo per questo effetto.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">multcomp<span class="op">::</span><span class="kw">cld</span>(medieA, <span class="dt">Letters =</span> LETTERS)
##  Lavorazione   emmean        SE    df lower.CL
##  MIN         9.584958 0.6637362 13.40 8.155375
##  SUP         9.743458 0.7700520 14.95 8.101649
##  PROF        9.808958 0.7700520 14.95 8.167149
##  upper.CL .group
##  11.01454  A    
##  11.38527  A    
##  11.45077  A    
## 
## Results are averaged over the levels of: Blocco, Diserbo 
## Confidence level used: 0.95 
## P value adjustment: tukey method for comparing a family of 3 estimates 
## significance level used: alpha = 0.05</code></pre></div>
<p>Un aspetto da considerare, qualora l’interazione ‘A:B’ fosse significativa, è che se vogliamo confrontare tra di loro combinazioni in cui i livelli di A sono diversi (ad esempio la media ottenuta con le lavorazioni superficiali e il diserbo totale con quella ottenuta con la lavorazione profonda e il diserbo totale), dobbiamo tener presente che sono coivolti entrambi gli strati di errore (vedi le formule più sopra). In questo caso il SED è costruito come combinazione lineare di <span class="math inline">\(MSE(1)\)</span> ed <span class="math inline">\(MSE(2)\)</span> e il calcolo dei suoi gradi di libertà non è banale. In questo esempio, il SED è:</p>
<p><span class="math display">\[SED_{A:B}  = \sqrt {\rm{2} \times \frac{{{\rm{(2 - 1)}} \times {\rm{2}}{\rm{.711 + 0}}{\rm{.6097}}}}{{4 \times 2}}}\]</span></p>
<p>La combinazione lineare tra varianze è della forma:</p>
<p><span class="math display">\[M = \alpha _1 MS(1) + \alpha _2 MS(2) = ({\rm{2 - 1}}) \times {\rm{2}}.{\rm{711 + 1}} \times {\rm{0}}.{\rm{6097}}\]</span></p>
<p>ed il numero di gradi di libertà per M (da utilizzare nel confronto multiplo) si può ottenere con l’approssimazione di Satterthwaite:</p>
<p><span class="math display">\[df_M  = \frac{{M^2 }}{{\sum\limits_{i = 1}^n {\frac{{\left( {\alpha _i MS_i } \right)^2 }}{{df_i }}} }} = \frac{{11.6097}}{{\frac{{({\rm{2 - 1}}) \times {\rm{2}}.{\rm{711}}}}{6} + \frac{{0.6097}}{9}}} = 12.554\]</span></p>
<p>dove df sta per ‘degrees of freedom’ (gradi di libertà) relativi ad ognuna delle varianze in gioco.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">multcomp<span class="op">::</span><span class="kw">cld</span>(medieAB, <span class="dt">Letters =</span> LETTERS)
##  Lavorazione Diserbo    emmean        SE    df
##  MIN         parz     8.091083 0.3187835  6.00
##  PROF        tot      9.097958 1.2687587 12.05
##  SUP         parz     9.410458 0.5040409  6.00
##  SUP         tot     10.076458 1.2687587 12.05
##  PROF        parz    10.519958 0.5040409  6.00
##  MIN         tot     11.078833 1.2071927 10.31
##  lower.CL  upper.CL .group
##  7.311048  8.871118  A    
##  6.334951 11.860966  AB   
##  8.177115 10.643802  AB   
##  7.313451 12.839466  AB   
##  9.286615 11.753302   B   
##  8.400063 13.757604  AB   
## 
## Results are averaged over the levels of: Blocco 
## Confidence level used: 0.95 
## P value adjustment: tukey method for comparing a family of 6 estimates 
## significance level used: alpha = 0.05</code></pre></div>
</div>
</div>
<div id="disegni-a-split-block" class="section level3 unnumbered">
<h3>Disegni a split-block</h3>
<p>Una variante dello schema a split-plot è relativa al disegno split-block, che permette di eseguire i trattamenti in bande perpendicolari. Questa esigenza si ravvisa spesso nelle prove sperimentali sui fitofarmaci, quando si vogliono utilizzare per il trattamento le normali attrezzature aziendali, piuttosto che attrezzature parcellari. Un esempio tipico, con i dati presentati in precedenza è riportato in Figura <a href="appendix-3-per-chi-vuole-approfondire-un-po.html#fig:figNameA3112">15.12</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:figNameA3112"></span>
<img src="_images/Strip-plot.jpg" alt="Esempio di un disegno a split-plot. L'esperimento prevede tre livelli di lavorazione (tesi di primo ordine, contraddistinte dai colori) e due livelli di diserbo chimico (tesi di secondo ordine)" width="75%" />
<p class="caption">
Figure 15.12: Esempio di un disegno a split-plot. L’esperimento prevede tre livelli di lavorazione (tesi di primo ordine, contraddistinte dai colori) e due livelli di diserbo chimico (tesi di secondo ordine)
</p>
</div>
<p>Si può osservare come, per entrambi i fattori sperimentali, il disegno può essere assimilato ad un blocco randomizzato e, per ogni fattore sperimentale, abbiamo main-plots diverse. Di conseguenza, possiamo applicare per entrambi i fattori quanto esposto a proposito del disegno a split-plot, il che porta ad individuare tre tipi di errore sperimentale: il primo relativo alla lavorazione, il secondo relativo al diserbo ed il terzo (residuo) relativo all’interazione lavorazione x diserbo.</p>
<div id="anova-a-split-block" class="section level4 unnumbered">
<h4>ANOVA a split-block</h4>
<p>Per la scomposizione della varianza utilizziamo R e la funzione ‘aov()’. Il codice è esposto di seguito; come nel caso precedente, è opportuno creare una variabile aggiuntiva che, in questo caso, codifica per le main-plots relative al diserbo chimico. Facciamo notare come ognuna di queste main-plots è univocamente definita come combinazione tra un blocco e una modalità di diserbo.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mainPlot2 &lt;-<span class="st"> </span><span class="kw">with</span>(dataset, <span class="kw">factor</span>(Blocco)<span class="op">:</span><span class="kw">factor</span>(Diserbo))
model.strip &lt;-<span class="st"> </span><span class="kw">aov</span>(Prod <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(Blocco) <span class="op">+</span><span class="st"> </span>Lavorazione<span class="op">*</span>Diserbo <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">Error</span>(mainPlot <span class="op">+</span><span class="st"> </span>mainPlot2), <span class="dt">data =</span> dataset)
## Warning in aov(Prod ~ factor(Blocco) + Lavorazione *
## Diserbo + Error(mainPlot + : Error() model is singular
<span class="kw">anova</span>(model.strip)
## 
## Error: mainPlot
##                Df Sum Sq Mean Sq F value Pr(&gt;F)   
## factor(Blocco)  3  3.660    1.22   2.001 0.2155   
## Lavorazione     2 23.656   11.83  19.399 0.0024 **
## Residuals       6  3.658    0.61                  
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Error: mainPlot2
##           Df Sum Sq Mean Sq F value Pr(&gt;F)
## Diserbo    1   3.32    3.32   0.988  0.393
## Residuals  3  10.08    3.36               
## 
## Error: Within
##                     Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Lavorazione:Diserbo  2  19.46   9.732   4.077 0.0762 .
## Residuals            6  14.32   2.387                 
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></div>
</div>
<div id="sed-e-confronti-multipli-1" class="section level4 unnumbered">
<h4>SED e confronti multipli</h4>
<p>Si opera nel modo usuale. In questa sede, come riferimento, riportiamo solo le formule per il calcolo dei SED.</p>
<p><span class="math display">\[SED_A = \sqrt{2 \times \frac{MSE(1)}{rb}}\]</span> <span class="math display">\[SED_B = \sqrt{2 \times \frac{MSE(2)}{ra}}\]</span></p>
<p><span class="math display">\[SED_{A|B} = \sqrt{2 \times \frac{\left(b-1\right) MSE(3) + MSE(1)}{rb}}\]</span></p>
<p><span class="math display">\[SED_{B|A} = \sqrt{2 \times \frac{\left(a-1\right) MSE(3) + MSE(2)}{ra}}\]</span></p>
<p><span class="math display">\[SED_{A:B} = \sqrt{2 \times \frac{\left(ab - a-b\right) MSE(3) + b \, MSE(2) + a \, MSE(1)}{rab}}\]</span></p>
</div>
</div>
<div id="disegni-a-split-split-plot" class="section level3 unnumbered">
<h3>Disegni a split-split-plot</h3>
<p>Se il disegno sperimentale split-plot ha tre livelli (A, B e C) avremo tre tipi di parcelle e quindi tre errori sperimentali (Errore A, Errore B e residuo). Trascuriamo questo disegno per motivi di spazio, assumendo che lo studente utilizzi un software specializzato per l’analisi dei dati. Alleghiamo una tabella riassuntiva per il calcolo dei SED.</p>
<p><span class="math display">\[SED_C = \sqrt{2 \times \frac{MSE(3)}{rab}}\]</span></p>
<p><span class="math display">\[SED_{C|A} = \sqrt{2 \times \frac{MSE(3)}{rb}}\]</span></p>
<p><span class="math display">\[SED_{C|B} = \sqrt{2 \times \frac{MSE(3)}{ra}}\]</span></p>
<p><span class="math display">\[SED_{C|AB} = \sqrt{2 \times \frac{MSE(3)}{r}}\]</span></p>
<p>B for same or different levels of C <span class="math display">\[SED_{B:C} = \sqrt{2 \times \frac{\left(c-1\right) MSE(3) + MSE(2)}{rac}}\]</span></p>
<p><span class="math display">\[SED_{B|AC} = \sqrt{2 \times \frac{\left(c-1\right) MSE(3) + MSE(1)}{rbc}}\]</span></p>
<p><span class="math display">\[SED_{A:C} = \sqrt{2 \times \frac{\left(c-1\right) MSE(3) + MSE(2)}{rc}}\]</span></p>
<p><span class="math display">\[SED_{A:B:C} = \sqrt{2 \times \frac{b \left(c-1\right) MSE(3) + (b-1) \, MSE(2) + MSE(1)}{rbc}}\]</span></p>
</div>
</div>
<div id="capitolo-12-regressione-lineare" class="section level2">
<h2><span class="header-section-number">15.1</span> Capitolo 12: Regressione lineare</h2>
<p>In questa appendice forniamo il codice con il quale abbiamo generato il dataset di prova. Immaginiamo di conoscere la legge deterministica che definisce la risposta del frumento alla concimazione azotata. In particolare, immaginiamo che questa risposta produttiva sia fondamentalmente lineare:</p>
<p><span class="math display">\[Y_E = b_0 + b_1 X\]</span></p>
<p>ed immaginiamo che, senza concimazione (X = 0), la produzione sia pari a 25 q/ha (<span class="math inline">\(b_0\)</span> = 25). Immaginiamo che l’incremente produttivo per kg di azoto somministrato sia pari a 0.15 q/ha (<span class="math inline">\(b_1\)</span> = 0.15).</p>
<p>Per individuare questa legge naturale organizziamo un esperimento, con quattro dosi di azoto e quattro repliche. In questo esperimento, come in tutti gli esperimenti, agirà anche una componente stocastica, che in qualche modo sposterà la risposta osservata dalla risposta attesa:</p>
<p><span class="math display">\[Y_o = b_0 + b_1 X + \varepsilon \quad \textrm{con}  \quad \varepsilon \sim N(0, \sigma)\]</span></p>
<p>Si assume che la componente stocastica <span class="math inline">\(\varepsilon\)</span> sia distribuita normalmente, come media 0 e deviazione standard <span class="math inline">\(\sigma\)</span>, che immaginiamo essere pari a 2.5 q/ha.</p>
<p>Su questa base, generiamo i dati osservati.</p>
</div>
<div id="capitolo-13-regressione-non-lineare" class="section level2">
<h2><span class="header-section-number">15.2</span> Capitolo 13: Regressione non-lineare</h2>
<div id="riparametrizzazione-delle-funzioni" class="section level3">
<h3><span class="header-section-number">15.2.1</span> Riparametrizzazione delle funzioni</h3>
<p>In alcuni casi è conveniente riparametrizzare le funzioni, se è necessario per le nostre esigenze di analisi. Anche questo aspetto sarà illustrato con un esempio, relativo ad un esperimento nel quale è stata valutata la produzione del girasole a densità crescenti di piante infestanti, da 0 a 100 piante per metro quadrato. I risultati ottenuti sono riportati nel dataset sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(competition)
<span class="kw">head</span>(competition)
##   Dens    Yield
## 1    0 29.58587
## 2   10 20.16776
## 3   20 17.82846
## 4   30  9.02289
## 5   40 13.41521
## 6   50 12.80159</code></pre></div>
<p>Secondo la letteratura, la relazione tra perdite produttive e densità delle piante infestanti può essere descritta con una funzione iperbolica di questo tipo (Cousens, 1985):</p>
<p><span class="math display">\[YL = \frac{iD}{1 + \frac{iD}{a}}\]</span></p>
<p>Dove <span class="math inline">\(YL\)</span> sta per perdite produttive (Yield Loss) percentuali, <span class="math inline">\(D\)</span> è la densità delle piante infestanti, <span class="math inline">\(a\)</span> è la perdita produttiva massima asintotica. Il grafico è mostrato qui sotto.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="dv">3</span><span class="op">*</span>x<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>(<span class="dv">3</span><span class="op">*</span>x)<span class="op">/</span><span class="dv">60</span>), <span class="dt">from=</span><span class="dv">0</span>, <span class="dt">to=</span><span class="dv">350</span>, <span class="dt">xlab=</span><span class="st">&quot;Weed density&quot;</span>,
      <span class="dt">ylab=</span><span class="st">&quot;Yield loss (%)&quot;</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">80</span>))
<span class="kw">abline</span>(<span class="dt">a=</span><span class="dv">0</span>, <span class="dt">b=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">2</span>))
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">60</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">2</span>))
<span class="kw">text</span>(<span class="dv">20</span>,<span class="dv">50</span>, <span class="dt">label=</span><span class="st">&quot;i = 3&quot;</span>)
<span class="kw">text</span>(<span class="dv">300</span>,<span class="dv">65</span>, <span class="dt">label=</span><span class="st">&quot;A = 60&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-248-1.png" /><!-- --></p>
<p>Normalmente, in campo non vengono determinate le perdite produttive, bensì le produzioni, come nel caso del nostro dataset. Di conseguenza abbiamo due possibilità:</p>
<ol style="list-style-type: decimal">
<li>modificare il dataset, esprimendo i dati in termini di perdite produttive percentuali;</li>
<li>modificare il modello, per utilizzare la produzione come variabile dipendente, al posto della perdita produttiva.</li>
</ol>
<p>La prima strada è più agevole, ma ci porta a perdere parte dell’informazione, cioè il livello produttivo nel testimone non infestato. La seconda strada può essere perseguita considerando che le perdite produttive percentuali sono pari a:</p>
<p><span class="math display">\[YL = \frac{{YWF - YW}}{{YWF}} \times 100\]</span></p>
<p>dove <span class="math inline">\(YWF\)</span> è la produzione nel testimone non infestato e <span class="math inline">\(YW\)</span> è la produzione nella parcella in studio. Dalla precedente funzione si ricava che:</p>
<p><span class="math display">\[YW = YWF - \frac{YL \times YWF}{100} = YWF\left( {1 - \frac{YL}{100}} \right)\]</span></p>
<p>che mostra come la produzione in una parcella infestata (<span class="math inline">\(YW\)</span>) può essere ottenuta in funzione della perdita produttiva. Considerando l’equazione precedente e il modello delle perdite produttive, possiamo scrivere:</p>
<p><span class="math display">\[YW = YWF\left( {1 - \frac{iD}{100\left( {1 + \frac{iD}{a}} \right)}} \right)\]</span></p>
<p>Questa equazione consente di utilizzare i dati produttivi osservati come variabile dipendente e di stimare i parametri competitivi <span class="math inline">\(i\)</span> ed <span class="math inline">\(a\)</span>, insiema alla produzione stimata in asssenza di competizione. Il fitting può essere eseguito utilizzando drm() e la funzione cousens85().</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modComp &lt;-<span class="st"> </span><span class="kw">drm</span>(Yield <span class="op">~</span><span class="st"> </span>Dens, <span class="dt">fct=</span><span class="kw">DRC.cousens85</span>() ,
               <span class="dt">data=</span>competition)
<span class="kw">summary</span>(modComp)
## 
## Model fitted: Yield-Weed Density function (Cousens, 1985) (3 parms)
## 
## Parameter estimates:
## 
##                 Estimate Std. Error t-value   p-value
## YWF:(Intercept) 30.47211    0.92763 32.8493 &lt; 2.2e-16
## i:(Intercept)    8.24038    1.36541  6.0351 3.857e-07
## a:(Intercept)   75.07312    2.40366 31.2328 &lt; 2.2e-16
##                    
## YWF:(Intercept) ***
## i:(Intercept)   ***
## a:(Intercept)   ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  1.866311 (41 degrees of freedom)</code></pre></div>
</div>
<div id="modelli-ancova" class="section level3">
<h3><span class="header-section-number">15.2.2</span> Modelli ANCOVA</h3>
<p>In molti casi, gli esperimenti includono contemporaneamente variabili qualitative e quantitative. Ad esempio, possiamo studiare la risposta alla concimazione azotata (variabile quantitativa) per due varietà di frumento (variabile qualitativa). In questo caso si parla di ANalisi della COVArianza (ANCOVA).</p>
<p>Tradizionalmente, questo modelli sono stati visti come modelli ANOVA per la variabile qualitativa (confronto varietale, quindi, nell’esempio precedente), nei quali la produzione di una parcella è aggiustata per il livello di concimazione azotata. Più di recente, sta divenendo importante ua visione alternativa, che consiste nel considerare un modello ANCOVA come un’analisi di regressione per ogni livello della variabile qualitativa. Anche in questo caso partiremo da un esempio.</p>
<div id="esempio-3" class="section level4">
<h4><span class="header-section-number">15.2.2.1</span> Esempio 3</h4>
<p>E’ stata misurata la risposta di due varietà di girasole (Sambro e Oleko) alla presenza di una sostanza allelopatica nel terreno di coltivazione. Questa sostanza è stata utilizzata a quattro dosi (da 0 a 17.5 g/ha) ed è stata rilevata la lunghezza dell’ipocotile degli individui trattati <span class="citation">(Pannacci, Pettorossi, and Tei <a href="#ref-pannacci2013_Phytotoxiceffectsaqueous">2013</a>)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(sunflower)
<span class="kw">head</span>(sunflower, <span class="dv">10</span>)
##    Dose Rep     Var Length
## 1   0.0   1 Sambro    77.0
## 2   0.0   2 Sambro    85.2
## 3   0.0   3 Sambro    80.2
## 4   5.0   1 Sambro    66.8
## 5   5.0   2 Sambro    70.2
## 6   5.0   3 Sambro    73.8
## 7  10.0   1 Sambro    51.6
## 8  10.0   2 Sambro    47.4
## 9  10.0   3 Sambro    43.2
## 10 17.5   1 Sambro    11.2</code></pre></div>
<p>In letteratura, è noto che la risposta degli organismi ad agenti tossici è sigmoidale, sul logaritmo della dose. L’equazione più utilizzata è quella log-logistica:</p>
<p><span class="math display">\[y = c + \frac{d - c}{1 + \exp \{ b[\log (dose) - \log (e)] \} }\]</span></p>
<p>dove <span class="math inline">\(y\)</span> è la risposta (la lunghezza, nel nostro esempio), <span class="math inline">\(x\)</span> è la dose, <span class="math inline">\(d\)</span> è la risposta nel testimone non trattato, <span class="math inline">\(c\)</span> è la risposta a dose estremamente elevata (che non necessariamente è nulla), <span class="math inline">\(e\)</span> è la dose che produce una risposta a metà strada tra <span class="math inline">\(d\)</span> e <span class="math inline">\(c\)</span> (normalmente nota come ED50) e b è la pendenza della curva nel punto di flesso.</p>
<p>Questo modello può essere parametrizzato con la funzione drm(), utilizzando la funzione LL.4() ed inserendo la varietà di frumento come variabile qualitativa (argomento curveid).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.sun &lt;-<span class="st"> </span><span class="kw">drm</span>(Length <span class="op">~</span><span class="st"> </span>Dose, <span class="dt">curveid=</span>Var, <span class="dt">data =</span> sunflower, <span class="dt">fct =</span> <span class="kw">LL.4</span>())
<span class="kw">summary</span>(mod.sun)
## 
## Model fitted: Log-logistic (ED50 as parameter) (4 parms)
## 
## Parameter estimates:
## 
##           Estimate Std. Error t-value   p-value    
## b:Sambro    1.9425     1.5487  1.2543   0.22775    
## b:Oleko     3.3872     1.3756  2.4624   0.02553 *  
## c:Sambro  -61.1131   228.5635 -0.2674   0.79259    
## c:Oleko    -3.9345    11.8818 -0.3311   0.74484    
## d:Sambro   80.8000     5.7774 13.9855 2.174e-10 ***
## d:Oleko    74.4500     5.7866 12.8659 7.450e-10 ***
## e:Sambro   18.3383    29.1718  0.6286   0.53846    
## e:Oleko     8.5322     1.2763  6.6848 5.242e-06 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  10.02111 (16 degrees of freedom)</code></pre></div>
<p>Otteniamo quattro parametri (quindi una curva diversa) per ogni varietà. Notiamo subito che l’asintoto inferiore assume valori negativi, quindi inaccettabili da un punto di vista biologico. Provvediamo quindi a rimuovere gli asintoti inferiori, ammettendo che, a dose molto elevata, la sostanza in studio inibisce completamente la crescita dell’ipocotile in entrambe le varietà. Riparametrizziamo il modello, arrivando alla determinazione di due curve diverse con tre parametri ciascuna (funzione LL.3()).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.sun2 &lt;-<span class="st"> </span><span class="kw">drm</span>(Length <span class="op">~</span><span class="st"> </span>Dose, <span class="dt">curveid=</span>Var, <span class="dt">data =</span> sunflower, <span class="dt">fct =</span> <span class="kw">LL.3</span>())
<span class="kw">summary</span>(mod.sun2)
## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)
## 
## Parameter estimates:
## 
##           Estimate Std. Error t-value   p-value    
## b:Sambro   3.20503    0.99156  3.2323  0.004622 ** 
## b:Oleko    3.73287    1.07596  3.4693  0.002737 ** 
## d:Sambro  78.90444    5.26134 14.9970 1.293e-11 ***
## d:Oleko   74.03407    5.55331 13.3315 9.112e-11 ***
## e:Sambro  11.03545    1.07380 10.2770 5.856e-09 ***
## e:Oleko    8.23737    0.88496  9.3081 2.661e-08 ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  9.641889 (18 degrees of freedom)
<span class="kw">plot</span>(mod.sun)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-252-1.png" /><!-- --></p>
<p>I risultati sono analoghi a quelli che avremmo ottenuto parametrizzando separatamente le curve per le due varietà ,ma con chiari vantaggi che illustreremo nel prossimo capitolo.</p>
</div>
</div>
<div id="confronto-tra-modelli-alternativi" class="section level3">
<h3><span class="header-section-number">15.2.3</span> Confronto tra modelli alternativi</h3>
<p>La possibilità di confrontare modelli matematici è forse uno degli aspetti più rilevanti delle regressioni non-lineari, nel senso che ci permette di valutare e scegliere ipotesi biologiche, in base alla loro maggiore o minore compatibilità con le osservazioni sperimentali.</p>
<p>Se prendiamo l’esempio precedente, è rilevante chiedersi se le due varietà rispondono alla stessa sostanza allelopatica in modo diverso. In termini statistici abbiamo due modelli alternativi:</p>
<ol style="list-style-type: decimal">
<li>modello con due curve diverse, una per ogni varietà</li>
<li>modello alternativo, con un’unica curva di risposta per le due varietà</li>
</ol>
<p>Questo secondo modello deriva dal primo, semplicemente rimuovendo tre parametri, cioè un valore di <span class="math inline">\(b\)</span>, uno di <span class="math inline">\(d\)</span> ed uno di <span class="math inline">\(e\)</span>. Si tratta quindi di due modelli ‘nested’. Parametrizziamo il modello alternativo.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.sunR &lt;-<span class="st"> </span><span class="kw">drm</span>(Length <span class="op">~</span><span class="st"> </span>Dose, <span class="dt">data =</span> sunflower, <span class="dt">fct =</span> <span class="kw">LL.3</span>())
<span class="kw">summary</span>(mod.sunR)
## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value
## b:(Intercept)  3.23478    0.78527  4.1193 0.0004885
## d:(Intercept) 76.81273    4.52016 16.9934 9.481e-14
## e:(Intercept)  9.46516    0.82245 11.5085 1.568e-10
##                  
## b:(Intercept) ***
## d:(Intercept) ***
## e:(Intercept) ***
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  11.34069 (21 degrees of freedom)</code></pre></div>
<p>Quando i modelli sono ‘nested’ è possibile confrontarli con un test di F per la ‘extra sum of squares’. Le devianze del residuo dei due modelli sono date dalla somma dei quadrati degli scarti: il modello ridotto presenta, ovviamente, un peggior fitting e quindi una devianza molto più alta.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devC &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">residuals</span>(mod.sun2)<span class="op">^</span><span class="dv">2</span>)
devR &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">residuals</span>(mod.sunR)<span class="op">^</span><span class="dv">2</span>)
devC; devR
## [1] 1673.388
## [1] 2700.837</code></pre></div>
<p>I gradi di libertà delle due devianze sono rispettivamente 24 - 6 = 18 per il modello completo con 6 parametri e 24 - 3 = 21 per il modello ridotto. La differenza (exra sum of squares) è 1027.448 con 3 gradi di libertà. Questa quota aggiuntiva è legata alla rimozione dei tre parametri e la relativa varianza può essere confrontata con la varianza del residuo del modello completo, per vedere se la rimozione dei parametri provoca un significativo incremento della mancanza di adatttamento.</p>
<p><span class="math display">\[ F = \frac{\frac{RSS_c - RSS_s}{df_c - df_s}}{\frac{RSS_c}{df_c}} = \frac{\frac{1027.448}{3}}{\frac{1673.4}{18}}= 3.684\]</span></p>
<p>A questo valore di F corrisponde una probabilità pari a 0.0315, che ci permette di rifiutare l’ipotesi nulla di assenza di differenza tra le due varietà. In R il confronto tra modelli ‘nested’ si esegue con la funzione anova()</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(mod.sun2, mod.sunR)
## 
## 1st model
##  fct:      LL.3()
##  pmodels: 1 (for all parameters)
## 2nd model
##  fct:      LL.3()
##  pmodels: Var (for all parameters)
## ANOVA table
## 
##           ModelDf    RSS Df F value p value
## 2nd model      21 2700.8                   
## 1st model      18 1673.4  3  3.6840  0.0315</code></pre></div>
<p>E’anche possibile confrontare tra di loro i parametri del modello, per capire quale caratteristica della regressione (pendenza, ED50 o asintoto superiore) contribuisce maggiormente alla differenza significativa tra le curve. Questo è possibile con test di t eteroscedastici, nell’ipotesi che non vi siano correlazioni tra parametri misurati su curve diverse (il che è vero). Ad esempio, considerando i due ED50 (rispettivamente 11.04 <span class="math inline">\(\pm\)</span> 1.074 e 8.24 <span class="math inline">\(\pm\)</span> 0.885), il test di t è:</p>
<p><span class="math display">\[ t = \frac{e_1 - e_2}{\sqrt(ES_1^2 + ES_2^2)} = \frac{11.04 - 8.24}{\sqrt(1.074^2 + 0.885^2)} = 2.012\]</span></p>
<p>che corrisponde ad una probabilità (due code) P = 0.05956, considerando un numero di gradi di libertà pari a quelli del residuo. Confronti tra parametri possono essere compiuti facilmente con la funzione compParm() in drc.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">compParm</span>(mod.sun2, <span class="dt">strVal=</span><span class="st">&quot;b&quot;</span>, <span class="dt">operator=</span><span class="st">&quot;-&quot;</span>)
## 
## Comparison of parameter &#39;b&#39; 
## 
##                Estimate Std. Error t-value p-value
## Sambro -Oleko  -0.52784    1.46318 -0.3607  0.7225
<span class="kw">compParm</span>(mod.sun2, <span class="dt">strVal=</span><span class="st">&quot;d&quot;</span>, <span class="dt">operator=</span><span class="st">&quot;-&quot;</span>)
## 
## Comparison of parameter &#39;d&#39; 
## 
##                Estimate Std. Error t-value p-value
## Sambro -Oleko    4.8704     7.6499  0.6367  0.5324
<span class="kw">compParm</span>(mod.sun2, <span class="dt">strVal=</span><span class="st">&quot;e&quot;</span>, <span class="dt">operator=</span><span class="st">&quot;-&quot;</span>)
## 
## Comparison of parameter &#39;e&#39; 
## 
##                Estimate Std. Error t-value p-value  
## Sambro -Oleko    2.7981     1.3915  2.0109 0.05956 .
## ---
## Signif. codes:  
## 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></div>
<p>Vediamo che le due curve sono diverse nel complesso, ma considerando i singoli parametri, solo <span class="math inline">\(e\)</span> mostra una differenza vicina alla significatività.</p>
</div>
<div id="confronto-tra-modelli-non-nested" class="section level3">
<h3><span class="header-section-number">15.2.4</span> Confronto tra modelli non-nested</h3>
<p>Quando le equazioni sono non-nested i confronti non possono essere effettuati con test statistici formali. In questa situazione si cerca di utilizzare criteri che tengano conto sia della bontà di adattamento (più basso è il residuo, migliore è il modello), sia della parsinomia (minore è il numero dei parametri, migliore è il modello). Un indicatore che viene spesso utilizzato è l’AKAIKE Information Criterion (AIC):</p>
<p><span class="math display">\[ AIC =  - 2 \, log(2\pi ) + n\,\, log(RSS/n) + n + 2(p + 1) \]</span></p>
<p>dove RSS è la devianza del residuo, n è il numero di osservazioni e p è il numero di parametri. Più basso è il valore dell’AIC e migliore è il modello.</p>
</div>
<div id="il-package-drc" class="section level3">
<h3><span class="header-section-number">15.2.5</span> Il package ‘drc’</h3>
<p>Abbiamo visto che il package  è estremamente comodo, perchè contiene tutte le funzioni necessarie per eseguire analisi di regressione adeguate. Le funzioni disponibili nel pacchetto originale e nell’estensione collegata a questo libro (con i relativi <em>self-starter</em>) sono</p>
<ol style="list-style-type: decimal">
<li>log-logistica a due tre e quattro parametri ()</li>
<li>weibull a due, tre, quattro parametri (),</li>
<li>funzione sigmoidale con picco picco iniziale (),</li>
<li>crescita Gompertz (tre parametrizzazioni alternative: , , ),</li>
<li>decrescita esponenziale ()</li>
<li>allometrica (), crescita esponenziale (), degradazione del primo ordine (), iperbole rettangolare (), crescita logistica (tre parametrizzazioni alternative ), crescita monomolecolare (), equazione di Freundlich (), loglineare (), esponenziale negativa a due parametri (), regressione asintotica (), valori estremi (), funzione di Hill (), Chapman-Richard ().</li>
</ol>
<p>[DA FARE: Come definire una funzione semplice in drm()…..]</p>
</div>
<div id="altre-statistiche" class="section level3">
<h3><span class="header-section-number">15.2.6</span> Altre statistiche</h3>
<p>Altri indicatori di bontà di adattamento molto usati in letteratura per finalità puramente descrittive sono il Mean Square Error:</p>
<p><span class="math display">\[MSE = \frac{1}{N}\sum\limits_{i = 1}^N {(Y_i  - } \widehat{Y_i })^2\]</span></p>
<p>che, nel caso in esempio, è pari a 6.299.</p>
<p>Come vediamo si tratta della varianza del residuo, ma ottenuta divedendo per il numero dei dati e non per il numero dei gradi di libertà (varianza della popolazione e non varianza del campione). E’quindi un indicatore inferenziale distorto, ma è importante consocerlo perché viene spesso utilizzato per stabilire la bontà d’adattamento e il valore predittivo di modelli deterministici.</p>
<p>Il MSE è spesso difficile da valutare perché, essendo una somma di quadrati, la sua unità di misura non è quella dei dati. Per questo motivo, spesso si utilizza la sua radice quadrata:</p>
<p><span class="math display">\[RMSE = \sqrt{MSE}\]</span></p>
<p>che ha la stessa unità di misura delle osservazioni. In questo caso, il RRMSE (Root Mean Square Error) è uguale a 2.510, che, considerando i dati ,rappresenta un valore decisamente basso.</p>
<p>Una variante molto utilizzata è il Relative Root Mean Square Error (RRMSE):</p>
<p><span class="math display">\[RRMSE = \frac{\sqrt{MSE}} {\overline{Y}} \times 100\]</span></p>
<p>dove <span class="math inline">\(\overline{Y}\)</span> è la media dei dati. Si tratta di un indicatore analogo al coefficiente di variabilità, nel quale la bontà del modello viene espressa relativamente alla media delle previsioni. Nel nostro caso è pari al 9.8%.</p>

<div id="refs" class="references">
<div>
<p>Bates, D. M., and D. G. Watts. 1988. <em>Nonlinear Regression Analysis &amp; Its Applications.</em> Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div>
<p>Bolker, B. M. 2008. <em>Ecological Models and Data in R</em>. Books: Princeton University Press.</p>
</div>
<div>
<p>Carroll, R. J., and D. Ruppert. 1988. <em>Transformation and Weighting in Regression.</em> Books: Chapman and Hall.</p>
</div>
<div>
<p>Daniel, Johnnie. 2011. <em>Sampling Essentials: Practical Guidelines for Making Sampling Choices</em>. USA: SAGE.</p>
</div>
<div>
<p>de Mendiburu, Felipe. 2019. <em>Agricolae: Statistical Procedures for Agricultural Research</em>. <a href="https://CRAN.R-project.org/package=agricolae" class="uri">https://CRAN.R-project.org/package=agricolae</a>.</p>
</div>
<div>
<p>Draper, N. R., and H. Smith. 1998. <em>Applied Regression Analysis</em>. III. Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div>
<p>LeClerg, E. L., W. H. Leonard, and A. G. Clark. 1962. <em>Field Plot Technique</em>. Books: Burgess Publishing Company.</p>
</div>
<div>
<p>Pannacci, E., D. Pettorossi, and F. Tei. 2013. “Phytotoxic Effects of Aqueous Extracts of Sunflower on Seed Germination and Growth of Sinapis Alba L., Triticum Aestivum L. and Lolium Multiflorum Lam.” <em>Allelopathy Journal</em> 32 (1): 23.</p>
</div>
<div>
<p>Ratkowsky, David A. 1990. <em>Handbook of Nonlinear Regression Models</em>. Books: Marcel Dekker Inc.</p>
</div>
<div>
<p>Ritz, C., and J. C. Streibig. 2008. <em>Nonlinear Regression with R</em>. Books: Springer-Verlag New York Inc.</p>
</div>
</div>
</div>
</div>
</div>








<h3>References</h3>
<div id="refs" class="references">
<div id="ref-de-Mendiburu:2019aa">
<p>de Mendiburu, Felipe. 2019. <em>Agricolae: Statistical Procedures for Agricultural Research</em>. <a href="https://CRAN.R-project.org/package=agricolae" class="uri">https://CRAN.R-project.org/package=agricolae</a>.</p>
</div>
<div id="ref-pannacci2013_Phytotoxiceffectsaqueous">
<p>Pannacci, E., D. Pettorossi, and F. Tei. 2013. “Phytotoxic Effects of Aqueous Extracts of Sunflower on Seed Germination and Growth of Sinapis Alba L., Triticum Aestivum L. and Lolium Multiflorum Lam.” <em>Allelopathy Journal</em> 32 (1): 23.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Con il termine inglese <em>coverage</em> si intende, in un esperimento ripetuto un elevatissimo numero di volte, l’effettiva percentuale di campioni, per i quali l’intervallo di confidenza, calcolato per un certo P nominale (es. P = 0.95), contiene effettivamente la media <span class="math inline">\(\mu\)</span> della popolazione.<a href="appendix-3-per-chi-vuole-approfondire-un-po.html#fnref3">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="appendix-2-richiami-di-statistica-descrittiva.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
