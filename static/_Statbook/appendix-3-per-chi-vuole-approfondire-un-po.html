<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Metodologia statistica per le scienze agrarie</title>
  <meta name="description" content="Appunti dai corsi S.I.A.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Metodologia statistica per le scienze agrarie" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Appunti dai corsi S.I.A." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Metodologia statistica per le scienze agrarie" />
  
  <meta name="twitter:description" content="Appunti dai corsi S.I.A." />
  

<meta name="author" content="Andrea Onofri e Dario Sacco">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="appendix-2-richiami-di-statistica-descrittiva.html">

<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global Site Tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131792052-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-131792052-1');
  </script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduzione</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#organizzazione-del-testo"><i class="fa fa-check"></i>Organizzazione del testo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#gli-autori"><i class="fa fa-check"></i>Gli autori</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#pre-requisiti"><i class="fa fa-check"></i>Pre-requisiti</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html"><i class="fa fa-check"></i><b>1</b> Scienza e pseudo-scienza</a><ul>
<li class="chapter" data-level="1.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#introduzione-1"><i class="fa fa-check"></i><b>1.1</b> Introduzione</a><ul>
<li class="chapter" data-level="1.1.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#cosa-e-quindi-una-prova-scientifica"><i class="fa fa-check"></i><b>1.1.1</b> Cosa è quindi una prova scientifica?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#esperimenti-buoni-e-cattivi"><i class="fa fa-check"></i><b>1.2</b> Esperimenti buoni e cattivi!</a><ul>
<li class="chapter" data-level="1.2.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#lerrore-sperimentale"><i class="fa fa-check"></i><b>1.2.1</b> L’errore sperimentale</a></li>
<li class="chapter" data-level="1.2.2" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#il-campionamento"><i class="fa fa-check"></i><b>1.2.2</b> Il campionamento</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#scienza-metodo"><i class="fa fa-check"></i><b>1.3</b> Scienza = metodo</a></li>
<li class="chapter" data-level="1.4" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#chi-valuta-se-un-esperimento-e-attendibile"><i class="fa fa-check"></i><b>1.4</b> Chi valuta se un esperimento è attendibile?</a></li>
<li class="chapter" data-level="1.5" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#il-metodo-sperimentale"><i class="fa fa-check"></i><b>1.5</b> Il metodo sperimentale</a></li>
<li class="chapter" data-level="1.6" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#metodi-sperimentali-validi-ed-invalidi"><i class="fa fa-check"></i><b>1.6</b> Metodi sperimentali validi ed invalidi</a><ul>
<li class="chapter" data-level="1.6.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#primo-esperimento"><i class="fa fa-check"></i><b>1.6.1</b> Primo esperimento</a></li>
<li class="chapter" data-level="1.6.2" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#secondo-esperimento"><i class="fa fa-check"></i><b>1.6.2</b> Secondo esperimento</a></li>
<li class="chapter" data-level="1.6.3" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#terzo-esperimento"><i class="fa fa-check"></i><b>1.6.3</b> Terzo esperimento</a></li>
<li class="chapter" data-level="1.6.4" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#quarto-esperimento-quello-buono"><i class="fa fa-check"></i><b>1.6.4</b> Quarto esperimento: quello buono</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#incertezza-residua"><i class="fa fa-check"></i><b>1.7</b> Incertezza residua</a></li>
<li class="chapter" data-level="1.8" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#il-ruolo-della-statistica"><i class="fa fa-check"></i><b>1.8</b> Il ruolo della statistica</a></li>
<li class="chapter" data-level="1.9" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#conclusioni"><i class="fa fa-check"></i><b>1.9</b> Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html"><i class="fa fa-check"></i><b>2</b> Esperimenti validi ed invalidi</a><ul>
<li class="chapter" data-level="2.1" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#definizioni"><i class="fa fa-check"></i><b>2.1</b> Definizioni</a></li>
<li class="chapter" data-level="2.2" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#elementi-fondamentali-del-disegno-sperimentale"><i class="fa fa-check"></i><b>2.2</b> Elementi fondamentali del disegno sperimentale</a><ul>
<li class="chapter" data-level="2.2.1" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#primo-elemento-controllo-degli-errori"><i class="fa fa-check"></i><b>2.2.1</b> Primo elemento: controllo degli errori</a></li>
<li class="chapter" data-level="2.2.2" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#secondo-elemento-replicazione"><i class="fa fa-check"></i><b>2.2.2</b> Secondo elemento: replicazione</a></li>
<li class="chapter" data-level="2.2.3" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#terzo-elemento-randomizzazione"><i class="fa fa-check"></i><b>2.2.3</b> Terzo elemento: randomizzazione</a></li>
<li class="chapter" data-level="2.2.4" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#esperimenti-non-validi"><i class="fa fa-check"></i><b>2.2.4</b> Esperimenti non validi</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#conclusione"><i class="fa fa-check"></i><b>2.3</b> Conclusione</a></li>
<li class="chapter" data-level="2.4" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#per-approfondimenti"><i class="fa fa-check"></i><b>2.4</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html"><i class="fa fa-check"></i><b>3</b> Progettare un esperimento</a><ul>
<li class="chapter" data-level="3.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#ipotesi-scientifica-rightarrow-obiettivo-dellesperimento"><i class="fa fa-check"></i><b>3.1</b> Ipotesi scientifica <span class="math inline">\(\rightarrow\)</span> obiettivo dell’esperimento</a></li>
<li class="chapter" data-level="3.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#casi-di-studio---1"><i class="fa fa-check"></i><b>3.2</b> Casi di studio - 1</a><ul>
<li class="chapter" data-level="3.2.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-1---diserbo-chimico"><i class="fa fa-check"></i><b>3.2.1</b> Esempio 1 - Diserbo chimico</a></li>
<li class="chapter" data-level="3.2.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-2---valutazione-varietale"><i class="fa fa-check"></i><b>3.2.2</b> Esempio 2 - Valutazione varietale</a></li>
<li class="chapter" data-level="3.2.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-3---diserbo-parziale"><i class="fa fa-check"></i><b>3.2.3</b> Esempio 3 - Diserbo parziale</a></li>
<li class="chapter" data-level="3.2.4" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-4---colture-poliennali"><i class="fa fa-check"></i><b>3.2.4</b> Esempio 4 - Colture poliennali</a></li>
<li class="chapter" data-level="3.2.5" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-5---inquinamento-da-micotossine"><i class="fa fa-check"></i><b>3.2.5</b> Esempio 5 - Inquinamento da micotossine</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#identificazione-dei-fattori-sperimentali"><i class="fa fa-check"></i><b>3.3</b> Identificazione dei fattori sperimentali</a></li>
<li class="chapter" data-level="3.4" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esperimenti-multifattoriali"><i class="fa fa-check"></i><b>3.4</b> Esperimenti (multi)fattoriali</a></li>
<li class="chapter" data-level="3.5" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#aggiungere-un-controllo"><i class="fa fa-check"></i><b>3.5</b> Aggiungere un controllo?</a></li>
<li class="chapter" data-level="3.6" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#fattori-sperimentali-di-trattamento-e-di-blocco"><i class="fa fa-check"></i><b>3.6</b> Fattori sperimentali di trattamento e di blocco</a></li>
<li class="chapter" data-level="3.7" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#casi-di-studio---2"><i class="fa fa-check"></i><b>3.7</b> Casi di studio - 2</a><ul>
<li class="chapter" data-level="3.7.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-1"><i class="fa fa-check"></i><b>3.7.1</b> Esempio 1</a></li>
<li class="chapter" data-level="3.7.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-2"><i class="fa fa-check"></i><b>3.7.2</b> Esempio 2</a></li>
<li class="chapter" data-level="3.7.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-3"><i class="fa fa-check"></i><b>3.7.3</b> Esempio 3</a></li>
<li class="chapter" data-level="3.7.4" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-4"><i class="fa fa-check"></i><b>3.7.4</b> Esempio 4</a></li>
<li class="chapter" data-level="3.7.5" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-5"><i class="fa fa-check"></i><b>3.7.5</b> Esempio 5</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#identificazione-delle-unita-sperimentali-e-delle-repliche"><i class="fa fa-check"></i><b>3.8</b> Identificazione delle unità sperimentali e delle repliche</a><ul>
<li class="chapter" data-level="3.8.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#cornice-di-campionamento-e-numero-di-repliche"><i class="fa fa-check"></i><b>3.8.1</b> Cornice di campionamento e numero di repliche</a></li>
<li class="chapter" data-level="3.8.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#campionamento-delle-unita-sperimentali"><i class="fa fa-check"></i><b>3.8.2</b> Campionamento delle unità sperimentali</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#scelta-delle-variabili-da-rilevare"><i class="fa fa-check"></i><b>3.9</b> Scelta delle variabili da rilevare</a><ul>
<li class="chapter" data-level="3.9.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-nominali-categoriche"><i class="fa fa-check"></i><b>3.9.1</b> Variabili nominali (categoriche)</a></li>
<li class="chapter" data-level="3.9.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-ordinali"><i class="fa fa-check"></i><b>3.9.2</b> Variabili ordinali</a></li>
<li class="chapter" data-level="3.9.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-quantitative-discrete"><i class="fa fa-check"></i><b>3.9.3</b> Variabili quantitative discrete</a></li>
<li class="chapter" data-level="3.9.4" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-quantitative-continue"><i class="fa fa-check"></i><b>3.9.4</b> Variabili quantitative continue</a></li>
<li class="chapter" data-level="3.9.5" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#rilievi-visivi-e-sensoriali"><i class="fa fa-check"></i><b>3.9.5</b> Rilievi visivi e sensoriali</a></li>
<li class="chapter" data-level="3.9.6" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-di-confondimento"><i class="fa fa-check"></i><b>3.9.6</b> Variabili di confondimento</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#casi-di-studio---3"><i class="fa fa-check"></i><b>3.10</b> Casi di studio - 3</a></li>
<li class="chapter" data-level="3.11" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#allocazione-dei-trattamenti"><i class="fa fa-check"></i><b>3.11</b> Allocazione dei trattamenti</a></li>
<li class="chapter" data-level="3.12" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#casi-di-studio---4"><i class="fa fa-check"></i><b>3.12</b> Casi di studio - 4</a><ul>
<li class="chapter" data-level="3.12.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-1-1"><i class="fa fa-check"></i><b>3.12.1</b> Esempio 1</a></li>
<li class="chapter" data-level="3.12.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-2-1"><i class="fa fa-check"></i><b>3.12.2</b> Esempio 2</a></li>
<li class="chapter" data-level="3.12.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-3-1"><i class="fa fa-check"></i><b>3.12.3</b> Esempio 3</a></li>
<li class="chapter" data-level="3.12.4" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-4-1"><i class="fa fa-check"></i><b>3.12.4</b> Esempio 4</a></li>
<li class="chapter" data-level="3.12.5" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esempio-5-1"><i class="fa fa-check"></i><b>3.12.5</b> Esempio 5</a></li>
</ul></li>
<li class="chapter" data-level="3.13" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#impianto-delle-prove"><i class="fa fa-check"></i><b>3.13</b> Impianto delle prove</a></li>
<li class="chapter" data-level="3.14" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#scrivere-un-progettoreport-di-ricerca-semplici-indicazioni"><i class="fa fa-check"></i><b>3.14</b> Scrivere un progetto/report di ricerca: semplici indicazioni</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html"><i class="fa fa-check"></i><b>4</b> Modelli matematici a ‘due facce’</a><ul>
<li class="chapter" data-level="4.1" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#verita-vera-e-modelli-deterministici"><i class="fa fa-check"></i><b>4.1</b> Verità ‘vera’ e modelli deterministici</a></li>
<li class="chapter" data-level="4.2" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#qualche-esempio-di-modello-deterministico"><i class="fa fa-check"></i><b>4.2</b> Qualche esempio di modello deterministico</a></li>
<li class="chapter" data-level="4.3" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#genesi-deterministica-delle-osservazioni-sperimentali"><i class="fa fa-check"></i><b>4.3</b> Genesi deterministica delle osservazioni sperimentali</a></li>
<li class="chapter" data-level="4.4" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#errore-sperimentale-e-modelli-stocastici"><i class="fa fa-check"></i><b>4.4</b> Errore sperimentale e modelli stocastici</a><ul>
<li class="chapter" data-level="4.4.1" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#funzioni-di-probabilita"><i class="fa fa-check"></i><b>4.4.1</b> Funzioni di probabilità</a></li>
<li class="chapter" data-level="4.4.2" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#funzioni-di-densita"><i class="fa fa-check"></i><b>4.4.2</b> Funzioni di densità</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#la-distribuzione-normale-curva-di-gauss"><i class="fa fa-check"></i><b>4.5</b> La distribuzione normale (curva di Gauss)</a></li>
<li class="chapter" data-level="4.6" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#modelli-a-due-facce"><i class="fa fa-check"></i><b>4.6</b> Modelli ‘a due facce’</a><ul>
<li class="chapter" data-level="4.6.1" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-1"><i class="fa fa-check"></i><b>4.6.1</b> Esercizio 1</a></li>
<li class="chapter" data-level="4.6.2" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-2"><i class="fa fa-check"></i><b>4.6.2</b> Esercizio 2</a></li>
<li class="chapter" data-level="4.6.3" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-3"><i class="fa fa-check"></i><b>4.6.3</b> Esercizio 3</a></li>
<li class="chapter" data-level="4.6.4" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-4"><i class="fa fa-check"></i><b>4.6.4</b> Esercizio 4</a></li>
<li class="chapter" data-level="4.6.5" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-5"><i class="fa fa-check"></i><b>4.6.5</b> Esercizio 5</a></li>
<li class="chapter" data-level="4.6.6" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-6"><i class="fa fa-check"></i><b>4.6.6</b> Esercizio 6</a></li>
<li class="chapter" data-level="4.6.7" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-7"><i class="fa fa-check"></i><b>4.6.7</b> Esercizio 7</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#altri-modelli-stocastici-di-interesse-per-lo-sperimentatore"><i class="fa fa-check"></i><b>4.7</b> Altri modelli stocastici di interesse per lo sperimentatore</a></li>
<li class="chapter" data-level="4.8" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#e-allora"><i class="fa fa-check"></i><b>4.8</b> E allora?</a></li>
<li class="chapter" data-level="4.9" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#le-simulazioni-monte-carlo"><i class="fa fa-check"></i><b>4.9</b> Le simulazioni Monte Carlo</a></li>
<li class="chapter" data-level="4.10" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#analisi-dei-dati-e-model-fitting"><i class="fa fa-check"></i><b>4.10</b> Analisi dei dati e ‘model fitting’</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html"><i class="fa fa-check"></i><b>5</b> Esperimenti, stime ed incertezza</a><ul>
<li class="chapter" data-level="5.1" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#lanalisi-dei-dati-gli-ingredienti-fondamentali"><i class="fa fa-check"></i><b>5.1</b> L’analisi dei dati: gli ‘ingredienti’ fondamentali</a></li>
<li class="chapter" data-level="5.2" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#esempio-una-soluzione-erbicida"><i class="fa fa-check"></i><b>5.2</b> Esempio: una soluzione erbicida</a><ul>
<li class="chapter" data-level="5.2.1" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#il-modello-dei-dati"><i class="fa fa-check"></i><b>5.2.1</b> Il modello dei dati</a></li>
<li class="chapter" data-level="5.2.2" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#analisi-dei-dati-stima-dei-parametri"><i class="fa fa-check"></i><b>5.2.2</b> Analisi dei dati: stima dei parametri</a></li>
<li class="chapter" data-level="5.2.3" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#la-sampling-distribution"><i class="fa fa-check"></i><b>5.2.3</b> La ‘sampling distribution’</a></li>
<li class="chapter" data-level="5.2.4" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#lerrore-standard"><i class="fa fa-check"></i><b>5.2.4</b> L’errore standard</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#riepilogo-1-caratterizzare-lincertezza-di-un-esperimento"><i class="fa fa-check"></i><b>5.3</b> Riepilogo 1: Caratterizzare l’incertezza di un esperimento</a></li>
<li class="chapter" data-level="5.4" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#lintervallo-di-confidenza"><i class="fa fa-check"></i><b>5.4</b> L’intervallo di confidenza</a></li>
<li class="chapter" data-level="5.5" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#qual-e-il-senso-dellintervallo-di-confidenza"><i class="fa fa-check"></i><b>5.5</b> Qual è il senso dell’intervallo di confidenza?</a></li>
<li class="chapter" data-level="5.6" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#come-presentare-i-risultati-degli-esperimenti"><i class="fa fa-check"></i><b>5.6</b> Come presentare i risultati degli esperimenti</a></li>
<li class="chapter" data-level="5.7" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#alcune-precisazioni"><i class="fa fa-check"></i><b>5.7</b> Alcune precisazioni</a><ul>
<li class="chapter" data-level="5.7.1" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#campioni-numerosi-e-non"><i class="fa fa-check"></i><b>5.7.1</b> Campioni numerosi e non</a></li>
<li class="chapter" data-level="5.7.2" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#popolazioni-gaussiane-e-non"><i class="fa fa-check"></i><b>5.7.2</b> Popolazioni gaussiane e non</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#analisi-statistica-dei-dati-riassunto-del-percorso-logico"><i class="fa fa-check"></i><b>5.8</b> Analisi statistica dei dati: riassunto del percorso logico</a></li>
<li class="chapter" data-level="5.9" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#da-ricordare"><i class="fa fa-check"></i><b>5.9</b> Da ricordare</a></li>
<li class="chapter" data-level="5.10" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#esercizi"><i class="fa fa-check"></i><b>5.10</b> Esercizi</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html"><i class="fa fa-check"></i><b>6</b> Breve introduzione al test d’ipotesi</a><ul>
<li class="chapter" data-level="6.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-una-media-osservata-e-una-media-teorica"><i class="fa fa-check"></i><b>6.1</b> Confronto tra una media osservata e una media teorica</a><ul>
<li class="chapter" data-level="6.1.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#simulazione-monte-carlo"><i class="fa fa-check"></i><b>6.1.1</b> Simulazione Monte Carlo</a></li>
<li class="chapter" data-level="6.1.2" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#soluzione-formale"><i class="fa fa-check"></i><b>6.1.2</b> Soluzione formale</a></li>
<li class="chapter" data-level="6.1.3" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#interpretazione-del-p-level"><i class="fa fa-check"></i><b>6.1.3</b> Interpretazione del P-level</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-medie-il-test-t-di-student"><i class="fa fa-check"></i><b>6.2</b> Confronto tra due medie: il test t di Student</a></li>
<li class="chapter" data-level="6.3" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-proporzioni-il-test-chi2"><i class="fa fa-check"></i><b>6.3</b> Confronto tra due proporzioni: il test <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="6.4" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#conclusioni-1"><i class="fa fa-check"></i><b>6.4</b> Conclusioni</a></li>
<li class="chapter" data-level="6.5" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#riepilogo"><i class="fa fa-check"></i><b>6.5</b> Riepilogo</a></li>
<li class="chapter" data-level="6.6" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#esercizi-1"><i class="fa fa-check"></i><b>6.6</b> Esercizi</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html"><i class="fa fa-check"></i><b>7</b> Una variabile indipendente categorica: ANOVA ad una via</a><ul>
<li class="chapter" data-level="7.1" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#la-situazione-sperimentale"><i class="fa fa-check"></i><b>7.1</b> La situazione sperimentale</a></li>
<li class="chapter" data-level="7.2" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#la-verita-vera-la-popolazione"><i class="fa fa-check"></i><b>7.2</b> La verità ‘vera’ (la popolazione)</a></li>
<li class="chapter" data-level="7.3" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#esecuzione-dellesperimento"><i class="fa fa-check"></i><b>7.3</b> Esecuzione dell’esperimento</a></li>
<li class="chapter" data-level="7.4" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#analisi-dei-dati"><i class="fa fa-check"></i><b>7.4</b> Analisi dei dati</a><ul>
<li class="chapter" data-level="7.4.1" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#statistiche-descrittive"><i class="fa fa-check"></i><b>7.4.1</b> Statistiche descrittive</a></li>
<li class="chapter" data-level="7.4.2" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#stima-dei-parametri"><i class="fa fa-check"></i><b>7.4.2</b> Stima dei parametri</a></li>
<li class="chapter" data-level="7.4.3" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#stima-della-varianza"><i class="fa fa-check"></i><b>7.4.3</b> Stima della varianza</a></li>
<li class="chapter" data-level="7.4.4" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#effetto-del-trattamento"><i class="fa fa-check"></i><b>7.4.4</b> Effetto del trattamento</a></li>
<li class="chapter" data-level="7.4.5" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#test-dipotesi"><i class="fa fa-check"></i><b>7.4.5</b> Test d’ipotesi</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#per-approfondimenti-1"><i class="fa fa-check"></i><b>7.5</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><i class="fa fa-check"></i><b>8</b> La verifica delle assunzioni di base: metodi diagnostici</a><ul>
<li class="chapter" data-level="8.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#introduzione-2"><i class="fa fa-check"></i><b>8.1</b> Introduzione</a></li>
<li class="chapter" data-level="8.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#procedure-diagnostiche"><i class="fa fa-check"></i><b>8.2</b> Procedure diagnostiche</a></li>
<li class="chapter" data-level="8.3" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#analisi-grafica-dei-residui"><i class="fa fa-check"></i><b>8.3</b> Analisi grafica dei residui</a><ul>
<li class="chapter" data-level="8.3.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#grafico-dei-residui-contro-i-valori-attesi"><i class="fa fa-check"></i><b>8.3.1</b> Grafico dei residui contro i valori attesi</a></li>
<li class="chapter" data-level="8.3.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#qq-plot"><i class="fa fa-check"></i><b>8.3.2</b> QQ-plot</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#altri-strumenti-diagnostici"><i class="fa fa-check"></i><b>8.4</b> Altri strumenti diagnostici</a></li>
<li class="chapter" data-level="8.5" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#risultati-contraddittori"><i class="fa fa-check"></i><b>8.5</b> Risultati contraddittori</a></li>
<li class="chapter" data-level="8.6" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#terapia"><i class="fa fa-check"></i><b>8.6</b> ‘Terapia’</a><ul>
<li class="chapter" data-level="8.6.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#correzionerimozione-degli-outliers"><i class="fa fa-check"></i><b>8.6.1</b> Correzione/Rimozione degli outliers</a></li>
<li class="chapter" data-level="8.6.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#correzione-del-modello"><i class="fa fa-check"></i><b>8.6.2</b> Correzione del modello</a></li>
<li class="chapter" data-level="8.6.3" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#non-normalita-dei-residui-ed-eterogeneita-delle-varianze"><i class="fa fa-check"></i><b>8.6.3</b> Non-normalità dei residui ed eterogeneità delle varianze</a></li>
<li class="chapter" data-level="8.6.4" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#la-procedura-di-box-e-cox"><i class="fa fa-check"></i><b>8.6.4</b> La procedura di Box e Cox</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#referenze-bibliografiche-per-approfondimenti"><i class="fa fa-check"></i><b>8.7</b> Referenze bibliografiche per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html"><i class="fa fa-check"></i><b>9</b> Modelli lineari con più variabili indipendenti</a><ul>
<li class="chapter" data-level="9.1" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html#introduzione-3"><i class="fa fa-check"></i><b>9.1</b> Introduzione</a></li>
<li class="chapter" data-level="9.2" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html#anova-a-blocchi-randomizzati"><i class="fa fa-check"></i><b>9.2</b> ANOVA a blocchi randomizzati</a></li>
<li class="chapter" data-level="9.3" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html#anova-a-quadrato-latino"><i class="fa fa-check"></i><b>9.3</b> ANOVA a quadrato latino</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html"><i class="fa fa-check"></i><b>10</b> Contrasti e confronti multipli con R</a><ul>
<li class="chapter" data-level="10.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#introduzione-4"><i class="fa fa-check"></i><b>10.1</b> Introduzione</a></li>
<li class="chapter" data-level="10.2" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#esempio"><i class="fa fa-check"></i><b>10.2</b> Esempio</a></li>
<li class="chapter" data-level="10.3" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-contrasti"><i class="fa fa-check"></i><b>10.3</b> I contrasti</a><ul>
<li class="chapter" data-level="10.3.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#varianza-del-contrasto-e-intervalli-di-confidenza"><i class="fa fa-check"></i><b>10.3.1</b> Varianza del contrasto e intervalli di confidenza</a></li>
<li class="chapter" data-level="10.3.2" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#significativita-del-contrasto-e-intervalli-di-confidenza"><i class="fa fa-check"></i><b>10.3.2</b> Significatività del contrasto e intervalli di confidenza</a></li>
<li class="chapter" data-level="10.3.3" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-contrasti-con-r"><i class="fa fa-check"></i><b>10.3.3</b> I contrasti con R</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-confronti-multipli-a-coppie-pairwise-comparisons"><i class="fa fa-check"></i><b>10.4</b> I confronti multipli a coppie (pairwise comparisons)</a></li>
<li class="chapter" data-level="10.5" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#display-a-lettere"><i class="fa fa-check"></i><b>10.5</b> Display a lettere</a></li>
<li class="chapter" data-level="10.6" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#problemi-di-molteplicita-tassi-di-errore-per-confronto-e-per-esperimento"><i class="fa fa-check"></i><b>10.6</b> Problemi di molteplicità: tassi di errore per confronto e per esperimento</a><ul>
<li class="chapter" data-level="10.6.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#correzione-per-la-molteplicita"><i class="fa fa-check"></i><b>10.6.1</b> Correzione per la molteplicità</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#intervalli-di-confidenza-simultanei"><i class="fa fa-check"></i><b>10.7</b> Intervalli di confidenza simultanei</a></li>
<li class="chapter" data-level="10.8" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#e-le-classiche-procedure-di-confronto-multiplo"><i class="fa fa-check"></i><b>10.8</b> E le classiche procedure di confronto multiplo?</a></li>
<li class="chapter" data-level="10.9" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#consigli-pratici"><i class="fa fa-check"></i><b>10.9</b> Consigli pratici</a></li>
<li class="chapter" data-level="10.10" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#referenze-bibliografiche"><i class="fa fa-check"></i><b>10.10</b> Referenze bibliografiche</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html"><i class="fa fa-check"></i><b>11</b> Analisi della varianza (ANOVA) a due vie</a><ul>
<li class="chapter" data-level="11.1" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#il-concetto-di-interazione"><i class="fa fa-check"></i><b>11.1</b> Il concetto di ’interazione’</a></li>
<li class="chapter" data-level="11.2" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#tipi-di-interazione"><i class="fa fa-check"></i><b>11.2</b> Tipi di interazione</a></li>
<li class="chapter" data-level="11.3" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#descrizione-del-caso-studio"><i class="fa fa-check"></i><b>11.3</b> Descrizione del caso studio</a></li>
<li class="chapter" data-level="11.4" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#analisi-dei-dati-1"><i class="fa fa-check"></i><b>11.4</b> Analisi dei dati</a></li>
<li class="chapter" data-level="11.5" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#stima-dei-parametri-1"><i class="fa fa-check"></i><b>11.5</b> Stima dei parametri</a></li>
<li class="chapter" data-level="11.6" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#verifica-delle-assunzioni-di-base"><i class="fa fa-check"></i><b>11.6</b> Verifica delle assunzioni di base</a></li>
<li class="chapter" data-level="11.7" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#scomposizione-delle-varianze"><i class="fa fa-check"></i><b>11.7</b> Scomposizione delle varianze</a></li>
<li class="chapter" data-level="11.8" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#funzioni-dei-parametri"><i class="fa fa-check"></i><b>11.8</b> Funzioni dei parametri</a><ul>
<li class="chapter" data-level="11.8.1" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#medie-delle-combinazioni-lavorazioni-x-diserbo"><i class="fa fa-check"></i><b>11.8.1</b> Medie delle combinazioni ‘lavorazioni x diserbo’</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#calcolo-degli-errori-standard-sem-e-sed"><i class="fa fa-check"></i><b>11.9</b> Calcolo degli errori standard (SEM e SED)</a></li>
<li class="chapter" data-level="11.10" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#contrasti-medie-attese-e-confronti-multipli-con-r"><i class="fa fa-check"></i><b>11.10</b> Contrasti, medie attese e confronti multipli con R</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html"><i class="fa fa-check"></i><b>12</b> La regressione lineare semplice</a><ul>
<li class="chapter" data-level="12.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#introduzione-5"><i class="fa fa-check"></i><b>12.1</b> Introduzione</a></li>
<li class="chapter" data-level="12.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#esempio-6"><i class="fa fa-check"></i><b>12.2</b> Esempio</a></li>
<li class="chapter" data-level="12.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#stima-dei-parametri-2"><i class="fa fa-check"></i><b>12.3</b> Stima dei parametri</a></li>
<li class="chapter" data-level="12.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-della-bonta-del-modello"><i class="fa fa-check"></i><b>12.4</b> Valutazione della bontà del modello</a><ul>
<li class="chapter" data-level="12.4.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-grafica"><i class="fa fa-check"></i><b>12.4.1</b> Valutazione grafica</a></li>
<li class="chapter" data-level="12.4.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#errori-standard-dei-parametri"><i class="fa fa-check"></i><b>12.4.2</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="12.4.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-mancanza-dadattamento"><i class="fa fa-check"></i><b>12.4.3</b> Test F per la mancanza d’adattamento</a></li>
<li class="chapter" data-level="12.4.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-bonta-di-adattamento-e-coefficiente-di-determinazione"><i class="fa fa-check"></i><b>12.4.4</b> Test F per la bontà di adattamento e coefficiente di determinazione</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#previsioni"><i class="fa fa-check"></i><b>12.5</b> Previsioni</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html"><i class="fa fa-check"></i><b>13</b> La regressione non-lineare</a><ul>
<li class="chapter" data-level="13.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#introduzione-6"><i class="fa fa-check"></i><b>13.1</b> Introduzione</a></li>
<li class="chapter" data-level="13.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-1-2"><i class="fa fa-check"></i><b>13.2</b> Esempio 1</a><ul>
<li class="chapter" data-level="13.2.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#scelta-della-funzione"><i class="fa fa-check"></i><b>13.2.1</b> Scelta della funzione</a></li>
<li class="chapter" data-level="13.2.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#stima-dei-parametri-3"><i class="fa fa-check"></i><b>13.2.2</b> Stima dei parametri</a></li>
<li class="chapter" data-level="13.2.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#la-regressione-non-lineare-con-r"><i class="fa fa-check"></i><b>13.2.3</b> La regressione non-lineare con R</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#riparametrizzazione-delle-funzioni"><i class="fa fa-check"></i><b>13.3</b> Riparametrizzazione delle funzioni</a><ul>
<li class="chapter" data-level="13.3.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-2-2"><i class="fa fa-check"></i><b>13.3.1</b> Esempio 2</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#inferenze-statistiche-e-verifiche-delle-assunzioni-di-base"><i class="fa fa-check"></i><b>13.4</b> Inferenze statistiche e verifiche delle assunzioni di base</a><ul>
<li class="chapter" data-level="13.4.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#analisi-grafica-dei-residui-1"><i class="fa fa-check"></i><b>13.4.1</b> Analisi grafica dei residui</a></li>
<li class="chapter" data-level="13.4.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#test-f-per-la-mancanza-di-adattamento-approssimato"><i class="fa fa-check"></i><b>13.4.2</b> Test F per la mancanza di adattamento (approssimato)</a></li>
<li class="chapter" data-level="13.4.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#errori-standard-dei-parametri-1"><i class="fa fa-check"></i><b>13.4.3</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="13.4.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#coefficiente-di-determinazione"><i class="fa fa-check"></i><b>13.4.4</b> Coefficiente di determinazione</a></li>
<li class="chapter" data-level="13.4.5" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#coefficiente-di-determinazione-aggiustato"><i class="fa fa-check"></i><b>13.4.5</b> Coefficiente di determinazione aggiustato</a></li>
<li class="chapter" data-level="13.4.6" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#altre-statistiche"><i class="fa fa-check"></i><b>13.4.6</b> Altre statistiche</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#gestione-delle-situazioni-patologiche"><i class="fa fa-check"></i><b>13.5</b> Gestione delle situazioni ‘patologiche’</a><ul>
<li class="chapter" data-level="13.5.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-del-modello"><i class="fa fa-check"></i><b>13.5.1</b> Trasformazione del modello</a></li>
<li class="chapter" data-level="13.5.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-dei-dati"><i class="fa fa-check"></i><b>13.5.2</b> Trasformazione dei dati</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#funzioni-lineari-e-nonlineari-dei-parametri"><i class="fa fa-check"></i><b>13.6</b> Funzioni lineari e nonlineari dei parametri</a></li>
<li class="chapter" data-level="13.7" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#modelli-ancova"><i class="fa fa-check"></i><b>13.7</b> Modelli ANCOVA</a><ul>
<li class="chapter" data-level="13.7.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-3-2"><i class="fa fa-check"></i><b>13.7.1</b> Esempio 3</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#confronto-tra-modelli-alternativi"><i class="fa fa-check"></i><b>13.8</b> Confronto tra modelli alternativi</a><ul>
<li class="chapter" data-level="13.8.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#confronto-tra-modelli-non-nested"><i class="fa fa-check"></i><b>13.8.1</b> Confronto tra modelli non-nested</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#il-package-drc"><i class="fa fa-check"></i><b>13.9</b> Il package ‘drc’</a></li>
<li class="chapter" data-level="13.10" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#previsioni-1"><i class="fa fa-check"></i><b>13.10</b> Previsioni</a></li>
<li class="chapter" data-level="13.11" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#bibliografia"><i class="fa fa-check"></i><b>13.11</b> Bibliografia</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html"><i class="fa fa-check"></i>Appendix 1: breve introduzione ad R</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#cosa-e-r"><i class="fa fa-check"></i>Cosa è R?</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#oggetti-e-assegnazioni"><i class="fa fa-check"></i>Oggetti e assegnazioni</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#costanti-e-vettori"><i class="fa fa-check"></i>Costanti e vettori</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#matrici"><i class="fa fa-check"></i>Matrici</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#operazioni-ed-operatori"><i class="fa fa-check"></i>Operazioni ed operatori</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#funzioni-ed-argomenti"><i class="fa fa-check"></i>Funzioni ed argomenti</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#dataframe"><i class="fa fa-check"></i>Dataframe</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#quale-oggetto-sto-utilizzando"><i class="fa fa-check"></i>Quale oggetto sto utilizzando?</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#consigli-per-limmissione-di-dati-sperimentali"><i class="fa fa-check"></i>Consigli per l’immissione di dati sperimentali</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#immissione-manuale-di-dati"><i class="fa fa-check"></i>Immissione manuale di dati</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#immissione-di-numeri-progressivi"><i class="fa fa-check"></i>Immissione di numeri progressivi</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#immissione-dei-codici-delle-tesi-e-dei-blocchi"><i class="fa fa-check"></i>Immissione dei codici delle tesi e dei blocchi</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#leggere-e-salvare-dati-esterni"><i class="fa fa-check"></i>Leggere e salvare dati esterni</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#alcune-operazioni-comuni-sul-dataset"><i class="fa fa-check"></i>Alcune operazioni comuni sul dataset</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#selezionare-un-subset-di-dati"><i class="fa fa-check"></i>Selezionare un subset di dati</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#ordinare-un-vettore-o-un-dataframe"><i class="fa fa-check"></i>Ordinare un vettore o un dataframe</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#workspace"><i class="fa fa-check"></i>Workspace</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#script-o-programmi"><i class="fa fa-check"></i>Script o programmi</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#interrogazione-di-oggetti"><i class="fa fa-check"></i>Interrogazione di oggetti</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#altre-funzioni-matriciali"><i class="fa fa-check"></i>Altre funzioni matriciali</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#cenni-sulle-funzionalita-grafiche-in-r"><i class="fa fa-check"></i>Cenni sulle funzionalità grafiche in R</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#per-approfondimenti-2"><i class="fa fa-check"></i>Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html"><i class="fa fa-check"></i>Appendix 2: richiami di statistica descrittiva</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#le-variabili-quantitative-analisi-chimiche-e-altre-misurazioni-fondamentali"><i class="fa fa-check"></i>Le variabili quantitative: analisi chimiche e altre misurazioni fondamentali</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#indicatori-di-tendenza-centrale"><i class="fa fa-check"></i>Indicatori di tendenza centrale</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#indicatori-di-variabilita"><i class="fa fa-check"></i>Indicatori di variabilità</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#arrotondamenti"><i class="fa fa-check"></i>Arrotondamenti</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#descrizione-dei-sottogruppi"><i class="fa fa-check"></i>Descrizione dei sottogruppi</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#distribuzioni-di-frequenza-e-classamento"><i class="fa fa-check"></i>Distribuzioni di frequenza e classamento</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#statistiche-descrittive-per-le-distribuzioni-di-frequenza"><i class="fa fa-check"></i>Statistiche descrittive per le distribuzioni di frequenza</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#distribuzioni-di-frequenza-bivariate-le-tabelle-di-contingenza"><i class="fa fa-check"></i>Distribuzioni di frequenza bivariate: le tabelle di contingenza</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#connessione"><i class="fa fa-check"></i>Connessione</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#correlazione"><i class="fa fa-check"></i>Correlazione</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#esercizi-2"><i class="fa fa-check"></i>Esercizi</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#esercizio-1-1"><i class="fa fa-check"></i>Esercizio 1</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#esercizio-2-1"><i class="fa fa-check"></i>Esercizio 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html"><i class="fa fa-check"></i><b>14</b> Appendix 3: Per chi vuole approfondire un po’…</a><ul>
<li class="chapter" data-level="14.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-4-modelli-matematici-a-due-facce"><i class="fa fa-check"></i><b>14.1</b> Capitolo 4: Modelli matematici a ‘due facce’</a><ul>
<li class="chapter" data-level="14.1.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#la-distribuzione-t-di-student"><i class="fa fa-check"></i><b>14.1.1</b> La distribuzione t di Student</a></li>
<li class="chapter" data-level="14.1.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#la-distribuzione-f-di-fisher"><i class="fa fa-check"></i><b>14.1.2</b> La distribuzione F di Fisher</a></li>
<li class="chapter" data-level="14.1.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#la-distribuzione-binomiale"><i class="fa fa-check"></i><b>14.1.3</b> La distribuzione binomiale</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-5-esperimenti-stime-ed-incertezza"><i class="fa fa-check"></i><b>14.2</b> Capitolo 5: Esperimenti stime ed incertezza</a><ul>
<li class="chapter" data-level="14.2.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#e-realistico-lintervallo-di-confidenza"><i class="fa fa-check"></i><b>14.2.1</b> E’ realistico l’intervallo di confidenza?</a></li>
<li class="chapter" data-level="14.2.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#che-cosa-non-significa-lintervallo-di-confidenza"><i class="fa fa-check"></i><b>14.2.2</b> Che cosa NON significa l’intervallo di confidenza?</a></li>
<li class="chapter" data-level="14.2.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#popolazioni-non-gaussiane"><i class="fa fa-check"></i><b>14.2.3</b> Popolazioni non gaussiane</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-6.-introduzione-al-test-dipotesi"><i class="fa fa-check"></i><b>14.3</b> Capitolo 6. Introduzione al test d’ipotesi</a><ul>
<li class="chapter" data-level="14.3.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#simulazione-monte-carlo-di-un-test-t-di-student"><i class="fa fa-check"></i><b>14.3.1</b> Simulazione Monte Carlo di un test t di Student</a></li>
<li class="chapter" data-level="14.3.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#tipologie-alternative-di-test-t-di-student"><i class="fa fa-check"></i><b>14.3.2</b> Tipologie alternative di test t di Student</a></li>
<li class="chapter" data-level="14.3.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#simulazione-di-un-test-di-chi-quadro"><i class="fa fa-check"></i><b>14.3.3</b> Simulazione di un test di chi quadro</a></li>
<li class="chapter" data-level="14.3.4" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#errori-di-prima-e-di-seconda-specie"><i class="fa fa-check"></i><b>14.3.4</b> Errori di prima e di seconda specie</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Metodologia statistica per le scienze agrarie</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendix-3-per-chi-vuole-approfondire-un-po" class="section level1">
<h1><span class="header-section-number">Capitolo 14</span> Appendix 3: Per chi vuole approfondire un po’…</h1>
<p>[Intro da fare]</p>
<div id="capitolo-4-modelli-matematici-a-due-facce" class="section level2">
<h2><span class="header-section-number">14.1</span> Capitolo 4: Modelli matematici a ‘due facce’</h2>
<div id="la-distribuzione-t-di-student" class="section level3">
<h3><span class="header-section-number">14.1.1</span> La distribuzione t di Student</h3>
<p>La distribuzione t di Student è analoga per forma ad una distribuzione normale con media 0 e deviazione standard 1. Rispetto a questa, la dispersione è un po’ più ampia, nel senso la probabilità di avere valori lontani dalla media è più alta. In realtà, non esiste una sola distribuzione t di Student, ma ne esistono molte, caratterizzate da un diverso numero di gradi di libertà (<span class="math inline">\(\nu\)</span>); maggiore è <span class="math inline">\(\nu\)</span>, minore la sovradispersione; se il numero di gradi di libertà è infinito, la distribuzione t di Student è identica alla normale standardizzata (distribuzione normale con media 0 e deviazione standard uguale ad 1).</p>
<p>Per verificare l’entità della sovradispersione, proviamo a disegnare su un grafico una curva normale standardizzata ed una serie di curve di t, con 2, 6 e 24 gradi di libertà.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x),<span class="op">-</span><span class="dv">3</span>, <span class="op">+</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;Black&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Densità&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">2</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">6</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">24</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-221-1.png" /><!-- --></p>
</div>
<div id="la-distribuzione-f-di-fisher" class="section level3">
<h3><span class="header-section-number">14.1.2</span> La distribuzione F di Fisher</h3>
<p>La distribuzione F di Fisher è definita solo per valori positivi ed è fortemente asimmetrica. Anche in questo caso, abbiamo una famiglia di distribuzioni, che differiscono tra di loro per due parametri (gradi di libertà) <span class="math inline">\(\nu_1\)</span> e <span class="math inline">\(\nu_2\)</span>. Solitamente questa distribuzione viene utilizzata per descrivere il rapporto tra le varianze di coppie di campioni estratti da un distribuzione normale standardizzata, per cui <span class="math inline">\(\nu_1\)</span> e <span class="math inline">\(\nu_2\)</span> sono i gradi di libertà del numeratore e del denominatore.</p>
<p>Col codice che segue, possiamo disegnare la distribuzione di F con <span class="math inline">\(\nu_1 = \nu_2 = 3\)</span> e possiamo calcolare la probabilità di estrarre da questa distribuzione un valore pari o superiore a 5. Inoltre, calcoliamo anche il 95° percentile, utilizzando le apposite funzioni in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">df</span>(x, <span class="dv">3</span>, <span class="dv">3</span>), <span class="dv">0</span>, <span class="op">+</span><span class="dv">3</span>,<span class="dt">col=</span><span class="st">&quot;Black&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Densità&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-222-1.png" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>(<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dt">lower.tail =</span> F)
## [1] 0.890449
<span class="kw">qf</span>(<span class="fl">0.95</span>, <span class="dv">3</span>, <span class="dv">3</span>)
## [1] 9.276628</code></pre></div>
</div>
<div id="la-distribuzione-binomiale" class="section level3">
<h3><span class="header-section-number">14.1.3</span> La distribuzione binomiale</h3>
<p>Ogni esperimento per il quale ci sono solo due esiti possibili (successo ed insuccesso) e una certa probabilità di successo, viene detto <strong>esperimento Bernoulliano</strong>. Il tipico esempio è il lancio della moneta, nel quale possiamo ottenere solo testa o croce, con una probabilità di 0.5 (se la moneta non è truccata). In alcuni casi, potremmo avere una serie di esperimenti Bernoulliani indipendenti, con probabilità di successo costante (ad esempio, lanciare la moneta 10 volte) e potremmo essere interessati a conoscere la probabilità di ottenere <em>k</em> successi su <em>n</em> prove. Questa probabilità può essere descritta attraverso la <strong>funzione di probabilità binomiale</strong>.</p>
<p>Poniamo di sapere che in una Facoltà di Agraria con un numero molto elevato di studenti il rapporto tra maschi e femmine sia pari a 0.7 e quindi che la probabilità di incontrare un maschio sia pari a <span class="math inline">\(p = 0.7\)</span> (evento semplice). Deve essere estratto a sorte un viaggio studio per quattro studenti e, per una questione di pari opportunità, si preferirebbe che fossero premiati in ugual misura maschi e femmine (cioè si vogliono premiare due femmine). Qual è la probabilità che un simile evento si realizzi?</p>
<p>La probabilità cercata si può ottenere pensando che abbiamo un evento “estrazione” che può dare due risultati possibili (maschio o femmina) e che deve essere ripetuto quattro volte. Se consideriamo “successo” estrarre una femmina, allora la probabilità di successo in ogni estrazione è <span class="math inline">\(p = 0.3\)</span> mentre quella di insuccesso (evento complementare) è pari a <span class="math inline">\(1 - p = q = 0.7\)</span>. Facciamo attenzione! Quanto abbiamo detto è vero solo se la popolazione è sufficientemente numerosa da pensare che la singola estrazione non cambia la probabilità degli eventi nelle successive (eventi indipendenti). La probabilità che su quattro estrazioni si abbiano 2 successi (due femmine) e due insuccessi (due maschi) è data da (teorema della probabilità composta):</p>
<p><span class="math display">\[0.3 \cdot 0.3 \cdot 0.7 \cdot 0.7 = 0.3^2 \cdot 0.7^2\]</span></p>
<p>In generale, data una popolazione molto numerosa, nella quale gli individui si presentano con due modalità possibili (in questo caso maschio e femmina) e posto di sapere che la frequenza con cui si presenta la prima modalità è pari a <span class="math inline">\(p\)</span> (in questo caso la frequenza delle femmine è pari a 0.3), mentre la frequenza della seconda modalità è pari a <span class="math inline">\(q = 1 - p\)</span>, se vogliamo estrarre da questa popolazione <span class="math inline">\(n\)</span> elementi, la probabilità che <span class="math inline">\(k\)</span> di questi presentino la prima modalità (successo) è data da:</p>
<p><span class="math display">\[p^k \cdot q^{(n-k)}\]</span></p>
<p>La formula di cui sopra, tuttavia, non risolve il nostro problema, in quanto noi vogliamo che vengano estratte due femmine, indipendentemente dall’ordine con cui esse vengono estratte (prima, seconda, terza o quarta estrazione), mentre la probabilità che abbiamo appena calcolato è quella relativa all’evento in cui le due femmine sono estratte al primo e secondo posto.</p>
<p>Di conseguenza (teorema della probabilità totale) alla probabilità dell’evento indicato in precedenza (estrazione di due femmine in prima e seconda posizione) dobbiamo sommare la probabilità di tutti gli altri eventi utili (due femmine in seconda e terza posizione, oppure in terza e seconda, oppure in terza e quarta e così via). Il numero delle combinazioni possibili per 2 femmine in quattro estrazioni (combinazione di 4 elementi di classe 2) è dato dal coefficiente binomiale:</p>
<p><span class="math display">\[\left( {\begin{array}{*{20}c}
n  \\
k  \\
\end{array}} \right) = \frac{n!}{(n - k)!k!} \]</span></p>
<p>Moltiplicando le due equazioni date in precedenza otteniamo la funzione di probabilità binomiale:</p>
<p><span class="math display">\[P(X = x_i ) = \frac{{n!}}{{(n - k)!k!}} \cdot p^k \cdot q^{(n - k)} \]</span></p>
<p>Nel caso specifico otteniamo il risultato:</p>
<p><span class="math display">\[P(X = 2) = \frac{4!}{(4 - 2)!2!} \cdot 0.3^2 \cdot 0.7^{(4 - 2)}  = 0.2646 \]</span></p>
<p>che è appunto la probabilità cercata.</p>
<p>In R, utilizziamo la funzione ‘dbinom(successi, prove, probabilità semplice)’ per calcolare la probabilità di ottenere <span class="math inline">\(k\)</span> successi in <span class="math inline">\(n\)</span> prove:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="fl">0.3</span>)
## [1] 0.2646</code></pre></div>
<p>La funzione binomiale è un modello stocastico e si può dimostrare che il valore atteso (media) è uguale ad <span class="math inline">\(n\cdot p\)</span>, mentre la varianza è pari a <span class="math inline">\(n\cdot p \cdot q\)</span>:</p>
<p>La funzione di ripartizione (probabilità cumulata) si calcola in R con la funzione ‘pbinom(successi, prove, probabilità semplice)’. Nell’esempio, se vogliamo sapere la probabilità totale di estrarre meno di tre femmine (2 femmine o meno), possiamo operare in questo modo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pbinom</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
## [1] 0.9163</code></pre></div>
<p>Che risulta anche dalla somma della probabilità di estrarre 0, 1, 2 femmine:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">zero &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
uno &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
due &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
zero <span class="op">+</span><span class="st"> </span>uno <span class="op">+</span><span class="st"> </span>due
## [1] 0.9163</code></pre></div>
<p>La funzione di ripartizione può anche essere utilizzata al contrario, per determinare i quantili, cioè il numero di successi che corrispondono ad una probabilità cumulata pari ad alfa:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qbinom</span>(<span class="fl">0.9163</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
## [1] 2</code></pre></div>
<div id="esercizio" class="section level4">
<h4><span class="header-section-number">14.1.3.1</span> Esercizio</h4>
<p>Da una popolazione di insetti che ha un rapporto tra maschi e femmine pari a 0.5, qual è la probabilità di campionare casualmente 2 maschi e 8 femmine?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.5</span>)
## [1] 0.04394531</code></pre></div>
</div>
<div id="esercizio-8" class="section level4">
<h4><span class="header-section-number">14.1.3.2</span> Esercizio</h4>
<p>Riportare su un grafico la funzione di ripartizione binomiale, per p=0.5 e n=5. Costruire anche la densità di frequenza, utilizzando le opportune funzioni R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prob &lt;-<span class="st"> </span><span class="fl">0.5</span>
n &lt;-<span class="st"> </span><span class="dv">5</span>
<span class="kw">barplot</span>(<span class="kw">dbinom</span>(<span class="kw">seq</span>(<span class="dv">0</span>, n, <span class="dt">by=</span><span class="dv">1</span>), <span class="dt">size=</span>n, <span class="dt">prob=</span>prob),
          <span class="dt">xlab=</span><span class="st">&quot;Successi&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Probabilità&quot;</span>,
          <span class="dt">names.arg=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName53"></span>
<img src="_main_files/figure-html/figName53-1.png" alt="Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)" width="90%" />
<p class="caption">
Figure 14.1: Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">barplot</span>(<span class="kw">pbinom</span>(<span class="kw">seq</span>(<span class="dv">0</span>, n, <span class="dt">by=</span><span class="dv">1</span>), <span class="dt">size=</span>n, <span class="dt">prob=</span>prob),
          <span class="dt">xlab=</span><span class="st">&quot;Successi&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Probabilità&quot;</span>,
          <span class="dt">names.arg=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName53"></span>
<img src="_main_files/figure-html/figName53-2.png" alt="Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)" width="90%" />
<p class="caption">
Figure 14.1: Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)
</p>
</div>
<p>Allo stesso modo possiamo immaginare di estrarre 20 insetti a caso da una popolazione in cui il rapporto tra i sessi è 1:1. Questo esperimento può essere simulato con:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">prob =</span> <span class="fl">0.5</span>)
Y
## [1] 10</code></pre></div>
<p>Assumendo che il ‘successo’ sia ottenere una femmina, il computer ci restituisce il numero delle femmine.</p>
</div>
</div>
</div>
<div id="capitolo-5-esperimenti-stime-ed-incertezza" class="section level2">
<h2><span class="header-section-number">14.2</span> Capitolo 5: Esperimenti stime ed incertezza</h2>
<div id="e-realistico-lintervallo-di-confidenza" class="section level3">
<h3><span class="header-section-number">14.2.1</span> E’ realistico l’intervallo di confidenza?</h3>
<p>Abbiamo visto che un metodo semplice per costruire un intervallo di confidenza è utilizzare il doppio dell’errore standard. Questo intervallo, se viene utilizzato come misura di precisione/incertezza, è sempre accettabile. Tuttavia, da un punto di vista strettamente probabilistico, è lecito chiedersi: ma è proprio vero che se io ripeto l’esperimento molte volte e calcolo sempre l’intervallo di confidenza, riesco a centrare la media <span class="math inline">\(\mu\)</span> nel 95% dei casi?</p>
<p>Proviamo a rispondere a questa domanda con una simulazione Monte Carlo. Prendiamo la nostra popolazione (<span class="math inline">\(\mu = 120\)</span> e <span class="math inline">\(\sigma = 12\)</span>) ed estraiamo centomila campioni. Per ogni campione calcoliamo l’intervallo di confidenza della media (P = 0.95) considerando il doppio dell’errore standard. Verifichiamo poi se questo intervallo contiene il valore 120: se si, assegniamo al campionamento il valore 1 (successo), altrimenti assegniamo il valore 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">-</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="dv">2</span>
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.81656</code></pre></div>
<p>La simulazione mostra che la risposta alla domanda precedente è no: il nostro intervallo di confidenza non è riuscito a centrare la media nel 95% dei casi; ciò è avvenuto in poco più dell’80% dei casi. In realtà, possiamo facilmente verificare, con altre simulazioni di Monte Carlo, che la copertura effettiva dell’intervallo di confidenza si avvicina al 95% solo se abbiamo un numero di repliche superiori a 15-20 circa.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  n &lt;-<span class="st"> </span><span class="dv">15</span>
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">-</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span>
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.93591</code></pre></div>
<p>Insomma, quando gli esperimenti sono piccoli, con poche repliche, dovremmo trovare un metodo di calcolo un po’ più affidabile, se veramente vogliamo ottenere un grado di copertura pari a quello nominale (P = 0.95).</p>
<p>Il problema nasce dal fatto che, nella statistica T che abbiamo introdotto nel capitolo 5:</p>
<p><span class="math display">\[T = \frac{m - \mu}{\sigma_m}\]</span> <span class="math inline">\(\sigma_m\)</span> viene sostituito con <span class="math inline">\(s_m\)</span>, cioè il valore di deviazione standard stimato nel campione. Come tutte le stime, anche <span class="math inline">\(s\)</span> è ’soggetto ad incertezza, il che aggiunge un elemento ulteriore di imprecisione nella sampling distribution di T. Insomma ci chiediamo, la <em>sampling distribution</em> di T, calcolata con <span class="math inline">\(s\)</span> invece che <span class="math inline">\(\sigma\)</span> è ancora normale? Verifichiamo questo aspetto empiricamente, con una nuova simulazione Monte Carlo. Questa volta facciamo la seguente operazione:</p>
<ol style="list-style-type: decimal">
<li>campioniamo tre individui</li>
<li>Calcoliamo il valore di T con la statistica precedente, utilizzando la deviazione standard del campione e lo salviamo</li>
<li>Con un po’ di pazienza, ripetiamo il tutto 100’000 volte.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#SIMULAZIONE MONTE CARLO - t di Student</span>
<span class="kw">set.seed</span>(<span class="dv">435</span>)
result &lt;-<span class="st"> </span><span class="kw">c</span>()
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample3 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  T &lt;-<span class="st"> </span>(<span class="kw">mean</span>(sample3) <span class="op">-</span><span class="st"> </span><span class="dv">120</span>) <span class="op">/</span><span class="st"> </span>(<span class="kw">sd</span>(sample3)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>))
  result[i] &lt;-<span class="st"> </span>T
  }</code></pre></div>
<p>Se riportiamo i valori ottenuti su una distribuzione di frequenze otteniamo il grafico sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Plot sampling distribution</span>
b &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">600</span>, <span class="dv">600</span>, <span class="dt">by=</span><span class="fl">0.2</span>)
<span class="kw">hist</span>(result, <span class="dt">breaks =</span> b, <span class="dt">freq=</span>F, <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(m)), <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.4</span>), <span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">2</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-232-1.png" /><!-- --></p>
<p>Vediamo che la <em>sampling distribution</em> di T calcolato utilizzando <span class="math inline">\(s\)</span> invece che <span class="math inline">\(\sigma\)</span> è solo approssimativamente normale. E’ facile vedere che questa approssimazione è sufficientemente buona solo se la numerosità del campione diviene abbastanza grande (es. <span class="math inline">\(n &gt; 30)\)</span>, ma non certamente quando <span class="math inline">\(n\)</span> = 3 (ve lo lascio per esercizio). In questo caso, la sampling distribution che osserviamo è più ‘dispersa’ di quella normale, con un maggior numero di valori sulle code.</p>
<p>Neyman scoprì che la sampling distribution di T poteva essere perfettamente descritta utilizzando la distribuzione t di Student, con un numero di gradi di libertà pari a quelli del campione (in questo caso 2), come vediamo nella figura sovrastante. In realtà questa conclusione era stata già raggiunta da William Sealy Gosset (1876 - 1937), uno statistico impiegato presso la fabbrica londinese della famosa birra Guinness, dove elaborava i dati relativi all’andamento del processo di maltazione. Egli, avendo definito questa nuova funzione di densità, per aggirare il divieto di pubblicazione imposto dal suo datore di lavoro, pubblicò i risultati sotto lo pseudonimo Student, da cui deriva il nome della distribuzione di densità.</p>
<p>Quindi, quando i campioni sono piccoli, il modo giusto di calcolare l’intervallo di confidenza è quello di utilizzare l’espressione seguente:</p>
<p><span class="math display">\[P \left( m + \textrm{qt}(0.025,n - 1) \cdot s_m \le \mu  \le m + \textrm{qt}(0.975,n - 1) \cdot s_m \right) = 0.95\]</span></p>
<p>dove <span class="math inline">\(\textrm{qt}(0.025,n - 1)\)</span> e <span class="math inline">\(\textrm{qt}(0.975,n - 1)\)</span> sono rispettivamente il 2.5-esimo e il 97.5-esimo percentile della distribuzione t di Student, con n-1 gradi di libertà.</p>
<p>Nel capitolo 5 abbiamo utilizzato un esempio in cui abbiamo eseguito tre analisi chimiche da una soluzione erbicida di concentrazione pari a 120 mg/l, con uno strumento caratterizzato da un coefficiente di variabilità del 10%, che quindi, in assenza di errori sistematici, produce misure distribuite normalmente con media uguale a 120 e deviazione standard uguale a 12. Il campione osservato era</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
Y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
Y
## [1] 125.1584 114.7349 105.6998</code></pre></div>
<p>le statistiche descrittive sono:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">mean</span>(Y)
s &lt;-<span class="st"> </span><span class="kw">sd</span>(Y)
m; s
## [1] 115.1977
## [1] 9.737554</code></pre></div>
<p>I valori della distribuzione t di Student che lasciano al loro esterno il 5% delle varianti (2.5% per coda) sono:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>)
## [1] -4.302653
<span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>)
## [1] 4.302653</code></pre></div>
<p>Gli intervalli di confidenza sono pertanto:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>s<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>)
## [1] 91.00824
m <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>s<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>)
## [1] 139.3871</code></pre></div>
<p>E’ facile osservare che, se l’intervallo di confidenza è calcolato in questo modo, il suo <em>coverage</em><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> Operiamo con una simulazione Monte Carlo analoga a quella utilizzata nel capitolo 5.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>) 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>) 
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.94992</code></pre></div>
<p>Ovviamente possiamo calcolare anche gli intervalli di confidenza al 99% di proababilità o qualunque altro intervallo di confidenza rilevante per il nostro studio.</p>
</div>
<div id="che-cosa-non-significa-lintervallo-di-confidenza" class="section level3">
<h3><span class="header-section-number">14.2.2</span> Che cosa NON significa l’intervallo di confidenza?</h3>
<p>Abbiamo già detto che l’intervallo di confidenza, calcolato su una serie di campionamenti ripetuti, contiene al suo interno la media vera e ignota della popolazione (<span class="math inline">\(\mu\)</span>) con una probabilità pari a 0.95.</p>
<p>Tuttavia, la formula di Neyman si presta a cattive letture, che sono insensate da un punto di vista probabilistico, ma tuttavia molto frequenti nella pratica operativa. Ad esempio:</p>
<ol style="list-style-type: decimal">
<li><strong>NON E’ VERO CHE:</strong> c’è il 95% di probabilità che la media ‘vera’ della popolazione si trovi tra 91.0082383 e 139.3870891. La media vera della popolazione è sempre fissa e pari a 120 e non cambia affatto tra un campionamento e l’altro.</li>
<li><strong>NON E’ VERO CHE:</strong> ripetendo l’esperimento, il 95% delle stime che otteniamo cadono nell’intervallo 91.0082383 e 139.3870891. Una semplice simulazione mostra che quasi tutte le medie campionate cadono in quell’intervallo:</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  <span class="cf">if</span> (<span class="kw">mean</span>(sample) <span class="op">&lt;=</span><span class="st"> </span><span class="fl">156.15</span> <span class="op">&amp;</span><span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">&gt;=</span><span class="st"> </span><span class="fl">92.13</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.99996</code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>NON E’ VERO CHE:</strong> c’è il 95% di probabilità che l’affermazione ’la media vera è compresa tra 91.0082383 e 139.3870891 sia vera. Nelle normali condizioni sperimentali la media vera è ignota e non sapremo mai nulla su di essa: il nostro intervallo di confidenza può catturarla o no. Nel nostro esempio lo ha fatto, ed è tutto quello che possiamo dire.</li>
</ol>
<p>Insomma, l’intervallo di confidenza vale per la sampling distribution e non vale per ogni singolo campionamento (esperimento). Pertanto, affermazioni del tipo: ”c’è il 95% di probabilità che <span class="math inline">\(\mu\)</span> è compreso nell’intervallo di confidenza” oppure ”il valor più probabile di <span class="math inline">\(\mu\)</span> è…” non sono corrette e anzi non hanno senso nella statistica tradizionale.</p>
<p>In altre parole, l’intervallo di confidenza è una sorta di polizza assicurativa che ci garantisce che, se operiamo continuativamente con le procedure indicate, al termine della nostra carriera avremo sbagliato in non più del 5% dei casi.</p>
</div>
<div id="popolazioni-non-gaussiane" class="section level3">
<h3><span class="header-section-number">14.2.3</span> Popolazioni non gaussiane</h3>
<p>Nel capitolo 5 abbiamo presentato un esempio in cui avevamo campionato da una distribuzione normale, riscontrando una <em>sampling distribution</em> per la media campionaria anch’essa normale. Ma che succede se la distribuzione di partenza è non-normale? La <em>sampling distribution</em> di uno stimatore è ancora normale? Vediamo un nuovo esempio.</p>
<p>Immaginiamo di avere 4’000’000 di semi ben mischiati (in modo che non ci siano raggruppamenti non casuali di qualche tipo), che costituiscono la nostra popolazione di partenza. Vogliamo appurare la frequenza relativa (p) dei semi dormienti. Questa informazione, nella realtà, esiste (<span class="math inline">\(\pi\)</span> = 0.25), ma non è nota.</p>
<p>Dato l’elevato numero di ‘soggetti’, non possiamo testare la germinabilità di tutti i semi, ma dobbiamo necessariamente prelevare un campione casuale di 40 soggetti; ogni seme viene saggiato e, dato che la popolazione è molto numerosa, l’estrazione di un seme non modifica sensibilmente la proporzione di quelli dormienti nella popolazione (esperimenti indipendenti).</p>
<div id="il-modello-dei-dati-1" class="section level4">
<h4><span class="header-section-number">14.2.3.1</span> Il modello dei dati</h4>
<p>Dopo aver descritto la popolazione e l’esperimento, ci chiediamo quale sia il modello matematico che genera i nostri dati (numero di successi su 40 semi estratti). Il disegno sperimentale ci assicura che ogni estrazione è totalmente indipendente dalla precedente e dalla successiva ed ha due soli risultati possibili, cioè successo (seme dormiente), o insuccesso (seme germinabile). Di conseguenza, ogni singola estrazione si configura come un esperimento Bernoulliano, con probabilità di successo pari a <span class="math inline">\(\pi\)</span>, il cui valore ‘vero’ esiste, è fisso, pre-determinato (esiste ancor prima di organizzare l’esperimento), anche se incognito e inconoscibile, a meno di non voler/poter esaminare tutti i semi disponibili. L’insieme delle 40 estrazioni (40 esperimenti Bernoulliani) può produrre un ventaglio di risultati possibili, da 40 successi a 40 insuccessi, per un totale di 41 possibili ‘outcomes’.</p>
<p>E’ evidente che i 41 possibili risultati non sono ugualmente probabili e si può dimostrare che la probabilità di ottenere <em>k</em> successi (con <em>k</em> che va da 0 ad <em>n</em>; <em>n</em> è al numero delle estrazioni) dipende da <span class="math inline">\(\pi\)</span> ed è descrivibile matematicamente con la distribuzione binomiale <span class="math inline">\(\phi\)</span>:</p>
<p><span class="math display">\[\phi(k, n, p) = \frac{n!}{(n-k)!k!} p^k (1 - p)^{(n-k)}\]</span></p>
<p>Abbiamo quindi definito il modello matematico che descrive la probabilità di tutti i possibili risultati del nostro esperimento e quindi può in qualche modo essere considerato il ‘meccanismo’ che ‘genera’ i dati sperimentali osservati. Si tratta di un meccanismo puramente ‘stocastico’ nel quale è solo il caso che, attraverso il campionamento, determina il risultato dell’esperimento.</p>
<p>Con queste informazioni, possiamo simulare un esperimento con R, ottenendo i seguenti risultati:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">23456789</span>)
<span class="kw">rbinom</span>(<span class="dv">1</span>, <span class="dv">40</span>, <span class="fl">0.25</span>)
## [1] 10</code></pre></div>
<p>Abbiamo ottenuto 9 successi su 40, cioè 9 semi dormienti su 40 saggiati.</p>
</div>
<div id="stima-dei-parametri-4" class="section level4">
<h4><span class="header-section-number">14.2.3.2</span> Stima dei parametri</h4>
<p>Dovendo stimare la quantità <span class="math inline">\(\pi\)</span>, la statistica tradizionale trascura totalmente le nostre aspettative sul fenomeno e utilizza soltanto i risultati dell’esperimento. Chiamiamo <em>p</em> la quantità stimata e, dato che abbiamo contato nove semi dormienti, concludiamo che p = 0.225, in quanto questa, con le informazioni che abbiamo, è la cosa più verosimile. Anche in questo caso vi è chiara discrasia tra la verità ‘vera’ e l’osservazione sperimentale (tra <span class="math inline">\(\pi\)</span> e <span class="math inline">\(p\)</span>).</p>
</div>
<div id="sampling-distribution" class="section level4">
<h4><span class="header-section-number">14.2.3.3</span> Sampling distribution</h4>
<p>Cosa succede se ripetiamo l’esperimento? Come abbiamo imparato a fare, possiamo cercare una risposta attraverso la simulazione Monte Carlo, ricorrendo ad un generatore di numeri casuali da una distribuzione binomiale con n = 40 e <span class="math inline">\(\pi\)</span> = 0.25 (in R si usa la funzione ‘rbinom(numeroDatiCasuali, n, p)’). Il codice è più semplice, in quanto non è necessario impostare un ciclo iterativo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
result &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">10000000</span>, <span class="dv">40</span>, <span class="fl">0.25</span>)</code></pre></div>
<p>Esploriamo i risultati ottenuti:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result_p &lt;-<span class="st"> </span>result<span class="op">/</span><span class="dv">40</span>
<span class="kw">mean</span>(result_p)
## [1] 0.2500129
<span class="kw">sd</span>(result_p)
## [1] 0.0684611</code></pre></div>
<p>Osserviamo subito che, anche se i singoli esperimenti portano a stime diverse da <span class="math inline">\(\pi\)</span>, la media di <span class="math inline">\(p\)</span> tende ad essere uguale a <span class="math inline">\(\pi\)</span>. L’errore standard (deviazione standard della <em>sampling distribution</em>) è 0.0685. Fino a qui, non vie è nulla di diverso dall’esempio precedente, se teniamo presente che la deviazione standard della popolazione originale (che è binomiale) è pari a <span class="math inline">\(\sqrt{p \times (1 - p)}\)</span>, quindi l’errore standard è <span class="math inline">\(\sqrt{0.25 \times 0.75 / 40} = 0.0685\)</span>.</p>
<p>Rimane da stabilire se la <em>sampling distribution</em> di <span class="math inline">\(p\)</span> è normale. Possiamo utilizzare i 10’000’000 di valori ottenuti per costruire una distribuzione empirica di frequenze, come nel codice sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">breaks &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">0.7</span>, <span class="dt">by=</span><span class="fl">0.025</span>)
freqAss &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( <span class="kw">table</span>(<span class="kw">cut</span>(result_p, breaks) ) ) 
freqRel &lt;-<span class="st"> </span>freqAss<span class="op">/</span><span class="kw">length</span>(result_p)
density &lt;-<span class="st"> </span>freqRel<span class="op">/</span><span class="fl">0.025</span>
p_oss &lt;-<span class="st"> </span>breaks[<span class="dv">2</span><span class="op">:</span><span class="kw">length</span>(breaks)]

<span class="kw">plot</span>(density <span class="op">~</span><span class="st"> </span>p_oss, <span class="dt">type =</span> <span class="st">&quot;h&quot;</span>,
     <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">bar</span>(p))),
     <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, 
    <span class="dt">main=</span><span class="st">&quot;Sampling distribution per p&quot;</span>, 
    <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.6</span>) )

<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="fl">0.25</span>, <span class="fl">0.0685</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-242-1.png" /><!-- --></p>
<p>Vediamo che <em>sampling distribution</em> è approssimativamente normale con media pari a 0.25 e deviazione standard pari a 0.0685. Lo percepiamo chiaramente dal grafico soprastante, ma c’è una spiegazione scientifica per questo, basata sul <strong>TEOREMA DEL LIMITE CENTRALE</strong>:</p>
<ol style="list-style-type: decimal">
<li>La sampling distribution di una statistica ottenuta da campioni casuali e indipendenti è approssimativamente normale, indipendentemente dalla distribuzione della popolazione da cui i campioni sono stati estratti.</li>
<li>La media della sampling distribution è uguale al valore della statistica calcolata sulla popolazione originale, la deviazione standard della sampling distribution (errore standard) è pari alla deviazione standard della popolazione originale divisa per la radice quadrata della numerosità di un campione.</li>
</ol>
</div>
</div>
</div>
<div id="capitolo-6.-introduzione-al-test-dipotesi" class="section level2">
<h2><span class="header-section-number">14.3</span> Capitolo 6. Introduzione al test d’ipotesi</h2>
<div id="simulazione-monte-carlo-di-un-test-t-di-student" class="section level3">
<h3><span class="header-section-number">14.3.1</span> Simulazione Monte Carlo di un test t di Student</h3>
<p>La sampling distribution per T potrebbe essere ottenuta empiricamente, utilizzando una simulazione MONTE CARLO ed immaginando di estrarre numerose coppie di campioni, dalla stessa distribuzione normale, analogamente a quanto abbiamo fatto nell’esempio precedente. Se l’ipotesi nulla è vera, possiamo immaginare che questa distribuzione gaussiana abbia una media pari a (70.2 + 85.4)/2 = 77.8 e una deviazione standard pari alla deviazione standard delle dieci osservazioni (tutte insieme, senza distinzioni di trattamento), cioè 5.71.</p>
<p>Il codice da utilizzare in R per le simulazioni è il seguente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">A &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">65</span>, <span class="dv">68</span>, <span class="dv">69</span>, <span class="dv">71</span>, <span class="dv">78</span>)
P &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">80</span>, <span class="dv">81</span>, <span class="dv">84</span>, <span class="dv">88</span>, <span class="dv">94</span>)
media &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">c</span>(A, P))
devSt &lt;-<span class="st"> </span><span class="kw">sd</span>(<span class="kw">c</span>(A, P))
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">5</span>, media, devSt)
  sample2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">5</span>, media, devSt)
  SED &lt;-<span class="st"> </span><span class="kw">sqrt</span>( (<span class="kw">sd</span>(sample1)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> <span class="op">+</span>
<span class="st">                 </span>(<span class="kw">sd</span>(sample2)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> )
  result[i] &lt;-<span class="st"> </span>(<span class="kw">mean</span>(sample1) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(sample2)) <span class="op">/</span><span class="st"> </span>SED
}</code></pre></div>
<p>I risultati delle 100’000 simulazioni sono riportati nel grafico sottostante. Possiamo notare che, dei 100’000 valori di T osservati assumendo vera l’ipotesi nulla, solo l’un per mille sono superiori a quello da noi osservato e altrettanti sono inferiori a -4.5217. In totale, la probabilità di osservare un valore di T così alto in valore assoluto e dello 0.21 %.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SED_obs &lt;-<span class="st"> </span><span class="kw">sqrt</span>( (<span class="kw">sd</span>(A)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> <span class="op">+</span>
<span class="st">                   </span>(<span class="kw">sd</span>(P)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> )
T_obs &lt;-<span class="st"> </span>(<span class="kw">mean</span>(A) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(P))<span class="op">/</span>SED_obs
(<span class="kw">length</span>(result[result <span class="op">&lt;</span><span class="st"> </span>T_obs]) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">length</span>(result[result <span class="op">&gt;</span><span class="st"> </span><span class="op">-</span><span class="st"> </span>T_obs])) <span class="op">/</span><span class="dv">100000</span>
## [1] 0.00164</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Codice Grafico </span>
b &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">12</span>, <span class="dv">12</span>, <span class="dt">by=</span><span class="fl">0.25</span>)
<span class="kw">hist</span>(result, <span class="dt">breaks =</span> b, <span class="dt">freq=</span>F, <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(m)), <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.45</span>), <span class="dt">main=</span><span class="st">&quot;&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-245-1.png" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x), <span class="dt">add=</span>T, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-245-2.png" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">8</span>), <span class="dt">add=</span>T, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="fl">4.52</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="op">-</span><span class="fl">4.52</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">text</span>(<span class="dv">5</span>, <span class="fl">0.4</span>, <span class="dt">label=</span><span class="st">&quot;4.52&quot;</span>, <span class="dt">adj=</span><span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
<span class="kw">text</span>(<span class="op">-</span><span class="dv">5</span>, <span class="fl">0.4</span>, <span class="dt">label=</span><span class="st">&quot;-4.52&quot;</span>, <span class="dt">adj=</span><span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-245-3.png" /><!-- --></p>
</div>
<div id="tipologie-alternative-di-test-t-di-student" class="section level3">
<h3><span class="header-section-number">14.3.2</span> Tipologie alternative di test t di Student</h3>
<p>Il test t può essere di tre tipi:</p>
<ol style="list-style-type: decimal">
<li>Appaiato. In questo caso le misure sono prese a coppia sullo stesso soggetto e non sono quindi indipendenti.</li>
<li>Omoscedastico. Le misure sono prese su soggetti diversi (indipendenti) e possiamo suppore che i due campioni provengano da due popolazioni con la stessa varianza.</li>
<li>Eteroscedastico. Le misure sono prese su soggetti diversi, ma le varianze non sono omogenee.</li>
</ol>
<p>Nel nostro esempio vediamo che le varianze dei campioni sono piuttosto simili e quindi adottiamo un test t omoscedastico (‘var.equal = T’).</p>
<p>Se dovessimo supporre che i due campioni provengono da popolazioni con varianze diverse, allora si porrebbe il problema di stabilire il numero di gradi di libertà del SEM. Abbiamo visto che se le varianze dei due campioni sono uguali (o meglio, sono due stime della stessa varianza), la varianza della somma/differenza ha un ha un numero di gradi di libertà pari alla somma dei gradi di libertà delle due varianze. Se le varianze fossero diverse, il numero di gradi di libertà della loro combinazione lineare (somma o differenza) si dovrebbe approssimare con la formula di Satterthwaite:</p>
<p><span class="math display">\[DF_s \simeq \frac{ \left( s^2_1 + s^2_2 \right)^2 }{ \frac{(s^2_1)^2}{DF_1} + \frac{(s^2_2)^2}{DF_2} }\]</span></p>
<p>Vediamo che se le varianze e i gradi di libertà sono uguali, la formula precedente riduce a:</p>
<p><span class="math display">\[DF_s = 2 \times DF\]</span></p>
<p>Nel nostro caso, se fosse <span class="math inline">\(s^2_1 \neq s^2_2\)</span> avremmo un numero frazionario di gradi di libertà:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dfS &lt;-<span class="st"> </span>(<span class="kw">var</span>(A) <span class="op">+</span><span class="st"> </span><span class="kw">var</span>(P))<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>
<span class="st">  </span>((<span class="kw">var</span>(A)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span> <span class="op">+</span><span class="st"> </span>(<span class="kw">var</span>(P)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span>)
dfS
## [1] 7.79772</code></pre></div>
<p>Il risultato può essere riscontrato con:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(A, P, <span class="dt">var.equal=</span>F)
## 
##  Two Sample t-test
## 
## data:  A and P
## t = -4.5217, df = 8, p-value = 0.001945
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -22.951742  -7.448258
## sample estimates:
## mean of x mean of y 
##      70.2      85.4</code></pre></div>
<p>Se invece avessimo rilevato le misure accoppiate su quattro individui avremmo solo 4 gradi di libertà:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(A, P, <span class="dt">var.equal=</span>T, <span class="dt">paired=</span>T)
## 
##  Paired t-test
## 
## data:  A and P
## t = -22.915, df = 4, p-value = 2.149e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -17.04169 -13.35831
## sample estimates:
## mean of the differences 
##                   -15.2</code></pre></div>
</div>
<div id="simulazione-di-un-test-di-chi-quadro" class="section level3">
<h3><span class="header-section-number">14.3.3</span> Simulazione di un test di chi quadro</h3>
<p>La simulazione di un test di <span class="math inline">\(\chi^2\)</span> può esser fatta utilizzando la funzione ‘r2dtable()’ che produce il numero voluto di tabelle di contingenza, con righe e colonne indipendenti r rispettando i totali marginali voluti. Le tabelle prodotte (nel nostro caso 10’000) sono restituite come lista, quindi possiamo utilizzare la funzione ‘lapply()’ per applicare ad ogni elemento della lista la funzione che restituisce il <span class="math inline">\(\chi^2\)</span> (‘chiSim’).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chiSim &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">summary</span>(<span class="kw">as.table</span>(x))<span class="op">$</span>stat
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
tabs &lt;-<span class="st"> </span><span class="kw">r2dtable</span>(<span class="dv">10000</span>, <span class="kw">apply</span>(tab, <span class="dv">1</span>, sum), <span class="kw">apply</span>(tab, <span class="dv">2</span>, sum))
chiVals &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( <span class="kw">lapply</span>( tabs, chiSim) )
<span class="kw">length</span>(chiVals[chiVals <span class="op">&gt;</span><span class="st"> </span><span class="fl">9.768</span>])
## [1] 435</code></pre></div>
<p>Vediamo che vi sono 19 valori più alti di quello da noi osservato (p = 0.0019).</p>
</div>
<div id="errori-di-prima-e-di-seconda-specie" class="section level3">
<h3><span class="header-section-number">14.3.4</span> Errori di prima e di seconda specie</h3>
<p>[da fare]</p>

<div id="refs" class="references">
<div>
<p>Bates, D. M., and D. G. Watts. 1988. <em>Nonlinear Regression Analysis &amp; Its Applications.</em> Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div>
<p>Box, G. E. P., and D. R. Cox. 1964. “An Analysis of Transformations.” <em>Journal of the Royal Statistical Society</em> B-26: 211–52.</p>
</div>
<div>
<p>Carroll, R. J., and D. Ruppert. 1988. <em>Transformation and Weighting in Regression.</em> Books: Chapman and Hall.</p>
</div>
<div>
<p>Daniel, Johnnie. 2011. <em>Sampling Essentials: Practical Guidelines for Making Sampling Choices</em>. USA: SAGE.</p>
</div>
<div>
<p>de Mendiburu, Felipe. 2019. <em>Agricolae: Statistical Procedures for Agricultural Research</em>. <a href="https://CRAN.R-project.org/package=agricolae" class="uri">https://CRAN.R-project.org/package=agricolae</a>.</p>
</div>
<div>
<p>Draper, N. R., and H. Smith. 1998. <em>Applied Regression Analysis</em>. III. Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div>
<p>LeClerg, E. L., W. H. Leonard, and A. G. Clark. 1962. <em>Field Plot Technique</em>. Books: Burgess Publishing Company.</p>
</div>
<div>
<p>Pannacci, E., D. Pettorossi, and F. Tei. 2013. “Phytotoxic Effects of Aqueous Extracts of Sunflower on Seed Germination and Growth of Sinapis Alba L., Triticum Aestivum L. and Lolium Multiflorum Lam.” <em>Allelopathy Journal</em> 32 (1): 23.</p>
</div>
<div>
<p>Ratkowsky, David A. 1990. <em>Handbook of Nonlinear Regression Models</em>. Books: Marcel Dekker Inc.</p>
</div>
<div>
<p>Ritz, C., and J. C. Streibig. 2008. <em>Nonlinear Regression with R</em>. Books: Springer-Verlag New York Inc.</p>
</div>
<div>
<p>Ritz, Christian, Florent Baty, Jens C. Streibig, and Daniel Gerhard. 2015. “Dose-Response Analysis Using R.” Edited by Yinglin Xia. <em>PLOS ONE</em> 10 (12): e0146021. doi:<a href="https://doi.org/10.1371/journal.pone.0146021">10.1371/journal.pone.0146021</a>.</p>
</div>
</div>
</div>
</div>
</div>








<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Con il termine inglese <em>coverage</em> si intende, in un esperimento ripetuto un elevatissimo numero di volte, l’effettiva percentuale di campioni, per i quali l’intervallo di confidenza, calcolato per un certo P nominale (es. P = 0.95), contiene effettivamente la media <span class="math inline">\(\mu\)</span> della popolazione.<a href="appendix-3-per-chi-vuole-approfondire-un-po.html#fnref3">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="appendix-2-richiami-di-statistica-descrittiva.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
