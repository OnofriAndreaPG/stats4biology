---
title: "The R-squared and nonlinear regression: a difficult marriage?"
author: "Andrea Onofri"
date: 2021-03-25
slug: 'nonlinear_regression'
categories:
  - R
  - 'nonlinear_regression'
tags:
  - R
  - 'nonlinear_regression'
  - 'nls'
  - 'aomisc'
  - 'drm'
archives:
  - 2021
---



<p>Making sure that a fitted model gives a good description of the observed data is a fundamental step of every nonlinear regression analysis. To this aim we can (and should) use several techniques, either graphical or based on formal hypothesis testing methods. However, in the end, I must admit that I often feel the need of displaying a simple index, based on a single and largely understood value, that reassures the readers about the goodness of fit of my models.</p>
<p>In linear regression, we already have such an index, that is known as the R<sup>2</sup> or the <em>coefficient of determination</em>. In words, this index represents the proportion of variance in the dependent variable that is explained by the regression effects. It ranges from 0 to 1 and, within this interval, the highest the value, the best the fit. The expression is:</p>
<p><span class="math display">\[ R^2 = \frac{SS_{reg}}{SS_{tot}}\]</span></p>
<p>and it represents the ratio between the regression sum of squares (<span class="math inline">\(SS_{reg}\)</span>) and total sum of squares (<span class="math inline">\(SS_{tot}\)</span>), which is equal to the proportion of explained variance when we consider the population variance, that is obtained by dividing both <span class="math inline">\(SS_{reg}\)</span> and <span class="math inline">\(SS_{tot}\)</span> by the number of observations (and not by the number of degrees of freedom). In the above expression, it is:</p>
<p><span class="math display">\[SS_{reg} = \sum_{i = 1}^{n}{\left(\hat{y_i} - \bar{y} \right)^2}\]</span></p>
<p>and:</p>
<p><span class="math display">\[SS_{tot} = \sum_{i = 1}^{n}{\left(y_i - \bar{y} \right)^2}\]</span></p>
<p>If we also consider the squared residuals from the regression line, we can also define the residual sum of squares as:</p>
<p><span class="math display">\[SS_{res} = \sum_{i = 1}^{n}{\left(y_i - \hat{y_i} \right)^2}\]</span></p>
<p>where: <span class="math inline">\(y_i\)</span> is the i-th observation, <span class="math inline">\(\hat{y_i}\)</span> is the i-th fitted value and <span class="math inline">\(\bar{y}\)</span> is the overall mean.</p>
<p>In all linear models with an intercept term, the following equality holds:</p>
<p><span class="math display">\[SS_{tot} = SS_{reg} + SS_{res}\]</span></p>
<p>Therefore, it is always <span class="math inline">\(SS_{reg} \leq SS_{tot}\)</span>, which implies that the R<sup>2</sup> value may never be higher than 1 or lower than 0. Furthermore, we can write the alternative (and equivalent) definition:</p>
<p><span class="math display">\[ R^2 = 1 - \frac{SS_{res}}{SS_{tot}}\]</span>
Now, the question is:</p>
<div id="can-we-use-the-r-squared-in-nonlinear-regression" class="section level1">
<h1>Can we use the R-squared in nonlinear regression?</h1>
<p>Basically, we have two problems:</p>
<ol style="list-style-type: decimal">
<li>nonlinear models do not have an intercept term, at least, not in the usual sense;</li>
<li>the equality <span class="math inline">\(SS_{tot} = SS_{reg} + SS_{res}\)</span> may not hold.</li>
</ol>
<p>For these reasons, most authors advocate against the use of the R<sup>2</sup> in nonlinear regression analysis and recommend alternative measures, such as the Mean Squared Error (MSE; see Ratkowsky, 1990) or the AIC and BIC (see Spiess and Neumeyer, 2010). I would argue that the R<sup>2</sup> may have a superior intuitive appeal as far as it is bound to 1 for a perfectly fitting model; with such a constraint, we can immediately see how good is the fit of our model.</p>
<p>Schabenberger and Pierce (2002) recommend the following statistic, that is similar to the R<sup>2</sup> for linear models:</p>
<p><span class="math display">\[ \textrm{Pseudo-}R^2 = 1 - \frac{SS_{res}}{SS_{tot}}\]</span></p>
<p>Why is it a ‘Pseudo-R<sup>2</sup>’?. In contrast to what happens with linear models, this statistic:</p>
<ol style="list-style-type: decimal">
<li>cannot exceed 1, but it may lower than 0;</li>
<li><strong>it cannot be interpreted as the proportion of variance explained by the model</strong></li>
</ol>
<p>Bearing these two limitations in mind, there is no reason why we should not use such a goodness-of-fit measure with nonlinear regression. In this line, the <code>R2.nls()</code> function in the ‘aomisc’ package can be used to retrieve the R<sup>2</sup> and Pseudo-R<sup>2</sup> values from a nonlinear model fitted with the <code>nls()</code> and <code>drm()</code> functions.</p>
<pre class="r"><code>library(aomisc)
X &lt;- c(0.1, 5, 7, 22, 28, 39, 46, 200)
Y &lt;- c(1, 13.66, 14.11, 14.43, 14.78, 14.86, 14.78, 14.91)

#drm fit
model &lt;- drm(Y ~ X, fct = MM.2())
R2nls(model)$PseudoR2
## [1] 0.9930399
 r
#
# nls fit
model2 &lt;- nls(Y ~ SSmicmen(X, Vm, K))
R2nls(model)$PseudoR2
## [1] 0.9930399</code></pre>
<p>Undoubtedly, the Pseudo-R<sup>2</sup> gives, at first glance, a good feel for the quality of our regressions; but, please, do not abuse it. In particular, please, remember that a negative value might indicate a big problem with the fitted model. Above all, remember that the Pseudo-R<sup>2</sup>, similarly to the R<sup>2</sup> in multiple linear regression, should never be used as the basis to select and compare alternative regression model. Other statistics should be used to this aim.</p>
<p>Thanks for reading and happy coding!</p>
<p>Andrea Onofri<br />
Department of Agricultural, Food and Environmental Sciences<br />
University of Perugia (Italy)<br />
<a href="mailto:andrea.onofri@unipg.it">andrea.onofri@unipg.it</a></p>
<hr />
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ol style="list-style-type: decimal">
<li>Ratkowsky, D.A., 1990. Handbook of nonlinear regression models. Marcel Dekker Inc., Books.</li>
<li>Schabenberger, O., Pierce, F.J., 2002. Contemporary statistical models for the plant and soil sciences. Taylor &amp; Francis, CRC Press, Books.</li>
<li>Spiess, A. N., &amp; Neumeyer, N., 2010. An evaluation of <span class="math inline">\(R^2\)</span> as an inadequate measure for nonlinear models in pharmacological and biochemical research: a Monte Carlo approach. BMC Pharmacology, 10, 6.</li>
</ol>
</div>
