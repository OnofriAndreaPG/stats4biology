---
title: "Subsampling in field experiments"
author: "Andrea Onofri"
date: 2023-03-29
slug: 'Mixed models'
categories:
  - R
  - 'Mixed_models'
tags:
  - R
  - 'Mixed_models'
  - 'Subsampling'
archives:
  - 2023
---


```{r setup, cache = F, echo = F}
#Put at the beginning
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
knitr::knit_hooks$set(document = function(x){ 
  gsub("```\n*```r*\n*", "", x) 
})
```


Subsampling is very common in field experiments in agriculture. It happens when we collect several random samples from each plot and we submit them to some sort of measurement process. Some examples? Let's imagine that we have randomised field experiments with three replicates and, either,:

1. we collect the whole grain yield in each plot, select four subsamples and measure, in each subsample, the oil content or some other relevant chemical property, or
2. we collect, from each plot, four plants and measure their heights, or
3. we collect a representative soil sample from each plot and perform chemical analyses in triplicate.

For all the above examples, we end up with 3 by 4 equal 12 data for each treatment level. The question is: do we have 12 replicates? This is exactly the point: **subsamples should never be mistaken for true-replicates, as the experimental treatments were not independently allocated to each one of them**. In literature, subsamples are usually known as sub-replicates or pseudo-replicates: for the above examples, we have three true-replicates and four pseudo-replicates per true-replicate. Let's see how to handle pseudo-replicates in data analysis. But, first of all, do not forget that: **experiments with pseudo-replicates are valid only when we also have true-replicates!** If we only have pseudo-replicates... well, there is nothing we can do in data analysis that transforms our experiment into a valid one...

# A motivating example

Let's consider a dataset from an experiment where we had 30 genotypes in three blocks and recorded the Weight of Thousand Kernels (TKW) in three subsamples per plot, which were labelled by using the 'Sample' variable. In the box below, we load the data and all the necessary packages.

```{r message=FALSE, warning=FALSE}
rm(list=ls())
library(tidyverse)
library(nlme)
library(emmeans)

filePath <- "https://www.casaonofri.it/_datasets/TKW.csv"
TKW <- read.csv(filePath)
TKW <- TKW %>% 
  mutate(across(1:4, .fns = factor))
head(TKW)
```

# The wrong analysis

A 'naive' analysis would be to perform an ANOVA on all data, without making any distinction between true-replicates and sub-replicates. Let's do this by using the code shown in the box below.


```{r}
# Naive analysis
mod <- lm(TKW ~ Block + Genotype, data=TKW)
anova(mod)
muG <- emmeans(mod, ~Genotype)
muG
pairwise <- as.data.frame(pairs(emmeans(mod, ~Genotype)))
sum(pairwise$p.value < 0.05)
```

We see that the SE for genotype means is 0.903, the F test for the genotypes is highly significant and there are 225 significant pairwise comparisons among the 30 genotypes.

As we said, this is simple, but it is also **terribly wrong**. By putting true-replicates and pseudo-replicates on an equal footing, we have forgotten that the 270 observations are grouped by plot and that the observations in the same plot are more alike than the observations in different plots, because they share the same 'origin'. We say that the observations in each plot are correlated and, therefore, the basic assumption of independence of residuals is broken. Our analysis is invalid and our manuscript can be very likely rejected.

But, why are the editors so critical when we mistake pseudo-replicates for true-replicates? We'll see this in a few minutes.

# The correct way to go

A fully correct model for our dataset is:

$$ y_{ijks} = \mu + \alpha_i + \beta_j + \gamma_{k} + \varepsilon_{s}$$

where $y$ is the thousand kernel weight for the i^th^ genotype, j^th^ block, k^th^ plot and s^th^ subsample, $\alpha$ is the effect of the i^th^ genotype, $\beta$ is the effect of the j^th^ block, $\gamma$ is the effect of the the k^th^ plot and $\varepsilon$ is the effect of the s^th^ subsample. The presence of the $\gamma$ element accounts for the effects of plots as a grouping factor and restores the independence of model residuals.

Obviously, the difference between plots (for a given genotype and block) must be regarded as a random effect, as well as the difference between subsamples, within each plot. Indeed. we have two random effects and, therefore, this is a mixed model. These two random effects are assumed to be normal, independent from each other, with mean equal to 0 and variances respectively equal to $\sigma^2_p$ and $\sigma^2_e$. (BTW: I am regarding the block effect as fixed! You may not agree, but this does not change what I am going to say later...).

We can fit this mixed model by using the `lme()` function in the `nlme` package, including the 'Plot' (i.e. the grouping factor) as a random effect. Obviously, we need to have a variable in the dataset that uniquely identifies each plot.

```{r}
# Mixed model fit
mod.mix <- lme(TKW ~ Block + Genotype, 
               random = ~1|Plot, data=TKW)
anova(mod.mix)
emmeans(mod.mix, ~Genotype)
pairwise <- as.data.frame(pairs(emmeans(mod.mix, ~Genotype)))
sum(pairwise$p.value < 0.05)
```

We see several differences with respect to the previous fit:

1. in the 'naive' model, the error term for the genotype effect (MS~e~) is 7.346 with 238 DF and it represents the whole subsample-to-subsample variability. In the mixed model, the error term for the genotype effect is not shown, but it has only 58 degrees of freedom.
2. The SE for genotype means is 1.75 and it is much higher than that from the 'naive' fit.
3. The number of significant pairwise comparisons between genotypes has dropped to 91.

Let's concentrate on the correct error term for the genotype effect; we know that the *error term must be obtained by a comparison of plots treated alike* (see Fisher, 1937. The design of experiments). From this, it is immediately clear that the MS~e~ from te 'naive' analysis compares the subsamples treated alike (and not the plots). Now, if we take the 'naive' analysis and include the 'plot' among the experimental factors, we get:

```{r}
mod2 <- lm(TKW ~ Block + Genotype + Plot, data=TKW)
anova(mod2)
```

We see that the 'plot' effect, once the genotype and block effects have been removed, takes 58 DFs and leave us with 180 DFs in the residuals. Indeed, we have decomposed the MS~e~ from the 'naive' analysis in two parts, one measuring the plot-to-plot variability and the other one measuring the subsample-to-subsample variability, within each plot. The MS for this latter element is equal to $\sigma_e$ from mixed model analysis, while the MS for the former element is the correct error term to test for the genotype effect, because it *compares the plots treated alike*. It is equal to $3 \times \sigma^2_p + \sigma^2_e$ and it should be used to calculate the SEs for genotype means, as $\sqrt{27.521/9} = 1.748689$ and not as $\sqrt{7.346/9} = 0.90345$.

We can now understand why the editors reject our manuscripts if we do not analyse the data properly: we may strongly overestimate the precision of our experiment and, consequently, commit a lot of false positive errors!

# A simpler alternative

In presence of subsampling, we strongly recommend the previous method of data analysis. But, a simpler alternative exists, which is feasible whenever the number of subsamples is the same for all plots: we can proceed in two-steps. In the first step, we calculate the means of subsamples for each plot and, in the second step, we submit the plot means to ANOVA, by considering the genotypes and the blocks as fixed factors.

```{r}
# First step
TKWm <- aggregate(TKW ~ Block + Genotype, data = TKW, mean)

#Second step
mod2step <- lm(TKW ~ Genotype + Block, data = TKWm)
anova(mod2step)
emmeans(mod2step, ~Genotype)
pairwise <- as.data.frame(pairs(emmeans(mod2step, ~Genotype)))
sum(pairwise$p.value < 0.05)
```

We see that the results are totally the same as with a mixed model fit, although all Mean Squares in ANOVA are fractions of those obtained by mixed model analysis.

**Please, remember that this simple solution is only feasible when we have the same number of subsamples per each plot**.

Thanks for reading and happy coding!

Andrea Onofri   
Department of Agricultural, Food and Environmental Sciences        
University of Perugia (Italy)        
[andrea.onofri@unipg.it](mailto:andrea.onofri@unipg.it)  

<a href="https://twitter.com/onofriandreapg?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @onofriandreapg</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

---

# References

1. Fisher, R.A., 1937. The design of experiments, 2nd ed. Oliver and Boyd, Edinburgh, UK.
2. Hurlbert, S.H., 1984. Pseudoreplication and the design of ecological experiments. Ecological Monographs 54, 187â€“211.


