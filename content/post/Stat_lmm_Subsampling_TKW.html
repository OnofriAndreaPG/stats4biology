---
title: "Subsampling in field experiments"
author: "Andrea Onofri"
date: 2023-03-29
slug: 'Mixed models'
categories:
  - R
  - 'Mixed_models'
tags:
  - R
  - 'Mixed_models'
  - 'Subsampling'
archives:
  - 2023
---



<p>Subsampling is very common in field experiments in agriculture. It happens when we collect several random samples from each plot and we submit them to some sort of measurement process. Some examples? Let’s look at the following (very incomplete) list.</p>
<ol style="list-style-type: decimal">
<li>We collect the whole grain yield in each plot, select four subsamples and measure, in each subsample, the oil content or some other relevant chemical property.</li>
<li>We collect, from each plot, four plants and measure their height.</li>
<li>We collect a representative soil samples from each plot and analyse the residual content in some xenobiotic substance, by making four repeated measurements.</li>
</ol>
<p>The presence of sub-samples is a good thing, as long as true-replicates are also available. Indeed, the precision of our experiment increases, although the process of data analysis must be run properly. We should bear in mind that, if the experimental design is, e.g., a Randomised Complete Block with four replicates, for all the above examples we end up with sixteen values for each experimental treatment (four replicates and four sub-samples per replicate). It must be clear that the four sub-samples are not like true-replicates, because the experimental treatments were not independently allocated to each of them. The four subsamples are sub-replicates (or pseudo-replicates) and we should account for this when we analyse our data.</p>
<div id="a-motivating-example" class="section level1">
<h1>A motivating example</h1>
<p>Let’s consider a dataset from an experiment where we had 30 genotypes in three blocks and recorded the Weight of Thousand Kernels (TKW) in three subsamples per plot, which were labelled by using the ‘Sample’ variable. In the box below, we load the data and all the necessary packages.</p>
<pre class="r"><code>rm(list=ls())
library(tidyverse)
library(nlme)
library(emmeans)

filePath &lt;- &quot;https://www.casaonofri.it/_datasets/TKW.csv&quot;
TKW &lt;- read.csv(filePath)
TKW &lt;- TKW %&gt;% 
  mutate(across(1:4, .fns = factor))
head(TKW)
##   Plot Block  Genotype Sample  TKW
## 1    1     1 Meridiano      1 28.6
## 2    2     1     Solex      1 33.3
## 3    3     1  Liberdur      1 22.3
## 4    4     1  Virgilio      1 28.1
## 5    5     1   PR22D40      1 26.7
## 6    6     1    Ciccio      1 34.2</code></pre>
</div>
<div id="the-wrong-analysis" class="section level1">
<h1>The wrong analysis</h1>
<p>A naive analysis would be to perform an ANOVA on all data, without making any distinction between true-replicates and sub-replicates. Let’s do this by using the code shown in the box below.</p>
<pre class="r"><code># Naive analysis
mod &lt;- lm(TKW ~ Block + Genotype, data=TKW)
anova(mod)
## Analysis of Variance Table
## 
## Response: TKW
##            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## Block       2  110.3  55.169   7.510 0.0006875 ***
## Genotype   29 7224.7 249.129  33.913 &lt; 2.2e-16 ***
## Residuals 238 1748.4   7.346                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
summary(mod)$sigma
## [1] 2.710373
pairwise &lt;- as.data.frame(pairs(emmeans(mod, ~Genotype)))
sum(pairwise$p.value &lt; 0.05)
## [1] 225</code></pre>
<p>We see that the Root Mean Square Error is 2.71, the F test for the genotypes is highly significant and there are 225 significant pairwise comparisons among the 30 genotypes.</p>
<p>As we said, this is simple, but it is also <strong>terribly wrong</strong>. By putting true-replicates and pseudo-replicates on an equal footing, we have forgotten that the 270 observations are grouped by plot and that the observations in the same plot are more alike than the observations in different plots, because they share the same ‘origin’. We say that the observations in each plot are correlated and, therefore, the basic assumption of independence of residuals is violated. Our analysis is invalid and our manuscript can be very likely rejected.</p>
<p>But, why are the editors so critical when we mistake pseudo-replicates for true-replicates? We’ll see this in a few minutes.</p>
</div>
<div id="the-correct-way-to-go" class="section level1">
<h1>The correct way to go</h1>
<p>A fully correct model for our dataset is:</p>
<p><span class="math display">\[ y_{ijks} = \mu + \alpha_i + \beta_j + \gamma_{k} + \varepsilon_{s}\]</span></p>
<p>where <span class="math inline">\(y\)</span> is the thousand kernel weight for the i<sup>th</sup> genotype, j<sup>th</sup> block, k<sup>th</sup> plot and s<sup>th</sup> sub-sample, <span class="math inline">\(\alpha\)</span> is the effect of the i<sup>th</sup> genotype, <span class="math inline">\(\beta\)</span> is the effect of the j<sup>th</sup> block, <span class="math inline">\(\gamma\)</span> is the effect of the the k<sup>th</sup> plot and <span class="math inline">\(\varepsilon\)</span> is the effect of the s<sup>th</sup> subsample. The presence of the <span class="math inline">\(\gamma\)</span> element accounts for the plot as a grouping factor and restores the independence of model residuals.</p>
<p>Obviously, the difference between plots (for a given genotype and block) must be regarded as a random effect, as well as the difference between subplots, within each plot. Indeed. we have two random effects and, therefore, this is a mixed model. These two random effects are assumed to be normal, independent from each other, with mean equal to 0 and variances respectively equal to <span class="math inline">\(\sigma^2_p\)</span> and <span class="math inline">\(\sigma^2_e\)</span>. (BTW: I am regarding the block as fixed! You may not agree, but this does not change what I am going to say later…).</p>
<p>We can fit this mixed model by using the <code>lme()</code> function in the <code>nlme</code> package.</p>
<pre class="r"><code># Mixed model fit
mod.mix &lt;- lme(TKW ~ Block + Genotype, 
               random=~1|Plot, data=TKW)
sigma2.p &lt;- as.numeric( VarCorr(mod.mix) )[1]
sigma2.e &lt;- as.numeric( VarCorr(mod.mix) )[2]
sigma2.p
## [1] 8.891984
sigma2.e
## [1] 0.8452593
anova(mod.mix)
##             numDF denDF   F-value p-value
## (Intercept)     1   180 11563.536  &lt;.0001
## Block           2    58     2.005  0.1439
## Genotype       29    58     9.052  &lt;.0001
pairwise &lt;- as.data.frame(pairs(emmeans(mod.mix, ~Genotype)))
sum(pairwise$p.value &lt; 0.05)
## [1] 91</code></pre>
<p>We already see several differences with respect to the previous fit:</p>
<ol style="list-style-type: decimal">
<li>in the ‘naive’ model, we have only one estimate for <span class="math inline">\(\sigma^2\)</span>, that is 7.346 with 238 DF. In this case the correct term to test for the genotype effect is <span class="math inline">\(\sigma^2_p\)</span>, that is equal to 8.892 with 58 DF. Clearly, the naive analysis strongly overestimates the number of DF: the observations taken in the same plot are correlated and they do not contribute full information.</li>
<li>The RMSE for the mixed model is equal to 2.98 and it is higher than that from the ‘naive’ fit. The variability within plot is much smaller.</li>
<li>The number of significant pairwise comparisons between genotypes has dropped to 91.</li>
</ol>
<p>You may wonder why <span class="math inline">\(\sigma^2_p\)</span>, instead of <span class="math inline">\(\sigma\)</span> or <span class="math inline">\(\sigma^2_e\)</span> is the correct error term for the genotypes. Because it is the only correct estimate of the random difference between the true-replicates that were independently submitted to the same treatment.</p>
<p>We can now understand why the editors reject our manuscript if we do not analyse the data properly: we may strongly overestimate the precision of our experiment and, consequently, commit a lot of false positive errors!</p>
</div>
<div id="a-simpler-alternative" class="section level1">
<h1>A simpler alternative</h1>
<p>We strongly recommend the previous method of data analysis. But, should you like to avoid the use of mixed models by all means (tell me,… why?), whenever the number of sub-samples is the same for all plots, we can also reach correct results by proceeding in two-steps. In the first step, we calculate the means of sub-samples for each plot and, in the second step, we submit the plot means to ANOVA, by considering the genotype and the block as fixed factors.</p>
<pre class="r"><code># First step, to get an estimate of the within plot error
mod1step &lt;- lm(TKW ~ Plot, data=TKW)
summary(mod1step)$sigma^2
## [1] 0.8452593
# Calculate the means per plot
avgTKW &lt;- as.data.frame(emmeans(mod1step, ~Plot))
head(avgTKW)
##   Plot   emmean        SE  df lower.CL upper.CL
## 1    1 28.56667 0.5308042 180 27.51927 29.61407
## 2    2 34.86667 0.5308042 180 33.81927 35.91407
## 3    3 23.66667 0.5308042 180 22.61927 24.71407
## 4    4 29.40000 0.5308042 180 28.35260 30.44740
## 5    5 27.30000 0.5308042 180 26.25260 28.34740
## 6    6 34.96667 0.5308042 180 33.91927 36.01407
# Recover infos on experimental design
Genotype &lt;- plyr::ddply(TKW, ~Plot,                   
        function(dataSet){as.character(dataSet[[&quot;Genotype&quot;]][1])} )[,2]
Block &lt;-  plyr::ddply(TKW, ~Plot, 
                  function(dataSet){as.factor(dataSet[[&quot;Block&quot;]][1])} )[,2]
dataset2step &lt;- data.frame(Block, Genotype, TKW = avgTKW$emmean)
dataset2step$Block &lt;- factor(dataset2step$Block)

#Second step
mod2step &lt;- lm(TKW ~ Genotype + Block, data = dataset2step)
anova(mod2step)
## Analysis of Variance Table
## 
## Response: TKW
##           Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## Genotype  29 2408.24  83.043  9.0522 9.943e-13 ***
## Block      2   36.78  18.390  2.0046    0.1439    
## Residuals 58  532.08   9.174                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
pairwise &lt;- as.data.frame(pairs(emmeans(mod2step, ~Genotype)))
sum(pairwise$p.value &lt; 0.05)
## [1] 91</code></pre>
<p>We see that the results are totally the same as with a mixed model fit, although all Mean Squares in ANOVA are fractions of those obtained by mixed model analyses.</p>
<p><strong>Please, remember that this simple solution is only feasible when we have the same number of subsamples per each plot</strong>.</p>
<p>Thanks for reading and happy coding!</p>
<p>Andrea Onofri<br />
Department of Agricultural, Food and Environmental Sciences<br />
University of Perugia (Italy)<br />
<a href="mailto:andrea.onofri@unipg.it">andrea.onofri@unipg.it</a></p>
<a href="https://twitter.com/onofriandreapg?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow <span class="citation">@onofriandreapg</span></a>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
