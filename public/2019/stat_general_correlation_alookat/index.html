<!DOCTYPE html>
<html lang="en">
<head>
  
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131792052-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-131792052-1');
  </script>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>The broken bridge between biologists and statisticians  | Going back to the basics: the correlation coefficient</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.7.1/css/bulma.min.css" />
    <link rel="stylesheet" href="/css/blog.css" />
    <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>    
</head>
<body>

    
    <nav class="navbar is-fixed-top" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a class="navbar-item" href="/">Home</a>
            <a class="navbar-item" href="/aboutThis">About this site</a>
            <a class="navbar-item" href="/Tutorials">Tutorials</a>
            <a class="navbar-item" href="/_statbook">Book</a>
            <a class="navbar-item" href="/links">Links</a>
            <a class="navbar-item" href="/about">About me</a>
        </div>
    </nav>
    

    
    <section class="hero is-info is-medium">
        <div class="hero-body" style="background-image: url(/img/bg-blog.jpg);">
            <div class="container has-text-centered">
                <br>
                <h1 class="title is-size-1">
                    
                        Going back to the basics: the correlation coefficient
                    
                </h1>
                
            </div>
        </div>
    </section>



<div class="container">
    <div class="section">
    

<div class="columns">
    <div class="column is-9">
        <div class="tile is-child box">
          <p class="subtitle is-size-6 has-text-grey-light">
          Andrea Onofri &middot;&nbsp; Added on February 7, 2019 &middot;
          <i class="far fa-clock"></i>&nbsp;7 min read 
          </p><hr/>
            <div class="content">
                


<div id="a-measure-of-joint-variability" class="section level1">
<h1>A measure of joint variability</h1>
<p>In statistics, dependence or association is any statistical relationship, whether causal or not, between two random variables or bivariate data. It is often measured by the Pearson correlation coefficient:</p>
<p><span class="math display">\[\rho _{X,Y} =\textrm{corr} (X,Y) = \frac {\textrm{cov}(X,Y) }{ \sigma_X \sigma_Y } = \frac{ \sum_{1 = 1}^n [(X - \mu_X)(Y - \mu_Y)] }{ \sigma_X \sigma_Y }\]</span></p>
<p>Other measures of correlation can be thought of, such as the Spearman <span class="math inline">\(\rho\)</span> rank correlation coefficient or Kendall <span class="math inline">\(\tau\)</span> rank correlation coefficient.</p>
</div>
<div id="assumptions-for-the-pearson-correlation-coefficient" class="section level1">
<h1>Assumptions for the Pearson Correlation Coefficient</h1>
<p>The Pearson correlation coefficients makes a few assumptions, which should be carefully checked.</p>
<ol style="list-style-type: decimal">
<li>Interval-level measurement. Both variables should be measured on a quantitative scale.</li>
<li>Random sampling. Each subject in the sample should contribute one value on X, and one value on Y. The values for both variables should represent a random sample drawn from the population of interest.</li>
<li>Linearity. The relationship between X and Y should be linear.</li>
<li>Bivarlate normal distribution. This means that (i) values of X should form a normal distribution at each value of Y and (ii) values of Y should form a normal distribution at each value of X.</li>
</ol>
</div>
<div id="hypothesis-testing" class="section level1">
<h1>Hypothesis testing</h1>
<p>It is possible to test whether <span class="math inline">\(r = 0\)</span> against the alternative $ r 0$. The test is based on the idea that the amount:</p>
<p><span class="math display">\[ T = \frac{r \sqrt{n - 2}}{\sqrt{1 - r^2}}\]</span> is distributed as a Student’s t variable.</p>
<p>Let’s take the two variables ‘cyl’ and ‘mpg’ from the ‘mtcars’ data frame. The correlation is:</p>
<pre class="r"><code>r &lt;- cor(mtcars$cyl, mtcars$gear)
r</code></pre>
<pre><code>## [1] -0.4926866</code></pre>
<p>The T statistic is:</p>
<pre class="r"><code>T &lt;- r * sqrt(32 - 2) / sqrt(1 - r^2)
T</code></pre>
<pre><code>## [1] -3.101051</code></pre>
<p>The p-value for the null is:</p>
<pre class="r"><code>2 * pt(T, 30)</code></pre>
<pre><code>## [1] 0.004173297</code></pre>
<p>which is clearly highly significant. The null can be rejected.</p>
<p>As for hypothesis testing, it should be considered that the individuals where couple of measurements were taken should be independent. If they are not, the t test is invalid. I am dealing with this aspect somewhere else in my blog.</p>
</div>
<div id="correlation-in-r" class="section level1">
<h1>Correlation in R</h1>
<p>We have already seen that we can use the usual function ‘cor(matrix, method=)’. In order to obtain the significance, we can use the ‘rcorr()’ function in the Hmisc package</p>
<pre class="r"><code># Correlations with significance levels
library(Hmisc)
corr2 &lt;- rcorr(as.matrix(mtcars), type=&quot;pearson&quot;)
print(corr2$r, digits = 2)</code></pre>
<pre><code>##        mpg   cyl  disp    hp   drat    wt   qsec    vs     am  gear   carb
## mpg   1.00 -0.85 -0.85 -0.78  0.681 -0.87  0.419  0.66  0.600  0.48 -0.551
## cyl  -0.85  1.00  0.90  0.83 -0.700  0.78 -0.591 -0.81 -0.523 -0.49  0.527
## disp -0.85  0.90  1.00  0.79 -0.710  0.89 -0.434 -0.71 -0.591 -0.56  0.395
## hp   -0.78  0.83  0.79  1.00 -0.449  0.66 -0.708 -0.72 -0.243 -0.13  0.750
## drat  0.68 -0.70 -0.71 -0.45  1.000 -0.71  0.091  0.44  0.713  0.70 -0.091
## wt   -0.87  0.78  0.89  0.66 -0.712  1.00 -0.175 -0.55 -0.692 -0.58  0.428
## qsec  0.42 -0.59 -0.43 -0.71  0.091 -0.17  1.000  0.74 -0.230 -0.21 -0.656
## vs    0.66 -0.81 -0.71 -0.72  0.440 -0.55  0.745  1.00  0.168  0.21 -0.570
## am    0.60 -0.52 -0.59 -0.24  0.713 -0.69 -0.230  0.17  1.000  0.79  0.058
## gear  0.48 -0.49 -0.56 -0.13  0.700 -0.58 -0.213  0.21  0.794  1.00  0.274
## carb -0.55  0.53  0.39  0.75 -0.091  0.43 -0.656 -0.57  0.058  0.27  1.000</code></pre>
<pre class="r"><code>print(corr2$P, digits = 2)</code></pre>
<pre><code>##          mpg     cyl    disp      hp    drat      wt    qsec      vs
## mpg       NA 6.1e-10 9.4e-10 1.8e-07 1.8e-05 1.3e-10 1.7e-02 3.4e-05
## cyl  6.1e-10      NA 1.8e-12 3.5e-09 8.2e-06 1.2e-07 3.7e-04 1.8e-08
## disp 9.4e-10 1.8e-12      NA 7.1e-08 5.3e-06 1.2e-11 1.3e-02 5.2e-06
## hp   1.8e-07 3.5e-09 7.1e-08      NA 1.0e-02 4.1e-05 5.8e-06 2.9e-06
## drat 1.8e-05 8.2e-06 5.3e-06 1.0e-02      NA 4.8e-06 6.2e-01 1.2e-02
## wt   1.3e-10 1.2e-07 1.2e-11 4.1e-05 4.8e-06      NA 3.4e-01 9.8e-04
## qsec 1.7e-02 3.7e-04 1.3e-02 5.8e-06 6.2e-01 3.4e-01      NA 1.0e-06
## vs   3.4e-05 1.8e-08 5.2e-06 2.9e-06 1.2e-02 9.8e-04 1.0e-06      NA
## am   2.9e-04 2.2e-03 3.7e-04 1.8e-01 4.7e-06 1.1e-05 2.1e-01 3.6e-01
## gear 5.4e-03 4.2e-03 9.6e-04 4.9e-01 8.4e-06 4.6e-04 2.4e-01 2.6e-01
## carb 1.1e-03 1.9e-03 2.5e-02 7.8e-07 6.2e-01 1.5e-02 4.5e-05 6.7e-04
##           am    gear    carb
## mpg  2.9e-04 5.4e-03 1.1e-03
## cyl  2.2e-03 4.2e-03 1.9e-03
## disp 3.7e-04 9.6e-04 2.5e-02
## hp   1.8e-01 4.9e-01 7.8e-07
## drat 4.7e-06 8.4e-06 6.2e-01
## wt   1.1e-05 4.6e-04 1.5e-02
## qsec 2.1e-01 2.4e-01 4.5e-05
## vs   3.6e-01 2.6e-01 6.7e-04
## am        NA 5.8e-08 7.5e-01
## gear 5.8e-08      NA 1.3e-01
## carb 7.5e-01 1.3e-01      NA</code></pre>
<p>We could also use these functions with two matrices, to obtain the correlations of each column in one matrix with each column in the other</p>
<pre class="r"><code># Correlation matrix from mtcars
x &lt;- mtcars[1:3]
y &lt;- mtcars[4:6]
cor(x, y)</code></pre>
<pre><code>##              hp       drat         wt
## mpg  -0.7761684  0.6811719 -0.8676594
## cyl   0.8324475 -0.6999381  0.7824958
## disp  0.7909486 -0.7102139  0.8879799</code></pre>
</div>
<div id="relationship-to-slope-in-linear-regression" class="section level1">
<h1>Relationship to slope in linear regression</h1>
<p>The correlation coefficient and slope in linear regression bear some similarities, as both describe how Y changes when X is changed. However, in correlation, we have two random variables, while in regression we have Y random, X fixed and Y is regarded as a function of X (not the other way round).</p>
<p>Without neglecting their different meaning, it may be useful to show the algebraic relationship between the correlation coefficient and the slope in regression. Let’s simulate a dataset with two variables, coming from a multivariate normal distribution, with means respectively equal to 10 and 2, and variance-covariance matrix of:</p>
<pre class="r"><code>library(MASS)
cov &lt;- matrix(c(2.20, 0.48, 0.48, 0.20), 2, 2)
cov</code></pre>
<pre><code>##      [,1] [,2]
## [1,] 2.20 0.48
## [2,] 0.48 0.20</code></pre>
<p>We use the ‘mvrnomr()’ function to generate the dataset.</p>
<pre class="r"><code>set.seed(1234)
dataset &lt;- data.frame( mvrnorm(n=10, mu = c(10, 2), Sigma = cov) )
names(dataset) &lt;- c(&quot;X&quot;, &quot;Y&quot;)
dataset</code></pre>
<pre><code>##            X        Y
## 1  11.756647 2.547203
## 2   9.522180 2.199740
## 3   8.341254 1.862362
## 4  13.480005 2.772031
## 5   9.428296 1.573435
## 6   9.242788 1.861756
## 7  10.817449 2.343918
## 8  10.749047 2.451999
## 9  10.780400 2.436263
## 10 11.480301 1.590436</code></pre>
<p>The correlation coefficient and slope are as follows:</p>
<pre class="r"><code>r &lt;- with(dataset, cor(X, Y))
b1 &lt;- coef( lm(Y ~ X, data=dataset) )[2]
r</code></pre>
<pre><code>## [1] 0.6372927</code></pre>
<pre class="r"><code>b1</code></pre>
<pre><code>##         X 
## 0.1785312</code></pre>
<p>The equation for the slope is:</p>
<p><span class="math display">\[b_1 = \frac{ \sum_{i = 1}^n \left[ ( X-\mu_X )( Y-\mu_Y )\right] }{ \sigma^2_X } \]</span></p>
<p>From there, we see that:</p>
<p><span class="math display">\[ r = b_1 \frac{\sigma_X}{ \sigma_Y }\]</span></p>
<p>and:</p>
<p><span class="math display">\[ b_1 = r \frac{\sigma_Y}{\sigma_X}\]</span></p>
<p>Indeed:</p>
<pre class="r"><code>sigmaX &lt;- with(dataset, sd(X) )
sigmaY &lt;- with(dataset, sd(Y) )
b1 * sigmaX / sigmaY </code></pre>
<pre><code>##         X 
## 0.6372927</code></pre>
<pre class="r"><code>r * sigmaY / sigmaX</code></pre>
<pre><code>## [1] 0.1785312</code></pre>
<p>It is also easy to see that the correlation coefficient is the slope of regression of standardised Y against standardised X:</p>
<pre class="r"><code>Yst &lt;- with(dataset, scale(Y, scale=T) )
summary( lm(Yst ~ I(scale(X, scale = T) ), data = dataset) )</code></pre>
<pre><code>## 
## Call:
## lm(formula = Yst ~ I(scale(X, scale = T)), data = dataset)
## 
## Residuals:
##       Min        1Q    Median        3Q       Max 
## -0.082006 -0.067143 -0.036850  0.009214  0.237923 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)            -5.633e-18  3.478e-02   0.000   1.0000  
## I(scale(X, scale = T))  1.785e-01  7.633e-02   2.339   0.0475 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.11 on 8 degrees of freedom
## Multiple R-squared:  0.4061, Adjusted R-squared:  0.3319 
## F-statistic: 5.471 on 1 and 8 DF,  p-value: 0.04748</code></pre>
</div>
<div id="intra-class-correlation-icc" class="section level1">
<h1>Intra-class correlation (ICC)</h1>
<p>It describes how strongly units in the same group resemble each other. While it is viewed as a type of correlation, unlike most other correlation measures it operates on data structured as groups, rather than data structured as paired observations. The intra-class correlation coefficient is:</p>
<p><span class="math display">\[IC = {\displaystyle {\frac {\sigma _{\alpha }^{2}}{\sigma _{\alpha }^{2}+\sigma _{\varepsilon }^{2}}}.}\]</span></p>
<p>where <span class="math inline">\(\sigma _{\alpha }^{2}\)</span> is the variance between groups and <span class="math inline">\(\sigma _{\varepsilon }^{2}\)</span> is the variance within a group (better, the variance of one observation within a group). The sum of those two variances is the total variance of observations. In words, the intra-class correlation coefficient measures the joint variability of subjects in the same group (that relates on how groups are different from one another), with respect to the total variability of observations. If subjects in one group are very similar to one another (small <span class="math inline">\(\sigma_{\varepsilon}\)</span>) but groups are very different (high <span class="math inline">\(\sigma_{\alpha}\)</span>), the ICC is very high.</p>
<p>The existence of grouping of residuals is very important in ANOVA, as it means that independence is violated, which calls for the use of mixed model.</p>
<p>But … this is a totally different story …</p>
</div>

            </div>
        </div>
    </div>
    <div class="column is-3">
        <div class="card">
    <div class="card-content">
        <h1 class="title is-5">Tags</h1>
        <div class="tags">
        
            <span class="tag"><a href="/tags/asreml">asreml</a></span>
        
            <span class="tag"><a href="/tags/blogdown">blogdown</a></span>
        
            <span class="tag"><a href="/tags/correlation">correlation</a></span>
        
            <span class="tag"><a href="/tags/delta_method">delta_method</a></span>
        
            <span class="tag"><a href="/tags/drm">drm</a></span>
        
            <span class="tag"><a href="/tags/error_propagation">error_propagation</a></span>
        
            <span class="tag"><a href="/tags/linear_models">linear_models</a></span>
        
            <span class="tag"><a href="/tags/mixed_models">mixed_models</a></span>
        
            <span class="tag"><a href="/tags/nonlinear_regression">nonlinear_regression</a></span>
        
            <span class="tag"><a href="/tags/r">r</a></span>
        
            <span class="tag"><a href="/tags/variance">variance</a></span>
        
        </div>          
    </div>
</div><br>
        <div class="card">
    <div class="card-content">
        <h1 class="title is-5">Recent posts</h1>
        
            <h1><a href="/2019/stat_general_thedeltamethod/">How do we combine errors, in biology? The delta method</a></h1>
            <time class="has-text-grey-light is-size-7">25 May 2019</time>
        
            <h1><a href="/2019/stat_general_correlationindependence2/">Dealing with correlation in designed field experiments: part II</a></h1>
            <time class="has-text-grey-light is-size-7">10 May 2019</time>
        
            <h1><a href="/2019/stat_general_correlationindependence1/">Dealing with correlation in designed field experiments: part I</a></h1>
            <time class="has-text-grey-light is-size-7">30 April 2019</time>
        
            <h1><a href="/2019/stat_general_errorpropagation/">How do we combine errors? The linear case</a></h1>
            <time class="has-text-grey-light is-size-7">15 April 2019</time>
        
            <h1><a href="/2019/r_shapingdata/">Some everyday data tasks: a few hints with R</a></h1>
            <time class="has-text-grey-light is-size-7">27 March 2019</time>
        
    </div>
</div>
    <br>
        <div class="card">
    <div class="card-content">
        <h1 class="title is-5">Archives</h1>
        
            <a href="/archives/2019">2019</a> (7)<br>
        
            <a href="/archives/2018">2018</a> (2)<br>
        
            <a href="/archives/2014">2014</a> (1)<br>
        
    </div>
</div>

    </div>
</div>


    </div>
</div>
<footer class="footer has-background-grey-darker has-text-white">
    <div class="content has-text-centered">
        <p>
             <span class="icon is-large"><a href="mailto:andrea.onofri@unipg.it" class="mysocial"><i class="far fa-envelope-open fa-3x"></i></a></span>&nbsp;&nbsp;
            <span class="icon is-large"><a href="https://github.com/OnofriAndreaPG/" class="mysocial"><i class="fab fa-github fa-3x"></i></a></span>&nbsp;&nbsp;
                       <span class="icon is-large"><a href="https://www.r.project.org/" class="mysocial"><i class="fab fa-r-project fa-3x"></i></a></span>&nbsp;&nbsp;

            <br><br>
            Copyright &copy; The broken bridge between biologists and statisticians, 2019 - Theme by <a href="https://jeffprod.com" class="mysocial">JeffProd.com</a>
            - <a class="mysocial" href="/aboutThis">About this site</a>
        </p>
    </div>
</footer>

<script defer src="https://use.fontawesome.com/releases/v5.1.0/js/all.js"></script>
</body>
</html>
