<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Capitolo 14 Appendix 3: Per chi vuole approfondire un po’… | Metodologia statistica per le scienze agrarie</title>
  <meta name="description" content="Appunti dai corsi S.I.A.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Capitolo 14 Appendix 3: Per chi vuole approfondire un po’… | Metodologia statistica per le scienze agrarie" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Appunti dai corsi S.I.A." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capitolo 14 Appendix 3: Per chi vuole approfondire un po’… | Metodologia statistica per le scienze agrarie" />
  
  <meta name="twitter:description" content="Appunti dai corsi S.I.A." />
  

<meta name="author" content="Andrea Onofri e Dario Sacco">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="appendix-2-richiami-di-statistica-descrittiva.html">

<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global Site Tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131792052-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-131792052-1');
  </script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduzione</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#organizzazione-del-testo"><i class="fa fa-check"></i>Organizzazione del testo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#gli-autori"><i class="fa fa-check"></i>Gli autori</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#pre-requisiti"><i class="fa fa-check"></i>Pre-requisiti</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html"><i class="fa fa-check"></i><b>1</b> Scienza e pseudo-scienza</a><ul>
<li class="chapter" data-level="1.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#introduzione-1"><i class="fa fa-check"></i><b>1.1</b> Introduzione</a><ul>
<li class="chapter" data-level="1.1.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#cosa-e-quindi-una-prova-scientifica"><i class="fa fa-check"></i><b>1.1.1</b> Cosa è quindi una prova scientifica?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#esperimenti-buoni-e-cattivi"><i class="fa fa-check"></i><b>1.2</b> Esperimenti buoni e cattivi!</a><ul>
<li class="chapter" data-level="1.2.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#lerrore-sperimentale"><i class="fa fa-check"></i><b>1.2.1</b> L’errore sperimentale</a></li>
<li class="chapter" data-level="1.2.2" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#il-campionamento"><i class="fa fa-check"></i><b>1.2.2</b> Il campionamento</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#scienza-metodo"><i class="fa fa-check"></i><b>1.3</b> Scienza = metodo</a></li>
<li class="chapter" data-level="1.4" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#chi-valuta-se-un-esperimento-e-attendibile"><i class="fa fa-check"></i><b>1.4</b> Chi valuta se un esperimento è attendibile?</a></li>
<li class="chapter" data-level="1.5" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#il-metodo-sperimentale"><i class="fa fa-check"></i><b>1.5</b> Il metodo sperimentale</a></li>
<li class="chapter" data-level="1.6" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#metodi-sperimentali-validi-ed-invalidi"><i class="fa fa-check"></i><b>1.6</b> Metodi sperimentali validi ed invalidi</a><ul>
<li class="chapter" data-level="1.6.1" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#primo-esperimento"><i class="fa fa-check"></i><b>1.6.1</b> Primo esperimento</a></li>
<li class="chapter" data-level="1.6.2" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#secondo-esperimento"><i class="fa fa-check"></i><b>1.6.2</b> Secondo esperimento</a></li>
<li class="chapter" data-level="1.6.3" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#terzo-esperimento"><i class="fa fa-check"></i><b>1.6.3</b> Terzo esperimento</a></li>
<li class="chapter" data-level="1.6.4" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#quarto-esperimento-quello-buono"><i class="fa fa-check"></i><b>1.6.4</b> Quarto esperimento: quello buono</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#incertezza-residua"><i class="fa fa-check"></i><b>1.7</b> Incertezza residua</a></li>
<li class="chapter" data-level="1.8" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#il-ruolo-della-statistica"><i class="fa fa-check"></i><b>1.8</b> Il ruolo della statistica</a></li>
<li class="chapter" data-level="1.9" data-path="scienza-e-pseudo-scienza.html"><a href="scienza-e-pseudo-scienza.html#conclusioni"><i class="fa fa-check"></i><b>1.9</b> Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html"><i class="fa fa-check"></i><b>2</b> Esperimenti validi ed invalidi</a><ul>
<li class="chapter" data-level="2.1" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#definizioni"><i class="fa fa-check"></i><b>2.1</b> Definizioni</a></li>
<li class="chapter" data-level="2.2" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#elementi-fondamentali-del-disegno-sperimentale"><i class="fa fa-check"></i><b>2.2</b> Elementi fondamentali del disegno sperimentale</a><ul>
<li class="chapter" data-level="2.2.1" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#primo-elemento-controllo-degli-errori"><i class="fa fa-check"></i><b>2.2.1</b> Primo elemento: controllo degli errori</a></li>
<li class="chapter" data-level="2.2.2" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#secondo-elemento-replicazione"><i class="fa fa-check"></i><b>2.2.2</b> Secondo elemento: replicazione</a></li>
<li class="chapter" data-level="2.2.3" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#terzo-elemento-randomizzazione"><i class="fa fa-check"></i><b>2.2.3</b> Terzo elemento: randomizzazione</a></li>
<li class="chapter" data-level="2.2.4" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#esperimenti-non-validi"><i class="fa fa-check"></i><b>2.2.4</b> Esperimenti non validi</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#conclusione"><i class="fa fa-check"></i><b>2.3</b> Conclusione</a></li>
<li class="chapter" data-level="2.4" data-path="esperimenti-validi-ed-invalidi.html"><a href="esperimenti-validi-ed-invalidi.html#per-approfondimenti"><i class="fa fa-check"></i><b>2.4</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html"><i class="fa fa-check"></i><b>3</b> Progettare un esperimento</a><ul>
<li class="chapter" data-level="3.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#ipotesi-scientifica-rightarrow-obiettivo-dellesperimento"><i class="fa fa-check"></i><b>3.1</b> Ipotesi scientifica <span class="math inline">\(\rightarrow\)</span> obiettivo dell’esperimento</a></li>
<li class="chapter" data-level="3.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#identificazione-dei-fattori-sperimentali"><i class="fa fa-check"></i><b>3.2</b> Identificazione dei fattori sperimentali</a><ul>
<li class="chapter" data-level="3.2.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#esperimenti-multifattoriali"><i class="fa fa-check"></i><b>3.2.1</b> Esperimenti (multi)fattoriali</a></li>
<li class="chapter" data-level="3.2.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#aggiungere-un-controllo"><i class="fa fa-check"></i><b>3.2.2</b> Aggiungere un controllo?</a></li>
<li class="chapter" data-level="3.2.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#fattori-sperimentali-di-trattamento-e-di-blocco"><i class="fa fa-check"></i><b>3.2.3</b> Fattori sperimentali di trattamento e di blocco</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#identificazione-delle-unita-sperimentali"><i class="fa fa-check"></i><b>3.3</b> Identificazione delle unità sperimentali</a><ul>
<li class="chapter" data-level="3.3.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#cornice-di-campionamento"><i class="fa fa-check"></i><b>3.3.1</b> Cornice di campionamento</a></li>
<li class="chapter" data-level="3.3.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#scelta-delle-unita-sperimentali"><i class="fa fa-check"></i><b>3.3.2</b> Scelta delle unità sperimentali</a></li>
<li class="chapter" data-level="3.3.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#unita-sperimentali-in-campo-le-parcelle"><i class="fa fa-check"></i><b>3.3.3</b> Unità sperimentali in campo: le parcelle</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#allocazione-dei-trattamenti-e-disegno-sperimentale"><i class="fa fa-check"></i><b>3.4</b> Allocazione dei trattamenti e disegno sperimentale</a><ul>
<li class="chapter" data-level="3.4.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#disegni-completamente-randomizzati"><i class="fa fa-check"></i><b>3.4.1</b> Disegni completamente randomizzati</a></li>
<li class="chapter" data-level="3.4.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#disegni-a-blocchi-randomizzati"><i class="fa fa-check"></i><b>3.4.2</b> Disegni a blocchi randomizzati</a></li>
<li class="chapter" data-level="3.4.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#disegni-a-quadrato-latino"><i class="fa fa-check"></i><b>3.4.3</b> Disegni a quadrato latino</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#scelta-delle-variabili-da-rilevare"><i class="fa fa-check"></i><b>3.5</b> Scelta delle variabili da rilevare</a><ul>
<li class="chapter" data-level="3.5.1" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-nominali-categoriche"><i class="fa fa-check"></i><b>3.5.1</b> Variabili nominali (categoriche)</a></li>
<li class="chapter" data-level="3.5.2" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-ordinali"><i class="fa fa-check"></i><b>3.5.2</b> Variabili ordinali</a></li>
<li class="chapter" data-level="3.5.3" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-quantitative-discrete"><i class="fa fa-check"></i><b>3.5.3</b> Variabili quantitative discrete</a></li>
<li class="chapter" data-level="3.5.4" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-quantitative-continue"><i class="fa fa-check"></i><b>3.5.4</b> Variabili quantitative continue</a></li>
<li class="chapter" data-level="3.5.5" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#rilievi-visivi-e-sensoriali"><i class="fa fa-check"></i><b>3.5.5</b> Rilievi visivi e sensoriali</a></li>
<li class="chapter" data-level="3.5.6" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#variabili-di-confondimento"><i class="fa fa-check"></i><b>3.5.6</b> Variabili di confondimento</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#impianto-delle-prove"><i class="fa fa-check"></i><b>3.6</b> Impianto delle prove</a></li>
<li class="chapter" data-level="3.7" data-path="progettare-un-esperimento.html"><a href="progettare-un-esperimento.html#scrivere-un-progettoreport-di-ricerca-semplici-indicazioni"><i class="fa fa-check"></i><b>3.7</b> Scrivere un progetto/report di ricerca: semplici indicazioni</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html"><i class="fa fa-check"></i><b>4</b> Modelli matematici a ‘due facce’</a><ul>
<li class="chapter" data-level="4.1" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#verita-vera-e-modelli-deterministici"><i class="fa fa-check"></i><b>4.1</b> Verità ‘vera’ e modelli deterministici</a></li>
<li class="chapter" data-level="4.2" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#qualche-esempio-di-modello-deterministico"><i class="fa fa-check"></i><b>4.2</b> Qualche esempio di modello deterministico</a></li>
<li class="chapter" data-level="4.3" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#genesi-deterministica-delle-osservazioni-sperimentali"><i class="fa fa-check"></i><b>4.3</b> Genesi deterministica delle osservazioni sperimentali</a></li>
<li class="chapter" data-level="4.4" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#errore-sperimentale-e-modelli-stocastici"><i class="fa fa-check"></i><b>4.4</b> Errore sperimentale e modelli stocastici</a><ul>
<li class="chapter" data-level="4.4.1" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#funzioni-di-probabilita"><i class="fa fa-check"></i><b>4.4.1</b> Funzioni di probabilità</a></li>
<li class="chapter" data-level="4.4.2" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#funzioni-di-densita"><i class="fa fa-check"></i><b>4.4.2</b> Funzioni di densità</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#la-distribuzione-normale-curva-di-gauss"><i class="fa fa-check"></i><b>4.5</b> La distribuzione normale (curva di Gauss)</a></li>
<li class="chapter" data-level="4.6" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#modelli-a-due-facce"><i class="fa fa-check"></i><b>4.6</b> Modelli ‘a due facce’</a><ul>
<li class="chapter" data-level="4.6.1" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-1"><i class="fa fa-check"></i><b>4.6.1</b> Esercizio 1</a></li>
<li class="chapter" data-level="4.6.2" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-2"><i class="fa fa-check"></i><b>4.6.2</b> Esercizio 2</a></li>
<li class="chapter" data-level="4.6.3" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-3"><i class="fa fa-check"></i><b>4.6.3</b> Esercizio 3</a></li>
<li class="chapter" data-level="4.6.4" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-4"><i class="fa fa-check"></i><b>4.6.4</b> Esercizio 4</a></li>
<li class="chapter" data-level="4.6.5" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-5"><i class="fa fa-check"></i><b>4.6.5</b> Esercizio 5</a></li>
<li class="chapter" data-level="4.6.6" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-6"><i class="fa fa-check"></i><b>4.6.6</b> Esercizio 6</a></li>
<li class="chapter" data-level="4.6.7" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#esercizio-7"><i class="fa fa-check"></i><b>4.6.7</b> Esercizio 7</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#altri-modelli-stocastici-di-interesse-per-lo-sperimentatore"><i class="fa fa-check"></i><b>4.7</b> Altri modelli stocastici di interesse per lo sperimentatore</a></li>
<li class="chapter" data-level="4.8" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#e-allora"><i class="fa fa-check"></i><b>4.8</b> E allora?</a></li>
<li class="chapter" data-level="4.9" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#le-simulazioni-monte-carlo"><i class="fa fa-check"></i><b>4.9</b> Le simulazioni Monte Carlo</a></li>
<li class="chapter" data-level="4.10" data-path="modelli-matematici-a-due-facce.html"><a href="modelli-matematici-a-due-facce.html#analisi-dei-dati-e-model-fitting"><i class="fa fa-check"></i><b>4.10</b> Analisi dei dati e ‘model fitting’</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html"><i class="fa fa-check"></i><b>5</b> Esperimenti, stime ed incertezza</a><ul>
<li class="chapter" data-level="5.1" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#lanalisi-dei-dati-gli-ingredienti-fondamentali"><i class="fa fa-check"></i><b>5.1</b> L’analisi dei dati: gli ‘ingredienti’ fondamentali</a></li>
<li class="chapter" data-level="5.2" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#esempio-una-soluzione-erbicida"><i class="fa fa-check"></i><b>5.2</b> Esempio: una soluzione erbicida</a><ul>
<li class="chapter" data-level="5.2.1" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#il-modello-dei-dati"><i class="fa fa-check"></i><b>5.2.1</b> Il modello dei dati</a></li>
<li class="chapter" data-level="5.2.2" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#analisi-dei-dati-stima-dei-parametri"><i class="fa fa-check"></i><b>5.2.2</b> Analisi dei dati: stima dei parametri</a></li>
<li class="chapter" data-level="5.2.3" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#la-sampling-distribution"><i class="fa fa-check"></i><b>5.2.3</b> La ‘sampling distribution’</a></li>
<li class="chapter" data-level="5.2.4" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#lerrore-standard"><i class="fa fa-check"></i><b>5.2.4</b> L’errore standard</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#riepilogo-1-caratterizzare-lincertezza-di-un-esperimento"><i class="fa fa-check"></i><b>5.3</b> Riepilogo 1: Caratterizzare l’incertezza di un esperimento</a></li>
<li class="chapter" data-level="5.4" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#lintervallo-di-confidenza"><i class="fa fa-check"></i><b>5.4</b> L’intervallo di confidenza</a></li>
<li class="chapter" data-level="5.5" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#qual-e-il-senso-dellintervallo-di-confidenza"><i class="fa fa-check"></i><b>5.5</b> Qual è il senso dell’intervallo di confidenza?</a></li>
<li class="chapter" data-level="5.6" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#come-presentare-i-risultati-degli-esperimenti"><i class="fa fa-check"></i><b>5.6</b> Come presentare i risultati degli esperimenti</a></li>
<li class="chapter" data-level="5.7" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#alcune-precisazioni"><i class="fa fa-check"></i><b>5.7</b> Alcune precisazioni</a><ul>
<li class="chapter" data-level="5.7.1" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#campioni-numerosi-e-non"><i class="fa fa-check"></i><b>5.7.1</b> Campioni numerosi e non</a></li>
<li class="chapter" data-level="5.7.2" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#popolazioni-gaussiane-e-non"><i class="fa fa-check"></i><b>5.7.2</b> Popolazioni gaussiane e non</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#analisi-statistica-dei-dati-riassunto-del-percorso-logico"><i class="fa fa-check"></i><b>5.8</b> Analisi statistica dei dati: riassunto del percorso logico</a></li>
<li class="chapter" data-level="5.9" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#da-ricordare"><i class="fa fa-check"></i><b>5.9</b> Da ricordare</a></li>
<li class="chapter" data-level="5.10" data-path="esperimenti-stime-ed-incertezza.html"><a href="esperimenti-stime-ed-incertezza.html#esercizi"><i class="fa fa-check"></i><b>5.10</b> Esercizi</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html"><i class="fa fa-check"></i><b>6</b> Breve introduzione al test d’ipotesi</a><ul>
<li class="chapter" data-level="6.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-una-media-osservata-e-una-media-teorica"><i class="fa fa-check"></i><b>6.1</b> Confronto tra una media osservata e una media teorica</a><ul>
<li class="chapter" data-level="6.1.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#simulazione-monte-carlo"><i class="fa fa-check"></i><b>6.1.1</b> Simulazione Monte Carlo</a></li>
<li class="chapter" data-level="6.1.2" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#soluzione-formale"><i class="fa fa-check"></i><b>6.1.2</b> Soluzione formale</a></li>
<li class="chapter" data-level="6.1.3" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#interpretazione-del-p-level"><i class="fa fa-check"></i><b>6.1.3</b> Interpretazione del P-level</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-medie-il-test-t-di-student"><i class="fa fa-check"></i><b>6.2</b> Confronto tra due medie: il test t di Student</a></li>
<li class="chapter" data-level="6.3" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-proporzioni-il-test-chi2"><i class="fa fa-check"></i><b>6.3</b> Confronto tra due proporzioni: il test <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="6.4" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#conclusioni-1"><i class="fa fa-check"></i><b>6.4</b> Conclusioni</a></li>
<li class="chapter" data-level="6.5" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#riepilogo"><i class="fa fa-check"></i><b>6.5</b> Riepilogo</a></li>
<li class="chapter" data-level="6.6" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#esercizi-1"><i class="fa fa-check"></i><b>6.6</b> Esercizi</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html"><i class="fa fa-check"></i><b>7</b> Una variabile indipendente categorica: ANOVA ad una via</a><ul>
<li class="chapter" data-level="7.1" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#la-situazione-sperimentale"><i class="fa fa-check"></i><b>7.1</b> La situazione sperimentale</a></li>
<li class="chapter" data-level="7.2" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#la-verita-vera-la-popolazione"><i class="fa fa-check"></i><b>7.2</b> La verità ‘vera’ (la popolazione)</a></li>
<li class="chapter" data-level="7.3" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#esecuzione-dellesperimento"><i class="fa fa-check"></i><b>7.3</b> Esecuzione dell’esperimento</a></li>
<li class="chapter" data-level="7.4" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#analisi-dei-dati"><i class="fa fa-check"></i><b>7.4</b> Analisi dei dati</a><ul>
<li class="chapter" data-level="7.4.1" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#statistiche-descrittive"><i class="fa fa-check"></i><b>7.4.1</b> Statistiche descrittive</a></li>
<li class="chapter" data-level="7.4.2" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#stima-dei-parametri"><i class="fa fa-check"></i><b>7.4.2</b> Stima dei parametri</a></li>
<li class="chapter" data-level="7.4.3" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#stima-della-varianza"><i class="fa fa-check"></i><b>7.4.3</b> Stima della varianza</a></li>
<li class="chapter" data-level="7.4.4" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#effetto-del-trattamento"><i class="fa fa-check"></i><b>7.4.4</b> Effetto del trattamento</a></li>
<li class="chapter" data-level="7.4.5" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#test-dipotesi"><i class="fa fa-check"></i><b>7.4.5</b> Test d’ipotesi</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#per-approfondimenti-1"><i class="fa fa-check"></i><b>7.5</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><i class="fa fa-check"></i><b>8</b> La verifica delle assunzioni di base: metodi diagnostici</a><ul>
<li class="chapter" data-level="8.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#introduzione-2"><i class="fa fa-check"></i><b>8.1</b> Introduzione</a></li>
<li class="chapter" data-level="8.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#procedure-diagnostiche"><i class="fa fa-check"></i><b>8.2</b> Procedure diagnostiche</a></li>
<li class="chapter" data-level="8.3" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#analisi-grafica-dei-residui"><i class="fa fa-check"></i><b>8.3</b> Analisi grafica dei residui</a><ul>
<li class="chapter" data-level="8.3.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#grafico-dei-residui-contro-i-valori-attesi"><i class="fa fa-check"></i><b>8.3.1</b> Grafico dei residui contro i valori attesi</a></li>
<li class="chapter" data-level="8.3.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#qq-plot"><i class="fa fa-check"></i><b>8.3.2</b> QQ-plot</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#altri-strumenti-diagnostici"><i class="fa fa-check"></i><b>8.4</b> Altri strumenti diagnostici</a></li>
<li class="chapter" data-level="8.5" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#risultati-contraddittori"><i class="fa fa-check"></i><b>8.5</b> Risultati contraddittori</a></li>
<li class="chapter" data-level="8.6" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#terapia"><i class="fa fa-check"></i><b>8.6</b> ‘Terapia’</a><ul>
<li class="chapter" data-level="8.6.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#correzionerimozione-degli-outliers"><i class="fa fa-check"></i><b>8.6.1</b> Correzione/Rimozione degli outliers</a></li>
<li class="chapter" data-level="8.6.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#correzione-del-modello"><i class="fa fa-check"></i><b>8.6.2</b> Correzione del modello</a></li>
<li class="chapter" data-level="8.6.3" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#non-normalita-dei-residui-ed-eterogeneita-delle-varianze"><i class="fa fa-check"></i><b>8.6.3</b> Non-normalità dei residui ed eterogeneità delle varianze</a></li>
<li class="chapter" data-level="8.6.4" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#la-procedura-di-box-e-cox"><i class="fa fa-check"></i><b>8.6.4</b> La procedura di Box e Cox</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#referenze-bibliografiche-per-approfondimenti"><i class="fa fa-check"></i><b>8.7</b> Referenze bibliografiche per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html"><i class="fa fa-check"></i><b>9</b> Modelli lineari con più variabili indipendenti</a><ul>
<li class="chapter" data-level="9.1" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html#introduzione-3"><i class="fa fa-check"></i><b>9.1</b> Introduzione</a></li>
<li class="chapter" data-level="9.2" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html#anova-a-blocchi-randomizzati"><i class="fa fa-check"></i><b>9.2</b> ANOVA a blocchi randomizzati</a></li>
<li class="chapter" data-level="9.3" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html#anova-a-quadrato-latino"><i class="fa fa-check"></i><b>9.3</b> ANOVA a quadrato latino</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html"><i class="fa fa-check"></i><b>10</b> Contrasti e confronti multipli con R</a><ul>
<li class="chapter" data-level="10.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#introduzione-4"><i class="fa fa-check"></i><b>10.1</b> Introduzione</a></li>
<li class="chapter" data-level="10.2" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#esempio"><i class="fa fa-check"></i><b>10.2</b> Esempio</a></li>
<li class="chapter" data-level="10.3" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-contrasti"><i class="fa fa-check"></i><b>10.3</b> I contrasti</a><ul>
<li class="chapter" data-level="10.3.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#varianza-del-contrasto-e-intervalli-di-confidenza"><i class="fa fa-check"></i><b>10.3.1</b> Varianza del contrasto e intervalli di confidenza</a></li>
<li class="chapter" data-level="10.3.2" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#significativita-del-contrasto-e-intervalli-di-confidenza"><i class="fa fa-check"></i><b>10.3.2</b> Significatività del contrasto e intervalli di confidenza</a></li>
<li class="chapter" data-level="10.3.3" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-contrasti-con-r"><i class="fa fa-check"></i><b>10.3.3</b> I contrasti con R</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-confronti-multipli-a-coppie-pairwise-comparisons"><i class="fa fa-check"></i><b>10.4</b> I confronti multipli a coppie (pairwise comparisons)</a></li>
<li class="chapter" data-level="10.5" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#display-a-lettere"><i class="fa fa-check"></i><b>10.5</b> Display a lettere</a></li>
<li class="chapter" data-level="10.6" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#problemi-di-molteplicita-tassi-di-errore-per-confronto-e-per-esperimento"><i class="fa fa-check"></i><b>10.6</b> Problemi di molteplicità: tassi di errore per confronto e per esperimento</a><ul>
<li class="chapter" data-level="10.6.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#correzione-per-la-molteplicita"><i class="fa fa-check"></i><b>10.6.1</b> Correzione per la molteplicità</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#intervalli-di-confidenza-simultanei"><i class="fa fa-check"></i><b>10.7</b> Intervalli di confidenza simultanei</a></li>
<li class="chapter" data-level="10.8" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#e-le-classiche-procedure-di-confronto-multiplo"><i class="fa fa-check"></i><b>10.8</b> E le classiche procedure di confronto multiplo?</a></li>
<li class="chapter" data-level="10.9" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#consigli-pratici"><i class="fa fa-check"></i><b>10.9</b> Consigli pratici</a></li>
<li class="chapter" data-level="10.10" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#referenze-bibliografiche"><i class="fa fa-check"></i><b>10.10</b> Referenze bibliografiche</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html"><i class="fa fa-check"></i><b>11</b> Analisi della varianza (ANOVA) a due vie</a><ul>
<li class="chapter" data-level="11.1" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#il-concetto-di-interazione"><i class="fa fa-check"></i><b>11.1</b> Il concetto di ’interazione’</a></li>
<li class="chapter" data-level="11.2" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#tipi-di-interazione"><i class="fa fa-check"></i><b>11.2</b> Tipi di interazione</a></li>
<li class="chapter" data-level="11.3" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#descrizione-del-caso-studio"><i class="fa fa-check"></i><b>11.3</b> Descrizione del caso studio</a></li>
<li class="chapter" data-level="11.4" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#analisi-dei-dati-1"><i class="fa fa-check"></i><b>11.4</b> Analisi dei dati</a></li>
<li class="chapter" data-level="11.5" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#stima-dei-parametri-1"><i class="fa fa-check"></i><b>11.5</b> Stima dei parametri</a></li>
<li class="chapter" data-level="11.6" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#verifica-delle-assunzioni-di-base"><i class="fa fa-check"></i><b>11.6</b> Verifica delle assunzioni di base</a></li>
<li class="chapter" data-level="11.7" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#scomposizione-delle-varianze"><i class="fa fa-check"></i><b>11.7</b> Scomposizione delle varianze</a></li>
<li class="chapter" data-level="11.8" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#funzioni-dei-parametri"><i class="fa fa-check"></i><b>11.8</b> Funzioni dei parametri</a><ul>
<li class="chapter" data-level="11.8.1" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#medie-delle-combinazioni-lavorazioni-x-diserbo"><i class="fa fa-check"></i><b>11.8.1</b> Medie delle combinazioni ‘lavorazioni x diserbo’</a></li>
</ul></li>
<li class="chapter" data-level="11.9" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#calcolo-degli-errori-standard-sem-e-sed"><i class="fa fa-check"></i><b>11.9</b> Calcolo degli errori standard (SEM e SED)</a></li>
<li class="chapter" data-level="11.10" data-path="analisi-della-varianza-anova-a-due-vie.html"><a href="analisi-della-varianza-anova-a-due-vie.html#contrasti-medie-attese-e-confronti-multipli-con-r"><i class="fa fa-check"></i><b>11.10</b> Contrasti, medie attese e confronti multipli con R</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html"><i class="fa fa-check"></i><b>12</b> La regressione lineare semplice</a><ul>
<li class="chapter" data-level="12.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#introduzione-5"><i class="fa fa-check"></i><b>12.1</b> Introduzione</a></li>
<li class="chapter" data-level="12.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#esempio-1"><i class="fa fa-check"></i><b>12.2</b> Esempio</a></li>
<li class="chapter" data-level="12.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#stima-dei-parametri-2"><i class="fa fa-check"></i><b>12.3</b> Stima dei parametri</a></li>
<li class="chapter" data-level="12.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-della-bonta-del-modello"><i class="fa fa-check"></i><b>12.4</b> Valutazione della bontà del modello</a><ul>
<li class="chapter" data-level="12.4.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-grafica"><i class="fa fa-check"></i><b>12.4.1</b> Valutazione grafica</a></li>
<li class="chapter" data-level="12.4.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#errori-standard-dei-parametri"><i class="fa fa-check"></i><b>12.4.2</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="12.4.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-mancanza-dadattamento"><i class="fa fa-check"></i><b>12.4.3</b> Test F per la mancanza d’adattamento</a></li>
<li class="chapter" data-level="12.4.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-bonta-di-adattamento-e-coefficiente-di-determinazione"><i class="fa fa-check"></i><b>12.4.4</b> Test F per la bontà di adattamento e coefficiente di determinazione</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#previsioni"><i class="fa fa-check"></i><b>12.5</b> Previsioni</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html"><i class="fa fa-check"></i><b>13</b> La regressione non-lineare</a><ul>
<li class="chapter" data-level="13.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#introduzione-6"><i class="fa fa-check"></i><b>13.1</b> Introduzione</a></li>
<li class="chapter" data-level="13.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-1-1"><i class="fa fa-check"></i><b>13.2</b> Esempio 1</a><ul>
<li class="chapter" data-level="13.2.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#scelta-della-funzione"><i class="fa fa-check"></i><b>13.2.1</b> Scelta della funzione</a></li>
<li class="chapter" data-level="13.2.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#stima-dei-parametri-3"><i class="fa fa-check"></i><b>13.2.2</b> Stima dei parametri</a></li>
<li class="chapter" data-level="13.2.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#la-regressione-non-lineare-con-r"><i class="fa fa-check"></i><b>13.2.3</b> La regressione non-lineare con R</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#riparametrizzazione-delle-funzioni"><i class="fa fa-check"></i><b>13.3</b> Riparametrizzazione delle funzioni</a><ul>
<li class="chapter" data-level="13.3.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-2"><i class="fa fa-check"></i><b>13.3.1</b> Esempio 2</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#inferenze-statistiche-e-verifiche-delle-assunzioni-di-base"><i class="fa fa-check"></i><b>13.4</b> Inferenze statistiche e verifiche delle assunzioni di base</a><ul>
<li class="chapter" data-level="13.4.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#analisi-grafica-dei-residui-1"><i class="fa fa-check"></i><b>13.4.1</b> Analisi grafica dei residui</a></li>
<li class="chapter" data-level="13.4.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#test-f-per-la-mancanza-di-adattamento-approssimato"><i class="fa fa-check"></i><b>13.4.2</b> Test F per la mancanza di adattamento (approssimato)</a></li>
<li class="chapter" data-level="13.4.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#errori-standard-dei-parametri-1"><i class="fa fa-check"></i><b>13.4.3</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="13.4.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#coefficiente-di-determinazione"><i class="fa fa-check"></i><b>13.4.4</b> Coefficiente di determinazione</a></li>
<li class="chapter" data-level="13.4.5" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#coefficiente-di-determinazione-aggiustato"><i class="fa fa-check"></i><b>13.4.5</b> Coefficiente di determinazione aggiustato</a></li>
<li class="chapter" data-level="13.4.6" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#altre-statistiche"><i class="fa fa-check"></i><b>13.4.6</b> Altre statistiche</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#gestione-delle-situazioni-patologiche"><i class="fa fa-check"></i><b>13.5</b> Gestione delle situazioni ‘patologiche’</a><ul>
<li class="chapter" data-level="13.5.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-del-modello"><i class="fa fa-check"></i><b>13.5.1</b> Trasformazione del modello</a></li>
<li class="chapter" data-level="13.5.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-dei-dati"><i class="fa fa-check"></i><b>13.5.2</b> Trasformazione dei dati</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#funzioni-lineari-e-nonlineari-dei-parametri"><i class="fa fa-check"></i><b>13.6</b> Funzioni lineari e nonlineari dei parametri</a></li>
<li class="chapter" data-level="13.7" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#modelli-ancova"><i class="fa fa-check"></i><b>13.7</b> Modelli ANCOVA</a><ul>
<li class="chapter" data-level="13.7.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-3"><i class="fa fa-check"></i><b>13.7.1</b> Esempio 3</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#confronto-tra-modelli-alternativi"><i class="fa fa-check"></i><b>13.8</b> Confronto tra modelli alternativi</a><ul>
<li class="chapter" data-level="13.8.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#confronto-tra-modelli-non-nested"><i class="fa fa-check"></i><b>13.8.1</b> Confronto tra modelli non-nested</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#il-package-drc"><i class="fa fa-check"></i><b>13.9</b> Il package ‘drc’</a></li>
<li class="chapter" data-level="13.10" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#previsioni-1"><i class="fa fa-check"></i><b>13.10</b> Previsioni</a></li>
<li class="chapter" data-level="13.11" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#bibliografia"><i class="fa fa-check"></i><b>13.11</b> Bibliografia</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html"><i class="fa fa-check"></i>Appendix 1: breve introduzione ad R</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#cosa-e-r"><i class="fa fa-check"></i>Cosa è R?</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#oggetti-e-assegnazioni"><i class="fa fa-check"></i>Oggetti e assegnazioni</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#costanti-e-vettori"><i class="fa fa-check"></i>Costanti e vettori</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#matrici"><i class="fa fa-check"></i>Matrici</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#operazioni-ed-operatori"><i class="fa fa-check"></i>Operazioni ed operatori</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#funzioni-ed-argomenti"><i class="fa fa-check"></i>Funzioni ed argomenti</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#dataframe"><i class="fa fa-check"></i>Dataframe</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#quale-oggetto-sto-utilizzando"><i class="fa fa-check"></i>Quale oggetto sto utilizzando?</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#consigli-per-limmissione-di-dati-sperimentali"><i class="fa fa-check"></i>Consigli per l’immissione di dati sperimentali</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#immissione-manuale-di-dati"><i class="fa fa-check"></i>Immissione manuale di dati</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#immissione-di-numeri-progressivi"><i class="fa fa-check"></i>Immissione di numeri progressivi</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#immissione-dei-codici-delle-tesi-e-dei-blocchi"><i class="fa fa-check"></i>Immissione dei codici delle tesi e dei blocchi</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#leggere-e-salvare-dati-esterni"><i class="fa fa-check"></i>Leggere e salvare dati esterni</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#alcune-operazioni-comuni-sul-dataset"><i class="fa fa-check"></i>Alcune operazioni comuni sul dataset</a><ul>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#selezionare-un-subset-di-dati"><i class="fa fa-check"></i>Selezionare un subset di dati</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#ordinare-un-vettore-o-un-dataframe"><i class="fa fa-check"></i>Ordinare un vettore o un dataframe</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#workspace"><i class="fa fa-check"></i>Workspace</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#script-o-programmi"><i class="fa fa-check"></i>Script o programmi</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#interrogazione-di-oggetti"><i class="fa fa-check"></i>Interrogazione di oggetti</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#altre-funzioni-matriciali"><i class="fa fa-check"></i>Altre funzioni matriciali</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#cenni-sulle-funzionalita-grafiche-in-r"><i class="fa fa-check"></i>Cenni sulle funzionalità grafiche in R</a></li>
<li class="chapter" data-level="" data-path="appendix-1-breve-introduzione-ad-r.html"><a href="appendix-1-breve-introduzione-ad-r.html#per-approfondimenti-2"><i class="fa fa-check"></i>Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html"><i class="fa fa-check"></i>Appendix 2: richiami di statistica descrittiva</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#le-variabili-quantitative-analisi-chimiche-e-altre-misurazioni-fondamentali"><i class="fa fa-check"></i>Le variabili quantitative: analisi chimiche e altre misurazioni fondamentali</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#indicatori-di-tendenza-centrale"><i class="fa fa-check"></i>Indicatori di tendenza centrale</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#indicatori-di-variabilita"><i class="fa fa-check"></i>Indicatori di variabilità</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#arrotondamenti"><i class="fa fa-check"></i>Arrotondamenti</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#descrizione-dei-sottogruppi"><i class="fa fa-check"></i>Descrizione dei sottogruppi</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#distribuzioni-di-frequenza-e-classamento"><i class="fa fa-check"></i>Distribuzioni di frequenza e classamento</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#statistiche-descrittive-per-le-distribuzioni-di-frequenza"><i class="fa fa-check"></i>Statistiche descrittive per le distribuzioni di frequenza</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#distribuzioni-di-frequenza-bivariate-le-tabelle-di-contingenza"><i class="fa fa-check"></i>Distribuzioni di frequenza bivariate: le tabelle di contingenza</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#connessione"><i class="fa fa-check"></i>Connessione</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#correlazione"><i class="fa fa-check"></i>Correlazione</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#esercizi-2"><i class="fa fa-check"></i>Esercizi</a><ul>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#esercizio-1-1"><i class="fa fa-check"></i>Esercizio 1</a></li>
<li class="chapter" data-level="" data-path="appendix-2-richiami-di-statistica-descrittiva.html"><a href="appendix-2-richiami-di-statistica-descrittiva.html#esercizio-2-1"><i class="fa fa-check"></i>Esercizio 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html"><i class="fa fa-check"></i><b>14</b> Appendix 3: Per chi vuole approfondire un po’…</a><ul>
<li class="chapter" data-level="14.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-3-progettare-un-esperimento"><i class="fa fa-check"></i><b>14.1</b> Capitolo 3: Progettare un esperimento</a><ul>
<li class="chapter" data-level="14.1.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#organizzare-un-esperimento-di-diserbo-chimico"><i class="fa fa-check"></i><b>14.1.1</b> Organizzare un esperimento di diserbo chimico</a></li>
<li class="chapter" data-level="14.1.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#organizzare-un-esperimento-di-confronto-varietale"><i class="fa fa-check"></i><b>14.1.2</b> Organizzare un esperimento di confronto varietale</a></li>
<li class="chapter" data-level="14.1.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#organizzare-un-esperimento-fattoriale"><i class="fa fa-check"></i><b>14.1.3</b> Organizzare un esperimento fattoriale</a></li>
<li class="chapter" data-level="14.1.4" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#organizzare-un-esperimento-con-una-coltura-poliennale"><i class="fa fa-check"></i><b>14.1.4</b> Organizzare un esperimento con una coltura poliennale</a></li>
<li class="chapter" data-level="14.1.5" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#utilizzare-r-per-disegnare-gli-esperimenti"><i class="fa fa-check"></i><b>14.1.5</b> Utilizzare R per disegnare gli esperimenti</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-4-modelli-matematici-a-due-facce"><i class="fa fa-check"></i><b>14.2</b> Capitolo 4: Modelli matematici a ‘due facce’</a><ul>
<li class="chapter" data-level="14.2.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#la-distribuzione-t-di-student"><i class="fa fa-check"></i><b>14.2.1</b> La distribuzione t di Student</a></li>
<li class="chapter" data-level="14.2.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#la-distribuzione-f-di-fisher"><i class="fa fa-check"></i><b>14.2.2</b> La distribuzione F di Fisher</a></li>
<li class="chapter" data-level="14.2.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#la-distribuzione-binomiale"><i class="fa fa-check"></i><b>14.2.3</b> La distribuzione binomiale</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-5-esperimenti-stime-ed-incertezza"><i class="fa fa-check"></i><b>14.3</b> Capitolo 5: Esperimenti stime ed incertezza</a><ul>
<li class="chapter" data-level="14.3.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#e-realistico-lintervallo-di-confidenza"><i class="fa fa-check"></i><b>14.3.1</b> E’ realistico l’intervallo di confidenza?</a></li>
<li class="chapter" data-level="14.3.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#che-cosa-non-significa-lintervallo-di-confidenza"><i class="fa fa-check"></i><b>14.3.2</b> Che cosa NON significa l’intervallo di confidenza?</a></li>
<li class="chapter" data-level="14.3.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#popolazioni-non-gaussiane"><i class="fa fa-check"></i><b>14.3.3</b> Popolazioni non gaussiane</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#capitolo-6.-introduzione-al-test-dipotesi"><i class="fa fa-check"></i><b>14.4</b> Capitolo 6. Introduzione al test d’ipotesi</a><ul>
<li class="chapter" data-level="14.4.1" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#simulazione-monte-carlo-di-un-test-t-di-student"><i class="fa fa-check"></i><b>14.4.1</b> Simulazione Monte Carlo di un test t di Student</a></li>
<li class="chapter" data-level="14.4.2" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#tipologie-alternative-di-test-t-di-student"><i class="fa fa-check"></i><b>14.4.2</b> Tipologie alternative di test t di Student</a></li>
<li class="chapter" data-level="14.4.3" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#simulazione-di-un-test-di-chi-quadro"><i class="fa fa-check"></i><b>14.4.3</b> Simulazione di un test di chi quadro</a></li>
<li class="chapter" data-level="14.4.4" data-path="appendix-3-per-chi-vuole-approfondire-un-po.html"><a href="appendix-3-per-chi-vuole-approfondire-un-po.html#errori-di-prima-e-di-seconda-specie"><i class="fa fa-check"></i><b>14.4.4</b> Errori di prima e di seconda specie</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Metodologia statistica per le scienze agrarie</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendix-3-per-chi-vuole-approfondire-un-po" class="section level1">
<h1><span class="header-section-number">Capitolo 14</span> Appendix 3: Per chi vuole approfondire un po’…</h1>
<p>[Intro da fare]</p>
<div id="capitolo-3-progettare-un-esperimento" class="section level2">
<h2><span class="header-section-number">14.1</span> Capitolo 3: Progettare un esperimento</h2>
<div id="organizzare-un-esperimento-di-diserbo-chimico" class="section level3">
<h3><span class="header-section-number">14.1.1</span> Organizzare un esperimento di diserbo chimico</h3>
<p>Si suppone che gli erbicidi A, B e C siano più efficaci di D, E ed F verso <em>Solanum nigrum</em>, una comune pianta infestante delle colture di pomodoro. L’obiettivo generale della ricerca sarà quello di trovare un’efficace soluzione per l’eliminazione di <em>Solanum nigrum</em> dal pomodoro. Gli obiettivi specifici saranno:</p>
<ol style="list-style-type: decimal">
<li>valutare l’efficacia erbicida di A, B e C, confrontandola con quella di D, E ed F</li>
<li>valutare la selettività degli anzidetti erbicidi verso il pomodoro</li>
</ol>
<p>Il fattore sperimentale oggetto di studio sarà il diserbo del pomodoro, con 5 livelli inseriti in prova (6 trattamenti sperimentali): A, B, C, D, E ed F. Inoltre, si ritiene opportuno inserire in prova un testimone non trattato (NT), che ci permetterà di quantificare la percentuale di malerbe controllate. In totale, avremo quindi sette tesi sperimentali.</p>
<p>Questo esperimento verrà eseguito in vaso e, di conseguenza, potremo realizzare sei repliche con un disegno sperimentale a randomizzazione completa. La variabile rilevata, tre settimane dopo il trattamento, sarà il peso della biomassa presente in ogni vasetto.</p>
</div>
<div id="organizzare-un-esperimento-di-confronto-varietale" class="section level3">
<h3><span class="header-section-number">14.1.2</span> Organizzare un esperimento di confronto varietale</h3>
<p>L’ipotesi è che le varietà di girasole A, B e C non abbiano la stessa base genetica e quindi non siano tutte ugualmente produttive. L’obiettivo generale è quello di capire quale tra A, B e C sia più adatta alle condizioni pedoclimatiche della collina Umbra. Gli obiettivi specifici sono quelli di valutare:</p>
<ol style="list-style-type: decimal">
<li>produttività di A, B e C</li>
<li>stabilità produttiva di A, B e C</li>
</ol>
<p>Il fattore sperimentale in studio sarà la varietà di girasole con 3 livelli inclusi in prova (varietà A, B e C). Come testimone, inseriremo la varietà di riferimento per la zona (D). Dato che eseguiremo questa prova su un terreno nel quale vi sono due chiari gradienti di fertilità, disegneremo l’esperimento considerando due fattori di blocco: trasversale e longitudinale (spiego meglio tra poco…). Poiché dobbiamo valutare la stabilità produttiva, dovremo ripetere l’esperimento più volte (es. in tre anni diversi) e quindi avremo un secondo fattore sperimentale, incrociato con il primo.</p>
<p>Questo esperimento verrà realizzato in pieno campo, su parcelle di dimensioni 2 m x 8 m, seguendo uno schema sperimentale a quadrato latino con quattro repliche. Dovendo misurare la stabilità produttiva, cioè l’oscillazione di produzione da un ambiente all’altro, questa prova dovrà essere ripetuta in più anni (es. tre anni).</p>
<p>Per ognuno degli anni di prova, la mappa contiene una griglia 4 x 4, nella quale possiamo identificare quattro colonne e quattro righe. Dato che abbiamo presupposto l’esistenza di un gradiente trasversale e lungitudinale (tra righe e tra colonne), l’allocazione dei trattamenti dovrà esser fatta in modo che ognuno di essi si trovi su ogni riga e ogni colonna (<strong>Quadrato latino</strong>). Un’aspetto fondamentale è comunque quello di <strong>definire una diversa randomizzazione in ogni anno/località</strong>, per evitare che le stesse varietà siano sempre nelle stesse posizioni, che potrebbe dare origine a dubbi di confounding. La definizione delle randomizzazioni per il secondo e terzo anno è lasciata per esercizio.</p>
<p>Anche in questo caso potremo chiedere ad R di aiutarci a trovare la combinazione corretta (anche se questo potrebbe essere comodamente fatto a mano).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(agricolae)
## Warning: package &#39;agricolae&#39; was built under R version 3.5.2
## 
## Attaching package: &#39;agricolae&#39;
## The following object is masked from &#39;package:aomisc&#39;:
## 
##     AMMI
trt &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="st">&quot;D&quot;</span>)
designLS &lt;-<span class="st"> </span><span class="kw">design.lsd</span>(trt, <span class="dt">seed=</span><span class="dv">543</span>, <span class="dt">serie=</span><span class="dv">2</span>)
designLS<span class="op">$</span>book
##    plots row col trt
## 1    101   1   1   C
## 2    102   1   2   A
## 3    103   1   3   B
## 4    104   1   4   D
## 5    201   2   1   D
## 6    202   2   2   B
## 7    203   2   3   C
## 8    204   2   4   A
## 9    301   3   1   B
## 10   302   3   2   D
## 11   303   3   3   A
## 12   304   3   4   C
## 13   401   4   1   A
## 14   402   4   2   C
## 15   403   4   3   D
## 16   404   4   4   B</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName35"></span>
<img src="_images/Mappa2LS.png" alt="Schema sperimentale a quadrato latino per l'Esempio 2 (un anno)" width="65%" />
<p class="caption">
Figure 14.1: Schema sperimentale a quadrato latino per l’Esempio 2 (un anno)
</p>
</div>
<p>Un’altro aspetto da considerare è la metodica impiegata per la determinazione del peso di 1000 semi. Abbiamo già visto che, per aumentare la precisione e la rappresentatività, da tutta la granella raccolta da una parcella preleviamo quattro lotti da 1000 semi, di cui determinare il peso. In questo modo, per ogni trattamento avremo 16 valori (quattro repliche x quattro lotti per replica). Ovviamente non possiamo affermare di avere 16 repliche, in quanto solo le parcelle sono da considerare repliche, in quanto ricevono il trattamento (varietà) in modo indipendente. I quattro lotti raccolti da ogni parcella sono unità osservazionali (perché ne viene rilevato il peso), ma non unità sperimentali, perché appartengono alla stessa parcella e non sono indipendenti. I quattro lotti si dicono <strong>sub-repliche</strong>, quindi il disegno ha quattro repliche e quattro sub-repliche per replica (<strong>disegno a quadrato latino con sottocampionamento</strong>). I due strati di errore (variabilità tra repliche e variabilità tra sub-repliche entro replica), devono essere mantenuti separati in fase di analisi, altrimenti l’analisi è invalida, perché è condotta come se avessimo un più alto grado di precisione (16 repliche) rispetto a quello che abbiamo effettivamente (una sorta di millantato credito!).</p>
<p>[Inserire immagine]</p>
<p>Al termine del ciclo colturale, si misurerà il peso di mille semi. Per questo, prenderemo dalla produzione di granella di ogni parcella, quattro sub-campioni da mille semi, da sottoporre a pesate.</p>
</div>
<div id="organizzare-un-esperimento-fattoriale" class="section level3">
<h3><span class="header-section-number">14.1.3</span> Organizzare un esperimento fattoriale</h3>
<p>Nella barbabietola da zucchero, il diserbo localizzato lungo la fila consente di diminuire l’impiego di erbicidi. Tuttavia, se la coltura precedente ha prodotto semi e se non abbiamo effettuato una lavorazione profonda per interrarli, la coltura sarà più infestata e quindi sarà più difficile ottenere una buona produttività con il diserbo parziale. Su questa ipotesi costruiamo un esperimento volto a valutare l’interazione tra lavorazione del terreno e diserbo chimico. Per raggiungere questo obiettivo generale, proveremo a valutare se:</p>
<ol style="list-style-type: decimal">
<li>il diserbo parziale consente di ottenere produzioni comparabili a quelle del diserbo totale</li>
<li>l’effetto erbicida è indipendente dalla lavorazione prescelta</li>
</ol>
<p>In questo caso avremo due fattori sperimentali incrociati: il diserbo, con due livelli (totale o parziale, localizzato sulla fila) e la lavorazione, con tre livelli (aratura profonda, aratura superficiale e <em>minimum tillage</em>). Non vi è la necessità di un testimone, ma avremo la necessità di un fattore di blocco. In totale, avremo sei tesi sperimentali.</p>
<p>In questo caso abbiamo un disegno fattoriale con due livelli a blocchi randomizzati. Nel principio, questo disegno non ha nulla di diverso da quello relativo all’esempio 1, fatto salvo un minor numero di trattamenti (solo 6). Anche in questo caso, ci facciamo aiutare da R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trt &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">2</span>) <span class="co"># factorial 3x2</span>
design2way &lt;-<span class="kw">design.ab</span>(trt, <span class="dt">r=</span><span class="dv">4</span>, <span class="dt">serie=</span><span class="dv">2</span>,
  <span class="dt">design=</span><span class="st">&quot;rcbd&quot;</span>, <span class="dt">seed=</span><span class="dv">777</span>)
book &lt;-<span class="st"> </span>design2way<span class="op">$</span>book
<span class="kw">levels</span>(book<span class="op">$</span>A) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;PROF&quot;</span>, <span class="st">&quot;SUP&quot;</span>, <span class="st">&quot;MIN&quot;</span>)
<span class="kw">levels</span>(book<span class="op">$</span>B) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;TOT&quot;</span>, <span class="st">&quot;PARZ&quot;</span>)
book
##    plots block    A    B
## 1    101     1  SUP PARZ
## 2    102     1 PROF PARZ
## 3    103     1 PROF  TOT
## 4    104     1  MIN  TOT
## 5    105     1  SUP  TOT
## 6    106     1  MIN PARZ
## 7    107     2  MIN  TOT
## 8    108     2  SUP  TOT
## 9    109     2  MIN PARZ
## 10   110     2 PROF  TOT
## 11   111     2  SUP PARZ
## 12   112     2 PROF PARZ
## 13   113     3  MIN  TOT
## 14   114     3  SUP  TOT
## 15   115     3 PROF PARZ
## 16   116     3  MIN PARZ
## 17   117     3  SUP PARZ
## 18   118     3 PROF  TOT
## 19   119     4  MIN PARZ
## 20   120     4 PROF  TOT
## 21   121     4 PROF PARZ
## 22   122     4  MIN  TOT
## 23   123     4  SUP  TOT
## 24   124     4  SUP PARZ</code></pre></div>
<p>La mappa risultante è visibile più sotto.</p>
<div class="figure" style="text-align: center"><span id="fig:figName36"></span>
<img src="_images/Mappa3FATT.png" alt="Schema sperimentale fattoriale a blocchi randomizzati per l'Esempio 3" width="65%" />
<p class="caption">
Figure 14.2: Schema sperimentale fattoriale a blocchi randomizzati per l’Esempio 3
</p>
</div>
<p>Questo disegno è totalmente appropriato, ma ci costringe a lasciare parecchio spazio tra una parcella e l’altra, per poter manovrare con la macchina per la lavorazione del terreno. Sarebbe utile raggruppare le parcelle caratterizzate dalla stessa lavorazione, in modo da poter lavorare su superfici più ampie. Ne guadagnerebbe l’uniformità dell’esperimento e l’accuratezza dei risultati. Possiamo quindi immaginare un disegno a un fattore, con parcelle di dimensione doppia (<strong>main-plots</strong>), sulle quali eseguire, in modo randomizzato le lavorazioni del terreno. Succesivamente, ogni main-plot può essere suddivisa in due e, su ognuna delle due metà, possono essere allocati in modo random i due trattamenti di diserbo. In questo modo ci troviamo ad operare con parcelle di due dimensioni diverse: le main-plots per le lavorazioni e le sub-plots per il diserbo. Questo tipo di schema prende il nome di <strong>parcella suddivisa</strong> (<strong>split-plot</strong>), ed è piuttosto comune nella sperimentazione di pieno campo.</p>
<p>Proviamo ad utilizzare R per redigere il piano sperimentale.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lavorazione &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;PROF&quot;</span>, <span class="st">&quot;SUP&quot;</span>, <span class="st">&quot;MIN&quot;</span>)
diserbo &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;TOT&quot;</span>, <span class="st">&quot;PARZ&quot;</span>)
designSPLIT &lt;-<span class="st"> </span><span class="kw">design.split</span>(lavorazione, diserbo,
  <span class="dt">r=</span><span class="dv">4</span>, <span class="dt">serie=</span><span class="dv">2</span>, <span class="dt">seed=</span><span class="dv">777</span>)
book &lt;-<span class="st"> </span>designSPLIT<span class="op">$</span>book
book
##    plots splots block lavorazione diserbo
## 1    101      1     1         SUP    PARZ
## 2    101      2     1         SUP     TOT
## 3    102      1     1        PROF     TOT
## 4    102      2     1        PROF    PARZ
## 5    103      1     1         MIN    PARZ
## 6    103      2     1         MIN     TOT
## 7    104      1     2         SUP    PARZ
## 8    104      2     2         SUP     TOT
## 9    105      1     2         MIN     TOT
## 10   105      2     2         MIN    PARZ
## 11   106      1     2        PROF     TOT
## 12   106      2     2        PROF    PARZ
## 13   107      1     3         MIN     TOT
## 14   107      2     3         MIN    PARZ
## 15   108      1     3         SUP     TOT
## 16   108      2     3         SUP    PARZ
## 17   109      1     3        PROF     TOT
## 18   109      2     3        PROF    PARZ
## 19   110      1     4        PROF    PARZ
## 20   110      2     4        PROF     TOT
## 21   111      1     4         MIN     TOT
## 22   111      2     4         MIN    PARZ
## 23   112      1     4         SUP    PARZ
## 24   112      2     4         SUP     TOT</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName37"></span>
<img src="_images/Mappa3split.png" alt="Schema sperimentale split-plot a blocchi randomizzati per l'Esempio 3" width="65%" />
<p class="caption">
Figure 14.3: Schema sperimentale split-plot a blocchi randomizzati per l’Esempio 3
</p>
</div>
<p>In alcune circostanze, soprattutto nelle prove di diserbo chimico, potrebbe trovare applicazione un altro tipo di schema sperimentale, nel quale, in ogni blocco, un trattamento viene applicato a tutte le parcelle di una riga e l’altro trattamento a tutte le parcelle di una colonna. Ad esempio, il disegno sottostante mostra una prova nella quale il terreno è stato diserbato in una striscia nel senso della lunghezza e, dopo il diserbo, le colture sono state seminate in striscia, nel senso della larghezza. Questo disegno è detto <strong>strip-plot</strong> ed è molto comodo perché consente di lavorare velocemente.</p>
<div class="figure" style="text-align: center"><span id="fig:figName38"></span>
<img src="_images/MappaStrip.png" alt="Schema sperimentale a strip-plot" width="90%" />
<p class="caption">
Figure 14.4: Schema sperimentale a strip-plot
</p>
</div>
</div>
<div id="organizzare-un-esperimento-con-una-coltura-poliennale" class="section level3">
<h3><span class="header-section-number">14.1.4</span> Organizzare un esperimento con una coltura poliennale</h3>
<p>Vogliamo porre a confronto tre varietà di erba medica (A, B e C) e, considerando che l’erba medica è una coltura poliennale, vogliamo capire se il giudizio di merito è indipendente dall’anno di coltivazione. I nostri obiettivi specifici saranno:</p>
<ol style="list-style-type: decimal">
<li>valutare la produttività media delle varietà in prova</li>
<li>valutare le oscillazione nei quattro anni di durata del cotico erboso</li>
</ol>
<p>Il fattore sperimentale in studio sarà la varietà di erba medica con 3 livelli inclusi in prova (varietà A, B e C) ai quali aggiungiamo il riferimento di zona (D) come testimone. Come nel caso del girasole, dovremo valutare la stabilità produttiva negli anni, ma, dato che abbiamo una coltura poliennale, non avremo bisogno di ripetere la prova, ma potremo ripetere le osservazioni per quattro anni sulla stessa prova.</p>
<p>La prova di erba medica è fondamentalmente un esperimento a blocchi randomizzati, il cui piano è riportato più sotto. Tuttavia, si tratta di una coltura poiliennale nella quale ripeteremo le misurazioni ogni anno sulle stesse parcelle. le misure ripetute non sono randomizzate (non possono esserlo), ma seguono una metrica temporale. Proprio per questo sviluppo lungo la scala del tempo, i dati che si raccolgono in questi esperimenti a misure ripetute sono detti <strong>dati longitudinali</strong>. Guardando bene il disegno si capisce anche per si parla di <strong>split-plot nel tempo</strong>. Esempi affini sono relativi all’analisi di accrescimento con misure non distruttive (esempio l’altezza) oppure i prelievi di terreno a profondità diverse, anche se, in quest’ultimo caso, la metrica delle misure ripetute è spaziale, non temporale.</p>
<p>Si può notare una certa analogia con il sottocampionamento illustrato più sopra, nel senso che vengono prese più misure per parcella. Tuttavia, bisogna tener presente che nel sottocampionamento le diverse misure sono solo repliche e non vi è nessuna esigenza di distinguere tra quelle prese nella stessa parcella. Invece, nel caso delle misure ripetute ognuna di esse ha interesse individuale, in quanto espressione di un’anno particolare.</p>
<div class="figure" style="text-align: center"><span id="fig:figName39"></span>
<img src="_images/Mappa4.png" alt="Schema sperimentale a blocchi randomizzati con misure ripetute (split-plot in time)" width="55%" />
<p class="caption">
Figure 14.5: Schema sperimentale a blocchi randomizzati con misure ripetute (split-plot in time)
</p>
</div>
</div>
<div id="utilizzare-r-per-disegnare-gli-esperimenti" class="section level3">
<h3><span class="header-section-number">14.1.5</span> Utilizzare R per disegnare gli esperimenti</h3>
<p>Negli esperimenti più semplici lo schema sperimentale può essere pianificato a mano. Per esperimenti complessi potremo invece utilizzare il computer; in R, potremo utilizzare, ad esempio, il package <em>agricolae</em> <span class="citation">(de Mendiburu <a href="#ref-de-Mendiburu:2019aa">2019</a>)</span>, seguento il codice che troverete nei paragrafi seguenti.</p>
<p>[Spostare qui gli esempi, lasciando sopra gli schemi]</p>
</div>
</div>
<div id="capitolo-4-modelli-matematici-a-due-facce" class="section level2">
<h2><span class="header-section-number">14.2</span> Capitolo 4: Modelli matematici a ‘due facce’</h2>
<div id="la-distribuzione-t-di-student" class="section level3">
<h3><span class="header-section-number">14.2.1</span> La distribuzione t di Student</h3>
<p>La distribuzione t di Student è analoga per forma ad una distribuzione normale con media 0 e deviazione standard 1. Rispetto a questa, la dispersione è un po’ più ampia, nel senso la probabilità di avere valori lontani dalla media è più alta. In realtà, non esiste una sola distribuzione t di Student, ma ne esistono molte, caratterizzate da un diverso numero di gradi di libertà (<span class="math inline">\(\nu\)</span>); maggiore è <span class="math inline">\(\nu\)</span>, minore la sovradispersione; se il numero di gradi di libertà è infinito, la distribuzione t di Student è identica alla normale standardizzata (distribuzione normale con media 0 e deviazione standard uguale ad 1).</p>
<p>Per verificare l’entità della sovradispersione, proviamo a disegnare su un grafico una curva normale standardizzata ed una serie di curve di t, con 2, 6 e 24 gradi di libertà.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x),<span class="op">-</span><span class="dv">3</span>, <span class="op">+</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&quot;Black&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Densità&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">2</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">6</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">24</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col =</span> <span class="st">&quot;green&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-219-1.png" /><!-- --></p>
</div>
<div id="la-distribuzione-f-di-fisher" class="section level3">
<h3><span class="header-section-number">14.2.2</span> La distribuzione F di Fisher</h3>
<p>La distribuzione F di Fisher è definita solo per valori positivi ed è fortemente asimmetrica. Anche in questo caso, abbiamo una famiglia di distribuzioni, che differiscono tra di loro per due parametri (gradi di libertà) <span class="math inline">\(\nu_1\)</span> e <span class="math inline">\(\nu_2\)</span>. Solitamente questa distribuzione viene utilizzata per descrivere il rapporto tra le varianze di coppie di campioni estratti da un distribuzione normale standardizzata, per cui <span class="math inline">\(\nu_1\)</span> e <span class="math inline">\(\nu_2\)</span> sono i gradi di libertà del numeratore e del denominatore.</p>
<p>Col codice che segue, possiamo disegnare la distribuzione di F con <span class="math inline">\(\nu_1 = \nu_2 = 3\)</span> e possiamo calcolare la probabilità di estrarre da questa distribuzione un valore pari o superiore a 5. Inoltre, calcoliamo anche il 95° percentile, utilizzando le apposite funzioni in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">df</span>(x, <span class="dv">3</span>, <span class="dv">3</span>), <span class="dv">0</span>, <span class="op">+</span><span class="dv">3</span>,<span class="dt">col=</span><span class="st">&quot;Black&quot;</span>,
     <span class="dt">xlab=</span><span class="st">&quot;&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Densità&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-220-1.png" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>(<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dt">lower.tail =</span> F)
## [1] 0.890449
<span class="kw">qf</span>(<span class="fl">0.95</span>, <span class="dv">3</span>, <span class="dv">3</span>)
## [1] 9.276628</code></pre></div>
</div>
<div id="la-distribuzione-binomiale" class="section level3">
<h3><span class="header-section-number">14.2.3</span> La distribuzione binomiale</h3>
<p>Ogni esperimento per il quale ci sono solo due esiti possibili (successo ed insuccesso) e una certa probabilità di successo, viene detto <strong>esperimento Bernoulliano</strong>. Il tipico esempio è il lancio della moneta, nel quale possiamo ottenere solo testa o croce, con una probabilità di 0.5 (se la moneta non è truccata). In alcuni casi, potremmo avere una serie di esperimenti Bernoulliani indipendenti, con probabilità di successo costante (ad esempio, lanciare la moneta 10 volte) e potremmo essere interessati a conoscere la probabilità di ottenere <em>k</em> successi su <em>n</em> prove. Questa probabilità può essere descritta attraverso la <strong>funzione di probabilità binomiale</strong>.</p>
<p>Poniamo di sapere che in una Facoltà di Agraria con un numero molto elevato di studenti il rapporto tra maschi e femmine sia pari a 0.7 e quindi che la probabilità di incontrare un maschio sia pari a <span class="math inline">\(p = 0.7\)</span> (evento semplice). Deve essere estratto a sorte un viaggio studio per quattro studenti e, per una questione di pari opportunità, si preferirebbe che fossero premiati in ugual misura maschi e femmine (cioè si vogliono premiare due femmine). Qual è la probabilità che un simile evento si realizzi?</p>
<p>La probabilità cercata si può ottenere pensando che abbiamo un evento “estrazione” che può dare due risultati possibili (maschio o femmina) e che deve essere ripetuto quattro volte. Se consideriamo “successo” estrarre una femmina, allora la probabilità di successo in ogni estrazione è <span class="math inline">\(p = 0.3\)</span> mentre quella di insuccesso (evento complementare) è pari a <span class="math inline">\(1 - p = q = 0.7\)</span>. Facciamo attenzione! Quanto abbiamo detto è vero solo se la popolazione è sufficientemente numerosa da pensare che la singola estrazione non cambia la probabilità degli eventi nelle successive (eventi indipendenti). La probabilità che su quattro estrazioni si abbiano 2 successi (due femmine) e due insuccessi (due maschi) è data da (teorema della probabilità composta):</p>
<p><span class="math display">\[0.3 \cdot 0.3 \cdot 0.7 \cdot 0.7 = 0.3^2 \cdot 0.7^2\]</span></p>
<p>In generale, data una popolazione molto numerosa, nella quale gli individui si presentano con due modalità possibili (in questo caso maschio e femmina) e posto di sapere che la frequenza con cui si presenta la prima modalità è pari a <span class="math inline">\(p\)</span> (in questo caso la frequenza delle femmine è pari a 0.3), mentre la frequenza della seconda modalità è pari a <span class="math inline">\(q = 1 - p\)</span>, se vogliamo estrarre da questa popolazione <span class="math inline">\(n\)</span> elementi, la probabilità che <span class="math inline">\(k\)</span> di questi presentino la prima modalità (successo) è data da:</p>
<p><span class="math display">\[p^k \cdot q^{(n-k)}\]</span></p>
<p>La formula di cui sopra, tuttavia, non risolve il nostro problema, in quanto noi vogliamo che vengano estratte due femmine, indipendentemente dall’ordine con cui esse vengono estratte (prima, seconda, terza o quarta estrazione), mentre la probabilità che abbiamo appena calcolato è quella relativa all’evento in cui le due femmine sono estratte al primo e secondo posto.</p>
<p>Di conseguenza (teorema della probabilità totale) alla probabilità dell’evento indicato in precedenza (estrazione di due femmine in prima e seconda posizione) dobbiamo sommare la probabilità di tutti gli altri eventi utili (due femmine in seconda e terza posizione, oppure in terza e seconda, oppure in terza e quarta e così via). Il numero delle combinazioni possibili per 2 femmine in quattro estrazioni (combinazione di 4 elementi di classe 2) è dato dal coefficiente binomiale:</p>
<p><span class="math display">\[\left( {\begin{array}{*{20}c}
n  \\
k  \\
\end{array}} \right) = \frac{n!}{(n - k)!k!} \]</span></p>
<p>Moltiplicando le due equazioni date in precedenza otteniamo la funzione di probabilità binomiale:</p>
<p><span class="math display">\[P(X = x_i ) = \frac{{n!}}{{(n - k)!k!}} \cdot p^k \cdot q^{(n - k)} \]</span></p>
<p>Nel caso specifico otteniamo il risultato:</p>
<p><span class="math display">\[P(X = 2) = \frac{4!}{(4 - 2)!2!} \cdot 0.3^2 \cdot 0.7^{(4 - 2)}  = 0.2646 \]</span></p>
<p>che è appunto la probabilità cercata.</p>
<p>In R, utilizziamo la funzione ‘dbinom(successi, prove, probabilità semplice)’ per calcolare la probabilità di ottenere <span class="math inline">\(k\)</span> successi in <span class="math inline">\(n\)</span> prove:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="fl">0.3</span>)
## [1] 0.2646</code></pre></div>
<p>La funzione binomiale è un modello stocastico e si può dimostrare che il valore atteso (media) è uguale ad <span class="math inline">\(n\cdot p\)</span>, mentre la varianza è pari a <span class="math inline">\(n\cdot p \cdot q\)</span>:</p>
<p>La funzione di ripartizione (probabilità cumulata) si calcola in R con la funzione ‘pbinom(successi, prove, probabilità semplice)’. Nell’esempio, se vogliamo sapere la probabilità totale di estrarre meno di tre femmine (2 femmine o meno), possiamo operare in questo modo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pbinom</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
## [1] 0.9163</code></pre></div>
<p>Che risulta anche dalla somma della probabilità di estrarre 0, 1, 2 femmine:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">zero &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
uno &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
due &lt;-<span class="st"> </span><span class="kw">dbinom</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
zero <span class="op">+</span><span class="st"> </span>uno <span class="op">+</span><span class="st"> </span>due
## [1] 0.9163</code></pre></div>
<p>La funzione di ripartizione può anche essere utilizzata al contrario, per determinare i quantili, cioè il numero di successi che corrispondono ad una probabilità cumulata pari ad alfa:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qbinom</span>(<span class="fl">0.9163</span>,<span class="dv">4</span>,<span class="fl">0.3</span>)
## [1] 2</code></pre></div>
<div id="esercizio" class="section level4">
<h4><span class="header-section-number">14.2.3.1</span> Esercizio</h4>
<p>Da una popolazione di insetti che ha un rapporto tra maschi e femmine pari a 0.5, qual è la probabilità di campionare casualmente 2 maschi e 8 femmine?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dbinom</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.5</span>)
## [1] 0.04394531</code></pre></div>
</div>
<div id="esercizio-8" class="section level4">
<h4><span class="header-section-number">14.2.3.2</span> Esercizio</h4>
<p>Riportare su un grafico la funzione di ripartizione binomiale, per p=0.5 e n=5. Costruire anche la densità di frequenza, utilizzando le opportune funzioni R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">prob &lt;-<span class="st"> </span><span class="fl">0.5</span>
n &lt;-<span class="st"> </span><span class="dv">5</span>
<span class="kw">barplot</span>(<span class="kw">dbinom</span>(<span class="kw">seq</span>(<span class="dv">0</span>, n, <span class="dt">by=</span><span class="dv">1</span>), <span class="dt">size=</span>n, <span class="dt">prob=</span>prob),
          <span class="dt">xlab=</span><span class="st">&quot;Successi&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Probabilità&quot;</span>,
          <span class="dt">names.arg=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName53"></span>
<img src="_main_files/figure-html/figName53-1.png" alt="Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)" width="90%" />
<p class="caption">
Figure 14.6: Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">barplot</span>(<span class="kw">pbinom</span>(<span class="kw">seq</span>(<span class="dv">0</span>, n, <span class="dt">by=</span><span class="dv">1</span>), <span class="dt">size=</span>n, <span class="dt">prob=</span>prob),
          <span class="dt">xlab=</span><span class="st">&quot;Successi&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Probabilità&quot;</span>,
          <span class="dt">names.arg=</span><span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:figName53"></span>
<img src="_main_files/figure-html/figName53-2.png" alt="Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)" width="90%" />
<p class="caption">
Figure 14.6: Distribuzione di probabilità binomiale (sinistra) e probabilità binomiale cumulata (destra)
</p>
</div>
<p>Allo stesso modo possiamo immaginare di estrarre 20 insetti a caso da una popolazione in cui il rapporto tra i sessi è 1:1. Questo esperimento può essere simulato con:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">1</span>, <span class="dt">size =</span> <span class="dv">20</span>, <span class="dt">prob =</span> <span class="fl">0.5</span>)
Y
## [1] 10</code></pre></div>
<p>Assumendo che il ‘successo’ sia ottenere una femmina, il computer ci restituisce il numero delle femmine.</p>
</div>
</div>
</div>
<div id="capitolo-5-esperimenti-stime-ed-incertezza" class="section level2">
<h2><span class="header-section-number">14.3</span> Capitolo 5: Esperimenti stime ed incertezza</h2>
<div id="e-realistico-lintervallo-di-confidenza" class="section level3">
<h3><span class="header-section-number">14.3.1</span> E’ realistico l’intervallo di confidenza?</h3>
<p>Abbiamo visto che un metodo semplice per costruire un intervallo di confidenza è utilizzare il doppio dell’errore standard. Questo intervallo, se viene utilizzato come misura di precisione/incertezza, è sempre accettabile. Tuttavia, da un punto di vista strettamente probabilistico, è lecito chiedersi: ma è proprio vero che se io ripeto l’esperimento molte volte e calcolo sempre l’intervallo di confidenza, riesco a centrare la media <span class="math inline">\(\mu\)</span> nel 95% dei casi?</p>
<p>Proviamo a rispondere a questa domanda con una simulazione Monte Carlo. Prendiamo la nostra popolazione (<span class="math inline">\(\mu = 120\)</span> e <span class="math inline">\(\sigma = 12\)</span>) ed estraiamo centomila campioni. Per ogni campione calcoliamo l’intervallo di confidenza della media (P = 0.95) considerando il doppio dell’errore standard. Verifichiamo poi se questo intervallo contiene il valore 120: se si, assegniamo al campionamento il valore 1 (successo), altrimenti assegniamo il valore 0.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">-</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="dv">2</span>
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.81656</code></pre></div>
<p>La simulazione mostra che la risposta alla domanda precedente è no: il nostro intervallo di confidenza non è riuscito a centrare la media nel 95% dei casi; ciò è avvenuto in poco più dell’80% dei casi. In realtà, possiamo facilmente verificare, con altre simulazioni di Monte Carlo, che la copertura effettiva dell’intervallo di confidenza si avvicina al 95% solo se abbiamo un numero di repliche superiori a 15-20 circa.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  n &lt;-<span class="st"> </span><span class="dv">15</span>
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(n, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">-</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span> 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">2</span>
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.93591</code></pre></div>
<p>Insomma, quando gli esperimenti sono piccoli, con poche repliche, dovremmo trovare un metodo di calcolo un po’ più affidabile, se veramente vogliamo ottenere un grado di copertura pari a quello nominale (P = 0.95).</p>
<p>Il problema nasce dal fatto che, nella statistica T che abbiamo introdotto nel capitolo 5:</p>
<p><span class="math display">\[T = \frac{m - \mu}{\sigma_m}\]</span> <span class="math inline">\(\sigma_m\)</span> viene sostituito con <span class="math inline">\(s_m\)</span>, cioè il valore di deviazione standard stimato nel campione. Come tutte le stime, anche <span class="math inline">\(s\)</span> è ’soggetto ad incertezza, il che aggiunge un elemento ulteriore di imprecisione nella sampling distribution di T. Insomma ci chiediamo, la <em>sampling distribution</em> di T, calcolata con <span class="math inline">\(s\)</span> invece che <span class="math inline">\(\sigma\)</span> è ancora normale? Verifichiamo questo aspetto empiricamente, con una nuova simulazione Monte Carlo. Questa volta facciamo la seguente operazione:</p>
<ol style="list-style-type: decimal">
<li>campioniamo tre individui</li>
<li>Calcoliamo il valore di T con la statistica precedente, utilizzando la deviazione standard del campione e lo salviamo</li>
<li>Con un po’ di pazienza, ripetiamo il tutto 100’000 volte.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#SIMULAZIONE MONTE CARLO - t di Student</span>
<span class="kw">set.seed</span>(<span class="dv">435</span>)
result &lt;-<span class="st"> </span><span class="kw">c</span>()
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample3 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  T &lt;-<span class="st"> </span>(<span class="kw">mean</span>(sample3) <span class="op">-</span><span class="st"> </span><span class="dv">120</span>) <span class="op">/</span><span class="st"> </span>(<span class="kw">sd</span>(sample3)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>))
  result[i] &lt;-<span class="st"> </span>T
  }</code></pre></div>
<p>Se riportiamo i valori ottenuti su una distribuzione di frequenze otteniamo il grafico sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Plot sampling distribution</span>
b &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">600</span>, <span class="dv">600</span>, <span class="dt">by=</span><span class="fl">0.2</span>)
<span class="kw">hist</span>(result, <span class="dt">breaks =</span> b, <span class="dt">freq=</span>F, <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(m)), <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.4</span>), <span class="dt">main=</span><span class="st">&quot;&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">2</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-230-1.png" /><!-- --></p>
<p>Vediamo che la <em>sampling distribution</em> di T calcolato utilizzando <span class="math inline">\(s\)</span> invece che <span class="math inline">\(\sigma\)</span> è solo approssimativamente normale. E’ facile vedere che questa approssimazione è sufficientemente buona solo se la numerosità del campione diviene abbastanza grande (es. <span class="math inline">\(n &gt; 30)\)</span>, ma non certamente quando <span class="math inline">\(n\)</span> = 3 (ve lo lascio per esercizio). In questo caso, la sampling distribution che osserviamo è più ‘dispersa’ di quella normale, con un maggior numero di valori sulle code.</p>
<p>Neyman scoprì che la sampling distribution di T poteva essere perfettamente descritta utilizzando la distribuzione t di Student, con un numero di gradi di libertà pari a quelli del campione (in questo caso 2), come vediamo nella figura sovrastante. In realtà questa conclusione era stata già raggiunta da William Sealy Gosset (1876 - 1937), uno statistico impiegato presso la fabbrica londinese della famosa birra Guinness, dove elaborava i dati relativi all’andamento del processo di maltazione. Egli, avendo definito questa nuova funzione di densità, per aggirare il divieto di pubblicazione imposto dal suo datore di lavoro, pubblicò i risultati sotto lo pseudonimo Student, da cui deriva il nome della distribuzione di densità.</p>
<p>Quindi, quando i campioni sono piccoli, il modo giusto di calcolare l’intervallo di confidenza è quello di utilizzare l’espressione seguente:</p>
<p><span class="math display">\[P \left( m + \textrm{qt}(0.025,n - 1) \cdot s_m \le \mu  \le m + \textrm{qt}(0.975,n - 1) \cdot s_m \right) = 0.95\]</span></p>
<p>dove <span class="math inline">\(\textrm{qt}(0.025,n - 1)\)</span> e <span class="math inline">\(\textrm{qt}(0.975,n - 1)\)</span> sono rispettivamente il 2.5-esimo e il 97.5-esimo percentile della distribuzione t di Student, con n-1 gradi di libertà.</p>
<p>Nel capitolo 5 abbiamo utilizzato un esempio in cui abbiamo eseguito tre analisi chimiche da una soluzione erbicida di concentrazione pari a 120 mg/l, con uno strumento caratterizzato da un coefficiente di variabilità del 10%, che quindi, in assenza di errori sistematici, produce misure distribuite normalmente con media uguale a 120 e deviazione standard uguale a 12. Il campione osservato era</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
Y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
Y
## [1] 125.1584 114.7349 105.6998</code></pre></div>
<p>le statistiche descrittive sono:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">mean</span>(Y)
s &lt;-<span class="st"> </span><span class="kw">sd</span>(Y)
m; s
## [1] 115.1977
## [1] 9.737554</code></pre></div>
<p>I valori della distribuzione t di Student che lasciano al loro esterno il 5% delle varianti (2.5% per coda) sono:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>)
## [1] -4.302653
<span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>)
## [1] 4.302653</code></pre></div>
<p>Gli intervalli di confidenza sono pertanto:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>s<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>)
## [1] 91.00824
m <span class="op">+</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>s<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>)
## [1] 139.3871</code></pre></div>
<p>E’ facile osservare che, se l’intervallo di confidenza è calcolato in questo modo, il suo <em>coverage</em><a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> Operiamo con una simulazione Monte Carlo analoga a quella utilizzata nel capitolo 5.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  limInf&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.025</span>, <span class="dv">2</span>) 
  limSup&lt;-<span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">+</span><span class="st"> </span><span class="kw">sd</span>(sample)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">3</span>) <span class="op">*</span><span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dv">2</span>) 
  <span class="cf">if</span> (limInf<span class="op">&lt;=</span><span class="st"> </span><span class="dv">120</span> <span class="op">&amp;</span><span class="st"> </span>limSup<span class="op">&gt;=</span><span class="st"> </span><span class="dv">120</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.94992</code></pre></div>
<p>Ovviamente possiamo calcolare anche gli intervalli di confidenza al 99% di proababilità o qualunque altro intervallo di confidenza rilevante per il nostro studio.</p>
</div>
<div id="che-cosa-non-significa-lintervallo-di-confidenza" class="section level3">
<h3><span class="header-section-number">14.3.2</span> Che cosa NON significa l’intervallo di confidenza?</h3>
<p>Abbiamo già detto che l’intervallo di confidenza, calcolato su una serie di campionamenti ripetuti, contiene al suo interno la media vera e ignota della popolazione (<span class="math inline">\(\mu\)</span>) con una probabilità pari a 0.95.</p>
<p>Tuttavia, la formula di Neyman si presta a cattive letture, che sono insensate da un punto di vista probabilistico, ma tuttavia molto frequenti nella pratica operativa. Ad esempio:</p>
<ol style="list-style-type: decimal">
<li><strong>NON E’ VERO CHE:</strong> c’è il 95% di probabilità che la media ‘vera’ della popolazione si trovi tra 91.0082383 e 139.3870891. La media vera della popolazione è sempre fissa e pari a 120 e non cambia affatto tra un campionamento e l’altro.</li>
<li><strong>NON E’ VERO CHE:</strong> ripetendo l’esperimento, il 95% delle stime che otteniamo cadono nell’intervallo 91.0082383 e 139.3870891. Una semplice simulazione mostra che quasi tutte le medie campionate cadono in quell’intervallo:</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">3</span>, <span class="dv">120</span>, <span class="dv">12</span>)
  <span class="cf">if</span> (<span class="kw">mean</span>(sample) <span class="op">&lt;=</span><span class="st"> </span><span class="fl">156.15</span> <span class="op">&amp;</span><span class="st"> </span><span class="kw">mean</span>(sample) <span class="op">&gt;=</span><span class="st"> </span><span class="fl">92.13</span>) result[i] =<span class="st"> </span><span class="dv">1</span>
}
<span class="kw">sum</span>(result)<span class="op">/</span><span class="dv">100000</span>
## [1] 0.99996</code></pre></div>
<ol start="3" style="list-style-type: decimal">
<li><strong>NON E’ VERO CHE:</strong> c’è il 95% di probabilità che l’affermazione ’la media vera è compresa tra 91.0082383 e 139.3870891 sia vera. Nelle normali condizioni sperimentali la media vera è ignota e non sapremo mai nulla su di essa: il nostro intervallo di confidenza può catturarla o no. Nel nostro esempio lo ha fatto, ed è tutto quello che possiamo dire.</li>
</ol>
<p>Insomma, l’intervallo di confidenza vale per la sampling distribution e non vale per ogni singolo campionamento (esperimento). Pertanto, affermazioni del tipo: ”c’è il 95% di probabilità che <span class="math inline">\(\mu\)</span> è compreso nell’intervallo di confidenza” oppure ”il valor più probabile di <span class="math inline">\(\mu\)</span> è…” non sono corrette e anzi non hanno senso nella statistica tradizionale.</p>
<p>In altre parole, l’intervallo di confidenza è una sorta di polizza assicurativa che ci garantisce che, se operiamo continuativamente con le procedure indicate, al termine della nostra carriera avremo sbagliato in non più del 5% dei casi.</p>
</div>
<div id="popolazioni-non-gaussiane" class="section level3">
<h3><span class="header-section-number">14.3.3</span> Popolazioni non gaussiane</h3>
<p>Nel capitolo 5 abbiamo presentato un esempio in cui avevamo campionato da una distribuzione normale, riscontrando una <em>sampling distribution</em> per la media campionaria anch’essa normale. Ma che succede se la distribuzione di partenza è non-normale? La <em>sampling distribution</em> di uno stimatore è ancora normale? Vediamo un nuovo esempio.</p>
<p>Immaginiamo di avere 4’000’000 di semi ben mischiati (in modo che non ci siano raggruppamenti non casuali di qualche tipo), che costituiscono la nostra popolazione di partenza. Vogliamo appurare la frequenza relativa (p) dei semi dormienti. Questa informazione, nella realtà, esiste (<span class="math inline">\(\pi\)</span> = 0.25), ma non è nota.</p>
<p>Dato l’elevato numero di ‘soggetti’, non possiamo testare la germinabilità di tutti i semi, ma dobbiamo necessariamente prelevare un campione casuale di 40 soggetti; ogni seme viene saggiato e, dato che la popolazione è molto numerosa, l’estrazione di un seme non modifica sensibilmente la proporzione di quelli dormienti nella popolazione (esperimenti indipendenti).</p>
<div id="il-modello-dei-dati-1" class="section level4">
<h4><span class="header-section-number">14.3.3.1</span> Il modello dei dati</h4>
<p>Dopo aver descritto la popolazione e l’esperimento, ci chiediamo quale sia il modello matematico che genera i nostri dati (numero di successi su 40 semi estratti). Il disegno sperimentale ci assicura che ogni estrazione è totalmente indipendente dalla precedente e dalla successiva ed ha due soli risultati possibili, cioè successo (seme dormiente), o insuccesso (seme germinabile). Di conseguenza, ogni singola estrazione si configura come un esperimento Bernoulliano, con probabilità di successo pari a <span class="math inline">\(\pi\)</span>, il cui valore ‘vero’ esiste, è fisso, pre-determinato (esiste ancor prima di organizzare l’esperimento), anche se incognito e inconoscibile, a meno di non voler/poter esaminare tutti i semi disponibili. L’insieme delle 40 estrazioni (40 esperimenti Bernoulliani) può produrre un ventaglio di risultati possibili, da 40 successi a 40 insuccessi, per un totale di 41 possibili ‘outcomes’.</p>
<p>E’ evidente che i 41 possibili risultati non sono ugualmente probabili e si può dimostrare che la probabilità di ottenere <em>k</em> successi (con <em>k</em> che va da 0 ad <em>n</em>; <em>n</em> è al numero delle estrazioni) dipende da <span class="math inline">\(\pi\)</span> ed è descrivibile matematicamente con la distribuzione binomiale <span class="math inline">\(\phi\)</span>:</p>
<p><span class="math display">\[\phi(k, n, p) = \frac{n!}{(n-k)!k!} p^k (1 - p)^{(n-k)}\]</span></p>
<p>Abbiamo quindi definito il modello matematico che descrive la probabilità di tutti i possibili risultati del nostro esperimento e quindi può in qualche modo essere considerato il ‘meccanismo’ che ‘genera’ i dati sperimentali osservati. Si tratta di un meccanismo puramente ‘stocastico’ nel quale è solo il caso che, attraverso il campionamento, determina il risultato dell’esperimento.</p>
<p>Con queste informazioni, possiamo simulare un esperimento con R, ottenendo i seguenti risultati:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">23456789</span>)
<span class="kw">rbinom</span>(<span class="dv">1</span>, <span class="dv">40</span>, <span class="fl">0.25</span>)
## [1] 10</code></pre></div>
<p>Abbiamo ottenuto 9 successi su 40, cioè 9 semi dormienti su 40 saggiati.</p>
</div>
<div id="stima-dei-parametri-4" class="section level4">
<h4><span class="header-section-number">14.3.3.2</span> Stima dei parametri</h4>
<p>Dovendo stimare la quantità <span class="math inline">\(\pi\)</span>, la statistica tradizionale trascura totalmente le nostre aspettative sul fenomeno e utilizza soltanto i risultati dell’esperimento. Chiamiamo <em>p</em> la quantità stimata e, dato che abbiamo contato nove semi dormienti, concludiamo che p = 0.225, in quanto questa, con le informazioni che abbiamo, è la cosa più verosimile. Anche in questo caso vi è chiara discrasia tra la verità ‘vera’ e l’osservazione sperimentale (tra <span class="math inline">\(\pi\)</span> e <span class="math inline">\(p\)</span>).</p>
</div>
<div id="sampling-distribution" class="section level4">
<h4><span class="header-section-number">14.3.3.3</span> Sampling distribution</h4>
<p>Cosa succede se ripetiamo l’esperimento? Come abbiamo imparato a fare, possiamo cercare una risposta attraverso la simulazione Monte Carlo, ricorrendo ad un generatore di numeri casuali da una distribuzione binomiale con n = 40 e <span class="math inline">\(\pi\)</span> = 0.25 (in R si usa la funzione ‘rbinom(numeroDatiCasuali, n, p)’). Il codice è più semplice, in quanto non è necessario impostare un ciclo iterativo:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1234</span>)
result &lt;-<span class="st"> </span><span class="kw">rbinom</span>(<span class="dv">10000000</span>, <span class="dv">40</span>, <span class="fl">0.25</span>)</code></pre></div>
<p>Esploriamo i risultati ottenuti:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">result_p &lt;-<span class="st"> </span>result<span class="op">/</span><span class="dv">40</span>
<span class="kw">mean</span>(result_p)
## [1] 0.2500129
<span class="kw">sd</span>(result_p)
## [1] 0.0684611</code></pre></div>
<p>Osserviamo subito che, anche se i singoli esperimenti portano a stime diverse da <span class="math inline">\(\pi\)</span>, la media di <span class="math inline">\(p\)</span> tende ad essere uguale a <span class="math inline">\(\pi\)</span>. L’errore standard (deviazione standard della <em>sampling distribution</em>) è 0.0685. Fino a qui, non vie è nulla di diverso dall’esempio precedente, se teniamo presente che la deviazione standard della popolazione originale (che è binomiale) è pari a <span class="math inline">\(\sqrt{p \times (1 - p)}\)</span>, quindi l’errore standard è <span class="math inline">\(\sqrt{0.25 \times 0.75 / 40} = 0.0685\)</span>.</p>
<p>Rimane da stabilire se la <em>sampling distribution</em> di <span class="math inline">\(p\)</span> è normale. Possiamo utilizzare i 10’000’000 di valori ottenuti per costruire una distribuzione empirica di frequenze, come nel codice sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">breaks &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="fl">0.7</span>, <span class="dt">by=</span><span class="fl">0.025</span>)
freqAss &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( <span class="kw">table</span>(<span class="kw">cut</span>(result_p, breaks) ) ) 
freqRel &lt;-<span class="st"> </span>freqAss<span class="op">/</span><span class="kw">length</span>(result_p)
density &lt;-<span class="st"> </span>freqRel<span class="op">/</span><span class="fl">0.025</span>
p_oss &lt;-<span class="st"> </span>breaks[<span class="dv">2</span><span class="op">:</span><span class="kw">length</span>(breaks)]

<span class="kw">plot</span>(density <span class="op">~</span><span class="st"> </span>p_oss, <span class="dt">type =</span> <span class="st">&quot;h&quot;</span>,
     <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">bar</span>(p))),
     <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, 
    <span class="dt">main=</span><span class="st">&quot;Sampling distribution per p&quot;</span>, 
    <span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.6</span>) )

<span class="kw">curve</span>(<span class="kw">dnorm</span>(x, <span class="fl">0.25</span>, <span class="fl">0.0685</span>), <span class="dt">add=</span><span class="ot">TRUE</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-240-1.png" /><!-- --></p>
<p>Vediamo che <em>sampling distribution</em> è approssimativamente normale con media pari a 0.25 e deviazione standard pari a 0.0685. Lo percepiamo chiaramente dal grafico soprastante, ma c’è una spiegazione scientifica per questo, basata sul <strong>TEOREMA DEL LIMITE CENTRALE</strong>:</p>
<ol style="list-style-type: decimal">
<li>La sampling distribution di una statistica ottenuta da campioni casuali e indipendenti è approssimativamente normale, indipendentemente dalla distribuzione della popolazione da cui i campioni sono stati estratti.</li>
<li>La media della sampling distribution è uguale al valore della statistica calcolata sulla popolazione originale, la deviazione standard della sampling distribution (errore standard) è pari alla deviazione standard della popolazione originale divisa per la radice quadrata della numerosità di un campione.</li>
</ol>
</div>
</div>
</div>
<div id="capitolo-6.-introduzione-al-test-dipotesi" class="section level2">
<h2><span class="header-section-number">14.4</span> Capitolo 6. Introduzione al test d’ipotesi</h2>
<div id="simulazione-monte-carlo-di-un-test-t-di-student" class="section level3">
<h3><span class="header-section-number">14.4.1</span> Simulazione Monte Carlo di un test t di Student</h3>
<p>La sampling distribution per T potrebbe essere ottenuta empiricamente, utilizzando una simulazione MONTE CARLO ed immaginando di estrarre numerose coppie di campioni, dalla stessa distribuzione normale, analogamente a quanto abbiamo fatto nell’esempio precedente. Se l’ipotesi nulla è vera, possiamo immaginare che questa distribuzione gaussiana abbia una media pari a (70.2 + 85.4)/2 = 77.8 e una deviazione standard pari alla deviazione standard delle dieci osservazioni (tutte insieme, senza distinzioni di trattamento), cioè 5.71.</p>
<p>Il codice da utilizzare in R per le simulazioni è il seguente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">A &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">65</span>, <span class="dv">68</span>, <span class="dv">69</span>, <span class="dv">71</span>, <span class="dv">78</span>)
P &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">80</span>, <span class="dv">81</span>, <span class="dv">84</span>, <span class="dv">88</span>, <span class="dv">94</span>)
media &lt;-<span class="st"> </span><span class="kw">mean</span>(<span class="kw">c</span>(A, P))
devSt &lt;-<span class="st"> </span><span class="kw">sd</span>(<span class="kw">c</span>(A, P))
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
result &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">100000</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100000</span>){
  sample1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">5</span>, media, devSt)
  sample2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">5</span>, media, devSt)
  SED &lt;-<span class="st"> </span><span class="kw">sqrt</span>( (<span class="kw">sd</span>(sample1)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> <span class="op">+</span>
<span class="st">                 </span>(<span class="kw">sd</span>(sample2)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> )
  result[i] &lt;-<span class="st"> </span>(<span class="kw">mean</span>(sample1) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(sample2)) <span class="op">/</span><span class="st"> </span>SED
}</code></pre></div>
<p>I risultati delle 100’000 simulazioni sono riportati nel grafico sottostante. Possiamo notare che, dei 100’000 valori di T osservati assumendo vera l’ipotesi nulla, solo l’un per mille sono superiori a quello da noi osservato e altrettanti sono inferiori a -4.5217. In totale, la probabilità di osservare un valore di T così alto in valore assoluto e dello 0.21 %.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SED_obs &lt;-<span class="st"> </span><span class="kw">sqrt</span>( (<span class="kw">sd</span>(A)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> <span class="op">+</span>
<span class="st">                   </span>(<span class="kw">sd</span>(P)<span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">5</span>))<span class="op">^</span><span class="dv">2</span> )
T_obs &lt;-<span class="st"> </span>(<span class="kw">mean</span>(A) <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(P))<span class="op">/</span>SED_obs
(<span class="kw">length</span>(result[result <span class="op">&lt;</span><span class="st"> </span>T_obs]) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">length</span>(result[result <span class="op">&gt;</span><span class="st"> </span><span class="op">-</span><span class="st"> </span>T_obs])) <span class="op">/</span><span class="dv">100000</span>
## [1] 0.00164</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Codice Grafico </span>
b &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">12</span>, <span class="dv">12</span>, <span class="dt">by=</span><span class="fl">0.25</span>)
<span class="kw">hist</span>(result, <span class="dt">breaks =</span> b, <span class="dt">freq=</span>F, <span class="dt">xlab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(m)), <span class="dt">ylab=</span><span class="st">&quot;Density&quot;</span>, <span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>), <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.45</span>), <span class="dt">main=</span><span class="st">&quot;&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-243-1.png" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x), <span class="dt">add=</span>T, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-243-2.png" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dt</span>(x, <span class="dv">8</span>), <span class="dt">add=</span>T, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="fl">4.52</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">abline</span>(<span class="dt">v =</span> <span class="op">-</span><span class="fl">4.52</span>, <span class="dt">lty =</span> <span class="dv">2</span>)
<span class="kw">text</span>(<span class="dv">5</span>, <span class="fl">0.4</span>, <span class="dt">label=</span><span class="st">&quot;4.52&quot;</span>, <span class="dt">adj=</span><span class="dv">0</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)
<span class="kw">text</span>(<span class="op">-</span><span class="dv">5</span>, <span class="fl">0.4</span>, <span class="dt">label=</span><span class="st">&quot;-4.52&quot;</span>, <span class="dt">adj=</span><span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-243-3.png" /><!-- --></p>
</div>
<div id="tipologie-alternative-di-test-t-di-student" class="section level3">
<h3><span class="header-section-number">14.4.2</span> Tipologie alternative di test t di Student</h3>
<p>Il test t può essere di tre tipi:</p>
<ol style="list-style-type: decimal">
<li>Appaiato. In questo caso le misure sono prese a coppia sullo stesso soggetto e non sono quindi indipendenti.</li>
<li>Omoscedastico. Le misure sono prese su soggetti diversi (indipendenti) e possiamo suppore che i due campioni provengano da due popolazioni con la stessa varianza.</li>
<li>Eteroscedastico. Le misure sono prese su soggetti diversi, ma le varianze non sono omogenee.</li>
</ol>
<p>Nel nostro esempio vediamo che le varianze dei campioni sono piuttosto simili e quindi adottiamo un test t omoscedastico (‘var.equal = T’).</p>
<p>Se dovessimo supporre che i due campioni provengono da popolazioni con varianze diverse, allora si porrebbe il problema di stabilire il numero di gradi di libertà del SEM. Abbiamo visto che se le varianze dei due campioni sono uguali (o meglio, sono due stime della stessa varianza), la varianza della somma/differenza ha un ha un numero di gradi di libertà pari alla somma dei gradi di libertà delle due varianze. Se le varianze fossero diverse, il numero di gradi di libertà della loro combinazione lineare (somma o differenza) si dovrebbe approssimare con la formula di Satterthwaite:</p>
<p><span class="math display">\[DF_s \simeq \frac{ \left( s^2_1 + s^2_2 \right)^2 }{ \frac{(s^2_1)^2}{DF_1} + \frac{(s^2_2)^2}{DF_2} }\]</span></p>
<p>Vediamo che se le varianze e i gradi di libertà sono uguali, la formula precedente riduce a:</p>
<p><span class="math display">\[DF_s = 2 \times DF\]</span></p>
<p>Nel nostro caso, se fosse <span class="math inline">\(s^2_1 \neq s^2_2\)</span> avremmo un numero frazionario di gradi di libertà:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dfS &lt;-<span class="st"> </span>(<span class="kw">var</span>(A) <span class="op">+</span><span class="st"> </span><span class="kw">var</span>(P))<span class="op">^</span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>
<span class="st">  </span>((<span class="kw">var</span>(A)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span> <span class="op">+</span><span class="st"> </span>(<span class="kw">var</span>(P)<span class="op">^</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">4</span>)
dfS
## [1] 7.79772</code></pre></div>
<p>Il risultato può essere riscontrato con:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(A, P, <span class="dt">var.equal=</span>F)
## 
##  Two Sample t-test
## 
## data:  A and P
## t = -4.5217, df = 8, p-value = 0.001945
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -22.951742  -7.448258
## sample estimates:
## mean of x mean of y 
##      70.2      85.4</code></pre></div>
<p>Se invece avessimo rilevato le misure accoppiate su quattro individui avremmo solo 4 gradi di libertà:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">t.test</span>(A, P, <span class="dt">var.equal=</span>T, <span class="dt">paired=</span>T)
## 
##  Paired t-test
## 
## data:  A and P
## t = -22.915, df = 4, p-value = 2.149e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -17.04169 -13.35831
## sample estimates:
## mean of the differences 
##                   -15.2</code></pre></div>
</div>
<div id="simulazione-di-un-test-di-chi-quadro" class="section level3">
<h3><span class="header-section-number">14.4.3</span> Simulazione di un test di chi quadro</h3>
<p>La simulazione di un test di <span class="math inline">\(\chi^2\)</span> può esser fatta utilizzando la funzione ‘r2dtable()’ che produce il numero voluto di tabelle di contingenza, con righe e colonne indipendenti r rispettando i totali marginali voluti. Le tabelle prodotte (nel nostro caso 10’000) sono restituite come lista, quindi possiamo utilizzare la funzione ‘lapply()’ per applicare ad ogni elemento della lista la funzione che restituisce il <span class="math inline">\(\chi^2\)</span> (‘chiSim’).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">chiSim &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">summary</span>(<span class="kw">as.table</span>(x))<span class="op">$</span>stat
<span class="kw">set.seed</span>(<span class="dv">1234</span>)
tabs &lt;-<span class="st"> </span><span class="kw">r2dtable</span>(<span class="dv">10000</span>, <span class="kw">apply</span>(tab, <span class="dv">1</span>, sum), <span class="kw">apply</span>(tab, <span class="dv">2</span>, sum))
chiVals &lt;-<span class="st"> </span><span class="kw">as.numeric</span>( <span class="kw">lapply</span>( tabs, chiSim) )
<span class="kw">length</span>(chiVals[chiVals <span class="op">&gt;</span><span class="st"> </span><span class="fl">9.768</span>])
## [1] 435</code></pre></div>
<p>Vediamo che vi sono 19 valori più alti di quello da noi osservato (p = 0.0019).</p>
</div>
<div id="errori-di-prima-e-di-seconda-specie" class="section level3">
<h3><span class="header-section-number">14.4.4</span> Errori di prima e di seconda specie</h3>
<p>[da fare]</p>

<div id="refs" class="references">
<div>
<p>Bates, D. M., and D. G. Watts. 1988. <em>Nonlinear Regression Analysis &amp; Its Applications.</em> Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div>
<p>Box, G. E. P., and D. R. Cox. 1964. “An Analysis of Transformations.” <em>Journal of the Royal Statistical Society</em> B-26: 211–52.</p>
</div>
<div>
<p>Carroll, R. J., and D. Ruppert. 1988. <em>Transformation and Weighting in Regression.</em> Books: Chapman and Hall.</p>
</div>
<div>
<p>Daniel, Johnnie. 2011. <em>Sampling Essentials: Practical Guidelines for Making Sampling Choices</em>. USA: SAGE.</p>
</div>
<div>
<p>de Mendiburu, Felipe. 2019. <em>Agricolae: Statistical Procedures for Agricultural Research</em>. <a href="https://CRAN.R-project.org/package=agricolae" class="uri">https://CRAN.R-project.org/package=agricolae</a>.</p>
</div>
<div>
<p>Draper, N. R., and H. Smith. 1998. <em>Applied Regression Analysis</em>. III. Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div>
<p>LeClerg, E. L., W. H. Leonard, and A. G. Clark. 1962. <em>Field Plot Technique</em>. Books: Burgess Publishing Company.</p>
</div>
<div>
<p>Pannacci, E., D. Pettorossi, and F. Tei. 2013. “Phytotoxic Effects of Aqueous Extracts of Sunflower on Seed Germination and Growth of Sinapis Alba L., Triticum Aestivum L. and Lolium Multiflorum Lam.” <em>Allelopathy Journal</em> 32 (1): 23.</p>
</div>
<div>
<p>Ratkowsky, David A. 1990. <em>Handbook of Nonlinear Regression Models</em>. Books: Marcel Dekker Inc.</p>
</div>
<div>
<p>Ritz, C., and J. C. Streibig. 2008. <em>Nonlinear Regression with R</em>. Books: Springer-Verlag New York Inc.</p>
</div>
<div>
<p>Ritz, Christian, Florent Baty, Jens C. Streibig, and Daniel Gerhard. 2015. “Dose-Response Analysis Using R.” Edited by Yinglin Xia. <em>PLOS ONE</em> 10 (12): e0146021. doi:<a href="https://doi.org/10.1371/journal.pone.0146021">10.1371/journal.pone.0146021</a>.</p>
</div>
</div>
</div>
</div>
</div>








<h3>References</h3>
<div id="refs" class="references">
<div id="ref-de-Mendiburu:2019aa">
<p>de Mendiburu, Felipe. 2019. <em>Agricolae: Statistical Procedures for Agricultural Research</em>. <a href="https://CRAN.R-project.org/package=agricolae" class="uri">https://CRAN.R-project.org/package=agricolae</a>.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="3">
<li id="fn3"><p>Con il termine inglese <em>coverage</em> si intende, in un esperimento ripetuto un elevatissimo numero di volte, l’effettiva percentuale di campioni, per i quali l’intervallo di confidenza, calcolato per un certo P nominale (es. P = 0.95), contiene effettivamente la media <span class="math inline">\(\mu\)</span> della popolazione.<a href="appendix-3-per-chi-vuole-approfondire-un-po.html#fnref3">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="appendix-2-richiami-di-statistica-descrittiva.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
