<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Metodologia statistica per le scienze agrarie</title>
  <meta name="description" content="Appunti dai corsi S.I.A.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="Metodologia statistica per le scienze agrarie" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Appunti dai corsi S.I.A." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Metodologia statistica per le scienze agrarie" />
  
  <meta name="twitter:description" content="Appunti dai corsi S.I.A." />
  

<meta name="author" content="Andrea Onofri e Dario Sacco">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="la-regressione-lineare-semplice.html">

<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<!-- Global Site Tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-131792052-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'UA-131792052-1');
  </script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduzione</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#organizzazione-del-testo"><i class="fa fa-check"></i><b>1.1</b> Organizzazione del testo</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#gli-autori"><i class="fa fa-check"></i><b>1.2</b> Gli autori</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><i class="fa fa-check"></i><b>2</b> Il metodo sperimentale: quando la scienza è scienza</a><ul>
<li class="chapter" data-level="2.1" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#introduzione-1"><i class="fa fa-check"></i><b>2.1</b> Introduzione</a><ul>
<li class="chapter" data-level="2.1.1" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#cosa-e-quindi-una-prova-scientifica"><i class="fa fa-check"></i><b>2.1.1</b> Cosa è quindi una prova scientifica?</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#esperimenti-buoni-e-cattivi"><i class="fa fa-check"></i><b>2.2</b> Esperimenti buoni e cattivi!</a><ul>
<li class="chapter" data-level="2.2.1" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#lerrore-sperimentale"><i class="fa fa-check"></i><b>2.2.1</b> L’errore sperimentale</a></li>
<li class="chapter" data-level="2.2.2" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#il-campionamento"><i class="fa fa-check"></i><b>2.2.2</b> Il campionamento</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#scienza-metodo"><i class="fa fa-check"></i><b>2.3</b> Scienza = metodo</a></li>
<li class="chapter" data-level="2.4" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#chi-valuta-se-un-esperimento-e-attendibile"><i class="fa fa-check"></i><b>2.4</b> Chi valuta se un esperimento è attendibile?</a></li>
<li class="chapter" data-level="2.5" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#il-metodo-sperimentale"><i class="fa fa-check"></i><b>2.5</b> Il metodo sperimentale</a></li>
<li class="chapter" data-level="2.6" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#metodi-sperimentali-validi-ed-invalidi"><i class="fa fa-check"></i><b>2.6</b> Metodi sperimentali validi ed invalidi</a><ul>
<li class="chapter" data-level="2.6.1" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#primo-esperimento"><i class="fa fa-check"></i><b>2.6.1</b> Primo esperimento</a></li>
<li class="chapter" data-level="2.6.2" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#secondo-esperimento"><i class="fa fa-check"></i><b>2.6.2</b> Secondo esperimento</a></li>
<li class="chapter" data-level="2.6.3" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#terzo-esperimento"><i class="fa fa-check"></i><b>2.6.3</b> Terzo esperimento</a></li>
<li class="chapter" data-level="2.6.4" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#quarto-esperimento-quello-buono"><i class="fa fa-check"></i><b>2.6.4</b> Quarto esperimento: quello buono</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#incertezza-residua"><i class="fa fa-check"></i><b>2.7</b> Incertezza residua</a></li>
<li class="chapter" data-level="2.8" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#il-ruolo-della-statistica"><i class="fa fa-check"></i><b>2.8</b> Il ruolo della statistica</a></li>
<li class="chapter" data-level="2.9" data-path="il-metodo-sperimentale-quando-la-scienza-e-scienza.html"><a href="il-metodo-sperimentale-quando-la-scienza-e-scienza.html#conclusioni"><i class="fa fa-check"></i><b>2.9</b> Conclusioni</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html"><i class="fa fa-check"></i><b>3</b> Introduzione al disegno sperimentale</a><ul>
<li class="chapter" data-level="3.1" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#definizioni"><i class="fa fa-check"></i><b>3.1</b> Definizioni</a></li>
<li class="chapter" data-level="3.2" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#elementi-fondamentali-del-disegno-sperimentale"><i class="fa fa-check"></i><b>3.2</b> Elementi fondamentali del disegno sperimentale</a><ul>
<li class="chapter" data-level="3.2.1" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#controllo-degli-errori"><i class="fa fa-check"></i><b>3.2.1</b> Controllo degli errori</a></li>
<li class="chapter" data-level="3.2.2" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#replicazione"><i class="fa fa-check"></i><b>3.2.2</b> Replicazione</a></li>
<li class="chapter" data-level="3.2.3" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#randomizzazione"><i class="fa fa-check"></i><b>3.2.3</b> Randomizzazione</a></li>
<li class="chapter" data-level="3.2.4" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#esperimenti-non-validi"><i class="fa fa-check"></i><b>3.2.4</b> Esperimenti non validi</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#progettazione-di-un-esperimento-protocollo"><i class="fa fa-check"></i><b>3.3</b> Progettazione di un esperimento (protocollo)</a><ul>
<li class="chapter" data-level="3.3.1" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#ipotesi-scientifica-rightarrow-obiettivo-dellesperimento"><i class="fa fa-check"></i><b>3.3.1</b> Ipotesi scientifica <span class="math inline">\(\rightarrow\)</span> obiettivo dell’esperimento</a></li>
<li class="chapter" data-level="3.3.2" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#casi-di-studio---1"><i class="fa fa-check"></i><b>3.3.2</b> Casi di studio - 1</a></li>
<li class="chapter" data-level="3.3.3" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#identificazione-dei-fattori-sperimentali"><i class="fa fa-check"></i><b>3.3.3</b> Identificazione dei fattori sperimentali</a></li>
<li class="chapter" data-level="3.3.4" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#esperimenti-multifattoriali"><i class="fa fa-check"></i><b>3.3.4</b> Esperimenti (multi)fattoriali</a></li>
<li class="chapter" data-level="3.3.5" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#aggiungere-un-controllo"><i class="fa fa-check"></i><b>3.3.5</b> Aggiungere un controllo?</a></li>
<li class="chapter" data-level="3.3.6" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#fattori-sperimentali-di-trattamento-e-di-blocco"><i class="fa fa-check"></i><b>3.3.6</b> Fattori sperimentali di trattamento e di blocco</a></li>
<li class="chapter" data-level="3.3.7" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#casi-di-studio---2"><i class="fa fa-check"></i><b>3.3.7</b> Casi di studio - 2</a></li>
<li class="chapter" data-level="3.3.8" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#identificazione-delle-unita-sperimentali-e-delle-repliche"><i class="fa fa-check"></i><b>3.3.8</b> Identificazione delle unità sperimentali e delle repliche</a></li>
<li class="chapter" data-level="3.3.9" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#scelta-delle-variabili-da-rilevare"><i class="fa fa-check"></i><b>3.3.9</b> Scelta delle variabili da rilevare</a></li>
<li class="chapter" data-level="3.3.10" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#casi-di-studio---3"><i class="fa fa-check"></i><b>3.3.10</b> Casi di studio - 3</a></li>
<li class="chapter" data-level="3.3.11" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#allocazione-dei-trattamenti"><i class="fa fa-check"></i><b>3.3.11</b> Allocazione dei trattamenti</a></li>
<li class="chapter" data-level="3.3.12" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#casi-di-studio---4"><i class="fa fa-check"></i><b>3.3.12</b> Casi di studio - 4</a></li>
<li class="chapter" data-level="3.3.13" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#impianto-delle-prove"><i class="fa fa-check"></i><b>3.3.13</b> Impianto delle prove</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#come-scrivere-un-progetto-di-ricerca-o-un-report-di-ricerca"><i class="fa fa-check"></i><b>3.4</b> Come scrivere un progetto di ricerca o un report di ricerca</a></li>
<li class="chapter" data-level="3.5" data-path="introduzione-al-disegno-sperimentale.html"><a href="introduzione-al-disegno-sperimentale.html#per-approfondimenti"><i class="fa fa-check"></i><b>3.5</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html"><i class="fa fa-check"></i><b>4</b> Per iniziare: introduzione ad R</a><ul>
<li class="chapter" data-level="4.1" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#cosa-e-r"><i class="fa fa-check"></i><b>4.1</b> Cosa è R?</a></li>
<li class="chapter" data-level="4.2" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#oggetti-e-assegnazioni"><i class="fa fa-check"></i><b>4.2</b> Oggetti e assegnazioni</a></li>
<li class="chapter" data-level="4.3" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#costanti-e-vettori"><i class="fa fa-check"></i><b>4.3</b> Costanti e vettori</a></li>
<li class="chapter" data-level="4.4" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#matrici"><i class="fa fa-check"></i><b>4.4</b> Matrici</a></li>
<li class="chapter" data-level="4.5" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#operazioni-ed-operatori"><i class="fa fa-check"></i><b>4.5</b> Operazioni ed operatori</a></li>
<li class="chapter" data-level="4.6" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#funzioni-ed-argomenti"><i class="fa fa-check"></i><b>4.6</b> Funzioni ed argomenti</a></li>
<li class="chapter" data-level="4.7" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#dataframe"><i class="fa fa-check"></i><b>4.7</b> Dataframe</a></li>
<li class="chapter" data-level="4.8" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#quale-oggetto-sto-utilizzando"><i class="fa fa-check"></i><b>4.8</b> Quale oggetto sto utilizzando?</a></li>
<li class="chapter" data-level="4.9" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#consigli-per-limmissione-di-dati-sperimentali"><i class="fa fa-check"></i><b>4.9</b> Consigli per l’immissione di dati sperimentali</a><ul>
<li class="chapter" data-level="4.9.1" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#immissione-manuale-di-dati"><i class="fa fa-check"></i><b>4.9.1</b> Immissione manuale di dati</a></li>
<li class="chapter" data-level="4.9.2" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#immissione-di-numeri-progressivi"><i class="fa fa-check"></i><b>4.9.2</b> Immissione di numeri progressivi</a></li>
<li class="chapter" data-level="4.9.3" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#immissione-dei-codici-delle-tesi-e-dei-blocchi"><i class="fa fa-check"></i><b>4.9.3</b> Immissione dei codici delle tesi e dei blocchi</a></li>
<li class="chapter" data-level="4.9.4" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#leggere-e-salvare-dati-esterni"><i class="fa fa-check"></i><b>4.9.4</b> Leggere e salvare dati esterni</a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#alcune-operazioni-comuni-sul-dataset"><i class="fa fa-check"></i><b>4.10</b> Alcune operazioni comuni sul dataset</a><ul>
<li class="chapter" data-level="4.10.1" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#selezionare-un-subset-di-dati"><i class="fa fa-check"></i><b>4.10.1</b> Selezionare un subset di dati</a></li>
<li class="chapter" data-level="4.10.2" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#ordinare-un-vettore-o-un-dataframe"><i class="fa fa-check"></i><b>4.10.2</b> Ordinare un vettore o un dataframe</a></li>
</ul></li>
<li class="chapter" data-level="4.11" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#workspace"><i class="fa fa-check"></i><b>4.11</b> Workspace</a></li>
<li class="chapter" data-level="4.12" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#script-o-programmi"><i class="fa fa-check"></i><b>4.12</b> Script o programmi</a></li>
<li class="chapter" data-level="4.13" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#interrogazione-di-oggetti"><i class="fa fa-check"></i><b>4.13</b> Interrogazione di oggetti</a></li>
<li class="chapter" data-level="4.14" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#altre-funzioni-matriciali"><i class="fa fa-check"></i><b>4.14</b> Altre funzioni matriciali</a></li>
<li class="chapter" data-level="4.15" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#cenni-sulle-funzionalita-grafiche-in-r"><i class="fa fa-check"></i><b>4.15</b> Cenni sulle funzionalità grafiche in R</a></li>
<li class="chapter" data-level="4.16" data-path="per-iniziare-introduzione-ad-r.html"><a href="per-iniziare-introduzione-ad-r.html#per-approfondimenti-1"><i class="fa fa-check"></i><b>4.16</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html"><i class="fa fa-check"></i><b>5</b> Primo passo: la descrizione dei dati raccolti</a><ul>
<li class="chapter" data-level="5.1" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#le-variabili-quantitative-analisi-chimiche-e-altre-misurazioni-fondamentali"><i class="fa fa-check"></i><b>5.1</b> Le variabili quantitative: analisi chimiche e altre misurazioni fondamentali</a><ul>
<li class="chapter" data-level="5.1.1" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#indicatori-di-tendenza-centrale"><i class="fa fa-check"></i><b>5.1.1</b> Indicatori di tendenza centrale</a></li>
<li class="chapter" data-level="5.1.2" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#indicatori-di-variabilita"><i class="fa fa-check"></i><b>5.1.2</b> Indicatori di variabilità</a></li>
<li class="chapter" data-level="5.1.3" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#arrotondamenti"><i class="fa fa-check"></i><b>5.1.3</b> Arrotondamenti</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#descrizione-dei-sottogruppi"><i class="fa fa-check"></i><b>5.2</b> Descrizione dei sottogruppi</a></li>
<li class="chapter" data-level="5.3" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#distribuzioni-di-frequenza-e-classamento"><i class="fa fa-check"></i><b>5.3</b> Distribuzioni di frequenza e classamento</a></li>
<li class="chapter" data-level="5.4" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#statistiche-descrittive-per-le-distribuzioni-di-frequenza"><i class="fa fa-check"></i><b>5.4</b> Statistiche descrittive per le distribuzioni di frequenza</a></li>
<li class="chapter" data-level="5.5" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#distribuzioni-di-frequenza-bivariate-le-tabelle-di-contingenza"><i class="fa fa-check"></i><b>5.5</b> Distribuzioni di frequenza bivariate: le tabelle di contingenza</a></li>
<li class="chapter" data-level="5.6" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#connessione"><i class="fa fa-check"></i><b>5.6</b> Connessione</a></li>
<li class="chapter" data-level="5.7" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#correlazione"><i class="fa fa-check"></i><b>5.7</b> Correlazione</a></li>
<li class="chapter" data-level="5.8" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#esercizi"><i class="fa fa-check"></i><b>5.8</b> Esercizi</a><ul>
<li class="chapter" data-level="5.8.1" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#esercizio-1"><i class="fa fa-check"></i><b>5.8.1</b> Esercizio 1</a></li>
<li class="chapter" data-level="5.8.2" data-path="primo-passo-la-descrizione-dei-dati-raccolti.html"><a href="primo-passo-la-descrizione-dei-dati-raccolti.html#esercizio-2"><i class="fa fa-check"></i><b>5.8.2</b> Esercizio 2</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html"><i class="fa fa-check"></i><b>6</b> Dalla popolazione al campione. I modelli stocastici</a><ul>
<li class="chapter" data-level="6.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#introduzione-2"><i class="fa fa-check"></i><b>6.1</b> Introduzione</a></li>
<li class="chapter" data-level="6.2" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#popolazione-di-soggetti-e-popolazione-di-misure"><i class="fa fa-check"></i><b>6.2</b> Popolazione di soggetti e popolazione di misure</a></li>
<li class="chapter" data-level="6.3" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#la-scienza-del-caso"><i class="fa fa-check"></i><b>6.3</b> La scienza del caso</a></li>
<li class="chapter" data-level="6.4" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#modelli-probabilistici-stocastici"><i class="fa fa-check"></i><b>6.4</b> Modelli probabilistici (stocastici)</a><ul>
<li class="chapter" data-level="6.4.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#funzioni-di-probabilita"><i class="fa fa-check"></i><b>6.4.1</b> Funzioni di probabilità</a></li>
<li class="chapter" data-level="6.4.2" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#funzioni-di-densita"><i class="fa fa-check"></i><b>6.4.2</b> Funzioni di densità</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#la-distribuzione-normale-curva-di-gauss"><i class="fa fa-check"></i><b>6.5</b> La distribuzione normale (curva di Gauss)</a><ul>
<li class="chapter" data-level="6.5.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-1-1"><i class="fa fa-check"></i><b>6.5.1</b> ESERCIZIO 1</a></li>
<li class="chapter" data-level="6.5.2" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-2-1"><i class="fa fa-check"></i><b>6.5.2</b> ESERCIZIO 2</a></li>
<li class="chapter" data-level="6.5.3" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-3"><i class="fa fa-check"></i><b>6.5.3</b> ESERCIZIO 3</a></li>
<li class="chapter" data-level="6.5.4" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-4"><i class="fa fa-check"></i><b>6.5.4</b> ESERCIZIO 4</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#la-distribuzione-t-di-student"><i class="fa fa-check"></i><b>6.6</b> La distribuzione t di Student</a><ul>
<li class="chapter" data-level="6.6.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-5"><i class="fa fa-check"></i><b>6.6.1</b> ESERCIZIO 5</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#la-distribuzione-f-di-fisher"><i class="fa fa-check"></i><b>6.7</b> La distribuzione F di Fisher</a><ul>
<li class="chapter" data-level="6.7.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-6"><i class="fa fa-check"></i><b>6.7.1</b> ESERCIZIO 6</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#modelli-stocastici-per-eventi-discreti-la-distribuzione-binomiale"><i class="fa fa-check"></i><b>6.8</b> Modelli stocastici per eventi discreti: la distribuzione binomiale</a><ul>
<li class="chapter" data-level="6.8.1" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-7"><i class="fa fa-check"></i><b>6.8.1</b> ESERCIZIO 7</a></li>
<li class="chapter" data-level="6.8.2" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#esercizio-8"><i class="fa fa-check"></i><b>6.8.2</b> ESERCIZIO 8</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#altri-modelli-stocastici-di-interesse-per-lo-sperimentatore"><i class="fa fa-check"></i><b>6.9</b> Altri modelli stocastici di interesse per lo sperimentatore</a></li>
<li class="chapter" data-level="6.10" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#e-allora"><i class="fa fa-check"></i><b>6.10</b> E allora?</a></li>
<li class="chapter" data-level="6.11" data-path="dalla-popolazione-al-campione-i-modelli-stocastici.html"><a href="dalla-popolazione-al-campione-i-modelli-stocastici.html#le-simulazioni-monte-carlo"><i class="fa fa-check"></i><b>6.11</b> Le simulazioni Monte Carlo</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><i class="fa fa-check"></i><b>7</b> Modellizzare l’errore sperimentale: introduzione all’inferenza statistica</a><ul>
<li class="chapter" data-level="7.1" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#introduzione-3"><i class="fa fa-check"></i><b>7.1</b> Introduzione</a></li>
<li class="chapter" data-level="7.2" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#lanalisi-dei-dati-gli-ingredienti-fondamentali"><i class="fa fa-check"></i><b>7.2</b> L’analisi dei dati: gli ’ingredienti’ fondamentali</a></li>
<li class="chapter" data-level="7.3" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#modello-della-realta-e-sampling-space"><i class="fa fa-check"></i><b>7.3</b> Modello della realtà e ’sampling space’</a></li>
<li class="chapter" data-level="7.4" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#esempio-1-2"><i class="fa fa-check"></i><b>7.4</b> Esempio 1</a><ul>
<li class="chapter" data-level="7.4.1" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#sampling-distribution"><i class="fa fa-check"></i><b>7.4.1</b> Sampling distribution</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#esempio-2-2"><i class="fa fa-check"></i><b>7.5</b> Esempio 2</a><ul>
<li class="chapter" data-level="7.5.1" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#definire-la-sampling-distribution-per-lesempio-2"><i class="fa fa-check"></i><b>7.5.1</b> Definire la ’sampling distribution’ per l’esempio 2</a></li>
<li class="chapter" data-level="7.5.2" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#le-simulazioni-monte-carlo-con-excel"><i class="fa fa-check"></i><b>7.5.2</b> Le simulazioni Monte Carlo con Excel</a></li>
<li class="chapter" data-level="7.5.3" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#la-distribuzione-delle-medie-campionarie-lerrore-standard"><i class="fa fa-check"></i><b>7.5.3</b> La distribuzione delle medie campionarie: l’errore standard</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#riepilogo-1-caratterizzare-lincertezza-di-un-esperimento"><i class="fa fa-check"></i><b>7.6</b> Riepilogo 1: Caratterizzare l’incertezza di un esperimento</a></li>
<li class="chapter" data-level="7.7" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#gli-intervalli-di-confidenza"><i class="fa fa-check"></i><b>7.7</b> Gli intervalli di confidenza</a></li>
<li class="chapter" data-level="7.8" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#gli-intervalli-di-confidenza-con-excel"><i class="fa fa-check"></i><b>7.8</b> Gli intervalli di confidenza con Excel</a></li>
<li class="chapter" data-level="7.9" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#qual-e-il-senso-dellintervallo-di-confidenza"><i class="fa fa-check"></i><b>7.9</b> Qual è il senso dell’intervallo di confidenza?</a></li>
<li class="chapter" data-level="7.10" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#analisi-statistica-dei-dati-riassunto-del-percorso-logico"><i class="fa fa-check"></i><b>7.10</b> Analisi statistica dei dati: riassunto del percorso logico</a></li>
<li class="chapter" data-level="7.11" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#presentazione-dei-risultati-degli-esperimenti"><i class="fa fa-check"></i><b>7.11</b> Presentazione dei risultati degli esperimenti</a></li>
<li class="chapter" data-level="7.12" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#da-ricordare"><i class="fa fa-check"></i><b>7.12</b> Da ricordare</a></li>
<li class="chapter" data-level="7.13" data-path="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html"><a href="modellizzare-lerrore-sperimentale-introduzione-allinferenza-statistica.html#esercizi-1"><i class="fa fa-check"></i><b>7.13</b> Esercizi</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html"><i class="fa fa-check"></i><b>8</b> Breve introduzione al test d’ipotesi</a><ul>
<li class="chapter" data-level="8.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-una-media-osservata-e-una-media-teorica"><i class="fa fa-check"></i><b>8.1</b> Confronto tra una media osservata e una media teorica</a><ul>
<li class="chapter" data-level="8.1.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#esempio-1-3"><i class="fa fa-check"></i><b>8.1.1</b> ESEMPIO 1</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#simulazione-monte-carlo"><i class="fa fa-check"></i><b>8.2</b> Simulazione Monte Carlo</a></li>
<li class="chapter" data-level="8.3" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#soluzione-formale"><i class="fa fa-check"></i><b>8.3</b> Soluzione formale</a></li>
<li class="chapter" data-level="8.4" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#interpretazione-del-p-level"><i class="fa fa-check"></i><b>8.4</b> Interpretazione del P-level</a></li>
<li class="chapter" data-level="8.5" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-medie-il-test-t-di-student"><i class="fa fa-check"></i><b>8.5</b> Confronto tra due medie: il test t di Student</a><ul>
<li class="chapter" data-level="8.5.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#esempio-2-3"><i class="fa fa-check"></i><b>8.5.1</b> ESEMPIO 2</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#approfondimento-tipologie-alternative-di-test-t"><i class="fa fa-check"></i><b>8.6</b> Approfondimento: tipologie alternative di test t</a></li>
<li class="chapter" data-level="8.7" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#confronto-tra-due-proporzioni"><i class="fa fa-check"></i><b>8.7</b> Confronto tra due proporzioni</a><ul>
<li class="chapter" data-level="8.7.1" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#esempio-3-2"><i class="fa fa-check"></i><b>8.7.1</b> ESEMPIO 3</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#conclusioni-1"><i class="fa fa-check"></i><b>8.8</b> Conclusioni</a></li>
<li class="chapter" data-level="8.9" data-path="breve-introduzione-al-test-dipotesi.html"><a href="breve-introduzione-al-test-dipotesi.html#riepilogo"><i class="fa fa-check"></i><b>8.9</b> Riepilogo</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="modelli-matamatici-descrittivi-breve-introduzione.html"><a href="modelli-matamatici-descrittivi-breve-introduzione.html"><i class="fa fa-check"></i><b>9</b> Modelli matamatici descrittivi: breve introduzione</a><ul>
<li class="chapter" data-level="9.1" data-path="modelli-matamatici-descrittivi-breve-introduzione.html"><a href="modelli-matamatici-descrittivi-breve-introduzione.html#che-centra-la-matematica"><i class="fa fa-check"></i><b>9.1</b> Che c’entra la matematica?</a></li>
<li class="chapter" data-level="9.2" data-path="modelli-matamatici-descrittivi-breve-introduzione.html"><a href="modelli-matamatici-descrittivi-breve-introduzione.html#mettiamo-alcuni-paletti"><i class="fa fa-check"></i><b>9.2</b> Mettiamo alcuni paletti</a></li>
<li class="chapter" data-level="9.3" data-path="modelli-matamatici-descrittivi-breve-introduzione.html"><a href="modelli-matamatici-descrittivi-breve-introduzione.html#metodo-di-lavoro"><i class="fa fa-check"></i><b>9.3</b> Metodo di lavoro</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html"><i class="fa fa-check"></i><b>10</b> Una variabile indipendente categorica: ANOVA ad una via</a><ul>
<li class="chapter" data-level="10.1" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#la-situazione-sperimentale"><i class="fa fa-check"></i><b>10.1</b> La situazione sperimentale</a></li>
<li class="chapter" data-level="10.2" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#la-verita-vera-la-popolazione"><i class="fa fa-check"></i><b>10.2</b> La verità ‘vera’ (la popolazione)</a></li>
<li class="chapter" data-level="10.3" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#esecuzione-dellesperimento"><i class="fa fa-check"></i><b>10.3</b> Esecuzione dell’esperimento</a></li>
<li class="chapter" data-level="10.4" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#analisi-dei-dati-1"><i class="fa fa-check"></i><b>10.4</b> Analisi dei dati</a><ul>
<li class="chapter" data-level="10.4.1" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#statistiche-descrittive"><i class="fa fa-check"></i><b>10.4.1</b> Statistiche descrittive</a></li>
<li class="chapter" data-level="10.4.2" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#stima-dei-parametri-1"><i class="fa fa-check"></i><b>10.4.2</b> Stima dei parametri</a></li>
<li class="chapter" data-level="10.4.3" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#stima-della-varianza"><i class="fa fa-check"></i><b>10.4.3</b> Stima della varianza</a></li>
<li class="chapter" data-level="10.4.4" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#effetto-del-trattamento"><i class="fa fa-check"></i><b>10.4.4</b> Effetto del trattamento</a></li>
<li class="chapter" data-level="10.4.5" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#test-dipotesi"><i class="fa fa-check"></i><b>10.4.5</b> Test d’ipotesi</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="una-variabile-indipendente-categorica-anova-ad-una-via.html"><a href="una-variabile-indipendente-categorica-anova-ad-una-via.html#per-approfondimenti-2"><i class="fa fa-check"></i><b>10.5</b> Per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><i class="fa fa-check"></i><b>11</b> La verifica delle assunzioni di base: metodi diagnostici</a><ul>
<li class="chapter" data-level="11.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#introduzione-4"><i class="fa fa-check"></i><b>11.1</b> Introduzione</a></li>
<li class="chapter" data-level="11.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#procedure-diagnostiche"><i class="fa fa-check"></i><b>11.2</b> Procedure diagnostiche</a></li>
<li class="chapter" data-level="11.3" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#analisi-grafica-dei-residui"><i class="fa fa-check"></i><b>11.3</b> Analisi grafica dei residui</a><ul>
<li class="chapter" data-level="11.3.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#grafico-dei-residui-contro-i-valori-attesi"><i class="fa fa-check"></i><b>11.3.1</b> Grafico dei residui contro i valori attesi</a></li>
<li class="chapter" data-level="11.3.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#qq-plot"><i class="fa fa-check"></i><b>11.3.2</b> QQ-plot</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#altri-strumenti-diagnostici"><i class="fa fa-check"></i><b>11.4</b> Altri strumenti diagnostici</a></li>
<li class="chapter" data-level="11.5" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#risultati-contraddittori"><i class="fa fa-check"></i><b>11.5</b> Risultati contraddittori</a></li>
<li class="chapter" data-level="11.6" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#terapia"><i class="fa fa-check"></i><b>11.6</b> ‘Terapia’</a><ul>
<li class="chapter" data-level="11.6.1" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#correzionerimozione-degli-outliers"><i class="fa fa-check"></i><b>11.6.1</b> Correzione/Rimozione degli outliers</a></li>
<li class="chapter" data-level="11.6.2" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#correzione-del-modello"><i class="fa fa-check"></i><b>11.6.2</b> Correzione del modello</a></li>
<li class="chapter" data-level="11.6.3" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#non-normalita-dei-residui-ed-eterogeneita-delle-varianze"><i class="fa fa-check"></i><b>11.6.3</b> Non-normalità dei residui ed eterogeneità delle varianze</a></li>
<li class="chapter" data-level="11.6.4" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#la-procedura-di-box-e-cox"><i class="fa fa-check"></i><b>11.6.4</b> La procedura di Box e Cox</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html"><a href="la-verifica-delle-assunzioni-di-base-metodi-diagnostici.html#referenze-bibliografiche-per-approfondimenti"><i class="fa fa-check"></i><b>11.7</b> Referenze bibliografiche per approfondimenti</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html"><i class="fa fa-check"></i><b>12</b> Modelli lineari con più variabili indipendenti</a><ul>
<li class="chapter" data-level="12.1" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html#introduzione-5"><i class="fa fa-check"></i><b>12.1</b> Introduzione</a></li>
<li class="chapter" data-level="12.2" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html#anova-a-blocchi-randomizzati"><i class="fa fa-check"></i><b>12.2</b> ANOVA a blocchi randomizzati</a></li>
<li class="chapter" data-level="12.3" data-path="modelli-lineari-con-piu-variabili-indipendenti.html"><a href="modelli-lineari-con-piu-variabili-indipendenti.html#anova-a-quadrato-latino"><i class="fa fa-check"></i><b>12.3</b> ANOVA a quadrato latino</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html"><i class="fa fa-check"></i><b>13</b> Contrasti e confronti multipli con R</a><ul>
<li class="chapter" data-level="13.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#introduzione-6"><i class="fa fa-check"></i><b>13.1</b> Introduzione</a></li>
<li class="chapter" data-level="13.2" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#esempio"><i class="fa fa-check"></i><b>13.2</b> Esempio</a></li>
<li class="chapter" data-level="13.3" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-contrasti"><i class="fa fa-check"></i><b>13.3</b> I contrasti</a><ul>
<li class="chapter" data-level="13.3.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#varianza-del-contrasto-e-intervalli-di-confidenza"><i class="fa fa-check"></i><b>13.3.1</b> Varianza del contrasto e intervalli di confidenza</a></li>
<li class="chapter" data-level="13.3.2" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#significativita-del-contrasto-e-intervalli-di-confidenza"><i class="fa fa-check"></i><b>13.3.2</b> Significatività del contrasto e intervalli di confidenza</a></li>
<li class="chapter" data-level="13.3.3" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-contrasti-con-r"><i class="fa fa-check"></i><b>13.3.3</b> I contrasti con R</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#i-confronti-multipli-a-coppie-pairwise-comparisons"><i class="fa fa-check"></i><b>13.4</b> I confronti multipli a coppie (pairwise comparisons)</a></li>
<li class="chapter" data-level="13.5" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#display-a-lettere"><i class="fa fa-check"></i><b>13.5</b> Display a lettere</a></li>
<li class="chapter" data-level="13.6" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#problemi-di-molteplicita-tassi-di-errore-per-confronto-e-per-esperimento"><i class="fa fa-check"></i><b>13.6</b> Problemi di molteplicità: tassi di errore per confronto e per esperimento</a><ul>
<li class="chapter" data-level="13.6.1" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#correzione-per-la-molteplicita"><i class="fa fa-check"></i><b>13.6.1</b> Correzione per la molteplicità</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#intervalli-di-confidenza-simultanei"><i class="fa fa-check"></i><b>13.7</b> Intervalli di confidenza simultanei</a></li>
<li class="chapter" data-level="13.8" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#e-le-classiche-procedure-di-confronto-multiplo"><i class="fa fa-check"></i><b>13.8</b> E le classiche procedure di confronto multiplo?</a></li>
<li class="chapter" data-level="13.9" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#consigli-pratici"><i class="fa fa-check"></i><b>13.9</b> Consigli pratici</a></li>
<li class="chapter" data-level="13.10" data-path="contrasti-e-confronti-multipli-con-r.html"><a href="contrasti-e-confronti-multipli-con-r.html#referenze-bibliografiche"><i class="fa fa-check"></i><b>13.10</b> Referenze bibliografiche</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html"><i class="fa fa-check"></i><b>14</b> La regressione lineare semplice</a><ul>
<li class="chapter" data-level="14.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#introduzione-7"><i class="fa fa-check"></i><b>14.1</b> Introduzione</a></li>
<li class="chapter" data-level="14.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#esempio-6"><i class="fa fa-check"></i><b>14.2</b> Esempio</a></li>
<li class="chapter" data-level="14.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#stima-dei-parametri-2"><i class="fa fa-check"></i><b>14.3</b> Stima dei parametri</a></li>
<li class="chapter" data-level="14.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-della-bonta-del-modello"><i class="fa fa-check"></i><b>14.4</b> Valutazione della bontà del modello</a><ul>
<li class="chapter" data-level="14.4.1" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#valutazione-grafica"><i class="fa fa-check"></i><b>14.4.1</b> Valutazione grafica</a></li>
<li class="chapter" data-level="14.4.2" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#errori-standard-dei-parametri"><i class="fa fa-check"></i><b>14.4.2</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="14.4.3" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-mancanza-dadattamento"><i class="fa fa-check"></i><b>14.4.3</b> Test F per la mancanza d’adattamento</a></li>
<li class="chapter" data-level="14.4.4" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#test-f-per-la-bonta-di-adattamento-e-coefficiente-di-determinazione"><i class="fa fa-check"></i><b>14.4.4</b> Test F per la bontà di adattamento e coefficiente di determinazione</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="la-regressione-lineare-semplice.html"><a href="la-regressione-lineare-semplice.html#previsioni"><i class="fa fa-check"></i><b>14.5</b> Previsioni</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html"><i class="fa fa-check"></i><b>15</b> La regressione non-lineare</a><ul>
<li class="chapter" data-level="15.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#introduzione-8"><i class="fa fa-check"></i><b>15.1</b> Introduzione</a></li>
<li class="chapter" data-level="15.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-1-4"><i class="fa fa-check"></i><b>15.2</b> Esempio 1</a><ul>
<li class="chapter" data-level="15.2.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#scelta-della-funzione"><i class="fa fa-check"></i><b>15.2.1</b> Scelta della funzione</a></li>
<li class="chapter" data-level="15.2.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#stima-dei-parametri-3"><i class="fa fa-check"></i><b>15.2.2</b> Stima dei parametri</a></li>
<li class="chapter" data-level="15.2.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#la-regressione-non-lineare-con-r"><i class="fa fa-check"></i><b>15.2.3</b> La regressione non-lineare con R</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#riparametrizzazione-delle-funzioni"><i class="fa fa-check"></i><b>15.3</b> Riparametrizzazione delle funzioni</a><ul>
<li class="chapter" data-level="15.3.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-2-4"><i class="fa fa-check"></i><b>15.3.1</b> Esempio 2</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#inferenze-statistiche-e-verifiche-delle-assunzioni-di-base"><i class="fa fa-check"></i><b>15.4</b> Inferenze statistiche e verifiche delle assunzioni di base</a><ul>
<li class="chapter" data-level="15.4.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#analisi-grafica-dei-residui-1"><i class="fa fa-check"></i><b>15.4.1</b> Analisi grafica dei residui</a></li>
<li class="chapter" data-level="15.4.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#test-f-per-la-mancanza-di-adattamento-approssimato"><i class="fa fa-check"></i><b>15.4.2</b> Test F per la mancanza di adattamento (approssimato)</a></li>
<li class="chapter" data-level="15.4.3" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#errori-standard-dei-parametri-1"><i class="fa fa-check"></i><b>15.4.3</b> Errori standard dei parametri</a></li>
<li class="chapter" data-level="15.4.4" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#coefficiente-di-determinazione"><i class="fa fa-check"></i><b>15.4.4</b> Coefficiente di determinazione</a></li>
<li class="chapter" data-level="15.4.5" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#coefficiente-di-determinazione-aggiustato"><i class="fa fa-check"></i><b>15.4.5</b> Coefficiente di determinazione aggiustato</a></li>
<li class="chapter" data-level="15.4.6" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#altre-statistiche"><i class="fa fa-check"></i><b>15.4.6</b> Altre statistiche</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#gestione-delle-situazioni-patologiche"><i class="fa fa-check"></i><b>15.5</b> Gestione delle situazioni ‘patologiche’</a><ul>
<li class="chapter" data-level="15.5.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-del-modello"><i class="fa fa-check"></i><b>15.5.1</b> Trasformazione del modello</a></li>
<li class="chapter" data-level="15.5.2" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#trasformazione-dei-dati"><i class="fa fa-check"></i><b>15.5.2</b> Trasformazione dei dati</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#funzioni-lineari-e-nonlineari-dei-parametri"><i class="fa fa-check"></i><b>15.6</b> Funzioni lineari e nonlineari dei parametri</a></li>
<li class="chapter" data-level="15.7" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#modelli-ancova"><i class="fa fa-check"></i><b>15.7</b> Modelli ANCOVA</a><ul>
<li class="chapter" data-level="15.7.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#esempio-3-3"><i class="fa fa-check"></i><b>15.7.1</b> Esempio 3</a></li>
</ul></li>
<li class="chapter" data-level="15.8" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#confronto-tra-modelli-alternativi"><i class="fa fa-check"></i><b>15.8</b> Confronto tra modelli alternativi</a><ul>
<li class="chapter" data-level="15.8.1" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#confronto-tra-modelli-non-nested"><i class="fa fa-check"></i><b>15.8.1</b> Confronto tra modelli non-nested</a></li>
</ul></li>
<li class="chapter" data-level="15.9" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#il-package-drc"><i class="fa fa-check"></i><b>15.9</b> Il package ‘drc’</a></li>
<li class="chapter" data-level="15.10" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#previsioni-1"><i class="fa fa-check"></i><b>15.10</b> Previsioni</a></li>
<li class="chapter" data-level="15.11" data-path="la-regressione-non-lineare.html"><a href="la-regressione-non-lineare.html#bibliografia"><i class="fa fa-check"></i><b>15.11</b> Bibliografia</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Metodologia statistica per le scienze agrarie</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="la-regressione-non-lineare" class="section level1">
<h1><span class="header-section-number">Capitolo 15</span> La regressione non-lineare</h1>
<div id="introduzione-8" class="section level2">
<h2><span class="header-section-number">15.1</span> Introduzione</h2>
<p>I fenomeni biologici, come ad esempio la crescita di una coltura, la cinetica degradativa degli erbicidi nel terreno, la risposta produttiva delle colture a densità crescenti di malerbe o a dosi crescenti di concime, la risposta fitotossica di una specie infestante alla dose di un erbicida, hanno in genere andamenti curvilinei, posseggono punti di massimo o minimo, flessi e, soprattutto, hanno frequentemente asintoti. Pertanto, difficilmente possono essere descritti con funzioni lineari, a meno che non ci accontentiamo di approssimare localmente l’andamento dei dati, in un intervallo ristretto della variabile indipendente.</p>
<p>Da un punto di vista pratico è quindi fondamentale sapere adattare ai dati funzioni curvilinee di ogni tipo. Introduciamo il problema con un esempio.</p>
</div>
<div id="esempio-1-4" class="section level2">
<h2><span class="header-section-number">15.2</span> Esempio 1</h2>
<p>Un suolo è stato trattato con metamitron (un erbicida) alla concentrazione di 100 <span class="math inline">\(ng \,\, g^1\)</span>. Dopo essere stato opportunamente mescolato, è stato posto in cella climatica alla temperatura di 20 C, distribuito in 24 contenitori di alluminio. In 8 tempi diversi dopo l’inizio del saggio, sono stati prelevati 3 contenitori e sottoposti ad analisi chimica per la determinazione della concentrazione residua dell’erbicida. I dati osservati sono riportati di seguito.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(drc)
<span class="kw">library</span>(aomisc)
<span class="kw">data</span>(degradation)
<span class="kw">head</span>(degradation, <span class="dv">10</span>)</code></pre></div>
<pre><code>##    Time   Conc
## 1     0  96.40
## 2    10  46.30
## 3    20  21.20
## 4    30  17.89
## 5    40  10.10
## 6    50   6.90
## 7    60   3.50
## 8    70   1.90
## 9     0 102.30
## 10   10  49.20</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-177-1.png" width="672" /></p>
<p>Il grafico suggerisce che la risposta della concentrazione nel tempo è curvilinea, secondo la seguente equazione generale:</p>
<p><span class="math display">\[ Y = f(X, \theta) + \epsilon \]</span></p>
<p>dove <span class="math inline">\(X\)</span> è il tempo, <span class="math inline">\(Y\)</span> la concentrazione, <span class="math inline">\(\theta\)</span> sono i parametri del modello ed <span class="math inline">\(\epsilon\)</span> sono i residui, che misurano lo scostamento dei dati osservati dalla risposta attesa, secondo l’equazione prescelta per <span class="math inline">\(f\)</span>. E’ evidente che <span class="math inline">\(X\)</span> ed <span class="math inline">\(Y\)</span> sono noti, ma resta da scegliere <span class="math inline">\(f\)</span> e da stimare <span class="math inline">\(\theta\)</span>.</p>
<div id="scelta-della-funzione" class="section level3">
<h3><span class="header-section-number">15.2.1</span> Scelta della funzione</h3>
<p>Uno dei criteri fondamentali, ancorché empirico, per la selezione di una curva è quello di considerarne la forma, in relazione al fenomeno biologico in studio. Un buon riferimento è dato da <span class="citation">Ratkowsky (<a href="#ref-ratkowsky1990_Handbooknonlinearregression">1990</a>)</span>, che classifica le equazioni in:</p>
<ul>
<li>Curve Lineari
<ol style="list-style-type: decimal">
<li>Retta</li>
<li>Parabola</li>
</ol></li>
<li>Curve convesse/concave
<ol style="list-style-type: decimal">
<li>Funzione esponenziale</li>
<li>Funzione di potenza</li>
<li>Funzione logaritmica</li>
<li>Iperbole rettangolare</li>
<li>Funzione monomolecolare</li>
<li>Funzione di Michaelis-Menten</li>
</ol></li>
<li>Curve sigmoidali
<ol style="list-style-type: decimal">
<li>Funzione logistica</li>
<li>Funzione di Gompertz</li>
<li>Funzione ’valori estremi’</li>
<li>Funzione Log-logistica (Equazione di Hill)</li>
<li>Weibull-1 (log-Gompertz)</li>
<li>Weibull-2 (log-Extreme)</li>
</ol></li>
<li>Curve con massimi/minimi
<ol style="list-style-type: decimal">
<li>Equazione di Brain-Cousens</li>
<li>Equazione di Braggs</li>
</ol></li>
</ul>
<p>La descrizione di queste curve verrà fatta in appendice. In questo caso specifico abbiamo bisogno di una funzione concava verso l’alto e con un asintoto orizzontale coincidente con l’asse delle X. Le conoscenze in relazione alla cinetica di degradazione dei composti chimici ci suggerisce una relazione esponenziale (cinetica del primo ordine), così definita:</p>
<p><span class="math display">\[ Y = A e^{-k \,X} \]</span></p>
<p>dove A è la concentrazione iniziale e <span class="math inline">\(k\)</span> e il tasso di degradazione (costante nel tempo).</p>
</div>
<div id="stima-dei-parametri-3" class="section level3">
<h3><span class="header-section-number">15.2.2</span> Stima dei parametri</h3>
<p>Dopo aver definito <span class="math inline">\(f\)</span>, dobbiamo stimare i parametri <span class="math inline">\(A\)</span> e <span class="math inline">\(k\)</span>. In generale esistono tre tecniche fondamentali <span class="citation">(Draper and Smith <a href="#ref-draper1998_Appliedregressionanalysis">1998</a>)</span> :</p>
<ol style="list-style-type: decimal">
<li>linearizzazione della funzione tramite trasformazione delle variabili;</li>
<li>approssimazione della vera funzione curvilinea con una polinomiale in X;</li>
<li>adattamento ai dati sperimentali di funzioni curvilinee, tramite metodiche di regressione non-lineare.</li>
</ol>
<div id="linearizzazione-della-funzione" class="section level4">
<h4><span class="header-section-number">15.2.2.1</span> Linearizzazione della funzione</h4>
<p>Nel caso specifico, prendendo il logaritmo di entrambe le parti dell’equazione, otteniamo la seguente trasformazione:</p>
<p><span class="math display">\[ log(Y) = log(A) + X \]</span></p>
<p>Possiamo quindi trasformare la Y nel suo logaritmo ed utilizzare un modello lineare per la stima dei parametri.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log</span>(Conc) <span class="op">~</span><span class="st"> </span>Time, <span class="dt">data=</span>degradation)
<span class="kw">summary</span>(mod)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log(Conc) ~ Time, data = degradation)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.11738 -0.09583  0.05336  0.31166  1.01243 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  4.662874   0.257325   18.12 1.04e-14 ***
## Time        -0.071906   0.006151  -11.69 6.56e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6905 on 22 degrees of freedom
## Multiple R-squared:  0.8613, Adjusted R-squared:  0.855 
## F-statistic: 136.6 on 1 and 22 DF,  p-value: 6.564e-11</code></pre>
<p>Le funzioni linearizzabili per semplice trasformazione delle variabili sono dette <em>linearizzabili</em> e presentano il vantaggio di semplificare molto i calcoli richiesti per la stima dei parametri. Un grave svantaggio è dato dal fatto che trasformando la Y si trasforma anche la distribuzione degli errori e quindi bisogna verificare che le assunzioni di base dei modelli lineari (omogeneità delle varianze e normalità dei residui) siano valide nella scala trasformata</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(<span class="kw">residuals</span>(mod) <span class="op">~</span><span class="st"> </span><span class="kw">fitted</span>(mod), 
     <span class="dt">xlab=</span><span class="st">&quot;Fitted data&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Residuals&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<div class="figure"><span id="fig:foo"></span>
<img src="_main_files/figure-html/foo-1.png" alt="Prova" width="672" />
<p class="caption">
Figure 15.1: Prova
</p>
</div>
<p>In questo caso specifico, il grafico dei residui suggerisci deviazioni consistenti rispetto alla omogeneità delle varianze, che risultano inversamente proporzionali ai valori attesi (più alto il logaritmo della concentrazione più bassi i residui). Questo fa sospettare che le varianze potrebbero essere omogenee sulla scala originale, impedendoci quindi di analizzare i dati nella scala trasformata.</p>
</div>
<div id="approssimazione-della-vera-funzione-tramite-una-polinomiale-in-x" class="section level4">
<h4><span class="header-section-number">15.2.2.2</span> Approssimazione della vera funzione tramite una polinomiale in X</h4>
<p>In generale, relazioni matematiche curvilinee possono essere approssimate tramite funzioni polinomiali di ordine . Le funzioni polinomiali sono molto flessibili; contengono la funzione lineare come caso particolare (n=1) e permette di descrivere curvature anche molto complesse semplicemente aumentando l’ ordine della funzione. In questo modo è possibile ottenere un adattamento ai dati sperimentali teoricamente anche perfetto.</p>
<p>Le funzioni polinomiali sono un tipico esempio di funzioni non-lineari nelle variabili, ma lineari nei parametri; esse possono essere trattate ricorrendo alle metodiche di calcolo normalmente utilizzate per la regressione lineare.</p>
<p>Gli svantaggi delle funzioni polinomiali sono relativi al fatto che queste presentano raramente giustificazione biologica. Per esempio, con le funzioni polinomiali non è possibile descrivere relazioni asintotiche, che sono invece molto comuni in biologia. Nel nostro esempio si potrebbe utilizzare una funzione polinomiale di II grado.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod2 &lt;-<span class="st"> </span><span class="kw">lm</span>(Conc <span class="op">~</span><span class="st"> </span>Time <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(Time<span class="op">^</span><span class="dv">2</span>), <span class="dt">data=</span>degradation)
<span class="kw">plot</span>(Conc <span class="op">~</span><span class="st"> </span>Time, <span class="dt">data=</span>degradation)
coefs &lt;-<span class="st"> </span><span class="kw">coef</span>(mod2)
<span class="kw">curve</span>(coefs[<span class="dv">1</span>] <span class="op">+</span><span class="st"> </span>coefs[<span class="dv">2</span>]<span class="op">*</span>x <span class="op">+</span><span class="st"> </span>coefs[<span class="dv">3</span>]<span class="op">*</span>x<span class="op">^</span><span class="dv">2</span>, <span class="dt">add=</span>T, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-179-1.png" width="672" /></p>
<p>Vediamo come la funzione inserita, mentre approssima bene i dati nell’intervallo da 0 a 40 giorni, successivamente mostra una ricrescita, che non ha alcun senso biologico.</p>
<p>In generale, le polinomiali sono utilizzate quando sia necessario approssimare una funzione curvilinea in un intervallo della X molto ristretto e non consentono nessuna estrapolazione al di fuori di questo intervallo, dato che possono portare a stime della risposta completamente insensate biologicamente.</p>
<p>Per questi motivi l’ uso delle funzioni polinomiali dovrebbe essere limitato ai casi in cui non si abbia nessuna conoscenza <em>a priori</em> dell’ andamento del fenomeno. Tra l’ altro i moderni supporti informatici consentono di risolvere il problema dell’ adattamento diretto di funzioni curvilinee qualunque senza i lunghi calcoli manuali che venivano richiesti fino ad alcuni anni fa.</p>
</div>
<div id="adattamento-di-funzioni-curvilinee-qualunque-regressione-non-lineare" class="section level4">
<h4><span class="header-section-number">15.2.2.3</span> Adattamento di funzioni curvilinee qualunque: regressione non-lineare</h4>
<p>Per quanto sopra accennato, ogniqualvolta possibile, si preferisce utilizzare metodologie di regressione non-lineare, che permettono di adattare direttamente funzioni curvilinee di qualunque tipo ai dati sperimentali. La stima dei parametri, tuttavia, non è immediata e richiede l’impiego di metodi iterativi, come il metodo di Gauss-Newton <span class="citation">(Bates and Watts <a href="#ref-bates1988_Nonlinearregressionanalysis">1988</a>)</span> (Gauss-Newton, Steepest Descent, Marquardt, Simplex; alcune informazioni sono riportate in appendice). In questo caso, è necessario fissare delle stime iniziali dei parametri, che vengono corrette in ogni iterazione successiva fino ad ottenere la convergenza sui valori che minimizzano lo scostamento tra i dati osservati e la funzione non-lineare (metodo dei minimi quadrati non-lineari). Ovviamente, trattandosi di metodi iterativi, le stime ottenute sono solo un’approssimazione (accettabile!) dei valori reali.</p>
</div>
</div>
<div id="la-regressione-non-lineare-con-r" class="section level3">
<h3><span class="header-section-number">15.2.3</span> La regressione non-lineare con R</h3>
<p>La funzione più comune in R per la parametrizzazione di funzioni non-lineari è nls(), che è descritta in dettaglio da <span class="citation">C. Ritz and Streibig (<a href="#ref-ritz2008_Nonlinearregression">2008</a>)</span>. Nella chiamata alla funzione dobbiamo anche fornire stime iniziali per i valori dei parametri. Ottenere queste stime è facile pensando al significato biologico dei parametri: <span class="math inline">\(A\)</span> è la concentrazione iniziale e quindi una stima ragionevole è data dal valor medio osservato al tempo 0 (100). Il parametro <span class="math inline">\(k\)</span> è invece il tasso di degradazione relativo; possiamo notare che nei primi 10 giorni la concentrazione si riduce della metà circa, cioè si abbassa mediamente un po’ più del 5% al giorno (considerando che inizialmente il calo è più rapido). Possiamo quindi assegnare a <span class="math inline">\(k\)</span> un valore iniziale pari a 0.06.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modNlin &lt;-<span class="st"> </span><span class="kw">nls</span>(Conc <span class="op">~</span><span class="st"> </span>A<span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>k<span class="op">*</span>Time), 
               <span class="dt">start=</span><span class="kw">list</span>(<span class="dt">A=</span><span class="dv">100</span>, <span class="dt">k=</span><span class="fl">0.06</span>), 
               <span class="dt">data=</span>degradation)
<span class="kw">summary</span>(modNlin)</code></pre></div>
<pre><code>## 
## Formula: Conc ~ A * exp(-k * Time)
## 
## Parameters:
##    Estimate Std. Error t value Pr(&gt;|t|)    
## A 99.634898   1.461047   68.19   &lt;2e-16 ***
## k  0.067039   0.001887   35.53   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.621 on 22 degrees of freedom
## 
## Number of iterations to convergence: 4 
## Achieved convergence tolerance: 1.549e-06</code></pre>
<p>In alternativa, preferiamo utilizzare il package drc, con la funzione drm(), che ha un’infrastruttura molto comoda per le regressioni non-lineari in genere, compresa la definizione di funzioni di self-starting, che ci liberano dal problema di dover reperire le stime iniziali dei parametri <span class="citation">(Christian Ritz et al. <a href="#ref-ritz2015_DoseResponseAnalysisUsing">2015</a>)</span>. La chiamata è simile a quella di nls(), anche se vengono indicate separatamente le due variabili (Y ~ X) e la funzione (in questo caso il nome è firstOrder()).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(drc)
modNlin2 &lt;-<span class="st"> </span><span class="kw">drm</span>(Conc <span class="op">~</span><span class="st"> </span>Time, <span class="dt">fct=</span><span class="kw">DRC.expoDecay</span>(),
                <span class="dt">data=</span>degradation)
<span class="kw">summary</span>(modNlin2)</code></pre></div>
<pre><code>## 
## Model fitted: Exponential Decay Model (2 parms)
## 
## Parameter estimates:
## 
##                    Estimate Std. Error t-value   p-value    
## init:(Intercept) 99.6349312  1.4646680  68.026 &lt; 2.2e-16 ***
## k:(Intercept)     0.0670391  0.0019089  35.120 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  2.621386 (22 degrees of freedom)</code></pre>
<p>I risultati sono praticamente identici.</p>
</div>
</div>
<div id="riparametrizzazione-delle-funzioni" class="section level2">
<h2><span class="header-section-number">15.3</span> Riparametrizzazione delle funzioni</h2>
<p>In alcuni casi è conveniente riparametrizzare le funzioni, se è necessario per le nostre esigenze di analisi. Anche questo aspetto sarà illustrato con un esempio.</p>
<div id="esempio-2-4" class="section level3">
<h3><span class="header-section-number">15.3.1</span> Esempio 2</h3>
<p>E’stata valutata la produzione del girasole a densità crescenti di piante infestanti, da 0 a 100 piante per metro quadrato. I risultati ottenuti sono riportati nel dataset sottostante.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(competition)
<span class="kw">head</span>(competition)</code></pre></div>
<pre><code>##   Dens    Yield
## 1    0 29.58587
## 2   10 20.16776
## 3   20 17.82846
## 4   30  9.02289
## 5   40 13.41521
## 6   50 12.80159</code></pre>
<p>Secondo la letteratura, la relazione tra perdite produttive e densità delle piante infestanti può essere descritta con una funzione iperbolica di questo tipo (Cousens, 1985):</p>
<p><span class="math display">\[YL = \frac{iD}{1 + \frac{iD}{a}}\]</span></p>
<p>Dove <span class="math inline">\(YL\)</span> sta per perdite produttive (Yield Loss) percentuali, <span class="math inline">\(D\)</span> è la densità delle piante infestanti, <span class="math inline">\(a\)</span> è la perdita produttiva massima asintotica. Il grafico è mostrato qui sotto.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="dv">3</span><span class="op">*</span>x<span class="op">/</span>(<span class="dv">1</span><span class="op">+</span>(<span class="dv">3</span><span class="op">*</span>x)<span class="op">/</span><span class="dv">60</span>), <span class="dt">from=</span><span class="dv">0</span>, <span class="dt">to=</span><span class="dv">350</span>, <span class="dt">xlab=</span><span class="st">&quot;Weed density&quot;</span>,
      <span class="dt">ylab=</span><span class="st">&quot;Yield loss (%)&quot;</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">80</span>))
<span class="kw">abline</span>(<span class="dt">a=</span><span class="dv">0</span>, <span class="dt">b=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">2</span>))
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">60</span>, <span class="dt">lty=</span><span class="dv">2</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">2</span>))
<span class="kw">text</span>(<span class="dv">20</span>,<span class="dv">50</span>, <span class="dt">label=</span><span class="st">&quot;i = 3&quot;</span>)
<span class="kw">text</span>(<span class="dv">300</span>,<span class="dv">65</span>, <span class="dt">label=</span><span class="st">&quot;A = 60&quot;</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-183-1.png" width="672" /></p>
<p>Normalmente, in campo non vengono determinate le perdite produttive, bensì le produzioni, come nel caso del nostro dataset. Di conseguenza abbiamo due possibilità:</p>
<ol style="list-style-type: decimal">
<li>modificare il dataset, esprimendo i dati in termini di perdite produttive percentuali;</li>
<li>modificare il modello, per utilizzare la produzione come variabile dipendente, al posto della perdita produttiva.</li>
</ol>
<p>La prima strada è più agevole, ma ci porta a perdere parte dell’informazione, cioè il livello produttivo nel testimone non infestato. La seconda strada può essere perseguita considerando che le perdite produttive percentuali sono pari a:</p>
<p><span class="math display">\[YL = \frac{{YWF - YW}}{{YWF}} \times 100\]</span></p>
<p>dove <span class="math inline">\(YWF\)</span> è la produzione nel testimone non infestato e <span class="math inline">\(YW\)</span> è la produzione nella parcella in studio. Dalla precedente funzione si ricava che:</p>
<p><span class="math display">\[YW = YWF - \frac{YL \times YWF}{100} = YWF\left( {1 - \frac{YL}{100}} \right)\]</span></p>
<p>che mostra come la produzione in una parcella infestata (<span class="math inline">\(YW\)</span>) può essere ottenuta in funzione della perdita produttiva. Considerando l’equazione precedente e il modello delle perdite produttive, possiamo scrivere:</p>
<p><span class="math display">\[YW = YWF\left( {1 - \frac{iD}{100\left( {1 + \frac{iD}{a}} \right)}} \right)\]</span></p>
<p>Questa equazione consente di utilizzare i dati produttivi osservati come variabile dipendente e di stimare i parametri competitivi <span class="math inline">\(i\)</span> ed <span class="math inline">\(a\)</span>, insiema alla produzione stimata in asssenza di competizione. Il fitting può essere eseguito utilizzando drm() e la funzione cousens85().</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modComp &lt;-<span class="st"> </span><span class="kw">drm</span>(Yield <span class="op">~</span><span class="st"> </span>Dens, <span class="dt">fct=</span><span class="kw">DRC.cousens85</span>() ,
               <span class="dt">data=</span>competition)
<span class="kw">summary</span>(modComp)</code></pre></div>
<pre><code>## 
## Model fitted: Yield-Weed Density function (Cousens, 1985) (3 parms)
## 
## Parameter estimates:
## 
##                 Estimate Std. Error t-value   p-value    
## YWF:(Intercept) 30.47211    0.92763 32.8493 &lt; 2.2e-16 ***
## i:(Intercept)    8.24038    1.36541  6.0351 3.857e-07 ***
## a:(Intercept)   75.07312    2.40366 31.2328 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  1.866311 (41 degrees of freedom)</code></pre>
</div>
</div>
<div id="inferenze-statistiche-e-verifiche-delle-assunzioni-di-base" class="section level2">
<h2><span class="header-section-number">15.4</span> Inferenze statistiche e verifiche delle assunzioni di base</h2>
<p>Le assunzioni parametriche di base relative ai modelli non-lineari sono le stesse dei modelli lineari e, di conseguenza, gli strumenti diagnostici sono analoghi. Bisogna tuttavia menzionare il fatto che, dato l’impiego di metodi iterativi per la ricerca dei valori dei parametri, tutti i risultati a cui si perviene (stima dei parametri, della varianza residua e numero dei gradi di libertà relativi) sono solo una approssimazione di quelli reali. Per questo motivo, nel caso non-lineare i metodi grafici (analisi dei residui) sono largamente preferiti.</p>
<div id="analisi-grafica-dei-residui-1" class="section level3">
<h3><span class="header-section-number">15.4.1</span> Analisi grafica dei residui</h3>
<p>I due strumenti grafici preferiti sono la visualizzazione della funzione insieme ai dati osservati e la visualizzazione dei residui, plottati verso i valori attesi. Avendo utilizzato la funzione drm(), possiamo approfittare dell’oggetto risultante per disegnare i grafici. Considerate che la funzione plot() applicata all’oggetto drm restituisce di default un grafico sul logaritmo della variabile indipendente. In questo caso abbiamo ovviato a questo comportamento utilizzando la funzione log=“”.</p>
<p>Consideriamo i due esempi precedenti.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(modNlin2, <span class="dt">log=</span><span class="st">&quot;&quot;</span>)
<span class="kw">plot</span>(<span class="kw">residuals</span>(modNlin2) <span class="op">~</span><span class="st"> </span><span class="kw">fitted</span>(modNlin2))
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-185-1.png" width="672" /></p>
<p>Nel caso dell’esempio relativo alla cinetica di degradazione, non si vedono importanti deviazioni rispetto agli assunti di base.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(modComp, <span class="dt">log=</span><span class="st">&quot;&quot;</span>)
<span class="kw">plot</span>(<span class="kw">residuals</span>(modComp) <span class="op">~</span><span class="st"> </span><span class="kw">fitted</span>(modComp))
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-186-1.png" width="672" /></p>
<p>Per quello che riguarda il modello di competizione, osserviamo invece una proporzionalità inversa tra residui e medie, che attesta qualche problema con l’omogeneità delle varianze.</p>
</div>
<div id="test-f-per-la-mancanza-di-adattamento-approssimato" class="section level3">
<h3><span class="header-section-number">15.4.2</span> Test F per la mancanza di adattamento (approssimato)</h3>
<p>Se abbiamo le repliche (come nei due esempi fin qui trattati) possiamo effettuare l’analisi della varianza. In questo modello, i valori attesi sono costituiti dalle medie dei trattamenti (tempi e livelli di densità, rispettivamente per i due esempi) e lo scostamento di ogni dato rispetto alla ‘sua’ media è evidentemente dovuto solo all’errore sperimentale ‘puro’. Nel modello di regressione, invece, esiste una componente aggiuntiva di errore, cioè lo scostamento di ogni media dalla curva di regressione. Questa componente si chiama mancanza d’adattamento e può essere stimata per differenza. Effettuiamo il calcolo per il primo esempio.</p>
<p>La tabella ANOVA è la seguente:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modAov &lt;-<span class="st"> </span><span class="kw">lm</span>(Conc <span class="op">~</span><span class="st"> </span><span class="kw">factor</span>(Time), <span class="dt">data=</span>degradation)
<span class="kw">anova</span>(modAov)</code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Response: Conc
##              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## factor(Time)  7 24698.4  3528.3  415.29 &lt; 2.2e-16 ***
## Residuals    16   135.9     8.5                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SSa &lt;-<span class="st"> </span><span class="kw">anova</span>(modAov)[<span class="dv">2</span>,<span class="dv">2</span>]</code></pre></div>
<p>Inseriamo il tempo come fattore (quindi variabile qualitativa, non quantitativa) e notiamo che la devianza del residuo è pari a 135.9. Salviamo questa quantità nella variabile SSa. La varianza del residuo del modello di regressione si ottiene facendo la somma dei quadrati degli scarti dei dati rispetto ai valori attesi. La salviamo nella variabile SSr.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SSr &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">residuals</span>(modNlin2)<span class="op">^</span><span class="dv">2</span>)
SSr</code></pre></div>
<pre><code>## [1] 151.1766</code></pre>
<p>Come ci aspettavamo, il modello di regressione ha una devianza più alta, in quanto questa contiene la componente di mancanza d’adattamento, pari alla differenza tra SSa e SSr, cioè:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SSl &lt;-<span class="st"> </span>SSr <span class="op">-</span><span class="st"> </span>SSa
SSl</code></pre></div>
<pre><code>## [1] 15.23792</code></pre>
<p>Mentre la devianza del residuo dell’ANOVA ha 16 gradi di libertà, quella del residuo della regression ha N - P = 22, gradi di libertà, dove N è il numero dei dati (24) e P è il numero dei parametri stimati (2). La devianza del ‘lack of fit’ ha quindi 22 - 16 = 6 gradi di libertà. La varianza del lack of fit è quindi pari a:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SSl<span class="op">/</span><span class="dv">6</span></code></pre></div>
<pre><code>## [1] 2.539654</code></pre>
<p>Possiamo quindi confrontare formalmente, con un test di F, le due varianze dell’errore puro (dall’ANOVA: 8.5) e quella della mancanza di adattamento, per vedere se quest’ultima è significativamente più ‘grande’ di quella dell’errore puro. L’ipotesi nulla è che la mancanza d’adattamento non è rilevante ed il test di F è:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(Fvalue &lt;-<span class="st"> </span>(SSl<span class="op">/</span><span class="dv">6</span>) <span class="op">/</span><span class="st"> </span><span class="kw">anova</span>(modAov)[<span class="dv">2</span>,<span class="dv">3</span>]) <span class="co">#F value</span></code></pre></div>
<pre><code>## [1] 0.2989175</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">pf</span>(<span class="fl">0.2989</span>, <span class="dv">6</span>, <span class="dv">16</span>, <span class="dt">lower.tail=</span>F)</code></pre></div>
<pre><code>## [1] 0.07155798</code></pre>
<p>Chiaramente il test è non significativo.</p>
<p>A questo risultato si arriva facilmente utilizzando la funzione modelFit(), applicata all’oggetto drm.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">modelFit</span>(modNlin2)</code></pre></div>
<pre><code>## Lack-of-fit test
## 
##           ModelDf    RSS Df F value p value
## ANOVA          16 135.94                   
## DRC model      22 151.18  6  0.2989  0.9284</code></pre>
<p>Per il secondo esempio abbiamo</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">modelFit</span>(modComp)</code></pre></div>
<pre><code>## Lack-of-fit test
## 
##           ModelDf    RSS Df F value p value
## ANOVA          33 116.95                   
## DRC model      41 142.81  8  0.9119  0.5188</code></pre>
</div>
<div id="errori-standard-dei-parametri-1" class="section level3">
<h3><span class="header-section-number">15.4.3</span> Errori standard dei parametri</h3>
<p>Un’altra valutazione importante da fare è quella relativa agli errori standard delle stime dei parametri, che non debbono mai essere superiori alla metà del valore del parametro stimato, cosa che in questo caso è pienamente verificata. Se così non fosse, l’intervallo di confidenza del parametro conterrebbe lo zero, il che equivale a dire che il valore stimato non sarebbe significativamente diverso da zero. Di conseguenza, avere, per esempio, un ‘rate’ non diverso da zero significherebbe che di fatto la degradazione non avviene o comunque non è descrivibile con il modello proposto.</p>
</div>
<div id="coefficiente-di-determinazione" class="section level3">
<h3><span class="header-section-number">15.4.4</span> Coefficiente di determinazione</h3>
<p>Abbiamo visto che il residuo della regressione è pari a 151.2 con 16 gradi di libertà. La devianza totale dei dati (somma dei quadrati degli scarti rispetto alla media generale) è invece:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SSt &lt;-<span class="st"> </span><span class="kw">deviance</span>(<span class="kw">lm</span>(Conc <span class="op">~</span><span class="st"> </span><span class="dv">1</span>, <span class="dt">data=</span>degradation))</code></pre></div>
<p>ed ha 23 gradi di libertà. La differenza:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">SSt <span class="op">-</span><span class="st"> </span>SSr</code></pre></div>
<pre><code>## [1] 24683.13</code></pre>
<p>costituisce la devianza spiegata dalla regressione. Il coefficente di determinazione <span class="math inline">\(R^2\)</span> è quindi:</p>
<p><span class="math display">\[R^2 = \frac{SSt - SSr}{SSt} = \frac{24683.13}{24834.3} = 0.994\]</span></p>
<p>Che attesta un ottimo adattamento, in quanto è vicino ad 1. Bisogna ricordare che, pur essendo utilizzato in modo pressoché ubiquitario, il coefficiente di determinazione per i modelli nonlineari fornisce solo un’indicazione abbastanza grezza sulla bontà del modello. Infatti:</p>
<ol style="list-style-type: decimal">
<li>valori bassi possono essere ottenuti non solo perché la devianza della regressione è bassa, ma anche perché la devianza totale delle osservazioni è alta (molti dati e molto variabili).</li>
<li>L’ <span class="math inline">\(R^2\)</span> dipende dall’intervallo di variazione della variabile indipendente; di conseguenza, se nella regressione aggiungiamo uno o più livelli della X, otteniamo un innalzamento del valore di <span class="math inline">\(R^2\)</span>, che tuttavia non necessariamente produce un miglior modello. In questo caso, ad esempio, se la semivita è pari a 10 giorni, un esperimento con 0, 20, 40 e 80 giorni darà sicuramente valori di <span class="math inline">\(R^2\)</span> più alti che non un esperimento con 5, 10, 20 e 40 giorni, anche se non necessariamente la bontà di adattamento è migliore.</li>
<li>Il coefficiente di determinazione è sensibile al numero di variabili esplicative presenti nel modello, e quindi non premia i modelli più semplici (viola quindi il principio del ‘rasoio di Occam’).</li>
<li>Il coefficiente di determinazione è sensibile al numero di parametri presenti nel modello. Modelli con molti parametri danno sempre valori di <span class="math inline">\(R^2\)</span> alti, ma non rispettano spesso le caratteristiche di semplicità e senso biologico che sono invece richieste ad un buon modello (anche qui una netta violazione del rasoio di Occam.</li>
</ol>
</div>
<div id="coefficiente-di-determinazione-aggiustato" class="section level3">
<h3><span class="header-section-number">15.4.5</span> Coefficiente di determinazione aggiustato</h3>
<p>Per evitare almeno gli ultimi due problemi, viene proposto il coefficiente di determinazione corretto, dato dalla proporzione di varianza (MS) spiegata dalla regressione:</p>
<p><span class="math display">\[R_a^2  = 1 - \frac{MS_{residuo} }{MS_{tot} }\]</span></p>
<p>Dato che dalle devianze si passa alle varianze, il valore di R<span class="math inline">\(^2\)</span> corretto è detto anche ‘R<span class="math inline">\(^2\)</span> corretto per i gradi di libertà’. Il suo rapporto con il coefficiente di determinazione tradizionale è:</p>
<p><span class="math display">\[ R_a^2  = 1 - \frac{\left( {1 - R^2 } \right)\left( {n - 1} \right)}{\left( {n - k - 1} \right)} \]</span></p>
<p>dove <span class="math inline">\(n\)</span> è il numero di osservazioni e <span class="math inline">\(k\)</span> il numero dei regressori. L’<span class="math inline">\(R^2\)</span> corretto è sempre più basso dell <span class="math inline">\(R^2\)</span> e diminuisce con l’aggiunta al modello di un nuovo regressore se l’incremento di devianza totale è meno che quello della devianza residua. Può assumere valori negativi se la varianza del residuo è maggiore della varianza della variabile dipendente.</p>
</div>
<div id="altre-statistiche" class="section level3">
<h3><span class="header-section-number">15.4.6</span> Altre statistiche</h3>
<p>Altri indicatori di bontà di adattamento molto usati in letteratura per finalità puramente descrittive sono il Mean Square Error:</p>
<p><span class="math display">\[MSE = \frac{1}{N}\sum\limits_{i = 1}^N {(Y_i  - } \widehat{Y_i })^2\]</span></p>
<p>che, nel caso in esempio, è pari a 6.299.</p>
<p>Come vediamo si tratta della varianza del residuo, ma ottenuta divedendo per il numero dei dati e non per il numero dei gradi di libertà (varianza della popolazione e non varianza del campione). E’quindi un indicatore inferenziale distorto, ma è importante consocerlo perché viene spesso utilizzato per stabilire la bontà d’adattamento e il valore predittivo di modelli deterministici.</p>
<p>Il MSE è spesso difficile da valutare perché, essendo una somma di quadrati, la sua unità di misura non è quella dei dati. Per questo motivo, spesso si utilizza la sua radice quadrata:</p>
<p><span class="math display">\[RMSE = \sqrt{MSE}\]</span></p>
<p>che ha la stessa unità di misura delle osservazioni. In questo caso, il RRMSE (Root Mean Square Error) è uguale a 2.510, che, considerando i dati ,rappresenta un valore decisamente basso.</p>
<p>Una variante molto utilizzata è il Relative Root Mean Square Error (RRMSE):</p>
<p><span class="math display">\[RRMSE = \frac{\sqrt{MSE}} {\overline{Y}} \times 100\]</span></p>
<p>dove <span class="math inline">\(\overline{Y}\)</span> è la media dei dati. Si tratta di un indicatore analogo al coefficiente di variabilità, nel quale la bontà del modello viene espressa relativamente alla media delle previsioni. Nel nostro caso è pari al 9.8%.</p>
</div>
</div>
<div id="gestione-delle-situazioni-patologiche" class="section level2">
<h2><span class="header-section-number">15.5</span> Gestione delle situazioni ‘patologiche’</h2>
<p>In alcuni casi la verifica della bontà del modello mette in luce situazioni patologiche. In particolare potrebbe capitare che il modello non sia adatto ai dati, o, al contrario, che i dati non siano adatti al modello. Nel primo caso è necessario trasformare il modello, mentre nel secondo caso l’azione più comune è quella di trasformare i dati.</p>
<div id="trasformazione-del-modello" class="section level3">
<h3><span class="header-section-number">15.5.1</span> Trasformazione del modello</h3>
<p>La trasformazione del modello dalla sua forma originaria in una forma alternativa può rendersi necessaria per diversi motivi:</p>
<ol style="list-style-type: decimal">
<li>il modello non presenta un buon adattamento ai dati sperimentali e l’analisi dei residui suggerisce deviazioni sistematiche. Per esempio, in una curva dose risposta può capitare che i residui siano prevalentemente positivi nella parte iniziale, facendo sospettare un effetto stimolante a basse dosi. Questo effetto non può essere descritto con una funzione sigmoidale, ma richiede un modello divsero, caratterizzato da un picco iniziale.</li>
<li>Alcuni parametri non sono significativamente diversi da zero, o non sono ben stimati, o assumono valori biologicamente irrealistici. In questo caso si può considerare la loro eliminazione dal modello, se è possibile. In alternativa, si può considerare la possibilità di imporre un vincolo, cioè sostituire il parametro con un valore arbitrario biologicamente ragionevole. Quest’ ultima soluzione è tuttavia da considerare con attenzione e buon senso, proprio per la sua arbitrarietà.</li>
<li>Alta correlazione tra i parametri. Questa situazione fa sospettare che il modello sia troppo complesso (troppi parametri) e quindi non supportato dai dati. In questo caso bisognerebbe verificare se e come sia possibile utilizzare un modello più semplice.</li>
</ol>
</div>
<div id="trasformazione-dei-dati" class="section level3">
<h3><span class="header-section-number">15.5.2</span> Trasformazione dei dati</h3>
<p>Se non è il modello ad essere mal definito, ma sono invece i dati a non conformarsi alle assunzioni di base della regressione, è necessarip valutare l’esigenza di una trasformazione stabilizzante. Nel caso dell’Esempio 2 la possibile eterogeneità delle varianze può spingerci a valutare l’impiego della famiglia di trasformazioni descritta da Box e Cox <span class="citation">(Box and Cox <a href="#ref-box1964_analysistransformations">1964</a>)</span>. L’unica differenza rispetto alle regressioni lineari è nel fatto che operare la trasformazione della sola variabile dipendente comporta anche la modifica della scala sulla quale vengono stimati i parametri, che quindi non conservano il loro valore biologico. Ad esempio, nel modello di competizione, il parametro <span class="math inline">\(a\)</span> è la perdita produttiva massima percentuale. Tuttavia, se dovessimo trasformare i dati nel logaritmo prima dell’analisi il parametro <span class="math inline">\(a\)</span> non conserverebbe il suo significato biologico.</p>
<p>Per questo motivo, dato che spesso le regressioni non-lineari vengono eseguite proprio perchè si è interessati all’informazione contenuta nei parametri di un modello, si preferisce adottare la cosiddetta tecnica della “trasformazione di entrambe le parti”, o metodo TBS (“Transform Both Sides”) e trasformare quindi sia i dati osservati per la variabile dipendente, sia il modello <span class="citation">(Carroll and Ruppert <a href="#ref-carroll1988_Transformationweightingregression">1988</a>)</span>:</p>
<p><span class="math display">\[Y^\lambda  = f(X)^\lambda\]</span></p>
<p>In questo modo si ottengono i parametri della funzione sulla scala originale come se la trasformazione non fosse stata eseguita per niente.</p>
<p>Se abbiamo utilizzato la funzione drm() per il fitting, possiamo utilizzare la funzione boxcox(), che confronta la verosimiglianza dei modelli ottenuti variando il valore di <span class="math inline">\(\lambda\)</span> da -2 a 2. Questa funzione applicata al modello di competizione mostra che il massimo di verosimiglianza si ottiene proprio con <span class="math inline">\(\lambda\)</span> = 1, cioè a dire che la trasformazione non è affatto necessaria.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">boxcox</span>(modComp)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-196-1.png" width="672" /></p>
<p>Se lo fosse, applicarla sarebbe banale: basterebbe aggiungere alla funzione di fitting l’argomento bcVal, a cui si dovrebbe assegnare il valore da utilizzare per la trasformazione.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">modComp2 &lt;-<span class="st"> </span><span class="kw">drm</span>(Yield <span class="op">~</span><span class="st"> </span>Dens, <span class="dt">fct=</span><span class="kw">DRC.cousens85</span>(), <span class="dt">data=</span>competition,
               <span class="dt">bcVal=</span><span class="fl">0.5</span>)
<span class="kw">summary</span>(modComp2)</code></pre></div>
<pre><code>## 
## Model fitted: Yield-Weed Density function (Cousens, 1985) (3 parms)
## 
## Parameter estimates:
## 
##                 Estimate Std. Error t-value   p-value    
## YWF:(Intercept)  30.5155     1.4523 21.0114 &lt; 2.2e-16 ***
## i:(Intercept)     8.4999     1.7141  4.9589  1.28e-05 ***
## a:(Intercept)    75.0527     2.4308 30.8762 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  0.5315512 (41 degrees of freedom)
## 
## Non-normality/heterogeneity adjustment through Box-Cox transformation
## 
## Specified lambda: 0.5</code></pre>
<p>Vediamo che, nonostante la trasformazione, i parametri conservano il loro significato biologico.</p>
</div>
</div>
<div id="funzioni-lineari-e-nonlineari-dei-parametri" class="section level2">
<h2><span class="header-section-number">15.6</span> Funzioni lineari e nonlineari dei parametri</h2>
<p>Gli studi di degradazione, in genere, richiedono la determinazione della semivita. E’facile vedere che questa può essere ricavata dalla funzione di degradazione in questo modo:</p>
<p><span class="math display">\[ \frac{A}{2} = A \exp ( - k \,\, t_{1/2}) \]</span></p>
<p>da cui:</p>
<p><span class="math display">\[ t_{1/2} = - \frac{ \log \left( {\frac{1}{2}} \right) }{k}\]</span></p>
<p>Vediamo insomma che la semivita <span class="math inline">\(t_{1/2}\)</span> è una funzione non-lineare di k e può essere ricavata facilmente come:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="op">-</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span><span class="kw">coef</span>(modNlin2)[<span class="dv">2</span>]</code></pre></div>
<pre><code>## k:(Intercept) 
##      10.33945</code></pre>
<p>Si pone ora il problema di ricavare l’errore standard della semivita e/o i suoi intervalli di confidenza. La legge di propagazione degli errori ci insegna che se abbiamo una quantità <span class="math inline">\(Z\)</span> con varianza <span class="math inline">\(\sigma^2_Z\)</span> e facciamo una trasformazione lineare:</p>
<p><span class="math display">\[W = b_0 + b_1 \,\, Z\]</span></p>
<p>con <span class="math inline">\(b_0\)</span> e <span class="math inline">\(b_1\)</span> numeri reali qualunque, la varianza di W è data da:</p>
<p><span class="math display">\[\sigma^2_W = b_1^2 \,\, \sigma^2_Z\]</span></p>
<p>In questo caso, purtroppo, la funzione di trasformazione è non lineare. Tuttavia, una funzione non-lineare (ma vicina alla linearità) può essere approssimata utilizzando la sua tangente in un punto dato (sviluppo in serie di Taylor; Fig 1).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="op">-</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>)<span class="op">/</span>x, <span class="dt">from=</span><span class="fl">0.05</span>, <span class="dt">to=</span><span class="fl">0.1</span>)
<span class="kw">curve</span>(<span class="kw">log</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>)<span class="op">/</span>(<span class="fl">0.067</span><span class="op">^</span><span class="dv">2</span>)<span class="op">*</span>(x <span class="op">-</span><span class="st"> </span><span class="fl">0.067</span>) <span class="op">+</span><span class="st"> </span>
<span class="st">        </span><span class="fl">10.35</span>, <span class="dt">from=</span><span class="fl">0.067</span>, <span class="dt">to=</span><span class="fl">0.1</span>, <span class="dt">add=</span>T, <span class="dt">lty=</span><span class="dv">1</span>)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-199-1.png" width="672" /></p>
<p>Consideriamo il punto <span class="math inline">\(k = 0.067\)</span>, dove la funzione vale <span class="math inline">\(t_{1/2} = 10.35\)</span>. Immaginiamo di prendere la retta tangente nel punto P(0.067, 10.35), questa retta ha equazione:</p>
<p><span class="math display">\[ y = m (x - x_0) + y_0 \]</span></p>
<p>dove m è la derivata prima della funzione nel punto <span class="math inline">\(k=0.067\)</span>:</p>
<p><span class="math display">\[ m = f&#39;(k) = \frac{log(1/2)}{k^2}\]</span></p>
<p>Nei dintorni di 0.067 le due funzioni (quella nonlineare e la sua tangente) sono molto vicine, quasi equivalenti. Allora posso pensare di utilizzare la tangente per applicare la legge di propagazione degli errori. Di conseguenza, la varianza della semivita è data da:</p>
<p><span class="math display">\[\sigma^2_{t_{1/2}} = m^2 \,\, \sigma^2_k\]</span></p>
<p>e l’errore standard è:</p>
<p><span class="math display">\[\frac{|log(1/2)|}{0.067^2} \,\, 0.0019 = 0.2944\]</span></p>
<p>Ovviamente, in R, possiamo utilizzare la funzione deltaMethod() del package car, per arrivare agli stessi risultati.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(car)</code></pre></div>
<pre><code>## Loading required package: carData</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">coefs &lt;-<span class="st"> </span><span class="kw">coef</span>(modNlin2) 
<span class="kw">names</span>(coefs) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;A&quot;</span>, <span class="st">&quot;k&quot;</span>)
<span class="kw">deltaMethod</span>(<span class="dt">object=</span>coefs, <span class="dt">g=</span><span class="st">&quot;-log(0.5)/k&quot;</span>, <span class="dt">vcov.=</span><span class="kw">vcov</span>(modNlin2))</code></pre></div>
<pre><code>##             Estimate        SE    2.5 %   97.5 %
## -log(0.5)/k 10.33945 0.2944068 9.762424 10.91648</code></pre>
</div>
<div id="modelli-ancova" class="section level2">
<h2><span class="header-section-number">15.7</span> Modelli ANCOVA</h2>
<p>In molti casi, gli esperimenti includono contemporaneamente variabili qualitative e quantitative. Ad esempio, possiamo studiare la risposta alla concimazione azotata (variabile quantitativa) per due varietà di frumento (variabile qualitativa). In questo caso si parla di ANalisi della COVArianza (ANCOVA).</p>
<p>Tradizionalmente, questo modelli sono stati visti come modelli ANOVA per la variabile qualitativa (confronto varietale, quindi, nell’esempio precedente), nei quali la produzione di una parcella è aggiustata per il livello di concimazione azotata. Più di recente, sta divenendo importante ua visione alternativa, che consiste nel considerare un modello ANCOVA come un’analisi di regressione per ogni livello della variabile qualitativa. Anche in questo caso partiremo da un esempio.</p>
<div id="esempio-3-3" class="section level3">
<h3><span class="header-section-number">15.7.1</span> Esempio 3</h3>
<p>E’ stata misurata la risposta di due varietà di girasole (Sambro e Oleko) alla presenza di una sostanza allelopatica nel terreno di coltivazione. Questa sostanza è stata utilizzata a quattro dosi (da 0 a 17.5 g/ha) ed è stata rilevata la lunghezza dell’ipocotile degli individui trattati <span class="citation">(Pannacci, Pettorossi, and Tei <a href="#ref-pannacci2013_Phytotoxiceffectsaqueous">2013</a>)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(sunflower)
<span class="kw">head</span>(sunflower, <span class="dv">10</span>)</code></pre></div>
<pre><code>##    Dose Rep     Var Length
## 1   0.0   1 Sambro    77.0
## 2   0.0   2 Sambro    85.2
## 3   0.0   3 Sambro    80.2
## 4   5.0   1 Sambro    66.8
## 5   5.0   2 Sambro    70.2
## 6   5.0   3 Sambro    73.8
## 7  10.0   1 Sambro    51.6
## 8  10.0   2 Sambro    47.4
## 9  10.0   3 Sambro    43.2
## 10 17.5   1 Sambro    11.2</code></pre>
<p>In letteratura, è noto che la risposta degli organismi ad agenti tossici è sigmoidale, sul logaritmo della dose. L’equazione più utilizzata è quella log-logistica:</p>
<p><span class="math display">\[y = c + \frac{d - c}{1 + \exp \{ b[\log (dose) - \log (e)] \} }\]</span></p>
<p>dove <span class="math inline">\(y\)</span> è la risposta (la lunghezza, nel nostro esempio), <span class="math inline">\(x\)</span> è la dose, <span class="math inline">\(d\)</span> è la risposta nel testimone non trattato, <span class="math inline">\(c\)</span> è la risposta a dose estremamente elevata (che non necessariamente è nulla), <span class="math inline">\(e\)</span> è la dose che produce una risposta a metà strada tra <span class="math inline">\(d\)</span> e <span class="math inline">\(c\)</span> (normalmente nota come ED50) e b è la pendenza della curva nel punto di flesso.</p>
<p>Questo modello può essere parametrizzato con la funzione drm(), utilizzando la funzione LL.4() ed inserendo la varietà di frumento come variabile qualitativa (argomento curveid).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.sun &lt;-<span class="st"> </span><span class="kw">drm</span>(Length <span class="op">~</span><span class="st"> </span>Dose, <span class="dt">curveid=</span>Var, <span class="dt">data =</span> sunflower, <span class="dt">fct =</span> <span class="kw">LL.4</span>())
<span class="kw">summary</span>(mod.sun)</code></pre></div>
<pre><code>## 
## Model fitted: Log-logistic (ED50 as parameter) (4 parms)
## 
## Parameter estimates:
## 
##           Estimate Std. Error t-value   p-value    
## b:Sambro    1.9425     1.5487  1.2543   0.22775    
## b:Oleko     3.3872     1.3756  2.4624   0.02553 *  
## c:Sambro  -61.1131   228.5635 -0.2674   0.79259    
## c:Oleko    -3.9345    11.8818 -0.3311   0.74484    
## d:Sambro   80.8000     5.7774 13.9855 2.174e-10 ***
## d:Oleko    74.4500     5.7866 12.8659 7.450e-10 ***
## e:Sambro   18.3383    29.1718  0.6286   0.53846    
## e:Oleko     8.5322     1.2763  6.6848 5.242e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  10.02111 (16 degrees of freedom)</code></pre>
<p>Otteniamo quattro parametri (quindi una curva diversa) per ogni varietà. Notiamo subito che l’asintoto inferiore assume valori negativi, quindi inaccettabili da un punto di vista biologico. Provvediamo quindi a rimuovere gli asintoti inferiori, ammettendo che, a dose molto elevata, la sostanza in studio inibisce completamente la crescita dell’ipocotile in entrambe le varietà. Riparametrizziamo il modello, arrivando alla determinazione di due curve diverse con tre parametri ciascuna (funzione LL.3()).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.sun2 &lt;-<span class="st"> </span><span class="kw">drm</span>(Length <span class="op">~</span><span class="st"> </span>Dose, <span class="dt">curveid=</span>Var, <span class="dt">data =</span> sunflower, <span class="dt">fct =</span> <span class="kw">LL.3</span>())
<span class="kw">summary</span>(mod.sun2)</code></pre></div>
<pre><code>## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)
## 
## Parameter estimates:
## 
##           Estimate Std. Error t-value   p-value    
## b:Sambro   3.20503    0.99156  3.2323  0.004622 ** 
## b:Oleko    3.73287    1.07596  3.4693  0.002737 ** 
## d:Sambro  78.90444    5.26134 14.9970 1.293e-11 ***
## d:Oleko   74.03407    5.55331 13.3315 9.112e-11 ***
## e:Sambro  11.03545    1.07380 10.2770 5.856e-09 ***
## e:Oleko    8.23737    0.88496  9.3081 2.661e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  9.641889 (18 degrees of freedom)</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(mod.sun)</code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-203-1.png" width="672" /></p>
<p>I risultati sono analoghi a quelli che avremmo ottenuto parametrizzando separatamente le curve per le due varietà ,ma con chiari vantaggi che illustreremo nel prossimo capitolo.</p>
</div>
</div>
<div id="confronto-tra-modelli-alternativi" class="section level2">
<h2><span class="header-section-number">15.8</span> Confronto tra modelli alternativi</h2>
<p>La possibilità di confrontare modelli matematici è forse uno degli aspetti più rilevanti delle regressioni non-lineari, nel senso che ci permette di valutare e scegliere ipotesi biologiche, in base alla loro maggiore o minore compatibilità con le osservazioni sperimentali.</p>
<p>Se prendiamo l’esempio precedente, è rilevante chiedersi se le due varietà rispondono alla stessa sostanza allelopatica in modo diverso. In termini statistici abbiamo due modelli alternativi:</p>
<ol style="list-style-type: decimal">
<li>modello con due curve diverse, una per ogni varietà</li>
<li>modello alternativo, con un’unica curva di risposta per le due varietà</li>
</ol>
<p>Questo secondo modello deriva dal primo, semplicemente rimuovendo tre parametri, cioè un valore di <span class="math inline">\(b\)</span>, uno di <span class="math inline">\(d\)</span> ed uno di <span class="math inline">\(e\)</span>. Si tratta quindi di due modelli ‘nested’. Parametrizziamo il modello alternativo.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mod.sunR &lt;-<span class="st"> </span><span class="kw">drm</span>(Length <span class="op">~</span><span class="st"> </span>Dose, <span class="dt">data =</span> sunflower, <span class="dt">fct =</span> <span class="kw">LL.3</span>())
<span class="kw">summary</span>(mod.sunR)</code></pre></div>
<pre><code>## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## b:(Intercept)  3.23478    0.78527  4.1193 0.0004885 ***
## d:(Intercept) 76.81273    4.52016 16.9934 9.481e-14 ***
## e:(Intercept)  9.46516    0.82245 11.5085 1.568e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error:
## 
##  11.34069 (21 degrees of freedom)</code></pre>
<p>Quando i modelli sono ‘nested’ è possibile confrontarli con un test di F per la ‘extra sum of squares’. Le devianze del residuo dei due modelli sono date dalla somma dei quadrati degli scarti: il modello ridotto presenta, ovviamente, un peggior fitting e quindi una devianza molto più alta.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devC &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">residuals</span>(mod.sun2)<span class="op">^</span><span class="dv">2</span>)
devR &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">residuals</span>(mod.sunR)<span class="op">^</span><span class="dv">2</span>)
devC; devR</code></pre></div>
<pre><code>## [1] 1673.388</code></pre>
<pre><code>## [1] 2700.837</code></pre>
<p>I gradi di libertà delle due devianze sono rispettivamente 24 - 6 = 18 per il modello completo con 6 parametri e 24 - 3 = 21 per il modello ridotto. La differenza (exra sum of squares) è 1027.448 con 3 gradi di libertà. Questa quota aggiuntiva è legata alla rimozione dei tre parametri e la relativa varianza può essere confrontata con la varianza del residuo del modello completo, per vedere se la rimozione dei parametri provoca un significativo incremento della mancanza di adatttamento.</p>
<p><span class="math display">\[ F = \frac{\frac{RSS_c - RSS_s}{df_c - df_s}}{\frac{RSS_c}{df_c}} = \frac{\frac{1027.448}{3}}{\frac{1673.4}{18}}= 3.684\]</span></p>
<p>A questo valore di F corrisponde una probabilità pari a 0.0315, che ci permette di rifiutare l’ipotesi nulla di assenza di differenza tra le due varietà. In R il confronto tra modelli ‘nested’ si esegue con la funzione anova()</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">anova</span>(mod.sun2, mod.sunR)</code></pre></div>
<pre><code>## 
## 1st model
##  fct:      LL.3()
##  pmodels: 1 (for all parameters)
## 2nd model
##  fct:      LL.3()
##  pmodels: Var (for all parameters)</code></pre>
<pre><code>## ANOVA table
## 
##           ModelDf    RSS Df F value p value
## 2nd model      21 2700.8                   
## 1st model      18 1673.4  3  3.6840  0.0315</code></pre>
<p>E’anche possibile confrontare tra di loro i parametri del modello, per capire quale caratteristica della regressione (pendenza, ED50 o asintoto superiore) contribuisce maggiormente alla differenza significativa tra le curve. Questo è possibile con test di t eteroscedastici, nell’ipotesi che non vi siano correlazioni tra parametri misurati su curve diverse (il che è vero). Ad esempio, considerando i due ED50 (rispettivamente 11.04 <span class="math inline">\(\pm\)</span> 1.074 e 8.24 <span class="math inline">\(\pm\)</span> 0.885), il test di t è:</p>
<p><span class="math display">\[ t = \frac{e_1 - e_2}{\sqrt(ES_1^2 + ES_2^2)} = \frac{11.04 - 8.24}{\sqrt(1.074^2 + 0.885^2)} = 2.012\]</span></p>
<p>che corrisponde ad una probabilità (due code) P = 0.05956, considerando un numero di gradi di libertà pari a quelli del residuo. Confronti tra parametri possono essere compiuti facilmente con la funzione compParm() in drc.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">compParm</span>(mod.sun2, <span class="dt">strVal=</span><span class="st">&quot;b&quot;</span>, <span class="dt">operator=</span><span class="st">&quot;-&quot;</span>)</code></pre></div>
<pre><code>## 
## Comparison of parameter &#39;b&#39; 
## 
##                Estimate Std. Error t-value p-value
## Sambro -Oleko  -0.52784    1.46318 -0.3607  0.7225</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">compParm</span>(mod.sun2, <span class="dt">strVal=</span><span class="st">&quot;d&quot;</span>, <span class="dt">operator=</span><span class="st">&quot;-&quot;</span>)</code></pre></div>
<pre><code>## 
## Comparison of parameter &#39;d&#39; 
## 
##                Estimate Std. Error t-value p-value
## Sambro -Oleko    4.8704     7.6499  0.6367  0.5324</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">compParm</span>(mod.sun2, <span class="dt">strVal=</span><span class="st">&quot;e&quot;</span>, <span class="dt">operator=</span><span class="st">&quot;-&quot;</span>)</code></pre></div>
<pre><code>## 
## Comparison of parameter &#39;e&#39; 
## 
##                Estimate Std. Error t-value p-value  
## Sambro -Oleko    2.7981     1.3915  2.0109 0.05956 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Vediamo che le due curve sono diverse nel complesso, ma considerando i singoli parametri, solo <span class="math inline">\(e\)</span> mostra una differenza vicina alla significatività.</p>
<div id="confronto-tra-modelli-non-nested" class="section level3">
<h3><span class="header-section-number">15.8.1</span> Confronto tra modelli non-nested</h3>
<p>Quando le equazioni sono non-nested i confronti non possono essere effettuati con test statistici formali. In questa situazione si cerca di utilizzare criteri che tengano conto sia della bontà di adattamento (più basso è il residuo, migliore è il modello), sia della parsinomia (minore è il numero dei parametri, migliore è il modello). Un indicatore che viene spesso utilizzato è l’AKAIKE Information Criterion (AIC):</p>
<p><span class="math display">\[ AIC =  - 2 \, log(2\pi ) + n\,\, log(RSS/n) + n + 2(p + 1) \]</span></p>
<p>dove RSS è la devianza del residuo, n è il numero di osservazioni e p è il numero di parametri. Più basso è il valore dell’AIC e migliore è il modello.</p>
</div>
</div>
<div id="il-package-drc" class="section level2">
<h2><span class="header-section-number">15.9</span> Il package ‘drc’</h2>
<p>Abbiamo visto che il package  è estremamente comodo, perchè contiene tutte le funzioni necessarie per eseguire analisi di regressione adeguate. Le funzioni disponibili nel pacchetto originale e nell’estensione collegata a questo libro (con i relativi <em>self-starter</em>) sono</p>
<ol style="list-style-type: decimal">
<li>log-logistica a due tre e quattro parametri ()</li>
<li>weibull a due, tre, quattro parametri (),</li>
<li>funzione sigmoidale con picco picco iniziale (),</li>
<li>crescita Gompertz (tre parametrizzazioni alternative: , , ),</li>
<li>decrescita esponenziale ()</li>
<li>allometrica (), crescita esponenziale (), degradazione del primo ordine (), iperbole rettangolare (), crescita logistica (tre parametrizzazioni alternative ), crescita monomolecolare (), equazione di Freundlich (), loglineare (), esponenziale negativa a due parametri (), regressione asintotica (), valori estremi (), funzione di Hill (), Chapman-Richard ().</li>
</ol>
<p>[DA FARE: Come definire una funzione semplice in drm()…..]</p>
</div>
<div id="previsioni-1" class="section level2">
<h2><span class="header-section-number">15.10</span> Previsioni</h2>
<p>In taluni casi, abbastanza frequenti per la verità, l’ analisi di regressione viene eseguita per stimare o predire il valore della Y corrispondente ad una data X (calibrazione), oppure della X corrispondente ad un dato Y (esempio determinazione delle dosi efficaci). Normalmente il problema si riduce alla definizione di un’equazione predittiva; nel caso della calibrazione essa coincide con l’equazione originale, nell’altro caso con la sua inversa. Utilizzando queste equazioni è possibile ottenere il valore cercato e il suo errore standard, tramite il metodo delta.</p>
<p>Anche da questo punto di vista, drc offre un buon aiuto mediante il metodo predict(), con il quale possiamo, ad esempio, calcolare la concentrazione dell’erbicida al tempo 15 (Esempio 1)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(modNlin2, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">Time=</span><span class="dv">15</span>), <span class="dt">se.fit=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## Prediction 
##   36.44946</code></pre>
<p>Se il modello lo prevede, come nel caso della funzione LL.3(), possiamo anche ottenere la ….</p>
<p>[Da completare]</p>
</div>
<div id="bibliografia" class="section level2">
<h2><span class="header-section-number">15.11</span> Bibliografia</h2>

<div id="refs" class="references">
<div>
<p>Bates, D. M., and D. G. Watts. 1988. <em>Nonlinear Regression Analysis &amp; Its Applications.</em> Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div>
<p>Box, G. E. P., and D. R. Cox. 1964. “An Analysis of Transformations.” <em>Journal of the Royal Statistical Society</em> B-26: 211–52.</p>
</div>
<div>
<p>Carroll, R. J., and D. Ruppert. 1988. <em>Transformation and Weighting in Regression.</em> Books: Chapman and Hall.</p>
</div>
<div>
<p>Draper, N. R., and H. Smith. 1998. <em>Applied Regression Analysis</em>. III. Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div>
<p>Pannacci, E., D. Pettorossi, and F. Tei. 2013. “Phytotoxic Effects of Aqueous Extracts of Sunflower on Seed Germination and Growth of Sinapis Alba L., Triticum Aestivum L. and Lolium Multiflorum Lam.” <em>Allelopathy Journal</em> 32 (1): 23.</p>
</div>
<div>
<p>Ratkowsky, David A. 1990. <em>Handbook of Nonlinear Regression Models</em>. Books: Marcel Dekker Inc.</p>
</div>
<div>
<p>Ritz, C., and J. C. Streibig. 2008. <em>Nonlinear Regression with R</em>. Books: Springer-Verlag New York Inc.</p>
</div>
<div>
<p>Ritz, Christian, Florent Baty, Jens C. Streibig, and Daniel Gerhard. 2015. “Dose-Response Analysis Using R.” Edited by Yinglin Xia. <em>PLOS ONE</em> 10 (12): e0146021. doi:<a href="https://doi.org/10.1371/journal.pone.0146021">10.1371/journal.pone.0146021</a>.</p>
</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-ratkowsky1990_Handbooknonlinearregression">
<p>Ratkowsky, David A. 1990. <em>Handbook of Nonlinear Regression Models</em>. Books: Marcel Dekker Inc.</p>
</div>
<div id="ref-draper1998_Appliedregressionanalysis">
<p>Draper, N. R., and H. Smith. 1998. <em>Applied Regression Analysis</em>. III. Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div id="ref-bates1988_Nonlinearregressionanalysis">
<p>Bates, D. M., and D. G. Watts. 1988. <em>Nonlinear Regression Analysis &amp; Its Applications.</em> Books: John Wiley &amp; Sons, Inc.</p>
</div>
<div id="ref-ritz2008_Nonlinearregression">
<p>Ritz, C., and J. C. Streibig. 2008. <em>Nonlinear Regression with R</em>. Books: Springer-Verlag New York Inc.</p>
</div>
<div id="ref-ritz2015_DoseResponseAnalysisUsing">
<p>Ritz, Christian, Florent Baty, Jens C. Streibig, and Daniel Gerhard. 2015. “Dose-Response Analysis Using R.” Edited by Yinglin Xia. <em>PLOS ONE</em> 10 (12): e0146021. doi:<a href="https://doi.org/10.1371/journal.pone.0146021">10.1371/journal.pone.0146021</a>.</p>
</div>
<div id="ref-box1964_analysistransformations">
<p>Box, G. E. P., and D. R. Cox. 1964. “An Analysis of Transformations.” <em>Journal of the Royal Statistical Society</em> B-26: 211–52.</p>
</div>
<div id="ref-carroll1988_Transformationweightingregression">
<p>Carroll, R. J., and D. Ruppert. 1988. <em>Transformation and Weighting in Regression.</em> Books: Chapman and Hall.</p>
</div>
<div id="ref-pannacci2013_Phytotoxiceffectsaqueous">
<p>Pannacci, E., D. Pettorossi, and F. Tei. 2013. “Phytotoxic Effects of Aqueous Extracts of Sunflower on Seed Germination and Growth of Sinapis Alba L., Triticum Aestivum L. and Lolium Multiflorum Lam.” <em>Allelopathy Journal</em> 32 (1): 23.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="la-regressione-lineare-semplice.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
