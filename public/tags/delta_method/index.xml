<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Delta_method on Fixing the bridge between biologists and statisticians</title>
    <link>https://www.statforbiology.com/tags/delta_method/</link>
    <description>Recent content in Delta_method on Fixing the bridge between biologists and statisticians</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Copyright © 2023, @AndreaOnofri</copyright>
    <lastBuildDate>Thu, 09 Jan 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://www.statforbiology.com/tags/delta_method/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Nonlinear combinations of model parameters in regression</title>
      <link>https://www.statforbiology.com/2020/stat_nls_gnlht/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2020/stat_nls_gnlht/</guid>
      <description>


&lt;p&gt;Nonlinear regression plays an important role in my research and teaching activities. While I often use the ‘drm()’ function in the ‘drc’ package for my research work, I tend to prefer the ‘nls()’ function for teaching purposes, mainly because, in my opinion, the transition from linear models to nonlinear models is smoother, for beginners. One problem with ‘nls()’ is that, in contrast to ‘drm()’, it is not specifically tailored to the needs of biologists or students in biology. Therefore, now and then, I have to build some helper functions, to perform some specific tasks; I usually share these functions within the ‘aomisc’ package, that is available on github (&lt;a href=&#34;https://www.statforbiology.com/rpackages/&#34;&gt;see this link&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In this post, I would like to describe one of these helper functions, i.e. ‘gnlht()’, which is aimed at helping students (and practitioners; why not?) with one of their tasks, i.e. making some simple manipulations of model parameters, to obtain relevant biological information. Let’s see a typical example.&lt;/p&gt;
&lt;div id=&#34;motivating-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivating example&lt;/h1&gt;
&lt;p&gt;This is a real-life example, taken from a research published by Vischetti et al. in 1996. That research considered three herbicides for weed control in sugar beet, i.e. metamitron (M), phenmedipham (P) and cloridazon (C). Four soil samples were contaminated, respectively with: (i) M alone, (ii) M + P (iii) M + C and (iv) M + P + C. The aim was to assess whether the degradation speed of metamitron in soil depended on the presence of co-applied herbicides. To reach this aim, the soil samples were incubated at 20°C and sub-samples were taken in different times after the beginning of the experiment. The concentration of metamitron in those sub-samples was measured by HPLC analyses, performed in triplicate. The resulting dataset is available within the ‘aomisc’ package; we can load it and use the ‘lattice’ package to visualise the observed means over time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools)
# install_github(&amp;quot;OnofriAndreaPG/aomisc&amp;quot;)
library(aomisc)
library(lattice)
data(metamitron)
xyplot(Conc ~ Time|Herbicide, data = metamitron,
       xlab = &amp;quot;Time (d)&amp;quot;, ylab = &amp;quot;Concentration&amp;quot;,
       scales = list(alternating = F),
       panel = function(x, y, ...) { 
         panel.grid(h = -1, v = -1)
         fmy &amp;lt;- tapply(y, list(factor(x)), mean)
         fmx &amp;lt;- tapply(x, list(factor(x)), mean)
         panel.xyplot(fmx, fmy, col=&amp;quot;red&amp;quot;, type=&amp;quot;b&amp;quot;, cex = 1)
       })&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/post/Stat_nls_gnlht_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Considering this exemplary dataset, let’s see how we can answer the following research questions.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;What is the degradation rate for metamitron, in the four combinations?&lt;/li&gt;
&lt;li&gt;Is there a significant difference between the degradation rate of metamitron alone and with co-applied herbicides?&lt;/li&gt;
&lt;li&gt;What is the half-life for metamitron, in the four combinations?&lt;/li&gt;
&lt;li&gt;What are the times to reach 70 and 30% of the initial concentration, for metamitron in the four combinations?&lt;/li&gt;
&lt;li&gt;Is there a significant difference between the half-life of metamitron alone and with co-applied herbicides?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-a-degradation-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fitting a degradation model&lt;/h1&gt;
&lt;p&gt;The figure above shows a visible difference in the degradation pattern of metamitron, which could be attributed to the presence of co-applied herbicides. The degradation kinetics can be described by the following (first-order) model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ C(t, h) = A_h \, \exp \left(-k_h  \, t \right) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(C(t, h)\)&lt;/span&gt; is the concentration of metamitron at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; in each of the four combinations &lt;span class=&#34;math inline&#34;&gt;\(h\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(A_h\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k_h\)&lt;/span&gt; are, respectively, the initial concentration and degradation rate for metamitron in each combination.&lt;/p&gt;
&lt;p&gt;The model is nonlinear and, therefore, we can use the ‘nls()’ function for nonlinear least squares regression. The code is given below: please, note that the two parameters are followed by the name of the factor variable in square brackets (i.e.: A[Herbicide] and k[Herbicide]). This is necessary to fit a different parameter value for each level of the ‘Herbicide’ factor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Fit nls grouped model
modNlin &amp;lt;- nls(Conc ~ A[Herbicide] * exp(-k[Herbicide] * Time), 
               start=list(A=rep(100, 4), k=rep(0.06, 4)), 
               data=metamitron)
summary(modNlin)
## 
## Formula: Conc ~ A[Herbicide] * exp(-k[Herbicide] * Time)
## 
## Parameters:
##     Estimate Std. Error t value Pr(&amp;gt;|t|)    
## A1 9.483e+01  4.796e+00   19.77   &amp;lt;2e-16 ***
## A2 1.021e+02  4.316e+00   23.65   &amp;lt;2e-16 ***
## A3 9.959e+01  4.463e+00   22.31   &amp;lt;2e-16 ***
## A4 1.116e+02  4.184e+00   26.68   &amp;lt;2e-16 ***
## k1 4.260e-02  4.128e-03   10.32   &amp;lt;2e-16 ***
## k2 2.574e-02  2.285e-03   11.26   &amp;lt;2e-16 ***
## k3 3.034e-02  2.733e-03   11.10   &amp;lt;2e-16 ***
## k4 2.186e-02  1.822e-03   12.00   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 9.701 on 88 degrees of freedom
## 
## Number of iterations to convergence: 5 
## Achieved convergence tolerance: 7.149e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the sake of simplicity, I will neglige an accurate model check, although I need to point out that this is highly wrong. I’ll come back to this issue in another post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;working-with-model-parameters&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Working with model parameters&lt;/h1&gt;
&lt;p&gt;Considering the research questions, it is clear that the above output answers the first one, as it gives the four degradation rates, &lt;span class=&#34;math inline&#34;&gt;\(k1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(k2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(k3\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k4\)&lt;/span&gt;. All the other questions can be translated into sets of linear/nonlinear functions (combinations) of model parameters. If we use the naming of parameter estimates in the nonlinear regression object, for the second question we can write the following functions: &lt;span class=&#34;math inline&#34;&gt;\(k1 - k2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(k1 - k3\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k1 - k4\)&lt;/span&gt;. The third question requires some slightly more complex math: if we invert the equation above for one herbicide, we get to the following inverse:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ t = \frac{- log \left[\frac{C(t)}{A} \right] }{k} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I do not think this is complex enough to scare the biologists, is it? The half-life is the time required for C(t) to drop to half of the initial value, so that &lt;span class=&#34;math inline&#34;&gt;\(C(t)/A\)&lt;/span&gt; is equal to &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt;. Thus:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ t_{1/2} = \frac{- \log \left[0.5 \right] }{k} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Analogously, we can answer the question 4, by replacing &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; respectively with &lt;span class=&#34;math inline&#34;&gt;\(0.7\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(0.3\)&lt;/span&gt;. The difference between the half-lives of metamitron alone and combined with the second herbicide can be calculated by:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{- \log \left[0.5 \right] }{k_1} - \frac{- \log \left[0.5 \right] }{k_2} = \frac{k_2 - k_1}{k_1 \, k_2} \, \log(0.5)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The other differences are obtained analogously.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;inferences-and-hypotheses-testing&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Inferences and hypotheses testing&lt;/h1&gt;
&lt;p&gt;All parameter estimates are characterised by some uncertainty, which is summarised by way of the standard errors (see the code output above). Clearly, such an uncertainty propagates to their combinations. As for the first question, the combinations are linear, as only subtraction is involved. Therefore, the standard error for the difference can be easily calculated by the usual law of propagation of errors, which I have dealt with in &lt;a href=&#34;https://www.statforbiology.com/2019/stat_general_errorpropagation/&#34;&gt;this post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In R, linear combinations of model parameters can be built and tested by using the ‘glht()’ function in the ‘multcomp’ package. However, I wanted to find a general solution, that could handle both linear and nonlinear combinations of model parameters. Such a solution should be based on the ‘delta method’, which I have dealt with in &lt;a href=&#34;https://www.statforbiology.com/2019/stat_general_thedeltamethod/&#34;&gt;this post&lt;/a&gt;. Unfortunately, the function ‘deltaMethod()’ in the ‘car’ package is not flexible enough to the aims of my students and mine.&lt;/p&gt;
&lt;p&gt;Therefore, I wrote a wrapper for the ‘deltaMethod()’ function, which I named ‘gnlht()’, as it might play for nonlinear combinations the same role as ‘glht()’ for linear combinations. To use this function, apart from loading the ‘aomisc’ package, we need to prepare a list of formulas. Care needs to be taken to make sure that the element in the formulas correspond to the names of the estimated parameters in the model object, as returned by the ‘coef()’ method. In the box below, I show how we can calculate the differences between the degradation rates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~k1 - k2, ~k1 - k3, ~k1 - k4)
gnlht(modNlin, funList)
##      Form   Estimate          SE  t-value      p-value
## 1 k1 - k2 0.01686533 0.004718465 3.574325 5.727310e-04
## 2 k1 - k3 0.01226241 0.004951372 2.476568 1.517801e-02
## 3 k1 - k4 0.02074109 0.004512710 4.596150 1.430392e-05&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The very same code can be used for nonlinear combinations of model parameters. In order to calculate the half-lives, we can use the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ -log(0.5)/k1, ~ -log(0.5)/k2,
                ~ -log(0.5)/k3, ~ -log(0.5)/k4)
gnlht(modNlin, funList)
##           Form Estimate       SE  t-value      p-value
## 1 -log(0.5)/k1 16.27089 1.576827 10.31876 7.987828e-17
## 2 -log(0.5)/k2 26.93390 2.391121 11.26413 9.552912e-19
## 3 -log(0.5)/k3 22.84747 2.058588 11.09861 2.064093e-18
## 4 -log(0.5)/k4 31.70942 2.643330 11.99601 3.257068e-20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Instead of writing ‘0.5’, we can introduce a new model term, e.g. ‘prop’, as a ‘constant’, in the sense that it is not an estimated parameter. We can pass a value for this constant in a data frame, by using the ‘const’ argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ -log(prop)/k1, ~ -log(prop)/k2,
                ~ -log(prop)/k3, ~ -log(prop)/k4)
gnlht(modNlin, funList, const = data.frame(prop = 0.5))
##            Form prop Estimate       SE  t-value      p-value
## 1 -log(prop)/k1  0.5 16.27089 1.576827 10.31876 7.987828e-17
## 2 -log(prop)/k2  0.5 26.93390 2.391121 11.26413 9.552912e-19
## 3 -log(prop)/k3  0.5 22.84747 2.058588 11.09861 2.064093e-18
## 4 -log(prop)/k4  0.5 31.70942 2.643330 11.99601 3.257068e-20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is very flexible, because it lets us to calculate, altogether, the half-life and the times required for the concentration to drop to 70 and 30% of the initial value:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ -log(prop)/k1, ~ -log(prop)/k2,
                ~ -log(prop)/k3, ~ -log(prop)/k4)
gnlht(modNlin, funList, const = data.frame(prop = c(0.7, 0.5, 0.3)))
##             Form prop  Estimate        SE  t-value      p-value
## 1  -log(prop)/k1  0.7  8.372564 0.8113927 10.31876 7.987828e-17
## 2  -log(prop)/k2  0.7 13.859465 1.2304069 11.26413 9.552912e-19
## 3  -log(prop)/k3  0.7 11.756694 1.0592942 11.09861 2.064093e-18
## 4  -log(prop)/k4  0.7 16.316815 1.3601865 11.99601 3.257068e-20
## 5  -log(prop)/k1  0.5 16.270892 1.5768267 10.31876 7.987828e-17
## 6  -log(prop)/k2  0.5 26.933905 2.3911214 11.26413 9.552912e-19
## 7  -log(prop)/k3  0.5 22.847468 2.0585881 11.09861 2.064093e-18
## 8  -log(prop)/k4  0.5 31.709416 2.6433295 11.99601 3.257068e-20
## 9  -log(prop)/k1  0.3 28.261979 2.7388938 10.31876 7.987828e-17
## 10 -log(prop)/k2  0.3 46.783265 4.1532955 11.26413 9.552912e-19
## 11 -log(prop)/k3  0.3 39.685266 3.5756966 11.09861 2.064093e-18
## 12 -log(prop)/k4  0.3 55.078164 4.5913725 11.99601 3.257068e-20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The differences between the half-lives (and other degradation times) can be calculated as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ (k2 - k1)/(k1 * k2) * log(prop),
                ~ (k3 - k1)/(k1 * k3) * log(prop), 
                ~ (k4 - k1)/(k1 * k4) * log(prop))
gnlht(modNlin, funList, const = data.frame(prop = c(0.7, 0.5, 0.3)))
##                              Form prop  Estimate       SE  t-value      p-value
## 1 (k2 - k1)/(k1 * k2) * log(prop)  0.7  5.486900 1.473859 3.722813 3.468973e-04
## 2 (k3 - k1)/(k1 * k3) * log(prop)  0.7  3.384130 1.334340 2.536183 1.297111e-02
## 3 (k4 - k1)/(k1 * k4) * log(prop)  0.7  7.944250 1.583814 5.015900 2.718444e-06
## 4 (k2 - k1)/(k1 * k2) * log(prop)  0.5 10.663013 2.864235 3.722813 3.468973e-04
## 5 (k3 - k1)/(k1 * k3) * log(prop)  0.5  6.576577 2.593100 2.536183 1.297111e-02
## 6 (k4 - k1)/(k1 * k4) * log(prop)  0.5 15.438524 3.077917 5.015900 2.718444e-06
## 7 (k2 - k1)/(k1 * k2) * log(prop)  0.3 18.521287 4.975078 3.722813 3.468973e-04
## 8 (k3 - k1)/(k1 * k3) * log(prop)  0.3 11.423287 4.504125 2.536183 1.297111e-02
## 9 (k4 - k1)/(k1 * k4) * log(prop)  0.3 26.816185 5.346236 5.015900 2.718444e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The possibility of passing constants in a data.frame adds flexibility with respect to the ‘deltaMethod()’ function in the ‘car’ package. For example, we can use this method to make predictions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ A1 * exp (- k1 * Time), ~ A2 * exp (- k2 * Time), 
                ~ A3 * exp (- k3 * Time), ~ A4 * exp (- k4 * Time))
pred &amp;lt;- gnlht(modNlin, funList, const = data.frame(Time = seq(0, 67, 1)))
head(pred)
##                   Form Time  Estimate       SE  t-value      p-value
## 1 A1 * exp(-k1 * Time)    0  94.83198 4.795948 19.77336 3.931106e-34
## 2 A2 * exp(-k2 * Time)    0 102.08592 4.316122 23.65223 6.671764e-40
## 3 A3 * exp(-k3 * Time)    0  99.58530 4.463418 22.31144 5.485452e-38
## 4 A4 * exp(-k4 * Time)    0 111.62446 4.183588 26.68151 5.980930e-44
## 5 A1 * exp(-k1 * Time)    1  90.87694 4.381511 20.74101 1.223613e-35
## 6 A2 * exp(-k2 * Time)    1  99.49225 4.062186 24.49229 4.617181e-41
 r
tail(pred)
##                     Form Time  Estimate       SE   t-value      p-value
## 267 A3 * exp(-k3 * Time)   66 13.446308 2.095933  6.415427 6.838561e-09
## 268 A4 * exp(-k4 * Time)   66 26.375174 2.618594 10.072266 2.555133e-16
## 269 A1 * exp(-k1 * Time)   67  5.462339 1.363509  4.006090 1.287737e-04
## 270 A2 * exp(-k2 * Time)   67 18.202556 2.358965  7.716331 1.752360e-11
## 271 A3 * exp(-k3 * Time)   67 13.044500 2.068082  6.307534 1.106297e-08
## 272 A4 * exp(-k4 * Time)   67 25.804886 2.607131  9.897810 5.827813e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although this is not very fast, in contrast to the ‘predict()’ method for ‘nls’ objects, it has the advantage of reporting standard errors.&lt;/p&gt;
&lt;p&gt;Hope this is useful. Happy coding!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;John Fox and Sanford Weisberg (2019). An {R} Companion to Applied Regression, Third Edition. Thousand Oaks CA:Sage. URL: &lt;a href=&#34;https://socialsciences.mcmaster.ca/jfox/Books/Companion/&#34; class=&#34;uri&#34;&gt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Torsten Hothorn, Frank Bretz and Peter Westfall (2008). Simultaneous Inference in General Parametric Models. Biometrical Journal 50(3), 346–363.&lt;/li&gt;
&lt;li&gt;Ritz, C., Baty, F., Streibig, J. C., Gerhard, D. (2015) Dose-Response Analysis Using R PLOS ONE, 10(12), e0146021&lt;/li&gt;
&lt;li&gt;Vischetti, C., Marini, M., Businelli, M., Onofri, A., 1996. The effect of temperature and co-applied herbicides on the degradation rate of phenmedipham, chloridazon and metamitron in a clay loam soil in the laboratory, in: Re, A.D., Capri, E., Evans, S.P., Trevisan, M. (Eds.), “The Environmental Phate of Xenobiotics”, Proceedings X Symposium on Pesticide Chemistry, Piacenza. La Goliardica Pavese, Piacenza, pp. 287–294.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Stabilising transformations: how do I present my results?</title>
      <link>https://www.statforbiology.com/2019/stat_general_reportingresults/</link>
      <pubDate>Sat, 15 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2019/stat_general_reportingresults/</guid>
      <description>


&lt;p&gt;ANOVA is routinely used in applied biology for data analyses, although, in some instances, the basic assumptions of normality and homoscedasticity of residuals do not hold. In those instances, most biologists would be inclined to adopt some sort of stabilising transformations (logarithm, square root, arcsin square root…), prior to ANOVA. Yes, there might be more advanced and elegant solutions, but stabilising transformations are suggested in most traditional biometry books, they are very straightforward to apply and they do not require any specific statistical software. I do not think that this traditional technique should be underrated.&lt;/p&gt;
&lt;p&gt;However, the use of stabilising transformations has one remarkable drawback, it may hinder the clarity of results. I’d like to give a simple, but relevant example.&lt;/p&gt;
&lt;div id=&#34;an-example-with-counts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;An example with counts&lt;/h1&gt;
&lt;p&gt;Consider the following dataset, that represents the counts of insects on 15 independent leaves, treated with the insecticides A, B and C (5 replicates):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset &amp;lt;- structure(data.frame(
  Insecticide = structure(c(1L, 1L, 1L, 1L, 1L, 
    2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L), 
    .Label = c(&amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;), class = &amp;quot;factor&amp;quot;), 
  Count = c(448, 906, 484, 477, 634, 211, 276, 
    415, 587, 298, 50, 90, 73, 44, 26)), 
  .Names = c(&amp;quot;Insecticide&amp;quot;, &amp;quot;Count&amp;quot;))
dataset
##    Insecticide Count
## 1            A   448
## 2            A   906
## 3            A   484
## 4            A   477
## 5            A   634
## 6            B   211
## 7            B   276
## 8            B   415
## 9            B   587
## 10           B   298
## 11           C    50
## 12           C    90
## 13           C    73
## 14           C    44
## 15           C    26&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We should not expect that a count variable is normally distributed with equal variances. Indeed, a graph of residuals against expected values shows clear signs of heteroscedasticity.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod &amp;lt;- lm(Count ~ Insecticide, data=dataset)
plot(mod, which = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/post/Stat_General_reportingResults_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this situation, a logarithmic transformation is often suggested to produce a new normal and homoscedastic dataset. Therefore we take the log-transformed variable and submit it to ANOVA.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- lm(log(Count) ~ Insecticide, data=dataset)
print(anova(model), digits=6)
## Analysis of Variance Table
## 
## Response: log(Count)
##             Df   Sum Sq Mean Sq F value     Pr(&amp;gt;F)    
## Insecticide  2 15.82001 7.91000 50.1224 1.4931e-06 ***
## Residuals   12  1.89376 0.15781                       
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
 r
summary(model)
## 
## Call:
## lm(formula = log(Count) ~ Insecticide, data = dataset)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.6908 -0.1849 -0.1174  0.2777  0.5605 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)    6.3431     0.1777  35.704 1.49e-13 ***
## InsecticideB  -0.5286     0.2512  -2.104   0.0572 .  
## InsecticideC  -2.3942     0.2512  -9.529 6.02e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.3973 on 12 degrees of freedom
## Multiple R-squared:  0.8931,	Adjusted R-squared:  0.8753 
## F-statistic: 50.12 on 2 and 12 DF,  p-value: 1.493e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, the standard error for each mean (SEM) corresponds to &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{0.158/5}\)&lt;/span&gt;. In the end, we might show the following table of means for transformed data:&lt;/p&gt;
&lt;!-- table --&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Insecticide&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Means (log n.)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6.343&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;5.815&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;3.985&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;SEM&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0.178&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!-- table --&gt;
&lt;p&gt;Unfortunately, we loose clarity: how many insects did we have on each leaf? If we present in our manuscript a table like this one we might be asked by our readers or by the reviewer to report the means on the original measurement unit. What should we do, then? Here are some suggestions.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We can present the means of the original data with standard deviations. This is clearly less than optimal, if we want to suggest more than the bare variability of the observed sample. Furthermore, &lt;strong&gt;please remember that the means of original data may not be a good measure of central tendency, if the original population is strongly ‘asymmetric’ (skewed)!&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;We can show back-transformed means. Accordingly, if we have done, e.g., a logarithmic transformation, we can exponentiate the means of transformed data and report them back to the original measurement unit. Back-transformed means ‘estimate’ the medians of the original populations, which may be regarded as better measures of central tendency for skewed data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We suggest that the use of the second method. However, this leaves us with the problem of adding a measure of uncertainty to back-transformed means. No worries, we can use the delta method to back-transform standard errors. It is straightforward:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;take the first derivative of the back-transform function [in this case the first derivative of exp(X)=exp(X)] and&lt;/li&gt;
&lt;li&gt;multiply it by the standard error of the transformed data.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This may be simply done by hand, with e.g &lt;span class=&#34;math inline&#34;&gt;\(exp(6.343) \times 0.178 = 101.19\)&lt;/span&gt; (for insecticide A). This ‘manual’ solution is always available, regardless of the statistical software at hand. With R, we can use the ‘emmeans’ package (Lenth, 2016):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(emmeans)
countM &amp;lt;- emmeans(model, ~Insecticide, regrid = &amp;quot;response&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is enough to set the argument ‘regrid’ to ’response, although the transformation must be embedded in the model. It means: it is ok if we coded the model as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;log(Count) ~ Insecticide&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the contrary, it fails if we coded the model as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;logCount ~ Insecticide&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where the transformation was performed prior to fitting (there are methods to circumvent this, but I’ll explain in another post).&lt;/p&gt;
&lt;p&gt;Obviously, the back-transformed standard error is different for each mean (there is no homogeneity of variances on the original scale, but we knew this already).
Back-transformed data might be presented as follows:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;center&#34;&gt;Insecticide&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Mean&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;SE&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;568.5&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;101.19&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;center&#34;&gt;B&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;335.1&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;59.68&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;center&#34;&gt;C&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;51.88&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;9.57&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It would be appropriate to state it clearly (e.g. in a footnote), that means and SEs were obtained by back-transformation via the delta method. Far clearer, isn’t it? As I said, there are other solutions, such as fitting a GLM, but stabilising transformations are simple and they are easily acceptable in biological Journals.&lt;/p&gt;
&lt;p&gt;If you want to know something more about the delta-method you might start from &lt;a href=&#34;https://www.statforbiology.com/2019/stat_general_thedeltamethod/&#34;&gt;my post here&lt;/a&gt;. A few years ago, some collegues and I have also discussed these issues in a journal paper (Onofri et al., 2010).&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
University of Perugia (Italy)&lt;/p&gt;
&lt;p&gt;#References&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Lenth, R.V., 2016. Least-Squares Means: The R Package lsmeans. Journal of Statistical Software 69. &lt;a href=&#34;https://doi.org/10.18637/jss.v069.i01&#34; class=&#34;uri&#34;&gt;https://doi.org/10.18637/jss.v069.i01&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Onofri, A., Carbonell, E.A., Piepho, H.-P., Mortimer, A.M., Cousens, R.D., 2010. Current statistical issues in Weed Research. Weed Research 50, 5–24.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>How do we combine errors, in biology? The delta method</title>
      <link>https://www.statforbiology.com/2019/stat_general_thedeltamethod/</link>
      <pubDate>Sat, 25 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2019/stat_general_thedeltamethod/</guid>
      <description>


&lt;p&gt;In a recent post I have shown that we can build linear combinations of model parameters (&lt;a href=&#34;https://www.statforbiology.com/2019/stat_general_errorpropagation/&#34;&gt;see here&lt;/a&gt; ). For example, if we have two parameter estimates, say Q and W, with standard errors respectively equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma_Q\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_W\)&lt;/span&gt;, we can build a linear combination as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Z = AQ + BW + C\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where A, B and C are three coefficients. The standard error for this combination can be obtained as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \sigma_Z = \sqrt{ A^2 \sigma^2_Q + B^2 \sigma^2_W + 2AB \sigma_{QW} }\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In biology, nonlinear transformations are much more frequent than linear transformations. Nonlinear transformations are, e.g., &lt;span class=&#34;math inline&#34;&gt;\(Z = exp(Q + W)\)&lt;/span&gt;, or, &lt;span class=&#34;math inline&#34;&gt;\(Z = 1/(Q + W)\)&lt;/span&gt;. What is the standard error for these nonlinear transformations? This is not a complex problem, but the solution may be beyond biologists with an average level of statistical proficiency. It is named the ‘delta method’ and it provides the so called ‘delta standard errors’. I thought it might be useful to talk about it, by using a very simple language and a few examples.&lt;/p&gt;
&lt;div id=&#34;example-1-getting-the-half-life-of-a-herbicide&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 1: getting the half-life of a herbicide&lt;/h1&gt;
&lt;p&gt;A herbicide has proven to follow a first order degradation kinetic in soil, with constant degradation rate &lt;span class=&#34;math inline&#34;&gt;\(k = -0.035\)&lt;/span&gt; and standard error equal to &lt;span class=&#34;math inline&#34;&gt;\(0.00195\)&lt;/span&gt;. What is the half-life (&lt;span class=&#34;math inline&#34;&gt;\(T_{1/2}\)&lt;/span&gt;) of this herbicide and its standard error?&lt;/p&gt;
&lt;p&gt;Every pesticide chemist knows that the half-life (&lt;span class=&#34;math inline&#34;&gt;\(T_{1/2}\)&lt;/span&gt;) is derived by the degradation rate, according to the following equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ T_{1/2} = \frac{\log(0.5)}{k}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Therefore, the half-life for our herbicide is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Thalf &amp;lt;- log(0.5)/-0.035
Thalf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 19.80421&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But … what is the standard error of this half-life? There is some uncertainty around the estimate of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; and it is clear that such an uncertainty should propagate to the estimate of &lt;span class=&#34;math inline&#34;&gt;\(T_{1/2}\)&lt;/span&gt;; unfortunately, the transformation is nonlinear and we cannot use the expression given above for linear transformations.&lt;/p&gt;
&lt;div id=&#34;the-basic-idea&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The basic idea&lt;/h2&gt;
&lt;p&gt;The basic idea behind the delta method is that most of the simple nonlinear functions, which we use in biology, can be locally approximated by the tangent line through a point of interest. For example, our nonlinear half-life function is &lt;span class=&#34;math inline&#34;&gt;\(Y  = \log(0.5)/X\)&lt;/span&gt; and, obviously, we are interested in the point where &lt;span class=&#34;math inline&#34;&gt;\(X = k = -0.035\)&lt;/span&gt;. In the graph below, we have represented our nonlinear function (in black) and its tangent line (in red) through the above point: we can see that the approximation is fairly good in the close vicinity of &lt;span class=&#34;math inline&#34;&gt;\(X = -0.035\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/post/Stat_General_TheDeltaMethod_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What is the equation of the tangent line? In general, if the nonlinear function is &lt;span class=&#34;math inline&#34;&gt;\(G(X)\)&lt;/span&gt;, you may remember from high school that the slope &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; of the tangent line is equal to the first derivative of &lt;span class=&#34;math inline&#34;&gt;\(G(X)\)&lt;/span&gt;, that is &lt;span class=&#34;math inline&#34;&gt;\(G&amp;#39;(X)\)&lt;/span&gt;. You may also remember that the equation of a line with slope &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; through the point &lt;span class=&#34;math inline&#34;&gt;\(P(X_1, Y_1)\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(Y - Y_1 = m(X - X_1)\)&lt;/span&gt;. As &lt;span class=&#34;math inline&#34;&gt;\(Y_1 = G(X_1)\)&lt;/span&gt;, the tangent line has equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = G(X_1) + G&amp;#39;(X_1)(X - X_1)\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-the-derivative&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We need the derivative!&lt;/h2&gt;
&lt;p&gt;In order to write the equation of the red line in the Figure above, we need to consider that &lt;span class=&#34;math inline&#34;&gt;\(X_1 = -0.035\)&lt;/span&gt; and we need to be able to calculate the first derivative of our nonlinear half-life fuction. I am not able to derive the expression of the first derivative for all nonlinear functions and it was a relief for me to discover that R can handle this task in simple ways, e.g. by using the function ‘D()’. For our case, it is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(log(0.5)/X), &amp;quot;X&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## -(log(0.5)/X^2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Therefore, we can use this R function to calculate the slope &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; of the tangent line in the figure above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- -0.035
m &amp;lt;- eval( D(expression(log(0.5)/X), &amp;quot;X&amp;quot;) )
m&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 565.8344&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We already know that &lt;span class=&#34;math inline&#34;&gt;\(G(-0.035) = 19.80421\)&lt;/span&gt;. Therefore, we can write the equation of the tangent line (red line in the graph above):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = 19.80421 + 565.8344 \, (X + 0.035)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;that is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = 19.80421 + 565.8344 \, X + 565.8344 \cdot 0.035 = 39.60841 + 565.8344 \, X\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;replacing-a-curve-with-a-line&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Replacing a curve with a line&lt;/h2&gt;
&lt;p&gt;Now, we have two functions:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;the original nonlinear half-life function &lt;span class=&#34;math inline&#34;&gt;\(Y = \log(0.5)/X\)&lt;/span&gt;$&lt;/li&gt;
&lt;li&gt;a new linear function (&lt;span class=&#34;math inline&#34;&gt;\(Y = 39.60841 + 565.8344 \, X\)&lt;/span&gt;), that is a very close approximation to the previous one, at least near to the point &lt;span class=&#34;math inline&#34;&gt;\(X = -0.035\)&lt;/span&gt;, which we are interested in.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Therefore, we can approximate the former with the latter! If we use the linear function, we see that the half-life is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;39.60841 + 565.8344 * -0.035&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 19.80421&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is what we expected. The advantage is that we can now use the low of propagation of errors to estimate the standard error (see the first and second equation in this post):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \sigma_{ \left[ 39.60841 + 565.8344 \, X \right]} = \sqrt{ 562.8344^2 \, \sigma^2_X}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here we go:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt( m^2 * (0.00195 ^ 2) )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.103377&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;in-general&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;In general…&lt;/h2&gt;
&lt;p&gt;If we have a nonlinear transformation &lt;span class=&#34;math inline&#34;&gt;\(G(X)\)&lt;/span&gt;, the standard error for this transformation is approximated by knowing the first derivative &lt;span class=&#34;math inline&#34;&gt;\(G&amp;#39;(X)\)&lt;/span&gt; and the standard error of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma_{G(X)}  \simeq \sqrt{ [G&amp;#39;(X)]^2 \, \sigma^2_X }\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;#Example 2: a back-transformed count&lt;/p&gt;
&lt;p&gt;A paper reports that the mean number of microorganisms in a substrate, on a logarithmic scale, was &lt;span class=&#34;math inline&#34;&gt;\(X_1 = 5\)&lt;/span&gt; with standard error &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 0.84\)&lt;/span&gt;. It is easy to derive that the actual number of micro-organisms was &lt;span class=&#34;math inline&#34;&gt;\(\exp{5} = 148.4132\)&lt;/span&gt;; what is the standard error of the back-transformed mean?&lt;/p&gt;
&lt;p&gt;The first derivative of our nonlinear function is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(exp(X)), &amp;quot;X&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## exp(X)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and thus the slope of the tangent line is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- 5
m &amp;lt;- eval( D(expression(exp(X)), &amp;quot;X&amp;quot;) )
m&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 148.4132&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to the function above, the standard error for the back-transformed mean is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sigma &amp;lt;- 0.84
sqrt( m^2 * sigma^2 )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 124.6671&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;example-3-selenium-concentration-in-olive-drupes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 3: Selenium concentration in olive drupes&lt;/h1&gt;
&lt;p&gt;The concentration of selenium in olive drupes was found to be &lt;span class=&#34;math inline&#34;&gt;\(3.1 \, \mu g \,\, g^{-1}\)&lt;/span&gt; with standard error equal to 0.8. What is the intake of selenium when eating one drupe? Please, consider that one drupe weights, on average, 3.4 g (SE = 0.31) and that selenium concentration and drupe weight show a covariance of 0.55.&lt;/p&gt;
&lt;p&gt;The amount of selenium is easily calculated as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- 3.1; W = 3.4
X * W&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10.54&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delta standard errors can be obtained by considering the partial derivatives for each of the two variables:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mX &amp;lt;- eval( D(expression(X*W), &amp;quot;X&amp;quot;) )
mW &amp;lt;- eval( D(expression(X*W), &amp;quot;W&amp;quot;) )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and combining them as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sigmaX &amp;lt;- 0.8; sigmaW &amp;lt;- 0.31; sigmaXW &amp;lt;- 0.55
sqrt( (mX^2)*sigmaX^2 + (mW^2)*sigmaW^2 + 2*X*W*sigmaXW )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4.462726&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For those of you who would like to get involved with matrix notation: we can reach the same result via matrix multiplication (see below). This might be easier when we have more than two variables to combine.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;der &amp;lt;- matrix(c(mX, mW), 1, 2)
sigma &amp;lt;- matrix(c(sigmaX^2, sigmaXW, sigmaXW, sigmaW^2), 2, 2, byrow = T)
sqrt( der %*% sigma %*% t(der) )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          [,1]
## [1,] 4.462726&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;#The delta method with R&lt;/p&gt;
&lt;p&gt;In R there is a shortcut function to calculate delta standard errors, that is available in the ‘car’ package. In order to use it, we need to have:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;a named vector for the variables that we have to combine&lt;/li&gt;
&lt;li&gt;an expression for the transformation&lt;/li&gt;
&lt;li&gt;a variance-covariance matrix&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For the first example, we have:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obj &amp;lt;- c(&amp;quot;k&amp;quot; = -0.035)
sigma &amp;lt;- matrix(c(0.00195^2), 1, 1)

library(car)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Loading required package: carData&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;deltaMethod(object = obj, g=&amp;quot;log(0.5)/k&amp;quot;, vcov = sigma)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Estimate      SE   2.5 % 97.5 %
## log(0.5)/k  19.8042  1.1034 17.6416 21.967&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the second example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obj &amp;lt;- c(&amp;quot;X1&amp;quot; = 5)
sigma &amp;lt;- matrix(c(0.84^2), 1, 1)
deltaMethod(object = obj, g=&amp;quot;exp(X1)&amp;quot;, vcov = sigma)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##         Estimate     SE  2.5 % 97.5 %
## exp(X1)   148.41 124.67 -95.93 392.76&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the third example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obj &amp;lt;- c(&amp;quot;X&amp;quot; = 3.1, &amp;quot;W&amp;quot; = 3.4)
sigma &amp;lt;- matrix(c(0.8^2, 0.55, 0.55, 0.31^2), 2, 2, byrow = T)
deltaMethod(object = obj, g=&amp;quot;X * W&amp;quot;, vcov = sigma)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       Estimate      SE   2.5 % 97.5 %
## X * W  10.5400  4.4627  1.7932 19.287&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function ‘deltaMethod()’ is very handy to be used in connection with model objects, as we do not need to provide anything, but the transformation function. But this is something that requires another post!&lt;/p&gt;
&lt;p&gt;However, two final notes relating to the delta method need to be pointed out here:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;the delta standard error is always approximate;&lt;/li&gt;
&lt;li&gt;if the original variables are gaussian, the transformed variable, usually, is not gaussian.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>