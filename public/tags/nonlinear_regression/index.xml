<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nonlinear_regression on Fixing the bridge between biologists and statisticians</title>
    <link>http://localhost:6346/tags/nonlinear_regression/</link>
    <description>Recent content in Nonlinear_regression on Fixing the bridge between biologists and statisticians</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Copyright © 2023, @AndreaOnofri</copyright>
    <lastBuildDate>Fri, 23 Feb 2024 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="http://localhost:6346/tags/nonlinear_regression/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Pairwise comparisons in nonlinear regression</title>
      <link>http://localhost:6346/2024/stat_nls_paircomp2/</link>
      <pubDate>Fri, 23 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2024/stat_nls_paircomp2/</guid>
      <description>


&lt;p&gt;Pairwise comparisons are one of the most debated topic in agricultural research: they are very often used and, sometimes, abused, in literature. I have nothing against the appropriate use of this very useful technique and, for those who are interested, some colleagues and I have given a bunch of (hopefully) useful suggestions in a paper, a few years ago (&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/10.1111/j.1365-3180.2009.00758.x&#34;&gt;follow this link here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;According to the emails I often receive, there might be some interest in making pairwise comparisons in linear/nonlinear regression models. In particular, whenever we have grouped data and we have fitted the same model to each group, we might like to compare the groups, to state whether the regression lines/curves are significantly different from each other. To this aim, we could consider two approaches:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;comparing the parameters of the curves; for example, I have three groups and, consequently, three different straight lines. I could ask: are the three slopes significantly different from one another? Or, are the three intercepts significanly different from one another?&lt;/li&gt;
&lt;li&gt;Comparing the lines/curves as a whole unit; for example, with three different straight lines I could ask: are the three lines, overall, significantly different?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I have already considered the #1 in a previous post (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_nls_paircomp/&#34;&gt;follow this link here&lt;/a&gt;); basically, there are functions in the ‘drc’ (&lt;code&gt;compParm()&lt;/code&gt;) and ‘aomisc’ (&lt;code&gt;compCoefs(),&lt;/code&gt; &lt;code&gt;pairComp()&lt;/code&gt; and &lt;code&gt;gnlht()&lt;/code&gt;) packages that permit pairwise comparisons across model parameters.&lt;/p&gt;
&lt;p&gt;Relating to the #2 above, the situation is rather similar: we have fitted the same model to all groups, so that the set of maximum likelihood parameter estimates is different for each group. In maths:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{ij} = f(X, \theta_j) + \varepsilon_{ij}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is the group, &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is the individual in each group, Y is the response, X is the set of predictors and &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is the set of estimated parameters.&lt;/p&gt;
&lt;p&gt;If the j&lt;sup&gt;th&lt;/sup&gt; groups are not significantly different, the model above reduces to the following one:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{i} = f(X, \theta) + \varepsilon_{i}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the different curves have been pooled into one common curve for all treatment levels. These two models are nested in nature and could be compared by using a likelihood ratio test or, in the context of nonlinear regression, by an F test for the extra-sum-of-squares. This way, we can test the hypothesis that the curves are all the same, against the alternative that at least two of those curves are significantly different from each other. I have shown this technique in the context of time-to-event models in &lt;a href=&#34;https://www.statforbiology.com/_seedtutorial/comparing-the-time-course-of-events-for-several-groups&#34;&gt;this post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, a question remains open: which are the different pairs? Let’s see a possible line of attack.&lt;/p&gt;
&lt;div id=&#34;a-case-study&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A case-study&lt;/h1&gt;
&lt;p&gt;This is a real-life example, taken from a research published by Vischetti et al. in 1996 (we have used this example in other posts, before). That research considered three herbicides for weed control in sugar beet, i.e. metamitron (M), phenmedipham (P) and chloridazon (C). Four soil samples were contaminated, respectively with: (i) M alone, (ii) M + P (iii) M + C and (iv) M + P + C. The aim was to assess whether the degradation speed of metamitron in soil depended on the presence of co-applied herbicides. To reach this aim, the soil samples were incubated at 20°C and sub-samples were taken in different times after the beginning of the experiment. The concentration of metamitron in those sub-samples was measured by HPLC analyses, performed in triplicate. The resulting dataset is available within the ‘aomisc’ package.&lt;/p&gt;
&lt;p&gt;In the box below. we install the ‘aomisc’ package from gitHub (if necessary), load it and load the ‘metamitron’ dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools)
# devtools::install_github(&amp;quot;OnofriAndreaPG/aomisc&amp;quot;)
rm(list = ls())
library(aomisc)
data(metamitron)
head(metamitron)
##   Time Herbicide   Conc
## 1    0         M  92.00
## 2    0         M 118.64
## 3    0         M  89.58
## 4    7         M  59.32
## 5    7         M  62.95
## 6    7         M  62.95
 r
#...
#...
tail(metamitron)
##    Time Herbicide  Conc
## 91   55       MPC 35.75
## 92   55       MPC 37.83
## 93   55       MPC 27.41
## 94   67       MPC 23.38
## 95   67       MPC 28.41
## 96   67       MPC 18.92&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first step we take is to fit a first-order degradation model, as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[C_{t, h} = A_h \, \exp \left(-k_h  \, t \right)\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; is the concentration at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; for metamitron in the &lt;span class=&#34;math inline&#34;&gt;\(h^{th}\)&lt;/span&gt; combination (M alone, M + P, M + C and M + P + C), &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is the initial concentration for the metamitron in the &lt;span class=&#34;math inline&#34;&gt;\(h^{th}\)&lt;/span&gt; combination, &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the degradation rate for metamitron in the &lt;span class=&#34;math inline&#34;&gt;\(h^{th}\)&lt;/span&gt; combination. This model is nonlinear and, therefore, we can use the &lt;code&gt;drm()&lt;/code&gt; function in the ‘drc’ package for nonlinear least squares regression. The code is given below: please, note that the factor variable ‘Herbicide’ is passed as the ‘curveid’ argument, so that we can fit different parameters for each level of grouping factor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit a grouped model
mod &amp;lt;- drm(Conc ~ Time, fct = DRC.expoDecay(),
               curveid = Herbicide, 
               data=metamitron)
summary(mod)
## 
## Model fitted: Exponential Decay Model (2 parms)
## 
## Parameter estimates:
## 
##          Estimate Std. Error t-value   p-value    
## C0:M   9.4832e+01 4.8822e+00  19.424 &amp;lt; 2.2e-16 ***
## C0:MP  9.9585e+01 4.4763e+00  22.247 &amp;lt; 2.2e-16 ***
## C0:MC  1.0209e+02 4.3613e+00  23.407 &amp;lt; 2.2e-16 ***
## C0:MPC 1.1162e+02 4.1297e+00  27.030 &amp;lt; 2.2e-16 ***
## k:M    4.2600e-02 4.3306e-03   9.837 8.327e-16 ***
## k:MP   3.0338e-02 2.7516e-03  11.025 &amp;lt; 2.2e-16 ***
## k:MC   2.5735e-02 2.3393e-03  11.001 &amp;lt; 2.2e-16 ***
## k:MPC  2.1859e-02 1.7677e-03  12.366 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  9.701411 (88 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we fit a common degradation curve for the four herbicides:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit a reduced model
modRed &amp;lt;- drm(Conc ~ Time, fct = DRC.expoDecay(),
                data=metamitron)
summary(modRed)
## 
## Model fitted: Exponential Decay Model (2 parms)
## 
## Parameter estimates:
## 
##                  Estimate Std. Error t-value   p-value    
## C0:(Intercept) 1.0119e+02 3.0656e+00  33.008 &amp;lt; 2.2e-16 ***
## k:(Intercept)  2.8212e-02 1.7546e-03  16.079 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  13.48936 (94 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we can compare these two nested models by using the ‘extra-sum-of-squares’ principle:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[F = \frac{\frac{RSS_r - RSSf}{DF_r-DF_f}}{\frac{RSS_f}{DF_f}},\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;that is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RSSr &amp;lt;- sum(residuals(modRed)^2)
RSSf &amp;lt;- sum(residuals(mod)^2)
DFr &amp;lt;- modRed$df.residual
DFf &amp;lt;- mod$df.residual
Fval &amp;lt;- ((RSSr - RSSf)/(DFr - DFf))/(RSSf/DFf)
pf(Fval, DFr-DFf, DFr, lower.tail = F)
## [1] 2.32031e-12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where the value F has an approximate F distribution. More simply, we can reject the null by using the &lt;code&gt;anova()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(mod, modRed, test = &amp;quot;F&amp;quot;)
## 
## 1st model
##  fct:      DRC.expoDecay()
##  pmodels: 1 (for all parameters)
## 2nd model
##  fct:      DRC.expoDecay()
##  pmodels: Herbicide (for all parameters)
## ANOVA table
## 
##           ModelDf     RSS Df F value p value
## 2nd model      94 17104.5                   
## 1st model      88  8282.3  6  15.623   0.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In conclusion, there is at least one pair of herbicides that degrade in a different manner. But, we have 4 herbicides and 6 possible pairs; which is different from which?&lt;/p&gt;
&lt;p&gt;Let’s consider the pair composed by the herbicides M and MP; one possible line of attack is that we code a reduced model with three different curves, one for MC, one for MPC and one, in common, for M and MP. Thus we buid a new factor where the levels for M and MP have been collapsed into one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# New factor with three levels
newFac &amp;lt;- metamitron$Herbicide
levels(newFac)[1:2] &amp;lt;- &amp;quot;D1&amp;quot;
newFac
##  [1] D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1 
## [20] D1  D1  D1  D1  D1  MP  MP  MP  MP  MP  MP  MP  MP  MP  MP  MP  MP  MP  MP 
## [39] MP  MP  MP  MP  MP  MP  MP  MP  MP  MP  D1  D1  D1  D1  D1  D1  D1  D1  D1 
## [58] D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  D1  MPC MPC MPC MPC
## [77] MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC MPC
## [96] MPC
## Levels: D1 MP MPC&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We refit the reduce model with three curves and compare with the full one (4 curves):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Fit a reduced model (3 curves)
modRed2 &amp;lt;- drm(Conc ~ Time, fct = DRC.expoDecay(),
              curveid = newFac,
              data=metamitron)
summary(modRed2)
## 
## Model fitted: Exponential Decay Model (2 parms)
## 
## Parameter estimates:
## 
##          Estimate Std. Error t-value   p-value    
## C0:D1  9.7816e+01 3.7911e+00 25.8015 &amp;lt; 2.2e-16 ***
## C0:MP  9.9585e+01 5.2295e+00 19.0429 &amp;lt; 2.2e-16 ***
## C0:MPC 1.1162e+02 4.8246e+00 23.1366 &amp;lt; 2.2e-16 ***
## k:D1   3.2290e-02 2.5371e-03 12.7271 &amp;lt; 2.2e-16 ***
## k:MP   3.0338e-02 3.2146e-03  9.4376 4.222e-15 ***
## k:MPC  2.1860e-02 2.0651e-03 10.5850 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  11.33378 (90 degrees of freedom)
 r
anova(mod, modRed2)
## 
## 1st model
##  fct:      DRC.expoDecay()
##  pmodels: newFac (for all parameters)
## 2nd model
##  fct:      DRC.expoDecay()
##  pmodels: Herbicide (for all parameters)
## ANOVA table
## 
##           ModelDf     RSS Df F value p value
## 2nd model      90 11560.9                   
## 1st model      88  8282.3  2  17.418   0.000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the null hypothesis (degradation M = degradation MP) can be rejected. In order to test the difference between the six pairs we can repeated this procees by six times. However, in order to make it quicker, we have added the &lt;code&gt;compCurves()&lt;/code&gt; function to our ‘aomisc’ package. In order to correct for multiplicity, we can add the appropriate value to the ‘adjusted’ argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compCurves(mod, adjusted = &amp;quot;bonferroni&amp;quot;)
## $Pairs
##             RSS1     RSS2 DF Test.value      p.level
## M-MC   11560.913 8282.329  2  17.417530 2.542176e-06
## M-MP    9691.075 8282.329  2   7.483983 5.977160e-03
## M-MPC  16698.655 8282.329  2  44.711862 2.391420e-13
## MC-MP   8683.576 8282.329  2   2.131632 7.483781e-01
## MC-MPC  9470.171 8282.329  2   6.310427 1.648606e-02
## MP-MPC 11241.475 8282.329  2  15.720510 8.722373e-06
## 
## $Letters
##     Curve Letters
## M       M       a
## MC     MC       b
## MP     MP       b
## MPC   MPC       c&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
email: &lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;
Blog &lt;a href=&#34;www.statforbiology.com&#34;&gt;www.statforbiology.com&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fitting threshold models to seed germination data</title>
      <link>http://localhost:6346/2023/stat_drcte_12-htt2step/</link>
      <pubDate>Mon, 13 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2023/stat_drcte_12-htt2step/</guid>
      <description>


&lt;p&gt;In previous posts we have shown that we can use time-to-event curves to describe the germination pattern of a seed population (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_drcte_2-methods/&#34;&gt;see here&lt;/a&gt;). We have also shown that these curves can be modified to include the effects of external/internal factors/covariates, such as the genotype, the species, the humidity content and temperature in the substrate (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_drcte_5-comparinglots/&#34;&gt;see here&lt;/a&gt; and &lt;a href=&#34;https://www.statforbiology.com/2023/stat_drcte_10-examplehtte/&#34;&gt;here&lt;/a&gt;). These modified time-to-event curves can be fitted in ‘one-step’, i.e., we start from the germination data with the appropriate shape (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_drcte_3-reshapingdata/&#34;&gt;see here&lt;/a&gt;), fit the model and retrieve the estimates of model parameters ( &lt;a href=&#34;https://www.statforbiology.com/2023/stat_drcte_10-examplehtte/&#34;&gt;go to here for an example&lt;/a&gt; ).&lt;/p&gt;
&lt;p&gt;In some cases, we may be interested in following a different approach, that is accomplished in two-steps. Let’s consider an example where we have performed germination assays at 10 different temperatures: instead of building a time-to-event model that contains the temperature as an external covariate, we could:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;independently fit a different time-to-event curve to the germination data at each temperature, so that we have ten independent time-to-event curves;&lt;/li&gt;
&lt;li&gt;derive from each curve a summary statistic of interest, such as the germination rate for the 50-th percentile (GR50: &lt;a href=&#34;https://www.statforbiology.com/2022/stat_drcte_9-quantiles/&#34;&gt;see here&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Fit, e.g., a thermal-time model to those derived statistics (second step of data analyses).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Fitting models in two-steps has always been a common practice in agriculture/biology (see, e.g., multienvironment genotype experiments): it is usually simpler, quicker and requires lower computing power than one-step fitting. The drawback is that some infomation may be lost between the two steps, and, for this reason, one-step and two-steps model fitting do not necessarily lead to the same results. But, we’ll make this point in a future post.&lt;/p&gt;
&lt;div id=&#34;definition-of-threshold-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Definition of threshold models&lt;/h1&gt;
&lt;p&gt;Threshold models are used to describe a relationship where the response variable changes abruptly, following a small change in the predictor. A typical threshold model looks like that in the Figure below, where we see three threshold levels:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X1 = 5.5\)&lt;/span&gt;: at this threshold, the response changes abruptly from ‘flat’ to linearly increasing;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X2 = 23.1\)&lt;/span&gt;: at this threshold, the response changes abruptly from linearly increasing to linearly decreasing;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X3 = 37.2\)&lt;/span&gt;: at this threshold, the response changes abruptly from linearly decreasing to ‘flat’.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You may recognise a ‘broken-stick’ pattern, although threshold models can also be curvilinear, as we will see later.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_drcte_12-HTT2step_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I have already considered threshold models in a previous post (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_seedgermination_htt2step/&#34;&gt;see here&lt;/a&gt;) and I have already mentioned that thermal-time, hydro-time and hydro-thermal-time models for seed germination can also be cast as threshold models; if we consider, e.g., the Germination Rate (GR) as the response variable and the environmental temperature as the predictor, the relationship could be very close to that represented in Figure 1 and the three thresholds would, respectively, be the &lt;em&gt;base temperature&lt;/em&gt; (T_b_), the &lt;em&gt;optimal temperature&lt;/em&gt; (T_o_) and the &lt;em&gt;ceiling temperature&lt;/em&gt; (T_c_). On the other hand, if we consider the effect of soil humidity on GR, we should expect a response pattern with only one threshold, i.e. the &lt;em&gt;base water potential&lt;/em&gt; level (e.g. the first half of the figure above, up to the maximum response level).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-possibly-incomplete-list-of-threshold-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A (possibly incomplete) list of threshold models&lt;/h1&gt;
&lt;p&gt;I have made a review of literature, searching for all threshold models that have been used so far in seed germination studies. For all those models, I have built the related R functions, together with self-starting routines, which can be used for nonlinear regression fitting with the &lt;code&gt;drm()&lt;/code&gt; function in the &lt;code&gt;drc&lt;/code&gt; package (Ritz et al., 2019). The availability of self-starting routines will free you from the hassle of having to provide initial guesses for model parameters. All these R functions are available within the &lt;code&gt;drcSeedGerm&lt;/code&gt; package (Onofri et al., 2018) and their names, with links to the relevant parts of the appendix to this post are:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#grpsilin---grt.gh&#34;&gt;GRPsi.Lin() - GRT.GH()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grpsipol---grpsipol2&#34;&gt;GRPsi.Pol() - GRPsi.Pol2()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pmaxpsi1-and-pmaxt1&#34;&gt;PmaxPsi1() - PmaxT1()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grt.bs&#34;&gt;GRT.BS()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grt.rf&#34;&gt;GRT.RF()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grt.m&#34;&gt;GRT.M()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grt.ex&#34;&gt;GRT.Ex()&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#grt.yl&#34;&gt;GRT.YL()&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It may be helpful to look at the shapes of the above models in the Figure below, while the equations are motivated in the appendix, at the end of this post.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_drcte_12-HTT2step_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, let’s look at a few examples of two-steps fitting. But, before working through this, you will need to install and load the &lt;code&gt;drcSeedGerm&lt;/code&gt; package, by using the code below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# installing drcSeedGerm package, if not yet available
# library(devtools)
# install_github(&amp;quot;onofriandreapg/drcSeedGerm&amp;quot;)

# loading package
library(drcSeedGerm)
library(tidyverse)
library(lmtest)
library(sandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 1&lt;/h1&gt;
&lt;p&gt;This dataset describes the germination of rapeseed (cv. Excalibur) at different water potential levels in the substrate. It has been already used for fitting a hydro-time model in one step (&lt;a href=&#34;https://www.statforbiology.com/2022/stat_drcte_6-ht1step/&#34;&gt;see here&lt;/a&gt;); in this present post, we try a different line of attack.&lt;/p&gt;
&lt;p&gt;First of all, we remove all dishes with water potential levels higher than -0.7 MPa, because the germinations were too quick to obtain a reliable estimate of the whole time-to-event curve. Next, we independently (‘separate = T’) fit a time to event model to the data observed in each dish. Lately, for each time to event curve, we retrieve the maximum proportion of germinated seeds (Pmax, i.e. the ‘d’ parameter of the time-to-event curve) and the germination rates for the 10&lt;sup&gt;th&lt;/sup&gt;, 30&lt;sup&gt;th&lt;/sup&gt; and 50&lt;sup&gt;th&lt;/sup&gt; percentile.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# First-step of data analyses
data(rape2G)
rape2G &amp;lt;- rape2G %&amp;gt;% 
  dplyr::filter(Psi &amp;lt;=-0.7 &amp;amp; CV == &amp;quot;Excalibur&amp;quot;) %&amp;gt;% 
  mutate(Dish2 = paste(Dish, Psi, sep = &amp;quot;:&amp;quot;))

# model fit
mod.first &amp;lt;- drmte(nSeeds ~ timeBef + timeAf, 
                   data = rape2G,
                   fct = LL.3(), curveid = Dish2, 
                   separate = T)

# Retrieve maximum proportion of germinated seeds
Pmax &amp;lt;- coef(mod.first)[substr(names(coef(mod.first)), 1, 1) == &amp;quot;d&amp;quot;]
PmaxList &amp;lt;- tibble(Pmax =  Pmax) %&amp;gt;% 
  mutate(temp = names(Pmax), .before = Pmax) %&amp;gt;% 
  separate(col = &amp;quot;temp&amp;quot;, into = c(&amp;quot;n&amp;quot;, &amp;quot;Dish&amp;quot;, &amp;quot;Psi&amp;quot;),
           sep = &amp;quot;:&amp;quot;) %&amp;gt;% 
  mutate(Psi = as.numeric(Psi)) %&amp;gt;% 
  select(-1)
head(PmaxList)
## # A tibble: 6 × 3
##   Dish    Psi  Pmax
##   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 64     -0.7 0.901
## 2 65     -0.7 0.986
## 3 66     -0.7 0.922
## 4 67     -0.8 0.914
## 5 68     -0.8 0.887
## 6 69     -0.8 0.835
 r
# Retrieve the GR values
GR &amp;lt;- quantile(mod.first, rate = T, probs = c(0.1, 0.3, 0.5))
GRlist &amp;lt;- tibble(temp = row.names(GR), GR, row.names = NULL) %&amp;gt;% 
  separate(col = &amp;quot;temp&amp;quot;, into = c(&amp;quot;Dish&amp;quot;, &amp;quot;Psi&amp;quot;, &amp;quot;g&amp;quot;),
           sep = &amp;quot;:&amp;quot;) %&amp;gt;% 
  mutate(Psi = as.numeric(Psi)) %&amp;gt;% 
  remove_rownames()
head(GRlist)
## # A tibble: 6 × 5
##   Dish    Psi g     Estimate     SE
##   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 64     -0.7 10%      0.581 0.0895
## 2 64     -0.7 30%      0.416 0.0397
## 3 64     -0.7 50%      0.333 0.0239
## 4 65     -0.7 10%      0.718 0.149 
## 5 65     -0.7 30%      0.468 0.0595
## 6 65     -0.7 50%      0.357 0.0330&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we are ready to move on to the second step of data analysis. Relating to the Pmax value, we can see that this values stays constant and equal to 0 up to -1 MPa and increases steadily afterwords. We can model this behaviour by using the &lt;code&gt;PmaxPsi1()&lt;/code&gt; function, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modPmax &amp;lt;- drm(Pmax ~ Psi, data = PmaxList,
               fct = PmaxPsi1())
plot(modPmax, log = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_drcte_12-HTT2step_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coeftest(modPmax, vcov. = sandwich)
## 
## t test of coefficients:
## 
##                     Estimate Std. Error   t value  Pr(&amp;gt;|t|)    
## G:(Intercept)      1.0737381  0.0746708   14.3796 2.608e-11 ***
## Psib:(Intercept)  -1.0053956  0.0016495 -609.5109 &amp;lt; 2.2e-16 ***
## sigma:(Intercept)  0.1367469  0.0272873    5.0114 9.058e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Regarding the germination percentiles, a look at the data shows that, for all percentiles, germination rates stay constant up to -1 MPa and, afterwords, they increase linearly. We can model this behaviour by using the &lt;code&gt;GRPsiLin()&lt;/code&gt; equation and, following Bradford (2002), we code a common base water potential level for the different germination percentiles. The code is given in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modGR &amp;lt;- drm(Estimate ~ Psi, data = GRlist,
               fct = GRPsi.Lin(), curveid = g,
             pmodels = list(~1, ~g - 1))
plot(modGR, log = &amp;quot;&amp;quot;,
             legendPos = c(-1.3, 0.7))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_drcte_12-HTT2step_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coeftest(modGR, vcov. = sandwich)
## 
## t test of coefficients:
## 
##                   Estimate Std. Error  t value  Pr(&amp;gt;|t|)    
## Psib:(Intercept) -0.989504   0.031937 -30.9832 &amp;lt; 2.2e-16 ***
## thetaH:g10%       0.446550   0.081366   5.4881 8.977e-07 ***
## thetaH:g30%       0.649827   0.099213   6.5498 1.557e-08 ***
## thetaH:g50%       0.852974   0.134058   6.3627 3.209e-08 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Usually, we are interested in the base osmotic potential level (&lt;span class=&#34;math inline&#34;&gt;\(\Psi_b\)&lt;/span&gt;) that is given in the output of the &lt;code&gt;coeftest()&lt;/code&gt; method. We used &lt;code&gt;coeftest()&lt;/code&gt; in the &lt;code&gt;lmtest&lt;/code&gt; package for reasons that will be clearer later on.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 2&lt;/h1&gt;
&lt;p&gt;This second dataset was obtained from a germination assays with barley, where three replicates of 50 seeds were placed in Petri dishes and assayed at 9 constant temperature levels (1, 3, 7, 10, 15, 20, 25, 30, 35, 40 °C). Germinated seeds were counted and removed daily for 10 days. We have already presented this analysis in a previous paper (Onofri et al., 2018), although in this post we use a different (and updated) coding.&lt;/p&gt;
&lt;p&gt;Also in this second example, the first step of data analysis is based on loading the data and fitting a separate time-to-event curve to the data at each temperature level.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(barley)
barley &amp;lt;- barley %&amp;gt;% 
  mutate(TempF = factor(Temp))

mod1 &amp;lt;- drmte(nSeeds ~ timeBef + timeAf, fct=W2.3(),
      curveid = TempF,
      data = barley,
      separate = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we retrieve the germination rates for the 10^th, 30&lt;sup&gt;th&lt;/sup&gt; and 50&lt;sup&gt;th&lt;/sup&gt; percentile; for analogy with the published paper, we restrict the percentiles to the germinated fraction, althoug it might be better to avoid such a restriction.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GR &amp;lt;- quantile(mod1, rate = T, restricted = T, 
               probs = c(0.1, 0.3, 0.5),
                display = F)
GRlist &amp;lt;- tibble(temp = row.names(GR), GR, row.names = NULL) %&amp;gt;% 
  separate(col = &amp;quot;temp&amp;quot;, into = c(&amp;quot;Temp&amp;quot;, &amp;quot;g&amp;quot;),
           sep = &amp;quot;:&amp;quot;) %&amp;gt;% 
  mutate(Temp = as.numeric(Temp)) %&amp;gt;% 
  remove_rownames()
head(GRlist)
## # A tibble: 6 × 4
##    Temp g     Estimate      SE
##   &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1     1 10%     0.0982 0.00328
## 2     1 30%     0.0777 0.00177
## 3     1 50%     0.0682 0.00125
## 4     3 10%     0.124  0.00307
## 5     3 30%     0.105  0.00173
## 6     3 50%     0.0962 0.00126&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The behaviour of germination rates against temperature can be described, e.g., by using the threshold model proposed by Masin et al. (2017), that is implemented in the R function &lt;code&gt;GRT.Ex()&lt;/code&gt;, as shown in the box below. Preliminary trials show that the three percentiles share the same ‘k’ parameter and base temperature level, which we can request by using the ‘pmodels’ argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modGR &amp;lt;- drm(Estimate ~ Temp, data = GRlist,
               fct = GRT.Ex(),
             curveid = g, pmodels = list(~1, ~1, ~g - 1, ~g -1))
coeftest(modGR, vcov. = sandwich)
## 
## t test of coefficients:
## 
##                 Estimate Std. Error   t value  Pr(&amp;gt;|t|)    
## k:(Intercept)   0.870259   0.137958    6.3082 4.697e-06 ***
## Tb:(Intercept) -0.551135   0.777058   -0.7093    0.4868    
## Tc:g10%        35.202423   0.021941 1604.4023 &amp;lt; 2.2e-16 ***
## Tc:g30%        33.262928   0.325741  102.1147 &amp;lt; 2.2e-16 ***
## Tc:g50%        32.215906   0.226664  142.1307 &amp;lt; 2.2e-16 ***
## ThetaT:g10%    25.449521   1.795846   14.1713 1.489e-11 ***
## ThetaT:g30%    40.481068   2.010929   20.1305 2.829e-14 ***
## ThetaT:g50%    51.406767   2.424133   21.2063 1.095e-14 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
 r
plot(modGR, log = &amp;quot;&amp;quot;, type = &amp;quot;all&amp;quot;, xlim = c(0, 40),
     ylim = c(0, 1.3),
     ylab = &amp;quot;GR&amp;quot;, xlab = &amp;quot;Temperature (°C)&amp;quot;,
     legendPos = c(12, 0.9))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_drcte_12-HTT2step_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;warning-message&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Warning message!&lt;/h1&gt;
&lt;p&gt;When we collect data about the response of germination rates to temperature and use them to parameterise nonlinear regression models by using nonlinear least squares, the basic assumption of homoscedasticity is rarely tenable. &lt;strong&gt;We should not forget this!&lt;/strong&gt;. In the above examples I used a robust variance-covariance sandwich estimator (Zeileis, 2006; see the use of the &lt;code&gt;coeftest()&lt;/code&gt; method, instead of the &lt;code&gt;summary()&lt;/code&gt; method), although other techniques can be successfully used to deal with this problem.&lt;/p&gt;
&lt;p&gt;Thanks for reading and happy coding!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
&lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;a href=&#34;https://twitter.com/onofriandreapg?ref_src=twsrc%5Etfw&#34; class=&#34;twitter-follow-button&#34; data-show-count=&#34;false&#34;&gt;Follow &lt;span class=&#34;citation&#34;&gt;@onofriandreapg&lt;/span&gt;&lt;/a&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Alvarado, V., Bradford, K.J., 2002. A hydrothermal time model explains the cardinal temperatures for seed germination. Plant, Cell and Environment 25, 1061–1069.&lt;/li&gt;
&lt;li&gt;Baty, F., Ritz, C., Charles, S., Brutsche, M., Flandrois, J. P., Delignette-Muller, M.-L., 2014. A toolbox for nonlinear regression in R: the package nlstools. Journal of Statistical Software, 65, 5, 1-21.&lt;/li&gt;
&lt;li&gt;Bradford, K.J., 2002. Applications of hydrothermal time to quantifying and modelling seed germination and dormancy. Weed Science 50, 248–260.&lt;/li&gt;
&lt;li&gt;Catara, S., Cristaudo, A., Gualtieri, A., Galesi, R., Impelluso, C., Onofri, A., 2016. Threshold temperatures for seed germination in nine species of Verbascum (Scrophulariaceae). Seed Science Research 26, 30–46.&lt;/li&gt;
&lt;li&gt;Garcia-Huidobro, J., Monteith, J.L., Squire, R., 1982. Time, temperature and germination of pearl millet (&lt;em&gt;Pennisetum typhoides&lt;/em&gt; S &amp;amp; H.). 1. Constant temperatures. Journal of Experimental Botany 33, 288–296.&lt;/li&gt;
&lt;li&gt;Kropff, M.J., van Laar, H.H. 1993. Modelling crop-weed interactions. CAB International, Books.&lt;/li&gt;
&lt;li&gt;Masin, R., Onofri, A., Gasparini, V., Zanin, G., 2017. Can alternating temperatures be used to estimate base temperature for seed germination? Weed Research 57, 390–398.&lt;/li&gt;
&lt;li&gt;Onofri, A., Benincasa, P., Mesgaran, M.B., Ritz, C., 2018. Hydrothermal-time-to-event models for seed germination. European Journal of Agronomy 101, 129–139.&lt;/li&gt;
&lt;li&gt;Ritz, C., Jensen, S. M., Gerhard, D., Streibig, J. C., 2019. Dose-Response Analysis Using R. CRC Press&lt;/li&gt;
&lt;li&gt;Rowse, H.R., Finch-Savage, W.E., 2003. Hydrothermal threshold models can describe the germination response of carrot (Daucus carota) and onion (Allium cepa) seed populations across both sub- and supra-optimal temperatures. New Phytologist 158, 101–108.&lt;/li&gt;
&lt;li&gt;Zeileis, A., 2006. Object-oriented computation of sandwich estimators. Journal of Statistical Software, 16, 9, 1-16.&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;appendix-description-of-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Appendix: description of models&lt;/h1&gt;
&lt;div id=&#34;grpsilin---grt.gh&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GRPsiLin() - GRT.GH()&lt;/h2&gt;
&lt;p&gt;The equation behind &lt;code&gt;GRPsiLin()&lt;/code&gt; has been used to describe the effect of environmental humidity (&lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;, in MPa) on germination rate (Bradford, 2002):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\max\left[\Psi, \Psi_b\right] - \Psi_b}{\theta_H}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The parameter &lt;span class=&#34;math inline&#34;&gt;\(\Psi_b\)&lt;/span&gt; is the &lt;em&gt;base water potential&lt;/em&gt; (in MPa), representing the minimum level of humidity in the substrate to trigger the germination process. The other parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta_H\)&lt;/span&gt; (in MPa day or MPa hour) is the hydro-time constant.&lt;/p&gt;
&lt;p&gt;A totally similar equation (with different parameter names) has been used by Garcia-Huidobro et al (1982), to describe the effect of sub-optimal temperatures (T in °C) on the germination rate:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\max \left[T, T_b\right] - T_b}{\theta_T}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(T_b\)&lt;/span&gt; is the base temperature and &lt;span class=&#34;math inline&#34;&gt;\(\theta_T\)&lt;/span&gt; is the thermal time (in °C d). This second model is available &lt;code&gt;GRT.GH()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sample code (not executed)
# Tlev &amp;lt;- c(2, 5, 10, 15, 20, 25)
# GR &amp;lt;- c(0, 0, 0.21, 0.49, 0.68, 0.86)
# modGH &amp;lt;- drm(GR ~ Tlev, fct = GRT.GH())
# library(sandwich); library(lmtest)
# coeftest(modGH, vcov = sandwich)
# plot(modGH, log=&amp;quot;&amp;quot;, xlim = c(0, 25), legendPos = c(5, 1.2),
#      xlab = &amp;quot;Temperature (°C)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;#a-possibly-incomplete-list-of-threshold-models&#34;&gt;Go up&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;grpsipol---grpsipol2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GRPsiPol() - GRPsiPol2()&lt;/h2&gt;
&lt;p&gt;In my experience, I have found that the relationship between GR and water potential in the substrate may, sometimes, be curvilinear. For these situations, I have successfully used the following equations:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\max\left[\Psi,\Psi_b\right]^2 - \Psi^2_b}{\theta_H}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\left(\max\left[\Psi, \Psi_b\right] - \Psi_b \right)^2}{ \theta_H }\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Both models can be fitted in R, by using the two functions &lt;code&gt;GRPsi.Pol()&lt;/code&gt; and &lt;code&gt;GRPsi.Pol2()&lt;/code&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sample code (not executed)
# Psi &amp;lt;- c(-2, -1.5, -1.2, -1, -0.8, -0.6, -0.4, -0.25,
#          -0.12, -0.06, -0.03, 0)
# GR &amp;lt;- c(0, 0, 0, 0, 0.0585, 0.094, 0.1231, 0.1351,
#         0.1418, 0.1453, 0.1458, 0.1459)
# Psi2 &amp;lt;- c(-0.5, -0.6, -0.7, -0.8, -0.9, -1, -1.1, -1.2,
#           -1.5)
# GR2 &amp;lt;- c(1.4018, 1.0071, 0.5614, 0.3546, 0.2293, 0, 0,
#          0, 0)
# 
# 
# modHT &amp;lt;- drm(GR ~ Psi, fct = GRPsiPol())
# modHT2 &amp;lt;- drm(GR2 ~ Psi2, fct = GRPsiPol2())
# par(mfrow = c(1,2))
# plot(modHT, log=&amp;quot;&amp;quot;, legendPos = c(-1.5, 0.15), 
#      ylim = c(0, 0.20), xlab = &amp;quot;Water potential (MPa)&amp;quot;)
# plot(modHT2, log=&amp;quot;&amp;quot;, legendPos=c(-1.3, 1), 
#      xlab = &amp;quot;Water potential (MPa)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;#a-possibly-incomplete-list-of-threshold-models&#34;&gt;Go up&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;pmaxpsi1-and-pmaxt1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;PmaxPsi1() and PmaxT1()&lt;/h2&gt;
&lt;p&gt;All the previous models tend to go up to infinity when the predictor value (temperature or water potential) goes to infinity. In some instances, we may need an asymptotic model, to describe the response of the maximum proportion of germinated seeds to soil humidity (Onofri et al., 2018).&lt;/p&gt;
&lt;p&gt;In practice, we could use a shifted exponential model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \pi = G \, \left[ 1 - exp \left( \frac{ \max\left[\Psi, \Psi_b\right] - \Psi_b }{\sigma} \right) \right]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; is the proportion of germinated seeds, &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; is the fraction of non-germinable seeds (e.g., dormant seeds) and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; describes how quickly the population of seeds responds to increased humidity in the substrate. This model can be fitted by using the R function the self-starters &lt;code&gt;PmaxPsi1()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If we reverse the sign of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; in the previous equation, we obtain a decreasing trend, which might be useful to describe the effect of super-optimal temperatures on the proportion of germinated seeds, going down to 0 at the ceiling temperature threshold. Also this model is available in R, under the name &lt;code&gt;PmaxT1()&lt;/code&gt;. &lt;code&gt;PmaxPsi1()&lt;/code&gt; &lt;code&gt;PmaxT1()&lt;/code&gt; are two equivalent R functions, apart from the name of model parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sample code (not executed)
# par(mfrow = c(1,2))
# # Pmax vs Psi
# Psi &amp;lt;- seq(-2.2, 0, by = 0.2)
# Pmax &amp;lt;- c(0, 0, 0.076, 0.413, 0.514, 0.643, 0.712,
#           0.832, 0.865, 0.849, 0.89, 0.90)
# mod &amp;lt;- drm(Pmax ~ Psi, fct = PmaxPsi1())
# plot(mod, log = &amp;quot;&amp;quot;, xlab = &amp;quot;Water potential (MPa)&amp;quot;, 
#      ylab = &amp;quot;Proportion of germinating seeds&amp;quot;)
# 
# # Pmax vs temperature
# Tval &amp;lt;- c(0, 2.5, 5, 7.5, 10, 12.5, 15, 17.5,
#           20, 22.5, 25, 27.5, 30, 32.5, 35)
# Pmax2 &amp;lt;- c(0.79, 0.81, 0.807, 0.776, 0.83,
#            0.73, 0.744, 0.73, 0.828, 0.818,
#            0.805, 0.706, 0.41, 0.002, 0)
# mod2 &amp;lt;- drm(Pmax2 ~ Tval, fct = PmaxT1())
# plot(mod2, log = &amp;quot;&amp;quot;, xlab = &amp;quot;Temperature (°C)&amp;quot;, 
#      ylab = &amp;quot;Proportion of germinating seeds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;#a-possibly-incomplete-list-of-threshold-models&#34;&gt;Go up&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;grt.bs&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GRT.BS()&lt;/h2&gt;
&lt;p&gt;A broken-stick trend, as the one depicted in the first Figure above was used by Alvarado and Bradford (2002) to model the effect of temperature on the germination rate. Their equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\max \left[\min \left[T,T_o \right], Tb \right] - T_b}{\theta_{T}} \, \left\{ 1 - k \left( \max \left[ T,T_o \right] - T_o \right) \right\}\]&lt;/span&gt;
The right factor is only meaningful when it is positive, that happens when &lt;span class=&#34;math inline&#34;&gt;\(T &amp;lt; T_c\)&lt;/span&gt;, i.e. when the environmental temperature is lower than the ceiling temperature. On this basis, the ceiling temperature is equal to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ T_c = \frac{1}{k} + T_o\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above equation can be easily fitted with the &lt;code&gt;GRT.BS()&lt;/code&gt; function in the ‘drcSeedGerm’ package. We have also implemented the reparameterised equation, where the parameter ‘k’ is replaced with &lt;span class=&#34;math inline&#34;&gt;\(1/(T_c - T_b)\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\min \left[T,T_o \right] - T_b}{\theta_{T}} \, \left\{ 1 - \frac {\min \left[\max \left[ T,T_o \right], T_c \right] - T_o}{T_c - T_o} \right\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This reparameterised equation is available as &lt;code&gt;GRT.BSb()&lt;/code&gt;; it is handy, because the ceiling temperature is included as a parameter, but its fitting properties are not as good as those of the previous equation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sample code
# Tval &amp;lt;- c(2, 5, 10, 15, 20, 25, 30, 35, 40)
# GR &amp;lt;- c(0, 0, 0.209, 0.435, 0.759, 0.821, 0.417, 0.145, 0)
# 
# modBS &amp;lt;- drm(GR ~ Tval, fct = GRT.BS())
# plot(modBS, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
#      legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)
# coeftest(modBS, vcov = sandwich)
# 
# # Reparameterised (self-starter is less accurate)
# modBS &amp;lt;- drm(GR ~ Tval, fct = GRT.BSb())
# plot(modBS, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
#      legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)
# coeftest(modBS, vcov = sandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;#a-possibly-incomplete-list-of-threshold-models&#34;&gt;Go up&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;grt.rf&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GRT.RF()&lt;/h2&gt;
&lt;p&gt;Broken-stick trends may not be reasonable for biological processes, which might be better described by curvilinear equations. Rowse and Finch-Savage (2003) proposed another equation with two components: the first one depicts a linear increase of the GR value with temperature, which is off-set by the second component, starting from &lt;span class=&#34;math inline&#34;&gt;\(T = T_d\)&lt;/span&gt;, which is close to (but not coincident with) &lt;span class=&#34;math inline&#34;&gt;\(T_o\)&lt;/span&gt;. The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{ \max \left( T, T_b \right) - T_b}{\theta_{T}} \left\{ 1 - k \left[ \max \left(T,T_d\right) - T_d \right] \right\}\]&lt;/span&gt;
The optimal temperature can be derived as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ T_o = \frac{1 + kT_b + kT_d}{2k}\]&lt;/span&gt;
while the ceiling temperature is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ T_c = \frac{1}{k} + T_d\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For this equation, you will find the &lt;code&gt;GRT.RF()&lt;/code&gt; self-starter in the ‘drcSeedGerm’ package. We also provide the self-starter &lt;code&gt;GRT.RFb()&lt;/code&gt;, where the parameters ‘k’ is replaced by $ 1/(T_c - T_d)$:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{ \max \left[ T, T_b \right] - T_b}{\theta_{T}} \left\{ 1 - \frac{\left[ \max \left(T,T_d\right) - T_d \right]}{T_c - T_d}  \right\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This reparameterised equation contains the ceiling temperature as a parameter, but its fitting properties are as good as those pf the previous equation.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;#a-possibly-incomplete-list-of-threshold-models&#34;&gt;Go up&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;grt.m&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GRT.M()&lt;/h2&gt;
&lt;p&gt;According to Mesgaran et al (2017), the negative and positive effects of temperature coexist for all temperatures above &lt;span class=&#34;math inline&#34;&gt;\(T_b\)&lt;/span&gt;. Their proposed equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{ \max \left( T, T_b \right) - T_b}{\theta_{T}} \left\{ 1 - k \left[ \min \left(T,T_c\right) - T_b \right] \right\}\]&lt;/span&gt;
This equation is only defined from base to ceiling temperature, while it is 0 elsewhere. The ceiling temperature is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ T_c = \frac{1}{k} + T_b\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is also easy to see that the GR value is a second-order polynomial function of &lt;span class=&#34;math inline&#34;&gt;\(T - T_b\)&lt;/span&gt; and, therefore, the curve is symmetric around the optimal temperature value, which can be derived as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T_o = \frac{T_c - T_b}{2} + T_b\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For this model, the self-starting function in &lt;code&gt;drcSeedGerm&lt;/code&gt; is &lt;code&gt;GRT.M()&lt;/code&gt;. The model can also be reparameterised to include the ceiling temperature as an explicit parameter:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\max \left[ T, T_b \right] - T_b}{\theta_{T}} \left[ 1 - \frac{\min \left[ T, T_c \right] - T_b}{T_c - T_b}  \right]\]&lt;/span&gt;
This reparameterised model is available as &lt;code&gt;GRT.Mb()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Sample code (not executed)
# Tval &amp;lt;- c(2, 5, 10, 15, 20, 25, 30, 35, 40)
# GR &amp;lt;- c(0, 0, 0.209, 0.435, 0.759, 0.821, 0.417, 0.145, 0)
# modM &amp;lt;- drm(GR ~ Tval, fct = GRT.Mb())
# plot(modM, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
#      legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)
# coeftest(modM, vcov. = sandwich)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;#a-possibly-incomplete-list-of-threshold-models&#34;&gt;Go up&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;grt.ex&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GRT.Ex()&lt;/h2&gt;
&lt;p&gt;All the equations above use a product, wherein the first term represents the accumulation of thermal time and the second term may be seen as a switch-off term that is 1 either when &lt;span class=&#34;math inline&#34;&gt;\(T &amp;lt; T_o\)&lt;/span&gt; (Alvarado-Bradford equation) or &lt;span class=&#34;math inline&#34;&gt;\(T &amp;lt; T_d\)&lt;/span&gt; (Rowse-Fintch-Savage equation) or &lt;span class=&#34;math inline&#34;&gt;\(T = T_b\)&lt;/span&gt; (Mesgaran equation) and decreases progressively as temperature increases. In all the above equations, the switch-off term is linear, although we can use other types of switch-off terms, to obtain more flexible models. One possibility is to use an exponential switch-off term, as in the equation below:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ GR = \frac{\max \left[T, T_b \right] - T_b}{\theta_T} \left\{ \frac{1 - \exp \left[ k (\min \left[T, T_c \right] - T_c) \right]}{1 - \exp \left[ k (T_b - T_c) \right]}  \right\}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the switch-off parameter: the lower the value, the higher the negative effect of temperature at super-optimal levels. The response of GR to temperature is highly asymmetric with a slow increase below &lt;span class=&#34;math inline&#34;&gt;\(T_o\)&lt;/span&gt; and a steep drop afterwards.&lt;/p&gt;
&lt;p&gt;I have successfully used this model in Catara et al (2016) and Masin et al (2017). The self-starting function in R is &lt;code&gt;GRT.Ex()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Sample code
# Tval &amp;lt;- c(2, 5, 10, 15, 20, 25, 30, 35, 40)
# GR &amp;lt;- c(0, 0, 0.209, 0.435, 0.759, 0.821, 0.917, 0.445, 0)
# 
# modExb &amp;lt;- drm(GR ~ Tval, fct = GRT.Ex())
# summary(modExb)
# plot(modExb, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
#     legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;#a-possibly-incomplete-list-of-threshold-models&#34;&gt;Go up&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;grt.yl&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;GRT.YL()&lt;/h2&gt;
&lt;p&gt;Another switch-off function can be derived from the simple yield loss function devised by Kropff and van Laar (1993). It is very flexible, as it may depict different types of relationships between temperature and base water potential, according to the value taken by the parameter &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR(g, T) = \frac{\max \left[T, T_b\right] - T_b}{\theta_T} \left( 1 - \frac{q \frac{\min \left[T, T_c\right] -T_b}{T_c- T_b} }{1 + (q-1) \frac{T-T_b}{T_c- T_b}}  \right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In R, this model can be fitted by using the self-starter &lt;code&gt;GRT.YL()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sample code
# Tval &amp;lt;- c(2, 5, 10, 15, 20, 25, 30, 35, 40)
# GR &amp;lt;- c(0, 0, 0.209, 0.435, 0.759, 0.821, 0.917, 0.445, 0)
# modYL &amp;lt;- drm(GR ~ Tval, fct = GRT.YL())
# plot(modYL, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
#      legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;#a-possibly-incomplete-list-of-threshold-models&#34;&gt;Go up&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The coefficient of determination: is it the R-squared or r-squared?</title>
      <link>http://localhost:6346/2022/stat_general_r2/</link>
      <pubDate>Sat, 26 Nov 2022 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2022/stat_general_r2/</guid>
      <description>


&lt;p&gt;We often use the &lt;strong&gt;coefficient of determination&lt;/strong&gt; as a swift ‘measure’ of goodness of fit for our regression models. Unfortunately, there is no unique symbol for such a coefficient and both &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(r^2\)&lt;/span&gt; are used in literature, almost interchangeably. Such an interchangeability is also endorsed by the Wikipedia (see at: &lt;a href=&#34;https://en.wikipedia.org/wiki/Coefficient_of_determination&#34;&gt;https://en.wikipedia.org/wiki/Coefficient_of_determination&lt;/a&gt; ), where both symbols are reported as the abbreviations for this statistical index.&lt;/p&gt;
&lt;p&gt;As an editor of several International Journals, I should not agree with such an approach; indeed, the two symbols &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(r^2\)&lt;/span&gt; mean two different things, and they are not necessarily interchangeable, because, depending on the setting, either of the two may be wrong or ambiguous. Let’s pay a little attention to such an issue.&lt;/p&gt;
&lt;div id=&#34;what-are-the-r-and-r-indices&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What are the ‘r’ and ‘R’ indices?&lt;/h1&gt;
&lt;p&gt;When studying the relationship between quantitative variables, we have two main statistical indices:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;the &lt;strong&gt;Pearson’s (simple linear) correlation coefficient&lt;/strong&gt;, that is almost always indicated as the &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; coefficient. Correlation is different from regression, as it does not assume any sort of dependency between two quantitative variables and it is only meant to express their joint variability;&lt;/li&gt;
&lt;li&gt;the &lt;strong&gt;coefficient of multiple correlation&lt;/strong&gt;, that is usually indicated with &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; and represents (definition from Wikipedia) a &lt;em&gt;measure of how well a given variable can be predicted using a linear function of a set of other variables&lt;/em&gt;. Although &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; is based on correlation (it is the correlation between the observed values for the dependent variable and the predictions made by the model), it is used in the context of multiple regression, where we are studying a dependency relationship.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And, what about the &lt;strong&gt;coefficient of determination&lt;/strong&gt;? It is yet another concept and another index, measuring (again from Wikipedia) the &lt;em&gt;proportion of the variation in the dependent variable that is predictable from the independent variable(s)&lt;/em&gt;. As you see, we are still in the context of regression and our aim is to describe the goodness of fit.&lt;/p&gt;
&lt;p&gt;To start with, let’s abbreviate the coefficient of determination as &lt;span class=&#34;math inline&#34;&gt;\(CD\)&lt;/span&gt;, in order to avoid any confusion with &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;; this index can be be obtained as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ CD_1 = \frac{SS_{reg}}{SS_{tot}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ CD_2 = 1 - \frac{SS_{res}}{SS_{tot}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where: &lt;span class=&#34;math inline&#34;&gt;\(SS_{reg}\)&lt;/span&gt; is the regression sum of squares, &lt;span class=&#34;math inline&#34;&gt;\(SS_{tot}\)&lt;/span&gt; is the total sum of squares and &lt;span class=&#34;math inline&#34;&gt;\(SS_{res}\)&lt;/span&gt; is the residual sum of squares, after a linear regression fit. The second formula is preferable: sum of squares are always positive and, thus, we clearly see that &lt;span class=&#34;math inline&#34;&gt;\(CD_2\)&lt;/span&gt; may not be higher than 1 (this is less obvious, for &lt;span class=&#34;math inline&#34;&gt;\(CD_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;So far, so good; we have three different indices and three different symbols: &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(CD\)&lt;/span&gt;. But, in practice, things did not go that smoothly! The early statisticians, instead of proposing a brand new symbol for the coefficient of determination, made the choice of highlighting the connections with &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;. For example, Sokal and Rohlf, in their very famous biometry book, at page 570 (2nd. Edition) demonstrated that the coefficient of determination could be obtained as the square of the coefficient of correlation and, thus, they used the symbol &lt;span class=&#34;math inline&#34;&gt;\(r^2\)&lt;/span&gt;. Later, in the same book (pag. 660), these same authors demonstrated that the coefficient of multiple correlation &lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt; was equal to the positive square root of the &lt;strong&gt;coefficient of multiple determination&lt;/strong&gt;, for which they used the symbol &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Obviously, Sokal and Rohlf (and other authors of other textbooks) meant to say that the coefficient of determination, depending on the context, can be obtained either as the square of the correlation coefficient, or as the square of the multiple correlation coefficient. An uncareful interpretation led to the idea that the coefficient of determination can be indicated either as the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; or as the &lt;span class=&#34;math inline&#34;&gt;\(r^2\)&lt;/span&gt; and that the two symbols are always interchangeable. But, is this really true? No, it depends on the context.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;simple-linear-regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simple linear regression&lt;/h1&gt;
&lt;p&gt;Let’s have a look at the following example: we fit a simple linear regression model to a dataset and retrieve the coefficient of determination by using the &lt;code&gt;summary()&lt;/code&gt; method.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- 1:20
Y &amp;lt;- c(17.79, 18.81, 19.02, 14.14, 16.72, 16.05, 13.99, 13.26,
       12.48, 11.33, 11.07, 9.68, 9.19, 9.44, 9.75, 7.71, 6.47, 
       5.22, 4.55, 7.7)
mod &amp;lt;- lm(Y ~ X)
summary(mod)$r.squared # Coeff. determination with R
## [1] 0.9270622&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is very easy to see that &lt;span class=&#34;math inline&#34;&gt;\(R = |r|\)&lt;/span&gt; and it is also easy to demonstrate that &lt;span class=&#34;math inline&#34;&gt;\(r^2 = CD_1\)&lt;/span&gt; (look, e.g., at Sokal and Rohlf for a mathematical proof). Furthermore, due to the equality &lt;span class=&#34;math inline&#34;&gt;\(SS_{tot} = SS_{reg} + SS_{res}\)&lt;/span&gt;, it is also easy to see that &lt;span class=&#34;math inline&#34;&gt;\(CD_1 = CD_2\)&lt;/span&gt;. We are ready to draw our first conclusion.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;SSreg &amp;lt;- sum((predict(mod) - mean(Y))^2)
SStot &amp;lt;- sum((Y - mean(Y))^2)
SSres &amp;lt;- sum(residuals(mod)^2)
CD1 &amp;lt;- SSreg/SStot

# Alternative equation
CD2 &amp;lt;- 1 - SSres/SStot

CD1
## [1] 0.9270622
CD2
## [1] 0.9270622&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;r.coef &amp;lt;- cor(X, Y)
R.coef &amp;lt;- cor(Y, fitted(mod))

r.coef^2
## [1] 0.9270622
R.coef^2
## [1] 0.9270622&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;CONCLUSION 1. For simple linear regression, the coefficient of determination is always equal to &lt;span class=&#34;math inline&#34;&gt;\(R^2 = r^2\)&lt;/span&gt; and both symbols are acceptable (and correct).&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;polynomial-regression-and-multiple-regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Polynomial regression and multiple regression&lt;/h1&gt;
&lt;p&gt;Apart from simple linear regression, for all other types of linear models, provided that an intercept is fitted, it is not, in general, true that &lt;span class=&#34;math inline&#34;&gt;\(R = |r|\)&lt;/span&gt;, while it is, in general, true that that the coefficient of determination is equal to the squared coefficient of multiple correlation &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;. I’ll show a swift example with a polynomial regression in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# R and r coefficients
mod2 &amp;lt;- lm(Y ~ X + I(X^2))
cor.coef &amp;lt;- cor(X, Y)
R.coef &amp;lt;- cor(Y, fitted(mod2))

# R and r are not equal
cor.coef
## [1] -0.9628407
R.coef
## [1] 0.9652451
#
# The coefficient of determination is R2
R.coef^2
## [1] 0.931698
summary(mod2)$r.squared
## [1] 0.931698&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Furthermore, when we have several predictors (e.g., multiple regression), the correlation coefficient is not unique and we could calculate as many &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; values as there are predictors in the model.&lt;/p&gt;
&lt;p&gt;In the box below I show another example where I analysed the ‘mtcars’ dataset by using multiple regression; we see that &lt;span class=&#34;math inline&#34;&gt;\(R^2 = CD_1 = CD_2\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(mtcars)
mod &amp;lt;- lm(mpg ~ wt+disp+hp - 1, data = mtcars)  
summary(mod)$r.squared # Coeff. determination with R
## [1] 0.8328665&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Coefficient of determination by &amp;#39;hand-calculation&amp;#39;
SSreg &amp;lt;- sum((predict(mod) - mean(mtcars$mpg))^2)
SStot &amp;lt;- sum((mtcars$mpg - mean(mtcars$mpg))^2)
SSres &amp;lt;- sum(residuals(mod)^2)
SSreg/SStot
## [1] 0.9852479
1 - SSres/SStot
## [1] -1.084229&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# The R^2
R.coef &amp;lt;- cor(mtcars$mpg, fitted(mod))
R.coef^2
## [1] 0.002746157&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are now ready to draw our second conclusion.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CONCLUSION 2: with all linear models, apart from simple linear regression, the &lt;span class=&#34;math inline&#34;&gt;\(r^2\)&lt;/span&gt; symbol should not be used for the coefficient of determination, because this latter index IS NOT, in general, equal to the square of the coefficient of correlation. The &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; symbol is a much better choice.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-models-with-no-intercept&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Linear models with no intercept&lt;/h1&gt;
&lt;p&gt;The situation becomes much more complex for linear models with no intercept. For these models, the squared multiple correlation coefficient IS NOT ALWAYS equal to the proportion of variance accounted for. Let’s look at the following example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod2 &amp;lt;- lm(Y ~ - 1 + X)
summary(mod2)$r.squared # Proportion of variance accounted for
## [1] 0.4390065
R.coef &amp;lt;- cor(Y, fitted(mod2))
R.coef^2
## [1] 0.9270622&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other words, the coefficient of determination IS NOT ALWAYS the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;; however, the coefficient of determination can be calculated by using &lt;span class=&#34;math inline&#34;&gt;\(CD_1 = CD_2\)&lt;/span&gt;, provided that &lt;span class=&#34;math inline&#34;&gt;\(SS_{tot}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(SS_{reg}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(SS_{res}\)&lt;/span&gt; are obtained in a way that accounts for the missing intercept. Schabenberger and Pierce recommend the following equations and the symbols they use clearly reflect that those equations do not return the squared multiple correlation coefficient:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[R^2_{noint} = \frac{\sum_{i = 1}^{n}{\hat{y_i}^2}}{\sum_{i = 1}^{n}{y_i^2}} \quad \textrm{or} \quad R^{2*}_{noint} =1 - \frac{SS_{res}}{\sum_{i = 1}^{n}{y_i^2}}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;SSreg &amp;lt;- sum(fitted(mod2)^2)
SStot &amp;lt;- sum(Y^2)
SSres &amp;lt;- sum(residuals(mod2)^2)
SSreg/SStot # R^2 ok
## [1] 0.4390065
1 - SSres/SStot # R^2 ok
## [1] 0.4390065&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are ready for our third conclusion.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CONCLUSION 3: in the case of models with no intercept, neither the &lt;span class=&#34;math inline&#34;&gt;\(r^2\)&lt;/span&gt; nor the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; symbols should be used for the coefficient of determination. The proportion of variability accounted for by the model can be calculated by using a modified formula and should be reported by using a different symbol (e.g. &lt;span class=&#34;math inline&#34;&gt;\(R^2_{noint}\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(R^2_0\)&lt;/span&gt; or similar).&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;nonlinear-regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Nonlinear regression&lt;/h1&gt;
&lt;p&gt;With this class of models, we have two main problems:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;they do not have an intercept term, at least, not in the usual sense. Consequently, the square of the multiple coefficient of correlation does not represent the proportion of variance accounted for by the model;&lt;/li&gt;
&lt;li&gt;the equality &lt;span class=&#34;math inline&#34;&gt;\(SS_{tot} = SS_{reg} + SS_{res}\)&lt;/span&gt; may not hold and thus the equations for &lt;span class=&#34;math inline&#34;&gt;\(CD_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(CD_2\)&lt;/span&gt; may produce different results.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In contrast to linear models with no intercept, for nonlinear models we do not have any general modified formula that consistently returns the proportion of variance accounted for by the model (i.e., the coefficient of determination). However, Schabenberger and Pierce (2002) suggested that we can still use &lt;span class=&#34;math inline&#34;&gt;\(CD_2\)&lt;/span&gt; as a swift measure of goodness of fit, but they also proposed that we use the term ‘Pseudo-&lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;’ instead oft &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;. Why ‘Pseudo’?. For two good reasons:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;the ’Pseudo-&lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;’cannot exceed 1, but it may lower than 0;&lt;/li&gt;
&lt;li&gt;the ‘Pseudo-&lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;’ &lt;strong&gt;cannot be interpreted as the proportion of variance explained by the model&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In R, the ‘Pseudo-R&lt;sup&gt;2&lt;/sup&gt;’ can be calculated by using the &lt;code&gt;R2.nls()&lt;/code&gt; function in the ‘aomisc’ package, for nonlinear models fitted with both the &lt;code&gt;nls()&lt;/code&gt; and &lt;code&gt;drm()&lt;/code&gt; functions (this latter function is in the ‘drc’ package).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(aomisc)
X &amp;lt;- c(0.1, 5, 7, 22, 28, 39, 46, 200)
Y &amp;lt;- c(1, 13.66, 14.11, 14.43, 14.78, 14.86, 14.78, 14.91)

# nls fit
library(aomisc)
model &amp;lt;- nls(Y ~ SSmicmen(X, Vm, K))
R2nls(model)$PseudoR2
## [1] 0.9930399
# It is not the R2, in strict sense
R.coef &amp;lt;- cor(Y, fitted(model))
R.coef^2
## [1] 0.9957255
# It cannot be calculated by the usual expression!
SSreg &amp;lt;- sum(fitted(model) - mean(Y))
SStot &amp;lt;- sum( (Y - mean(Y))^2 )
SSreg/SStot
## [1] 0.003622004
# It can be calculated by using the alternative form
# that is no longer equivalent
SSres &amp;lt;- sum(residuals(model)^2)
1 - SSres/SStot
## [1] 0.9930399&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We may now come to our final conclusion.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CONCLUSION 4. With nonlinear models, we should never use either &lt;span class=&#34;math inline&#34;&gt;\(r^2\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; because they are both wrong. If we need a swift measure of goodness of fit, we can use the &lt;span class=&#34;math inline&#34;&gt;\(CD_2\)&lt;/span&gt; index above, but we should not name it as the &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt;, because, in general, it does not correspond to the coefficient of determination. We should better use the term Pseudo-R&lt;sup&gt;2&lt;/sup&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Hope this was useful; for those who are interested in the use of the Pseud-&lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; in nonlinear regression, I hav already published one post at this link: &lt;a href=&#34;https://www.statforbiology.com/2021/stat_nls_r2/&#34;&gt;https://www.statforbiology.com/2021/stat_nls_r2/&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thanks for reading and happy coding!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
&lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Schabenberger, O., Pierce, F.J., 2002. Contemporary statistical models for the plant and soil sciences. Taylor &amp;amp; Francis, CRC Press, Books.&lt;/li&gt;
&lt;li&gt;Sokal, R.R., Rohlf F.J., 1981. Biometry. Second Edition, W.H. Freeman and Company, USA.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Analysing seed germination and emergence data with R: a tutorial. Part 5</title>
      <link>http://localhost:6346/2021/stat_drcte_5-comparinglots/</link>
      <pubDate>Thu, 23 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2021/stat_drcte_5-comparinglots/</guid>
      <description>


&lt;p&gt;This is a follow-up post. If you are interested in other posts of this series, please go to: &lt;a href=&#34;https://www.statforbiology.com/tags/drcte/&#34;&gt;https://www.statforbiology.com/tags/drcte/&lt;/a&gt;. All these posts exapand on a paper that we have recently published in the Journal ‘Weed Science’; please follow &lt;a href=&#34;https://doi.org/10.1017/wsc.2022.8&#34;&gt;this link&lt;/a&gt; to the paper.&lt;/p&gt;
&lt;div id=&#34;comparing-germinationemergence-for-several-seed-lots&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Comparing germination/emergence for several seed lots&lt;/h1&gt;
&lt;p&gt;Very often, seed scientists need to compare the germination behavior of different seed populations, e.g., different plant species, or one single plant species submitted to different temperatures, light conditions, priming treatments and so on. How should such a comparison be performed? For example, if we have submitted several seed samples to different environmental conditions, how do we decide whether the germinative response is affected by those environmental conditions?&lt;/p&gt;
&lt;p&gt;If the case that we have replicates for all experimental treatments, e.g. several Petri dishes, one possible line of attack is to take a summary measure for each dish and use that for further analyses, in a two-steps fashion. For example, we could take the total number of germinated seeds (Pmax) in each dish and use the resulting values to parameterise some sort of ANOVA-like model and test the significance of all effects.&lt;/p&gt;
&lt;p&gt;This method of data analysis is known as ‘response feature analysis’ and it may be regarded as ‘very traditional’, in the sense that it is often found in literature; although it is not wrong, it is, undoubtedly, sub-optimal. Indeed, two seed lots submitted to different treatments may show the same total number of germinated seeds, but a different velocity or uniformity of germination. In other words, if we only consider, e.g., the Pmax, we can answer the question: “do the seed lots differ for their germination capability?”, but not the more general question: “are the seed lots different?”.&lt;/p&gt;
&lt;p&gt;In order to answer this latter question, we should consider the entire time-course of germination and not only one single summary statistic. &lt;strong&gt;In other words, we need a method to fit and compare several time-to-event curves.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-motivating-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A motivating example&lt;/h1&gt;
&lt;p&gt;Let’s take a practical approach and start from an example: a few years ago, some colleagues of mine studied the germination behavior of a plant species (&lt;em&gt;Verbascum arcturus&lt;/em&gt;), in different conditions. In detail, they considered the factorial combination of two storage periods (LONG and SHORT storage) and two temperature regimes (FIX: constant daily temperature of 20°C; ALT: alternating daily temperature regime, with 25°C during daytime and 15°C during night time, with a 12:12h photoperiod). If you are a seed scientist and are interested in this experiment, you’ll find detail in Catara &lt;em&gt;et al.&lt;/em&gt; (2016).&lt;/p&gt;
&lt;p&gt;If you are not a seed scientist, you may wonder why my colleagues made such an assay; well, there is evidence that, for some plant species, the germination ability improves over time, after seed maturation. Therefore, if we take seeds and store them for different periods of time, there might be an effect on their germination traits. Likewise, there is also evidence that germinations may be hindered if seed is not submitted to daily temperature fluctuations. For seed scientists, all these mechanisms are very important, as they permit to trigger the germinations when the environmental conditions are favorable for seedling survival.&lt;/p&gt;
&lt;p&gt;Let’s go back to our assay: the experimental design consisted of four experimental ‘combinations’ (LONG-FIX, LONG-ALT, SHORT-FIX and SHORT-ALT) and four replicates for each combination. One replicate consisted of a Petri dish, that is a small plastic box containing humid blotting paper, with 25 seeds of &lt;em&gt;V. arcturus&lt;/em&gt;. In all, there were 16 Petri dishes, which were put in climatic chambers with the appropriate conditions. During the assay, my colleagues made daily inspections: germinated seeds were counted and removed from the dishes. Inspections were made for 15 days, until no more germinations could be observed.&lt;/p&gt;
&lt;p&gt;The original dataset is available on a web repository: let’s load and have a look at it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;datasetOr &amp;lt;- read.csv(&amp;quot;https://www.casaonofri.it/_datasets/TempStorage.csv&amp;quot;,
                      header = T, check.names = F)
head(datasetOr)
##   Dish Storage Temp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
## 1    1     Low  Fix 0 0 0 0 0 0 0 0 3  4  6  0  1  0  3
## 2    2     Low  Fix 0 0 0 0 1 0 0 0 2  7  2  3  0  5  1
## 3    3     Low  Fix 0 0 0 0 1 0 0 1 3  5  2  4  0  1  3
## 4    4     Low  Fix 0 0 0 0 1 0 3 0 0  3  1  1  0  4  4
## 5    5    High  Fix 0 0 0 0 0 0 0 0 1  2  5  4  2  3  0
## 6    6    High  Fix 0 0 0 0 0 0 0 0 2  2  7  8  1  2  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have one row per Petri dish; the first three columns show, respectively, the dish number, storage and temperature conditions. The next 15 columns represent the inspection times (from 1 to 15) and contain the counts of germinated seeds. The research question is:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Is germination behavior affected by storage and temperature conditions?&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reshaping-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reshaping the data&lt;/h1&gt;
&lt;p&gt;The original dataset for our example is in a WIDE format and, as we have shown in a previous post (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_drcte_3-reshapingdata/&#34;&gt;go to this link&lt;/a&gt;), it is necessary to reshape it in LONG GROUPED format, by using the &lt;code&gt;melt_te()&lt;/code&gt; function in the ‘drcte’ package. As I said in my previous posts, this package can be installed from gitHub (see the code at: &lt;a href=&#34;https://www.statforbiology.com/2021/stat_drcte_1-intro/&#34;&gt;this link&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;melt_te()&lt;/code&gt; function needs to receive the columns storing the counts (‘count_cols = 4:18’), the columns storing the factor variables (‘treat_cols = c(“Dish”, “Storage”, “Temp”)’), a vector of monitoring times (‘monitimes = 1:15’) and a vector with the total number of seeds in each Petri dish (‘n.subjects = rep(25,16)’).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(drcte)
dataset &amp;lt;- melt_te(datasetOr, count_cols = 4:18, 
                   treat_cols = c(&amp;quot;Dish&amp;quot;, &amp;quot;Storage&amp;quot;, &amp;quot;Temp&amp;quot;), 
                   monitimes = 1:15, n.subjects = rep(25, 16))
head(dataset, 16)
##    Dish Storage Temp Units timeBef timeAf count nCum propCum
## 1     1     Low  Fix     1       0      1     0    0    0.00
## 2     1     Low  Fix     1       1      2     0    0    0.00
## 3     1     Low  Fix     1       2      3     0    0    0.00
## 4     1     Low  Fix     1       3      4     0    0    0.00
## 5     1     Low  Fix     1       4      5     0    0    0.00
## 6     1     Low  Fix     1       5      6     0    0    0.00
## 7     1     Low  Fix     1       6      7     0    0    0.00
## 8     1     Low  Fix     1       7      8     0    0    0.00
## 9     1     Low  Fix     1       8      9     3    3    0.12
## 10    1     Low  Fix     1       9     10     4    7    0.28
## 11    1     Low  Fix     1      10     11     6   13    0.52
## 12    1     Low  Fix     1      11     12     0   13    0.52
## 13    1     Low  Fix     1      12     13     1   14    0.56
## 14    1     Low  Fix     1      13     14     0   14    0.56
## 15    1     Low  Fix     1      14     15     3   17    0.68
## 16    1     Low  Fix     1      15    Inf     8   NA      NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the resulting data frame, the column ‘timeAf’ contains the time when the inspection was made and the column ‘count’ contains the number of germinated seeds (e.g. 9 seeds were counted at day 9). These seeds did not germinate exactly at day 9; they germinated within the interval between two inspections, that is between day 8 and day 9. The beginning of the interval is given as the variable ‘timeBef’. Apart from these three columns, we have the columns for the blocking factor (‘Dish’ and ‘Units’; this latter column is added by the R function, but it is not useful in this case) and for the treatment factors (‘Storage’ and ‘Temp’) plus two other additional columns (‘nCum’ and ‘propCum’), which we are not going to use for our analyses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-several-time-to-event-curves&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fitting several time-to-event curves&lt;/h1&gt;
&lt;p&gt;In this case, we have reasons to believe that the germination time-course can be described by using a parametric log-logistic time-to-event model, which can be estimated by using either the &lt;code&gt;drm()&lt;/code&gt; function in the ‘drc’ package (Ritz et al., 2019) or the &lt;code&gt;drmte()&lt;/code&gt; function in the ‘drcte’ package (Onofri et al., submitted). In both cases, we have to include the experimental factor (‘curveid’ argument), to specify that we want to fit a different curve for each combination of storage and temperature.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
dataset &amp;lt;- dataset %&amp;gt;% 
  mutate(across(1:3, .fns = factor))
mod1 &amp;lt;- drmte(count ~ timeBef + timeAf, fct = loglogistic(),
            data = dataset, 
            curveid = Temp:Storage)
summary(mod1)
## 
## Model fitted: Log-logistic distribution of event times
## 
## Robust estimation: no 
## 
## Parameter estimates:
## 
##             Estimate Std. Error t-value   p-value    
## b:Fix:Low   4.974317   0.819632  6.0690 1.287e-09 ***
## b:Fix:High 11.476618   1.254439  9.1488 &amp;lt; 2.2e-16 ***
## b:Alt:Low   7.854558   5.239783  1.4990    0.1339    
## b:Alt:High 10.600439   1.014061 10.4534 &amp;lt; 2.2e-16 ***
## d:Fix:Low   0.998474   0.150189  6.6481 2.968e-11 ***
## d:Fix:High  0.861711   0.038987 22.1027 &amp;lt; 2.2e-16 ***
## d:Alt:Low   1.405930   5.607529  0.2507    0.8020    
## d:Alt:High  0.948113   0.024298 39.0208 &amp;lt; 2.2e-16 ***
## e:Fix:Low  12.009974   0.987039 12.1677 &amp;lt; 2.2e-16 ***
## e:Fix:High 10.906963   0.190532 57.2447 &amp;lt; 2.2e-16 ***
## e:Alt:Low  17.014976  13.214403  1.2876    0.1979    
## e:Alt:High  9.585255   0.166937 57.4183 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a previous post I have described a log-logistic time-to-event model (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_drcte_4-time-to-eventcurves/&#34;&gt;see here&lt;/a&gt;), which has a sygmoidal shape, with the three parameters &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;. These parameters represent, respectively, the slope at inflection point, the higher asymptote (i.e. the maximum proportion of germinated seeds) and the median germination time. As we have four curves, we have a number of 12 estimated parameters.&lt;/p&gt;
&lt;p&gt;We see that the optimization routines returns an unreasonable value for the higher asymptote for one of the curves (&lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; = 1.40 with Alt:Low); it is unreasonable because the maximum proportion of germinated seeds may not exceed 1. Therefore, we should refit the model by adding a constraint (&lt;span class=&#34;math inline&#34;&gt;\(d \le 1\)&lt;/span&gt;) for all the four curves. We can do so by setting the ‘upperl’ argument to 1 for the 5&lt;sup&gt;th&lt;/sup&gt; through 8&lt;sup&gt;th&lt;/sup&gt; estimands.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod1 &amp;lt;- drmte(count ~ timeBef + timeAf, fct = loglogistic(),
            data = dataset, 
            curveid = Temp:Storage,
            upperl = c(NA, NA, NA, NA, 1, 1, 1, 1, NA, NA, NA, NA))
summary(mod1)
## 
## Model fitted: Log-logistic distribution of event times
## 
## Robust estimation: no 
## 
## Parameter estimates:
## 
##             Estimate Std. Error t-value   p-value    
## b:Fix:Low   4.979667   0.818408  6.0846 1.168e-09 ***
## b:Fix:High 11.471633   1.254025  9.1478 &amp;lt; 2.2e-16 ***
## b:Alt:Low   8.408185   2.232684  3.7660 0.0001659 ***
## b:Alt:High 10.605820   1.014524 10.4540 &amp;lt; 2.2e-16 ***
## d:Fix:Low   0.997283   0.149233  6.6827 2.345e-11 ***
## d:Fix:High  0.861709   0.038999 22.0955 &amp;lt; 2.2e-16 ***
## d:Alt:Low   1.000000   0.881619  1.1343 0.2566785    
## d:Alt:High  0.948132   0.024282 39.0467 &amp;lt; 2.2e-16 ***
## e:Fix:Low  12.004515   0.981265 12.2337 &amp;lt; 2.2e-16 ***
## e:Fix:High 10.907108   0.190612 57.2214 &amp;lt; 2.2e-16 ***
## e:Alt:Low  15.903084   2.872251  5.5368 3.080e-08 ***
## e:Alt:High  9.585293   0.166873 57.4407 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
 r
plot(mod1, log = &amp;quot;&amp;quot;, legendPos = c(6, 1), xlab = &amp;quot;Time&amp;quot;,
     ylab = &amp;quot;Cumulative probability of germination&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_drcte_5-ComparingLots_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From the graph we see that there are visible differences between the fitted curves (the legend considers the curves in alphabetical order, i.e. 1: Fix-Low, 2: Fix-High, 3: Alt-Low and 4: Alt-High). Now, the question is: could we say that those differences are only due to chance (null hypothesis)?&lt;/p&gt;
&lt;p&gt;In order to make such a test, we could compare the logarithm of the likelihood for the fitted model with the logarithm of the likelihood for a ‘reduced’ model, where all curves have been pooled into one common curve for all treatment levels. The higher the log-likelihood difference, the lowest the probability that the null is true (Likelihood Ratio Test; LRT).&lt;/p&gt;
&lt;p&gt;A LRT for parametric models can be done with the &lt;code&gt;compCDF()&lt;/code&gt; function in the ‘drcte’ package, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compCDF(mod1)
## 
## 
## Likelihood ratio test
## NULL: time-to-event curves are equal
## 
## Observed LR value:  202.8052
## Degrees of freedom:  9
## P-value:  8.551556e-39&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the LR value, that relates to the difference between the two log-likelihoods, is rather high and equal to 202; when the null is true, this LR value has an approximate Chi-square distribution; accordingly, we see that the P-level is very low and, thus, the null should be rejected.&lt;/p&gt;
&lt;p&gt;It general, the results of LRTs should be taken with care, particularly when the observed data are not independent from one another. Unfortunately, the lack of independence is an intrinsic characteristic of germination/emergence assays, where seeds are, most often, clustered within Petri dishes or other types of containers.&lt;/p&gt;
&lt;p&gt;In this example, we got a very low p-level, which leaves us rather confident that the difference between time-to-event curves is significant. More generally, instead of relying on a chi-square approximation, we should better use a grouped-permutation approach. This technique is based on the idea that, when the difference between curves is not significant, we should be able to freely permute the labels (treatment level) among Petri dishes (clustering units) and, consequently, build an empirical distribution for the LR statistic under the null (permutation distribution). The p-level is related to the proportion of LR values in the permutation distribution that are higher than the observed value (i.e.: 202.8)&lt;/p&gt;
&lt;p&gt;In the code below, we show how we can do this. The code is rather slow and, therefore, we should not use a very high number of permutation; the default is 199, that gives us a minimum p-value of 0.005. We see that we can confirm that the difference between curves is highly significant.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compCDF(mod1, type = &amp;quot;permutation&amp;quot;, units = dataset$Dishes)
## Likelihood ratio test (permutation based)
## NULL: time-to-event curves are equal
## 
## Observed LR value:  202.8052
## Degrees of freedom:  9
## Naive P-value:  8.551556e-39
## Permutation P-value (B = 199): 0.005&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;comparing-non-parametric-curves&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Comparing non-parametric curves&lt;/h1&gt;
&lt;p&gt;In the above example, we have decided to fit a parametric time-to-event model. However, in other situations, we might be interested in fitting a non-parametric time-to-event model (NPMLE; &lt;a href=&#34;https://www.statforbiology.com/2021/stat_drcte_4-time-to-eventcurves/&#34;&gt;see here&lt;/a&gt;) and compare the curves for different treatment levels. In practice, nothing changes with respect to the approach I have shown above: first of all, we fit the NPMLEs with the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modNP &amp;lt;- drmte(count ~ timeBef + timeAf, fct = NPMLE(),
            data = dataset, 
            curveid = Temp:Storage)
plot(modNP, log = &amp;quot;&amp;quot;, legendPos = c(6, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_drcte_5-ComparingLots_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Next, we compare the non-parametric curves, in the very same fashion as above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compCDF(modNP, units = dataset$Units)
## Exact Wilcoxon test (permutation form)
## NULL: time-to-event curves are equal
## 
##      level   n   Scores
## 1  Fix:Low 100   2.5350
## 2 Fix:High 100   6.4600
## 3  Alt:Low 100 -51.2275
## 4 Alt:High 100  42.2325
## 
## Observed T value:  44.56
## Permutation P-value (B = 199): 0.005&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obviously, with NPMLEs, a different test statistic is used in the background; the default one is the Wilcoxon rank sum score, although two types of log-rank scores are also implemented (Sun’s scores and Finkelstein’s scores; see Fay and Shaw 2010). Permutation based P-values are calculated and reported.&lt;/p&gt;
&lt;p&gt;The approach is exactly the same with Kernel Density Estimators (KDE; &lt;a href=&#34;https://www.statforbiology.com/2021/stat_drcte_4-time-to-eventcurves/&#34;&gt;see here&lt;/a&gt;). First we fit the four curves curves, by including the experimental factor as the ‘curveid’ argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modKD &amp;lt;- drmte(count ~ timeBef + timeAf, fct = KDE(),
            data = dataset, 
            curveid = Temp:Storage)
plot(modKD, log = &amp;quot;&amp;quot;, legendPos = c(6, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_drcte_5-ComparingLots_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Second, we compare those curves, by using the &lt;code&gt;compCDF()&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compCDF(modKD, units = dataset$Units)
## Permutation test based on a Cramer-von-Mises type distance (Barreiro-Ures et al., 2019)
## NULL HYPOTHESIS: time-to-event curves are equal
## 
##      level   n         D
## 1  Fix:Low 100 0.0579661
## 2 Fix:High 100 0.1347005
## 3  Alt:Low 100 4.1378209
## 4 Alt:High 100 3.8581487
## 
## Observed D value =  2.0472
## P value =  0.005&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, a Cramér‐von Mises type distance among curves is used (Barreiro-Ures et al., 2019), which, roughly speaking, is based on the integrated distance between the KDEs for the different groups and the pooled KDE for all groups. Permutation based P-values are also calculated and reported.&lt;/p&gt;
&lt;p&gt;We do hope that this post helps you test your hypotheses about seed germination/emergence in a reliable way.&lt;/p&gt;
&lt;p&gt;Thanks for reading and, please, accept my best:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.casaonofri.it/_Figures/greetings.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Send comments to: &lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;a href=&#34;https://twitter.com/onofriandreapg?ref_src=twsrc%5Etfw&#34; class=&#34;twitter-follow-button&#34; data-show-count=&#34;false&#34;&gt;Follow &lt;span class=&#34;citation&#34;&gt;@onofriandreapg&lt;/span&gt;&lt;/a&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Barreiro‐Ures, D, M Francisco‐Fernández, R Cao, BB Fraguela, R Doallo, JL González‐Andújar, M Reyes (2019) Analysis of interval‐grouped data in weed science: The binnednp Rcpp package. Ecol Evol 9:10903–10915&lt;/li&gt;
&lt;li&gt;Catara, S., Cristaudo, A., Gualtieri, A., Galesi, R., Impelluso, C., Onofri, A., 2016. Threshold temperatures for seed germination in nine species of Verbascum (Scrophulariaceae). Seed Science Research 26, 30–46.&lt;/li&gt;
&lt;li&gt;Fay, MP, PA Shaw (2010) Exact and Asymptotic Weighted Logrank Tests for Interval Censored Data: The interval R Package. Journal of Statistical Software 36:1–34&lt;/li&gt;
&lt;li&gt;Ritz, C., Jensen, S. M., Gerhard, D., Streibig, J. C. (2019) Dose-Response Analysis Using R CRC Press&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Why are derivatives important in life? A case-study with nonlinear regression</title>
      <link>http://localhost:6346/2021/stat_nls_speciesarea/</link>
      <pubDate>Wed, 09 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2021/stat_nls_speciesarea/</guid>
      <description>


&lt;p&gt;In general, undergraduate students in biology/ecology courses tend to consider the derivatives as a very abstract entity, with no real usefulness in the everyday life. In my work as a teacher, I have often tried to fight against such an attitude, by providing convincing examples on how we can use the derivatives to get a better understanding about the changes on a given system.&lt;/p&gt;
&lt;p&gt;In this post I’ll tell you about a recent situation where I was involved with derivatives. A few weeks ago, a colleague of mine wrote me to ask the following question (I’m changing it a little, to make it, hopefully, more interesting). He asked: &lt;em&gt;“I am using a power curve to model how the size of the sampling area affects species richness. How can I quantify my knowledge gain?”&lt;/em&gt;. This is an interesting question, indeed, although I feel I should provide you with some background information.&lt;/p&gt;
&lt;p&gt;Ecologists and botanists are very often involved with field surveys, aimed at determining the richness of plant species in a given territory. In most cases, such territories are too big to conduct exhaustive samplings and, therefore, it is necessary to resort to sampling a smaller area. The problem is that it is clearly recognised that the wider the sampled area, the higher the number of plant species that we encounter. So, what is the minimum sampling area to conduct a reliable survey?&lt;/p&gt;
&lt;p&gt;First of all, let’s try to model the species-are relationship. In some instances, this relationship can be described by using a power curve, that is coded as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a \, X^b\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is the number of species, &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is the sampling area, &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; are regression parameters. In order to understand such a relationship, we can take the ‘speciesArea’ dataset in the ‘aomisc’ package, that comes from Cristaudo et al. (2015). We can fit a power curve to this dataset, by using the &lt;code&gt;drm()&lt;/code&gt; function in the ‘drc’ package, together with the &lt;code&gt;DRC.powerCurve()&lt;/code&gt; self-starter in the ‘aomisc’ package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(aomisc)
data(speciesArea)

# drm fit
model &amp;lt;- drm(numSpecies ~ Area, fct = DRC.powerCurve(),
             data = speciesArea)
summary(model)
## 
## Model fitted: Power curve (Freundlich equation) (2 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## a:(Intercept) 4.348404   0.337197  12.896 3.917e-06 ***
## b:(Intercept) 0.329770   0.016723  19.719 2.155e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.9588598 (7 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is very useful to look at the resulting graph: we clearly see that the harder we work, the higher is our knowledge gain, in terms of plant richness. We may not be experts of plant surveys, but we should keep in mind that this may be really hard work, especially if we have to survey citrus groves under the sunshine of an Italian summer in Sicily! Therefore, we’d better optimise our effort and enlarge our sampling area only if this gives us a relevant payback.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../../../../../../../../../../_Figures/Stat_nls_SpeciesArea.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;In this respect, we see that every additional sampling effort gives a progressively lower payback; for example, an increase of 50 m&lt;sup&gt;2&lt;/sup&gt; in sampling area let us discover almost 16 new species when we begin our survey, while, when we have already sampled 200 m&lt;sup&gt;2&lt;/sup&gt;, a similar increase of sampling area let us discover only 2 additional plant species.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(model, newdata = data.frame(Area = c(50)))
## Prediction 
##    15.7979
 r
predict(model, newdata = data.frame(Area = c(250))) -
  predict(model, newdata = data.frame(Area = c(200))) 
## Prediction 
##    1.90552&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above argument motivates my colleague’s question: how do we quantify the knowledge gain in relation to the effort it costs? This is a typical situation where the first derivative of the power function comes in handy. You might remember from high school that the first derivative represents the slope of the line tangent to the function at any point on the graph. Its value represents the ratio between the knowledge gain and the increase in sampling effort and it is a very good measure of how well our additional effort is paid back in terms of knowledge gain. In other words, the higher the derivative, the higher our convenience to increase our sampling effort.&lt;/p&gt;
&lt;p&gt;But, how do we find a derivative? Years ago, it was a big relief for me to discover that R can efficiently help us with this task. In particular, we have two main functions available: &lt;code&gt;D()&lt;/code&gt; and &lt;code&gt;deriv()&lt;/code&gt;. The first one takes an expression as an argument and returns an expression, which can be evaluated to get the derivative value. For example, if we want to know the derivative value for a sampling area ranging from 1 to 100 m&lt;sup&gt;2&lt;/sup&gt;, we can use the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;powerCurve.der &amp;lt;- D(expression(a * X ^ b), &amp;quot;X&amp;quot;)
powerCurve.der
## a * (X^(b - 1) * b)
 r
a &amp;lt;- coef(model)[1]
b &amp;lt;- coef(model)[2]
X &amp;lt;- seq(1, 100, by = 10)
eval(powerCurve.der)
##  [1] 1.43397379 0.28745425 0.18635899 0.14354434 0.11901599 0.10281978
##  [7] 0.09119265 0.08237067 0.07540802 0.06974823&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It confirms what we already knew, that is our payback decreases while our effort increases; it is also interesting to note that the function &lt;code&gt;deparse()&lt;/code&gt; transforms the resulting expression into character strings, which we can pass to the &lt;code&gt;gnlht()&lt;/code&gt; function in the ‘aomisc’ package, to calculate standard errors for the estimated derivatives.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(deparse(powerCurve.der))
samplingAreas &amp;lt;- data.frame(X = seq(1, 100, by = 10))
pred &amp;lt;- gnlht(model, funList, const = samplingAreas,
              parameterNames = c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;))
pred
##                   Form  X   Estimate          SE  t-value      p-value
## 1  a * (X^(b - 1) * b)  1 1.43397379 0.046072499 31.12429 9.127464e-09
## 2  a * (X^(b - 1) * b) 11 0.28745425 0.007794058 36.88121 2.800293e-09
## 3  a * (X^(b - 1) * b) 21 0.18635899 0.006470755 28.80019 1.565496e-08
## 4  a * (X^(b - 1) * b) 31 0.14354434 0.005745031 24.98583 4.196158e-08
## 5  a * (X^(b - 1) * b) 41 0.11901599 0.005240148 22.71233 8.123235e-08
## 6  a * (X^(b - 1) * b) 51 0.10281978 0.004857404 21.16764 1.321660e-07
## 7  a * (X^(b - 1) * b) 61 0.09119265 0.004552575 20.03100 1.934121e-07
## 8  a * (X^(b - 1) * b) 71 0.08237067 0.004301572 19.14897 2.637561e-07
## 9  a * (X^(b - 1) * b) 81 0.07540802 0.004089788 18.43813 3.421480e-07
## 10 a * (X^(b - 1) * b) 91 0.06974823 0.003907714 17.84886 4.276907e-07&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;deriv()&lt;/code&gt; function is similar, but it takes a formula as an argument and, if we provide the &lt;code&gt;function.arg()&lt;/code&gt; argument, it returns a function, which is very handy for further processing. For example, we can use such function for plotting purposes, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;powerCurve.der2 &amp;lt;- deriv(~ a * X ^ b, &amp;quot;X&amp;quot;,
              function.arg = c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;X&amp;quot;))

curve(attr(powerCurve.der2(4.348, 0.32977, x), &amp;quot;gradient&amp;quot;), 
      from = 0, to = 250, ylab = &amp;quot;First derivative&amp;quot;, 
      xlab = &amp;quot;Sampling area&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_SpeciesArea_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, how do we use the above information to decide how big our sampling area should be? According to Muller-Dumboise and Ellenberg (1974), the minimal sampling area should be selected so that an increase of 10% in sampling area yields an increase of 10% in the number of sampled species. In other words, the minimal sampling area should be selected so that the sampling effort in relative terms is equal to the gain in knowledge, also in relative terms.&lt;/p&gt;
&lt;p&gt;Considering that the total sampling area was 256 m&lt;sup&gt;2&lt;/sup&gt; and the total number of species was 26, the minimum sampling area should correspond to the point on the graph where the first derivative is equal to 2.6/25.6 = 26/256 = 0.1015625. Graphically, we need to find a point along the x-axis where the tangent line to the graph is parallel to the line connecting the origin of axes and the point with co-ordinates &lt;span class=&#34;math inline&#34;&gt;\(x = 256\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y = 26\)&lt;/span&gt; (see the graph below).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_SpeciesArea_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In order to find this minimum sampling area, we solve the derivative function so that it returns a value of 0.1015625. We can do this by using the &lt;code&gt;uniroot()&lt;/code&gt; function as shown in the box below. The minimum sampling area is approximately equal to 52 m&lt;sup&gt;2&lt;/sup&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;solveFun &amp;lt;- function(x) attr(powerCurve.der2(4.348, 0.32977, x),
                             &amp;quot;gradient&amp;quot;) - 0.1015625
uniroot(solveFun, lower = 0, upper = 256)$root
## [1] 51.93759&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I hope that I have put another brick to convince you that derivatives can help us to solve some problems in the everyday life! If you have comments, please drop me a line.&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
&lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Cristaudo, A., Restuccia, A., Onofri, A., Giudice, V.L., Gresta, F., 2015. Species-area relationships and minimum area in citrus grove weed communities. Plant Biosystems 149, 337–345.&lt;/li&gt;
&lt;li&gt;Muller-Dumbois, D., Ellenberg, H., 1974. Community sampling: the relevè method., in: Aims and Methods of Vegetation Ecology. John Wiley &amp;amp; Sons, Inc., Species/Area curves, pp. 45–66.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Other useful functions for nonlinear regression: threshold models and all that</title>
      <link>http://localhost:6346/2021/stat_seedgermination_htt2step/</link>
      <pubDate>Sat, 01 May 2021 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2021/stat_seedgermination_htt2step/</guid>
      <description>


&lt;p&gt;In a recent post I presented several equations and just as many &lt;a href=&#34;https://www.statforbiology.com/2020/stat_nls_usefulfunctions/&#34;&gt;self-starting functions for nonlinear regression analyses in R&lt;/a&gt;. Today, I would like to build upon that post and present some further equations, relating to the so-called threshold models.&lt;/p&gt;
&lt;p&gt;But, … what are threshold models? In some instances, we need to describe relationships where the response variable changes abruptly, following a small change in the predictor. A typical threshold model looks like that in the Figure below, where we see three threshold levels:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X = 5.5\)&lt;/span&gt;: at this threshold, the response changes abruptly from ‘flat’ to linearly increasing;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X = 23.1\)&lt;/span&gt;: at this threshold, the response changes abruptly from linearly increasing to linearly decreasing;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(X = 37.2\)&lt;/span&gt;: at this threshold, the response changes abruptly from linearly decreasing to ‘flat’.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You may recognise a ‘broken-stick’ pattern, although threshold models can also be curvilinear, as we will see later.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Threshold models are very common in biology, where they can be successfully used to describe the daily (or hourly) progress towards a certain developmental stage, as influenced by the environmental conditions, mainly humidity and temperature. In this post I will show examples relating to seed germination, but the very same concepts also apply to the growth of plants and other organisms. In biology, these models are often known as thermal-time or hydro-time models.&lt;/p&gt;
&lt;p&gt;Considering seed germination, the response variable is the Germination Rate (GR), that is the reciprocal of germination time; for example, if a seed takes 7 days to accomplish the germination process, the GR is equal to &lt;span class=&#34;math inline&#34;&gt;\(1/7 = 0.143\)&lt;/span&gt; and it represents the fraction of germination that is accomplished in one day. The GR is a good measure of velocity: the higher the value the higher the speed. If we plot the GR against, e.g., temperature, we should very likely observe a response pattern as in Figure 1; the three thresholds are, respectively, the &lt;em&gt;base temperature&lt;/em&gt; (T_b_), the &lt;em&gt;optimal temperature&lt;/em&gt; (T_o_) and the &lt;em&gt;ceiling temperature&lt;/em&gt; (T_c_). If we look at the effect of soil humidity on GR, we should expect a response pattern with only one threshold, i.e. the &lt;em&gt;base water potential&lt;/em&gt; (e.g. the first half of Figure 1, up to the maximum response level).&lt;/p&gt;
&lt;p&gt;Although the equations I am going to introduce are commonly used in the seed science literature, I am confident that you might find them useful for a lot of other applications. For all those equations, I have built the related R functions, together with self-starting routines, which can be used for nonlinear regression analyses with the &lt;code&gt;drm()&lt;/code&gt; function in the ‘drc’ package (Ritz et al., 2019). The availability of self-starting routines will free you from the hassle of having to provide initial guess for model parameters. All these R functions are available within the ‘drcSeedGerm’ package (Onofri, 2019).&lt;/p&gt;
&lt;p&gt;The post is rather long, but you do not need to read it all; have a look at the graph below to spot the shape you are interested in and use the link to reach the relevant part in this web page. But, first of all, do not forget to install (if necessary) and load the ‘drcSeedGerm’ package, by using the code below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#installing package, if not yet available
# library(devtools)
# install_github(&amp;quot;onofriandreapg/drcSeedGerm&amp;quot;)

# loading package
library(drcSeedGerm)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;list-of-threshold-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;List of threshold models&lt;/h1&gt;
&lt;p&gt;In this post I will show the following threshold models:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#one-threshold-linear-model&#34;&gt;One-threshold linear&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#one-threshold-polynomial&#34;&gt;One-threshold polynomial - 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#one-threshold-polynomial&#34;&gt;One-threshold polynomial - 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#one-threshold-exponential&#34;&gt;One-threshold exponential&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#broken-stick-model&#34;&gt;Broken-stick model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#broken-curvilinear-model&#34;&gt;Broken-curvilinear model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#polynomial-model&#34;&gt;Polynomial model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exponential-switch-off-model&#34;&gt;Exponential switch-off model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hyperbolic-model&#34;&gt;Hyperbolic model&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;90%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;one-threshold-linear-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;One-threshold linear model&lt;/h1&gt;
&lt;p&gt;In some cases, we may need to model a process occurring only above a certain threshold level for the predictor variable. Models of this kind have been used to describe the effect of environmental humidity (&lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;, in MPa) on germination rate (Bradford, 2002):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\max\left[\Psi, \Psi_b\right] - \Psi_b}{\theta_H} \quad \quad \quad \quad (1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The parameter &lt;span class=&#34;math inline&#34;&gt;\(\Psi_b\)&lt;/span&gt; is the &lt;em&gt;base water potential&lt;/em&gt; (in MPa), representing the minimum level of humidity in the substrate to trigger the germination process. The other parameter &lt;span class=&#34;math inline&#34;&gt;\(\theta_H\)&lt;/span&gt; (in MPa day or MPa hour) is the hydro-time constant.&lt;/p&gt;
&lt;p&gt;A totally similar model has been used by Garcia-Huidobro et al (1982), to describe the effect of sub-optimal temperatures (T in °C) on the germination rate:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\max \left[T, T_b\right] - T_b}{\theta_T} \quad \quad \quad \quad (2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(T_b\)&lt;/span&gt; is the base temperature and &lt;span class=&#34;math inline&#34;&gt;\(\theta_T\)&lt;/span&gt; is the thermal time (in °C d).&lt;/p&gt;
&lt;p&gt;Both models can be fitted in R, by using the two functions &lt;code&gt;GRPsi.Lin()&lt;/code&gt; and &lt;code&gt;GRT.GH()&lt;/code&gt;; they are totally equivalent, apart from parameter names. In the example below I have fitted the second equation to a seed germination dataset; this type of data is usually heteroscedastic, thus, please note the use of a robust variance-covariance estimator for model parameters (Zeileis, 2006).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Tlev &amp;lt;- c(2, 5, 10, 15, 20, 25)
GR &amp;lt;- c(0, 0, 0.21, 0.49, 0.68, 0.86)
modGH &amp;lt;- drm(GR ~ Tlev, fct = GRT.GH())
library(sandwich); library(lmtest)
coeftest(modGH, vcov = sandwich)
## 
## t test of coefficients:
## 
##                    Estimate Std. Error t value  Pr(&amp;gt;|t|)    
## Tb:(Intercept)      4.77160    0.31993  14.915 0.0001177 ***
## ThetaT:(Intercept) 22.83118    0.62847  36.328 3.428e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
 r
plot(modGH, log=&amp;quot;&amp;quot;, xlim = c(0, 25), legendPos = c(5, 1.2),
     xlab = &amp;quot;Temperature (°C)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;one-threshold-polynomial&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;One threshold polynomial&lt;/h1&gt;
&lt;p&gt;In my experience, I have found that the relationship between GR and water potential in the substrate may, sometimes, be curvilinear. For these situations, I have successfully used the following equations:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\max\left[\Psi,\Psi_b\right]^2 - \Psi^2_b}{\theta_H} \quad \quad \quad \quad (3)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\left(\max\left[\Psi, \Psi_b\right] - \Psi_b \right)^2}{ \theta_H } \quad \quad \quad \quad (4)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Both models can be fitted in R, by using the two functions &lt;code&gt;GRPsi.Pol()&lt;/code&gt; and &lt;code&gt;GRPsi.Pol2()&lt;/code&gt;, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Observed data
Psi &amp;lt;- c(-2, -1.5, -1.2, -1, -0.8, -0.6, -0.4, -0.25,
         -0.12, -0.06, -0.03, 0)
GR &amp;lt;- c(0, 0, 0, 0, 0.0585, 0.094, 0.1231, 0.1351,
        0.1418, 0.1453, 0.1458, 0.1459)
Psi2 &amp;lt;- c(-0.5, -0.6, -0.7, -0.8, -0.9, -1, -1.1, -1.2,
          -1.5)
GR2 &amp;lt;- c(1.4018, 1.0071, 0.5614, 0.3546, 0.2293, 0, 0,
         0, 0)


modHT &amp;lt;- drm(GR ~ Psi, fct = GRPsiPol())
modHT2 &amp;lt;- drm(GR2 ~ Psi2, fct = GRPsiPol2())
par(mfrow = c(1,2))

plot(modHT, log=&amp;quot;&amp;quot;, legendPos = c(-1.5, 0.15), 
     ylim = c(0, 0.20), xlab = &amp;quot;Water potential (MPa)&amp;quot;)
plot(modHT2, log=&amp;quot;&amp;quot;, legendPos=c(-1.3, 1), 
     xlab = &amp;quot;Water potential (MPa)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;one-threshold-exponential&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;One threshold: exponential&lt;/h1&gt;
&lt;p&gt;All the previous models tend to go up to infinity when the predictor value (temperature or water potential) goes to infinity. In some instances, we may need an asymptotic model, for example, to describe the oxygen uptake kinetics during a walk test (see Baty et al., 2014, although their threshold model is more complex) or to describe the response of the maximum proportion of germinated seeds to soil humidity (Onofri et al., 2018).&lt;/p&gt;
&lt;p&gt;In practice, we could use a shifted exponential model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \pi = G \, \left[ 1 - exp \left( \frac{ \max\left[\Psi, \Psi_b\right] - \Psi_b }{\sigma} \right) \right]  \quad \quad \quad \quad (5)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; is the proportion of germinated seeds, &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; is the fraction of non-germinable seeds (e.g., dormant seeds) and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; describes how quickly the population of seeds responds to increased humidity in the substrate.&lt;/p&gt;
&lt;p&gt;If we reverse the sign of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; in Eq. 5, we obtain a decreasing trend, which might be useful to describe the effect of super-optimal temperatures on the proportion of germinated seeds, going down to 0 at the ceiling temperature threshold.&lt;/p&gt;
&lt;p&gt;Both equations can be fitted using the self-starters &lt;code&gt;PmaxPsi1()&lt;/code&gt; and &lt;code&gt;PmaxT1()&lt;/code&gt;. The two R functions are totally equal, apart from parameters names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;par(mfrow = c(1,2))
# Pmax vs Psi
Psi &amp;lt;- seq(-2.2, 0, by = 0.2)
Pmax &amp;lt;- c(0, 0, 0.076, 0.413, 0.514, 0.643, 0.712,
          0.832, 0.865, 0.849, 0.89, 0.90)
mod &amp;lt;- drm(Pmax ~ Psi, fct = PmaxPsi1())
plot(mod, log = &amp;quot;&amp;quot;, xlab = &amp;quot;Water potential (MPa)&amp;quot;, 
     ylab = &amp;quot;Proportion of germinating seeds&amp;quot;)

# Pmax vs temperture
Tval &amp;lt;- c(0, 2.5, 5, 7.5, 10, 12.5, 15, 17.5,
          20, 22.5, 25, 27.5, 30, 32.5, 35)
Pmax2 &amp;lt;- c(0.79, 0.81, 0.807, 0.776, 0.83,
           0.73, 0.744, 0.73, 0.828, 0.818,
           0.805, 0.706, 0.41, 0.002, 0)
mod2 &amp;lt;- drm(Pmax2 ~ Tval, fct = PmaxT1())
plot(mod2, log = &amp;quot;&amp;quot;, xlab = &amp;quot;Temperature (°C)&amp;quot;, 
     ylab = &amp;quot;Proportion of germinating seeds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;broken-stick-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;‘Broken-stick’ model&lt;/h1&gt;
&lt;p&gt;A broken-stick trend, as the one depicted in the Figure 1 was used by Alvarado and Bradford (2002) to model the effect of temperature on the germination rate. The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\min \left[T,T_o \right] - T_b}{\theta_{T}} \, \left\{ 1 - \frac {\min \left[\max \left[ T,T_o \right], T_c \right] - T_o}{T_c - T_o} \right\} \quad \quad (6)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Base, optimal and ceiling temperatures (respectively &lt;span class=&#34;math inline&#34;&gt;\(T_b\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(T_o\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(T_c\)&lt;/span&gt;) are included as parameters, together with the hydro-thermal time parameter (&lt;span class=&#34;math inline&#34;&gt;\(\theta_T\)&lt;/span&gt;). Equation 6 can be easily fitted with the &lt;code&gt;GRT.BS()&lt;/code&gt; function in the ‘drcSeedGerm’ package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Tval &amp;lt;- c(2, 5, 10, 15, 20, 25, 30, 35, 40)
GR &amp;lt;- c(0, 0, 0.209, 0.435, 0.759, 0.821, 0.417, 0.145, 0)

modBS &amp;lt;- drm(GR ~ Tval, fct = GRT.BS())
plot(modBS, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
     legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coeftest(modBS, vcov = sandwich)
## 
## t test of coefficients:
## 
##                     Estimate Std. Error t value  Pr(&amp;gt;|t|)    
## k:(Intercept)       0.073515   0.002892  25.420 1.759e-06 ***
## Tb:(Intercept)      6.496708   0.431500  15.056 2.341e-05 ***
## To:(Intercept)     23.216552   0.294743  78.769 6.249e-09 ***
## ThetaT:(Intercept) 18.182167   0.763361  23.819 2.430e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;broken-curvilinear-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Broken-curvilinear model&lt;/h1&gt;
&lt;p&gt;Broken-stick trends may not be reasonable for biological processes, which might be better described by curvilinear equations. Rowse and Finch-Savage (2003) proposed another equation with two components: the first one depicts a linear increase of the GR value with temperature, which is off-set by the second component, starting from &lt;span class=&#34;math inline&#34;&gt;\(T = T_d\)&lt;/span&gt;, which is close to (but not coincident with) &lt;span class=&#34;math inline&#34;&gt;\(T_o\)&lt;/span&gt;. The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{ \max \left[ T, T_b \right] - T_b}{\theta_{T}} \left\{ 1 - \frac{\min \left[ \max \left[T,T_d\right], T_o \right] - T_d}{T_c - T_d}  \right\} \quad \quad (7)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The optimal temperature can be derived as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ T_o = \frac{1 + kT_b + kT_d}{2k}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ k = \frac{1}{T_c - T_d}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For this equation, you will find the &lt;code&gt;GRT.RFb()&lt;/code&gt; self-starter in the ‘drcSeedGerm’ package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modRF &amp;lt;- drm(GR ~ Tval, fct = GRT.RFb())
plot(modRF, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
     legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;polynomial-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Polynomial model&lt;/h1&gt;
&lt;p&gt;According to Mesgaran et al (2017), the negative and positive effects of temperature coexist for all temperatures above &lt;span class=&#34;math inline&#34;&gt;\(T_b\)&lt;/span&gt;. Their proposed equation can be parameterised as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR = \frac{\max \left[ T, T_b \right] - T_b}{\theta_{T}} \left[ 1 - \frac{\min \left[ T, T_c \right] - T_b}{T_c - T_b}  \right] \quad \quad \quad \quad (8)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It is easy to see that the GR value is a second-order polynomial function of &lt;span class=&#34;math inline&#34;&gt;\(T - T_b\)&lt;/span&gt; and, therefore, the curve is symmetric around the optimal temperature value, which can be derived as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[T_o = \frac{T_c - T_b}{2} + T_b\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For this equation, the self-starting function is &lt;code&gt;GRT.M()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modM &amp;lt;- drm(GR ~ Tval, fct = GRT.Mb())
plot(modM, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
     legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exponential-switch-off-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Exponential switch-off model&lt;/h1&gt;
&lt;p&gt;Equations 6 to 8 use a product, wherein the first term represents the accumulation of thermal time and the second term may be seen as a switch-off term that is 1 either when &lt;span class=&#34;math inline&#34;&gt;\(T &amp;lt; T_o\)&lt;/span&gt; (Equation 6) or &lt;span class=&#34;math inline&#34;&gt;\(T &amp;lt; T_d\)&lt;/span&gt; (Equation 7) or &lt;span class=&#34;math inline&#34;&gt;\(T = T_b\)&lt;/span&gt; (Equation 8) and decreases progressively as temperature increases. In all the above equations, the switch-off term is linear, although we can use other types of switch-off terms, to obtain more flexible models. One possibility is to use an exponential switch-off term, as in the equation below:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ GR = \frac{\max \left[T, T_b \right] - T_b}{\theta_T} \left\{ \frac{1 - \exp \left[ k (\min \left[T, T_c \right] - T_c) \right]}{1 - \exp \left[ k (T_b - T_c) \right]}  \right\} \quad \quad \quad (9)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the switch-off parameter: the lower the value, the higher the negative effect of temperature at super-optimal levels. The response of GR to temperature is highly asymmetric with a slow increase below &lt;span class=&#34;math inline&#34;&gt;\(T_o\)&lt;/span&gt; and a steep drop afterwards.&lt;/p&gt;
&lt;p&gt;I have successfully used this model in Catara et al (2016) and Masin et al (2017). The self-starting function in R is &lt;code&gt;GRT.Exb()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Tval &amp;lt;- c(2, 5, 10, 15, 20, 25, 30, 35, 40)
GR &amp;lt;- c(0, 0, 0.209, 0.435, 0.759, 0.821, 0.917, 0.445, 0)

modExb &amp;lt;- drm(GR ~ Tval, fct = GRT.Exb())
summary(modExb)
## 
## Model fitted: Exponential effect of temperature on GR50 (Masin et al., 2017)
## 
## Parameter estimates:
## 
##                     Estimate Std. Error t-value   p-value    
## k:(Intercept)       0.181022   0.060207  3.0067  0.029870 *  
## Tb:(Intercept)      5.999610   1.202555  4.9891  0.004143 ** 
## Tc:(Intercept)     36.937370   0.501322 73.6800 8.724e-09 ***
## ThetaT:(Intercept) 19.159270   2.907228  6.5902  0.001208 ** 
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.04049371 (5 degrees of freedom)
 r
plot(modExb, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
     legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hyperbolic-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Hyperbolic model&lt;/h1&gt;
&lt;p&gt;The following model was derived by the simple yield loss function devised by Kropff and van Laar (1993). It is very flexible, as it may depict different types of relationships between temperature and base water potential, according to the value taken by the parameter &lt;span class=&#34;math inline&#34;&gt;\(q\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GR(g, T) = \frac{\max \left[T, T_b\right] - T_b}{\theta_T} \left( 1 - \frac{q \frac{\min \left[T, T_c\right] -T_b}{T_c- T_b} }{1 + (q-1) \frac{T-T_b}{T_c- T_b}}  \right) \quad \quad \quad (10)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In R, this model can be fitted by using the self-starter &lt;code&gt;GRT.YL()&lt;/code&gt; and we see that, with our dataset, the fit is very much like that of the exponential switch-off function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modYL &amp;lt;- drm(GR ~ Tval, fct = GRT.YL())
plot(modYL, log=&amp;quot;&amp;quot;, xlim = c(0, 40), ylim=c(0,1.2),
     legendPos = c(5, 1.0), xlab = &amp;quot;Temperature (°C)&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HTT2step_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-warning-message&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A warning message&lt;/h1&gt;
&lt;p&gt;When we collect data about the response of germination rates to temperature and use them to parameterise nonlinear regression models by using nonlinear least squares, the basic assumption of homoscedasticity is rarely tenable. &lt;strong&gt;We should not forget this!&lt;/strong&gt; in the above example I used a robust variance-covariance sandwich estimator, although other techniques can be successfully used to deal with this problem.&lt;/p&gt;
&lt;p&gt;Thanks for reading and happy coding!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
&lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Alvarado, V., Bradford, K.J., 2002. A hydrothermal time model explains the cardinal temperatures for seed germination. Plant, Cell and Environment 25, 1061–1069.&lt;/li&gt;
&lt;li&gt;Baty, F., Ritz, C., Charles, S., Brutsche, M., Flandrois, J. P., Delignette-Muller, M.-L., 2014. A toolbox for nonlinear regression in R: the package nlstools. Journal of Statistical Software, 65, 5, 1-21.&lt;/li&gt;
&lt;li&gt;Bradford, K.J., 2002. Applications of hydrothermal time to quantifying and modelling seed germination and dormancy. Weed Science 50, 248–260.&lt;/li&gt;
&lt;li&gt;Catara, S., Cristaudo, A., Gualtieri, A., Galesi, R., Impelluso, C., Onofri, A., 2016. Threshold temperatures for seed germination in nine species of Verbascum (Scrophulariaceae). Seed Science Research 26, 30–46.&lt;/li&gt;
&lt;li&gt;Garcia-Huidobro, J., Monteith, J.L., Squire, R., 1982. Time, temperature and germination of pearl millet (&lt;em&gt;Pennisetum typhoides&lt;/em&gt; S &amp;amp; H.). 1. Constant temperatures. Journal of Experimental Botany 33, 288–296.&lt;/li&gt;
&lt;li&gt;Kropff, M.J., van Laar, H.H. 1993. Modelling crop-weed interactions. CAB International, Books.&lt;/li&gt;
&lt;li&gt;Masin, R., Onofri, A., Gasparini, V., Zanin, G., 2017. Can alternating temperatures be used to estimate base temperature for seed germination? Weed Research 57, 390–398.&lt;/li&gt;
&lt;li&gt;Onofri A., 2019. DrcSeedGerm: Statistical approaches for data analyses in seed germination assays. R package version 0.98. &lt;a href=&#34;https://www.statforbiology.com&#34; class=&#34;uri&#34;&gt;https://www.statforbiology.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Onofri, A., Benincasa, P., Mesgaran, M.B., Ritz, C., 2018. Hydrothermal-time-to-event models for seed germination. European Journal of Agronomy 101, 129–139.&lt;/li&gt;
&lt;li&gt;Ritz, C., Jensen, S. M., Gerhard, D., Streibig, J. C., 2019. Dose-Response Analysis Using R. CRC Press&lt;/li&gt;
&lt;li&gt;Rowse, H.R., Finch-Savage, W.E., 2003. Hydrothermal threshold models can describe the germination response of carrot (Daucus carota) and onion (Allium cepa) seed populations across both sub- and supra-optimal temperatures. New Phytologist 158, 101–108.&lt;/li&gt;
&lt;li&gt;Zeileis, A., 2006. Object-oriented computation of sandwich estimators. Journal of Statistical Software, 16, 9, 1-16.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The R-squared and nonlinear regression: a difficult marriage?</title>
      <link>http://localhost:6346/2021/stat_nls_r2/</link>
      <pubDate>Thu, 25 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2021/stat_nls_r2/</guid>
      <description>


&lt;p&gt;Making sure that a fitted model gives a good description of the observed data is a fundamental step of every nonlinear regression analysis. To this aim we can (and should) use several techniques, either graphical or based on formal hypothesis testing methods. However, in the end, I must admit that I often feel the need of displaying a simple index, based on a single and largely understood value, that reassures the readers about the goodness of fit of my models.&lt;/p&gt;
&lt;p&gt;In linear regression, we already have such an index, that is known as the R&lt;sup&gt;2&lt;/sup&gt; or the &lt;em&gt;coefficient of determination&lt;/em&gt;. In words, this index represents the proportion of variance in the dependent variable that is explained by the regression effects. It ranges from 0 to 1 and, within this interval, the highest the value, the best the fit. The expression is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = \frac{SS_{reg}}{SS_{tot}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and it represents the ratio between the regression sum of squares (&lt;span class=&#34;math inline&#34;&gt;\(SS_{reg}\)&lt;/span&gt;) and total sum of squares (&lt;span class=&#34;math inline&#34;&gt;\(SS_{tot}\)&lt;/span&gt;), which is equal to the proportion of explained variance when we consider the population variance, that is obtained by dividing both &lt;span class=&#34;math inline&#34;&gt;\(SS_{reg}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(SS_{tot}\)&lt;/span&gt; by the number of observations (and not by the number of degrees of freedom). In the above expression, it is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[SS_{reg} = \sum_{i = 1}^{n}{\left(\hat{y_i} - \bar{y} \right)^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[SS_{tot} = \sum_{i = 1}^{n}{\left(y_i - \bar{y} \right)^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If we also consider the squared residuals from the regression line, we can also define the residual sum of squares as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[SS_{res} = \sum_{i = 1}^{n}{\left(y_i - \hat{y_i} \right)^2}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where: &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; is the i-th observation, &lt;span class=&#34;math inline&#34;&gt;\(\hat{y_i}\)&lt;/span&gt; is the i-th fitted value and &lt;span class=&#34;math inline&#34;&gt;\(\bar{y}\)&lt;/span&gt; is the overall mean.&lt;/p&gt;
&lt;p&gt;In all linear models with an intercept term, the following equality holds:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[SS_{tot} = SS_{reg} + SS_{res}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Therefore, it is always &lt;span class=&#34;math inline&#34;&gt;\(SS_{reg} \leq SS_{tot}\)&lt;/span&gt;, which implies that the R&lt;sup&gt;2&lt;/sup&gt; value may never be higher than 1 or lower than 0. Furthermore, we can write the alternative (and equivalent) definition:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ R^2 = 1 - \frac{SS_{res}}{SS_{tot}}\]&lt;/span&gt;
Now, the question is:&lt;/p&gt;
&lt;div id=&#34;can-we-use-the-r-squared-in-nonlinear-regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Can we use the R-squared in nonlinear regression?&lt;/h1&gt;
&lt;p&gt;Basically, we have two problems:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;nonlinear models do not have an intercept term, at least, not in the usual sense;&lt;/li&gt;
&lt;li&gt;the equality &lt;span class=&#34;math inline&#34;&gt;\(SS_{tot} = SS_{reg} + SS_{res}\)&lt;/span&gt; may not hold.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For these reasons, most authors advocate against the use of the R&lt;sup&gt;2&lt;/sup&gt; in nonlinear regression analysis and recommend alternative measures, such as the Mean Squared Error (MSE; see Ratkowsky, 1990) or the AIC and BIC (see Spiess and Neumeyer, 2010). I would argue that the R&lt;sup&gt;2&lt;/sup&gt; may have a superior intuitive appeal as far as it is bound to 1 for a perfectly fitting model; with such a constraint, we can immediately see how good is the fit of our model.&lt;/p&gt;
&lt;p&gt;Schabenberger and Pierce (2002) recommend the following statistic, that is similar to the R&lt;sup&gt;2&lt;/sup&gt; for linear models:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \textrm{Pseudo-}R^2 = 1 - \frac{SS_{res}}{SS_{tot}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Why is it a ‘Pseudo-R&lt;sup&gt;2&lt;/sup&gt;’?. In contrast to what happens with linear models, this statistic:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;cannot exceed 1, but it may lower than 0;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;it cannot be interpreted as the proportion of variance explained by the model&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Bearing these two limitations in mind, there is no reason why we should not use such a goodness-of-fit measure with nonlinear regression. In this line, the &lt;code&gt;R2.nls()&lt;/code&gt; function in the ‘aomisc’ package can be used to retrieve the R&lt;sup&gt;2&lt;/sup&gt; and Pseudo-R&lt;sup&gt;2&lt;/sup&gt; values from a nonlinear model fitted with the &lt;code&gt;nls()&lt;/code&gt; and &lt;code&gt;drm()&lt;/code&gt; functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(aomisc)
X &amp;lt;- c(0.1, 5, 7, 22, 28, 39, 46, 200)
Y &amp;lt;- c(1, 13.66, 14.11, 14.43, 14.78, 14.86, 14.78, 14.91)

#drm fit
model &amp;lt;- drm(Y ~ X, fct = MM.2())
R2nls(model)$PseudoR2
## [1] 0.9930399
 r
#
# nls fit
model2 &amp;lt;- nls(Y ~ SSmicmen(X, Vm, K))
R2nls(model)$PseudoR2
## [1] 0.9930399&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Undoubtedly, the Pseudo-R&lt;sup&gt;2&lt;/sup&gt; gives, at first glance, a good feel for the quality of our regressions; but, please, do not abuse it. In particular, please, remember that a negative value might indicate a big problem with the fitted model. Above all, remember that the Pseudo-R&lt;sup&gt;2&lt;/sup&gt;, similarly to the R&lt;sup&gt;2&lt;/sup&gt; in multiple linear regression, should never be used as the basis to select and compare alternative regression model. Other statistics should be used to this aim.&lt;/p&gt;
&lt;p&gt;Thanks for reading and happy coding!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
&lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Ratkowsky, D.A., 1990. Handbook of nonlinear regression models. Marcel Dekker Inc., Books.&lt;/li&gt;
&lt;li&gt;Schabenberger, O., Pierce, F.J., 2002. Contemporary statistical models for the plant and soil sciences. Taylor &amp;amp; Francis, CRC Press, Books.&lt;/li&gt;
&lt;li&gt;Spiess, A. N., &amp;amp; Neumeyer, N., 2010. An evaluation of &lt;span class=&#34;math inline&#34;&gt;\(R^2\)&lt;/span&gt; as an inadequate measure for nonlinear models in pharmacological and biochemical research: a Monte Carlo approach. BMC Pharmacology, 10, 6.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Pairwise comparisons in nonlinear regression</title>
      <link>http://localhost:6346/2021/stat_nls_paircomp/</link>
      <pubDate>Tue, 19 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2021/stat_nls_paircomp/</guid>
      <description>


&lt;p&gt;Pairwise comparisons are one of the most debated topic in agricultural research: they are very often used and, sometimes, abused, in literature. I have nothing against the appropriate use of this very useful technique and, for those who are interested, some colleagues and I have given a bunch of (hopefully) useful suggestions in a paper, a few years ago (&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/10.1111/j.1365-3180.2009.00758.x&#34;&gt;follow this link here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Pairwise comparisons usually follow the application of some sort of linear or generalised linear model; in this setting, the ‘emmeans’ package (Lenth, 2020) is very handy, as it uses a very logical approach. However, we can find ourselves in the need of making pairwise comparisons between the elements of a vector, which does not came as the result of linear model fitting.&lt;/p&gt;
&lt;p&gt;For example, we may happen to have an old table of means with standard errors and have lost the original raw data. Or, we may happen to have a vector of parameters from a nonlinear regression model, fitted with the &lt;code&gt;nls()&lt;/code&gt; function. How do we make pairwise comparisons? Experienced users can make profit of the &lt;code&gt;glht()&lt;/code&gt; function in the ‘multcomp’ package, although this is not immediate and, at least for me, it takes always some attempts to recall the exact syntax.&lt;/p&gt;
&lt;p&gt;Therefore, I have built the &lt;code&gt;pairComp()&lt;/code&gt; wrapper, which is available within the ‘aomisc’ package, the accompanying package for this website. Let’s see how this function works by using a typical example.&lt;/p&gt;
&lt;div id=&#34;a-case-study&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A case-study&lt;/h1&gt;
&lt;p&gt;This is a real-life example, taken from a research published by Vischetti et al. in 1996 (we have used this example in other posts, before). That research considered three herbicides for weed control in sugar beet, i.e. metamitron (M), phenmedipham (P) and chloridazon (C). Four soil samples were contaminated, respectively with: (i) M alone, (ii) M + P (iii) M + C and (iv) M + P + C. The aim was to assess whether the degradation speed of metamitron in soil depended on the presence of co-applied herbicides. To reach this aim, the soil samples were incubated at 20°C and sub-samples were taken in different times after the beginning of the experiment. The concentration of metamitron in those sub-samples was measured by HPLC analyses, performed in triplicate. The resulting dataset is available within the ‘aomisc’ package.&lt;/p&gt;
&lt;p&gt;In the box below. we install the ‘aomisc’ package from gitHub (if necessary), load it and load the ‘metamitron’ dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools)
# install_github(&amp;quot;OnofriAndreaPG/aomisc&amp;quot;)
library(aomisc)
data(metamitron)
head(metamitron)
##   Time Herbicide   Conc
## 1    0         M  92.00
## 2    0         M 118.64
## 3    0         M  89.58
## 4    7         M  59.32
## 5    7         M  62.95
## 6    7         M  62.95
 r
#...
#...
tail(metamitron)
##    Time Herbicide  Conc
## 91   55       MPC 35.75
## 92   55       MPC 37.83
## 93   55       MPC 27.41
## 94   67       MPC 23.38
## 95   67       MPC 28.41
## 96   67       MPC 18.92&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first step we take is to fit a first-order degradation model, as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[C_{t, h} = A_h \, \exp \left(-k_h  \, t \right)\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(C\)&lt;/span&gt; is the concentration at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; for metamitron in the &lt;span class=&#34;math inline&#34;&gt;\(h^{th}\)&lt;/span&gt; combination (M alone, M + P, M + C and M + P + C), &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is the initial concentration for the metamitron in the &lt;span class=&#34;math inline&#34;&gt;\(h^{th}\)&lt;/span&gt; combination, &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; is the degradation rate for metamitron in the &lt;span class=&#34;math inline&#34;&gt;\(h^{th}\)&lt;/span&gt; combination. This model is nonlinear and, therefore, we can use the &lt;code&gt;nls()&lt;/code&gt; function for nonlinear least squares regression. The code is given below: please, note that the two parameters are followed by the name of the factor variable in square brackets (i.e.: A[Herbicide] and k[Herbicide]). This is necessary, to fit a different parameter value for each level of the ‘Herbicide’ factor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Fit nls grouped model
modNlin &amp;lt;- nls(Conc ~ A[Herbicide] * exp(-k[Herbicide] * Time), 
               start=list(A=rep(100, 4), k=rep(0.06, 4)), 
               data=metamitron)
summary(modNlin)
## 
## Formula: Conc ~ A[Herbicide] * exp(-k[Herbicide] * Time)
## 
## Parameters:
##     Estimate Std. Error t value Pr(&amp;gt;|t|)    
## A1 9.483e+01  4.796e+00   19.77   &amp;lt;2e-16 ***
## A2 1.021e+02  4.316e+00   23.65   &amp;lt;2e-16 ***
## A3 9.959e+01  4.463e+00   22.31   &amp;lt;2e-16 ***
## A4 1.116e+02  4.184e+00   26.68   &amp;lt;2e-16 ***
## k1 4.260e-02  4.128e-03   10.32   &amp;lt;2e-16 ***
## k2 2.574e-02  2.285e-03   11.26   &amp;lt;2e-16 ***
## k3 3.034e-02  2.733e-03   11.10   &amp;lt;2e-16 ***
## k4 2.186e-02  1.822e-03   12.00   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 9.701 on 88 degrees of freedom
## 
## Number of iterations to convergence: 5 
## Achieved convergence tolerance: 7.149e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can retrieve the degradation rates for the four herbicides (&lt;em&gt;k1&lt;/em&gt;, &lt;em&gt;k2&lt;/em&gt;, &lt;em&gt;k3&lt;/em&gt; and &lt;em&gt;k4&lt;/em&gt;) together with standard errors and load them into two vectors, as shown in the box below. In order to make pairwise comparisons, we also need to retrieve an estimate of the residual degrees of freedom, which we can also extract from the model fit object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tab &amp;lt;- summary(modNlin)
dRates &amp;lt;- tab$coef[5:8,1]
SEs &amp;lt;- tab$coef[5:8,2]
dfr = tab$df[2]
dRates
##         k1         k2         k3         k4 
## 0.04260044 0.02573512 0.03033803 0.02185935
 r
SEs
##          k1          k2          k3          k4 
## 0.004128447 0.002284696 0.002733498 0.001822218
 r
dfr
## [1] 88&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have one vector of estimates to be compared and one vector of standard errors. In this situation, we can make pairwise comparisons by using the &lt;code&gt;pairComp()&lt;/code&gt; function in the ‘aomisc’ package. We just have to pass the vector of model parameters, the vector of standard errors, and, optionally, the names of parameters (we do not need this, as ‘dRates’ is a named vector), the number of residual degrees of freedom (defaults to ‘Inf’) and the multiplicity adjustment method, as in the ‘multcomp’ package (defaults to “single-step”).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vcovMat &amp;lt;- vcov(modNlin)[5:8,5:8]
cp &amp;lt;- pairComp(dRates, vcovMat, dfr = dfr, adjust = &amp;quot;holm&amp;quot;)
cp$Pairs
## 
## 	 Simultaneous Tests for General Linear Hypotheses
## 
## Linear Hypotheses:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## k4-k2 == 0 -0.003876   0.002922  -1.326  0.37639    
## k4-k3 == 0 -0.008479   0.003285  -2.581  0.04604 *  
## k4-k1 == 0 -0.020741   0.004513  -4.596 8.58e-05 ***
## k2-k3 == 0 -0.004603   0.003563  -1.292  0.37639    
## k2-k1 == 0 -0.016865   0.004718  -3.574  0.00286 ** 
## k3-k1 == 0 -0.012262   0.004951  -2.477  0.04604 *  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## (Adjusted p values reported -- holm method)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also obtain a letter display, by taking the ‘Letters’ slot in the ‘cp’ object. In this case, we might like to change the yardstick protection level, by passing the ‘level’ argument in ‘pairComp()’, that defaults to 0.05.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cp$Letters
##          Mean          SE CLD
## k4 0.02185935 0.001822218   a
## k2 0.02573512 0.002284696  ab
## k3 0.03033803 0.002733498   b
## k1 0.04260044 0.004128447   c&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please, note that the &lt;code&gt;pairComp()&lt;/code&gt; function can be flexibly used in every situation where we have a vector of estimates and a vector of standard errors. It yields correct results whenever the elements of the vector of estimates are uncorrelated. Hope this is useful. Thanks for reading!&lt;/p&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
email: &lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;
Blog &lt;a href=&#34;www.statforbiology.com&#34;&gt;www.statforbiology.com&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;References&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Torsten Hothorn, Frank Bretz and Peter Westfall (2008). Simultaneous Inference in General Parametric Models. Biometrical Journal 50(3), 346–363.&lt;/li&gt;
&lt;li&gt;Russell Lenth (2020). emmeans: Estimated Marginal Means, aka Least-Squares Means. R package version 1.5.0-5. &lt;a href=&#34;https://github.com/rvlenth/emmeans&#34; class=&#34;uri&#34;&gt;https://github.com/rvlenth/emmeans&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Accounting for the experimental design in linear/nonlinear regression analyses</title>
      <link>http://localhost:6346/2020/stat_nlmm_designconstraints/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2020/stat_nlmm_designconstraints/</guid>
      <description>


&lt;p&gt;In this post, I am going to talk about an issue that is often overlooked by agronomists and biologists. The point is that field experiments are very often laid down in blocks, using split-plot designs, strip-plot designs or other types of designs with grouping factors (blocks, main-plots, sub-plots). We know that these grouping factors should be appropriately accounted for in data analyses: ‘analyze them as you have randomized them’ is a common saying attributed to Ronald Fisher. Indeed, observations in the same group are correlated, as they are more alike than observations in different groups. What happens if we neglect the grouping factors? We break the independence assumption and our inferences are invalid (Onofri et al., 2010).&lt;/p&gt;
&lt;p&gt;To my experience, field scientists are totally aware of this issue when they deal with ANOVA-type models (e.g., see Jensen et al., 2018). However, a brief survey of literature shows that there is not the same awareness, when field scientists deal with linear/nonlinear regression models. Therefore, I decided to sit down and write this post, in the hope that it may be useful to obtain more reliable data analyses.&lt;/p&gt;
&lt;div id=&#34;an-example-with-linear-regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;An example with linear regression&lt;/h1&gt;
&lt;p&gt;Let’s take a look at the ‘yieldDensity.csv’ dataset, that is available on gitHub. It represents an experiment where sunflower was tested with increasing weed densities (0, 14, 19, 28, 32, 38, 54, 82 plants per &lt;span class=&#34;math inline&#34;&gt;\(m^2\)&lt;/span&gt;), on a randomised complete block design, with 10 blocks. a swift plot shows that yield is linearly related to weed density, which calls for linear regression analysis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
library(nlme)
library(lattice)
dataset &amp;lt;- read.csv(&amp;quot;https://raw.githubusercontent.com/OnofriAndreaPG/agroBioData/master/yieldDensityB.csv&amp;quot;,
  header=T)
dataset$block &amp;lt;- factor(dataset$block)
head(dataset)
##   block density yield
## 1     1       0 29.90
## 2     2       0 34.23
## 3     3       0 37.12
## 4     4       0 26.37
## 5     5       0 34.48
## 6     6       0 33.70
 r
plot(yield ~ density, data = dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nlmm_DesignConstraints_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We might be tempted to neglect the block effect and run a linear regression analysis of yield against density. This is clearly wrong (I am violating the independence assumption) and inefficient, as any block-to-block variability goes into the residual error term, which is, therefore, inflated.&lt;/p&gt;
&lt;p&gt;Some of my collegues would take the means for densities and use those to fit a linear regression model (two-steps analysis). By doing so, block-to-block variability is cancelled out and the analysis becomes more efficient. However, such a solution is not general, as it is not feasible, e.g., when we have unbalanced designs and heteroscedastic data. With the appropriate approach, sound analyses can also be made in two-steps (Damesa et al., 2017). From my point of view, it is reasonable to search for more general solutions to deal with one-step analyses.&lt;/p&gt;
&lt;p&gt;Based on our experience with traditional ANOVA models, we might think of taking the block effect as fixed and fit it as and additive term. See the code below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod.reg &amp;lt;- lm(yield ~ block + density, data=dataset)
summary(mod.reg)
## 
## Call:
## lm(formula = yield ~ block + density, data = dataset)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.6062 -0.8242 -0.3315  0.7505  4.6244 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept) 29.10462    0.57750  50.397  &amp;lt; 2e-16 ***
## block2       4.57750    0.74668   6.130 4.81e-08 ***
## block3       7.05875    0.74668   9.453 4.49e-14 ***
## block4      -3.98000    0.74668  -5.330 1.17e-06 ***
## block5       6.17625    0.74668   8.272 6.37e-12 ***
## block6       5.92750    0.74668   7.938 2.59e-11 ***
## block7       1.23750    0.74668   1.657  0.10199    
## block8       1.25500    0.74668   1.681  0.09733 .  
## block9       2.34875    0.74668   3.146  0.00245 ** 
## block10      2.25125    0.74668   3.015  0.00359 ** 
## density     -0.26744    0.00701 -38.149  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.493 on 69 degrees of freedom
## Multiple R-squared:  0.9635,	Adjusted R-squared:  0.9582 
## F-statistic: 181.9 on 10 and 69 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With regression, this solution is not convincing. Indeed, the above model assumes that the blocks produce an effect only on the intercept of the regression line, while the slope is unaffected. Is this a reasonable assumption? I vote no.&lt;/p&gt;
&lt;p&gt;Let’s check this by fitting a different regression model per block (ten different slopes + ten different intercepts):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod.reg2 &amp;lt;- lm(yield ~ block/density + block, data=dataset)
anova(mod.reg, mod.reg2)
## Analysis of Variance Table
## 
## Model 1: yield ~ block + density
## Model 2: yield ~ block/density + block
##   Res.Df    RSS Df Sum of Sq      F  Pr(&amp;gt;F)  
## 1     69 153.88                              
## 2     60 115.75  9    38.135 2.1965 0.03465 *
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The p-level confirms that the block had a significant effect both on the intercept and on the slope. To describe such an effect we need 20 parameters in the model, which is not very parsimonious. And above all: which regression line do we use for predictions? Taking the block effect as fixed is clearly sub-optimal with regression models.&lt;/p&gt;
&lt;p&gt;The question is: can we fit a simpler and clearer model? The answer is: yes. Why don’t we take the block effect as random? This is perfectly reasonable. Let’s do it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modMix.1 &amp;lt;- lme(yield ~ density, random = ~ density|block, data=dataset)
summary(modMix.1)
## Linear mixed-effects model fit by REML
##   Data: dataset 
##        AIC      BIC    logLik
##   340.9166 355.0569 -164.4583
## 
## Random effects:
##  Formula: ~density | block
##  Structure: General positive-definite, Log-Cholesky parametrization
##             StdDev     Corr  
## (Intercept) 3.16871858 (Intr)
## density     0.02255249 0.09  
## Residual    1.38891957       
## 
## Fixed effects:  yield ~ density 
##                Value Std.Error DF   t-value p-value
## (Intercept) 31.78987 1.0370844 69  30.65311       0
## density     -0.26744 0.0096629 69 -27.67704       0
##  Correlation: 
##         (Intr)
## density -0.078
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -1.9923722 -0.5657555 -0.1997103  0.4961675  2.6699060 
## 
## Number of Observations: 80
## Number of Groups: 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above fit shows that the random effects (slope and intercept) are sligthly correlated (r = 0.091). We might like to try a simpler model, where random effects are independent. To do so, we need to consider that the above model is equivalent to the following model:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;modMix.1 &amp;lt;- lme(yield ~ density, random = list(block = pdSymm(~density)), data=dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s just two different ways to code the very same model. However, this latter coding, based on a ‘pdMat’ structure, can be easily modified to remove the correlation. Indeed, ‘pdSymm’ specifies a totally unstructured variance-covariance matrix for random effects and it can be replaced by ‘pdDiag’, which specifies a diagonal matrix, where covariances (off-diagonal terms) are constrained to 0. The coding is as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modMix.2 &amp;lt;- lme(yield ~ density, random = list(block = pdDiag(~density)), data=dataset)
summary(modMix.2)
## Linear mixed-effects model fit by REML
##   Data: dataset 
##       AIC      BIC   logLik
##   338.952 350.7355 -164.476
## 
## Random effects:
##  Formula: ~density | block
##  Structure: Diagonal
##         (Intercept)    density Residual
## StdDev:    3.198263 0.02293222 1.387148
## 
## Fixed effects:  yield ~ density 
##                Value Std.Error DF   t-value p-value
## (Intercept) 31.78987 1.0460272 69  30.39105       0
## density     -0.26744 0.0097463 69 -27.44019       0
##  Correlation: 
##         (Intr)
## density -0.139
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -1.9991173 -0.5451478 -0.1970267  0.4925090  2.6700386 
## 
## Number of Observations: 80
## Number of Groups: 10
 r
anova(modMix.1, modMix.2)
##          Model df      AIC      BIC    logLik   Test    L.Ratio p-value
## modMix.1     1  6 340.9166 355.0569 -164.4583                          
## modMix.2     2  5 338.9520 350.7355 -164.4760 1 vs 2 0.03535079  0.8509&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model could be further simplified. For example, the code below shows how we could fit models with either random intercept or random slope.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Model with only random intercept
modMix.3 &amp;lt;- lme(yield ~ density, random = list(block = ~1), data=dataset)

#Alternative
#random = ~ 1|block

#Model with only random slope
modMix.4 &amp;lt;- lme(yield ~ density, random = list(block = ~ density - 1), data=dataset)

#Alternative
#random = ~density - 1 | block&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example-with-nonlinear-regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;An example with nonlinear regression&lt;/h1&gt;
&lt;p&gt;The problem may become trickier if we have a nonlinear relationship. Let’s have a look at another similar dataset (‘YieldLossB.csv’), that is also available on gitHub. It represents another experiment where sunflower was grown with the same increasing densities of another weed (0, 14, 19, 28, 32, 38, 54, 82 plants per &lt;span class=&#34;math inline&#34;&gt;\(m^2\)&lt;/span&gt;), on a randomised complete block design, with 8 blocks. In this case, the yield loss was recorded and analysed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
dataset &amp;lt;- read.csv(&amp;quot;https://raw.githubusercontent.com/OnofriAndreaPG/agroBioData/master/YieldLossB.csv&amp;quot;,
  header=T)
dataset$block &amp;lt;- factor(dataset$block)
head(dataset)
##   block density yieldLoss
## 1     1       0     1.532
## 2     2       0    -0.661
## 3     3       0    -0.986
## 4     4       0    -0.697
## 5     5       0    -2.264
## 6     6       0    -1.623
 r
plot(yieldLoss ~ density, data = dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nlmm_DesignConstraints_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A swift plot shows that the relationship between density and yield loss is not linear. Literature references (Cousens, 1985) show that this could be modelled by using a rectangular hyperbola:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[YL = \frac{i \, D}{1 + \frac{i \, D}{a}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(YL\)&lt;/span&gt; is the yield loss, &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is weed density, &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is the slope at the origin of axes and &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is the maximum asymptotic yield loss. This function, together with self-starters, is available in the ‘NLS.YL()’ function in the ‘aomisc’ package, which is the accompanying package for this blog. If you do not have this package, please refer to &lt;a href=&#34;https://www.statforbiology.com/rpackages/&#34;&gt;this link&lt;/a&gt; to download it.&lt;/p&gt;
&lt;p&gt;The problem is the very same as above: the block effect may produce random fluctuations for both model parameters. The only difference is that we need to use the ‘nlme()’ function instead of ‘lme()’. With nonlinear mixed models, I strongly suggest you use a ‘groupedData’ object, which permits to avoid several problems. The second line below shows how to turn a data frame into a ‘groupedData’ object.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(aomisc)
datasetG &amp;lt;- groupedData(yieldLoss ~ 1|block, dataset)
nlin.mix &amp;lt;- nlme(yieldLoss ~ NLS.YL(density, i, A), data=datasetG, 
						fixed = list(i ~ 1, A ~ 1),
            random = i + A ~ 1|block)
summary(nlin.mix)
## Nonlinear mixed-effects model fit by maximum likelihood
##   Model: yieldLoss ~ NLS.YL(density, i, A) 
##   Data: datasetG 
##        AIC      BIC    logLik
##   474.8228 491.5478 -231.4114
## 
## Random effects:
##  Formula: list(i ~ 1, A ~ 1)
##  Level: block
##  Structure: General positive-definite, Log-Cholesky parametrization
##          StdDev    Corr 
## i        0.1112841 i    
## A        4.0444816 0.195
## Residual 1.4142267      
## 
## Fixed effects:  list(i ~ 1, A ~ 1) 
##      Value Std.Error  DF  t-value p-value
## i  1.23238 0.0382246 104 32.24035       0
## A 68.52305 1.9449780 104 35.23076       0
##  Correlation: 
##   i     
## A -0.408
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -2.4416777 -0.7049390 -0.1805691  0.3385459  2.8788990 
## 
## Number of Observations: 120
## Number of Groups: 15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similarly to linear mixed models, the above coding implies correlated random effects (r = 0.194). Alternatively, the above model can be coded by using a ’pdMat construct, as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nlin.mix2 &amp;lt;- nlme(yieldLoss ~ NLS.YL(density, i, A), data=datasetG, 
						      fixed = list(i ~ 1, A ~ 1),
                  random = pdSymm(list(i ~ 1, A ~ 1)))
summary(nlin.mix2)
## Nonlinear mixed-effects model fit by maximum likelihood
##   Model: yieldLoss ~ NLS.YL(density, i, A) 
##   Data: datasetG 
##        AIC      BIC    logLik
##   474.8225 491.5474 -231.4112
## 
## Random effects:
##  Formula: list(i ~ 1, A ~ 1)
##  Level: block
##  Structure: General positive-definite
##          StdDev    Corr 
## i        0.1112837 i    
## A        4.0468443 0.194
## Residual 1.4141993      
## 
## Fixed effects:  list(i ~ 1, A ~ 1) 
##      Value Std.Error  DF  t-value p-value
## i  1.23242  0.038225 104 32.24114       0
## A 68.52050  1.945186 104 35.22568       0
##  Correlation: 
##   i     
## A -0.409
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -2.4413852 -0.7049358 -0.1805300  0.3385252  2.8787256 
## 
## Number of Observations: 120
## Number of Groups: 15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can try to simplify the model, for example by excluding the correlation between random effects.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nlin.mix3 &amp;lt;- nlme(yieldLoss ~ NLS.YL(density, i, A), data=datasetG, 
						      fixed = list(i ~ 1, A ~ 1),
                  random = pdDiag(list(i ~ 1, A ~ 1)))
summary(nlin.mix3)
## Nonlinear mixed-effects model fit by maximum likelihood
##   Model: yieldLoss ~ NLS.YL(density, i, A) 
##   Data: datasetG 
##        AIC      BIC    logLik
##   472.9076 486.8451 -231.4538
## 
## Random effects:
##  Formula: list(i ~ 1, A ~ 1)
##  Level: block
##  Structure: Diagonal
##                 i        A Residual
## StdDev: 0.1172791 4.389173 1.408963
## 
## Fixed effects:  list(i ~ 1, A ~ 1) 
##      Value Std.Error  DF  t-value p-value
## i  1.23243 0.0393514 104 31.31852       0
## A 68.57655 1.9905549 104 34.45097       0
##  Correlation: 
##   i     
## A -0.459
## 
## Standardized Within-Group Residuals:
##        Min         Q1        Med         Q3        Max 
## -2.3577292 -0.6849962 -0.1785860  0.3255925  2.8592764 
## 
## Number of Observations: 120
## Number of Groups: 15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a little fantasy, we can easily code several alternative models to represent alternative hypotheses about the observed data. Obviously, the very same method can be used (and SHOULD be used) to account for other grouping factors, such as main-plots in split-plot designs or plots in repeated measure designs.&lt;/p&gt;
&lt;p&gt;Happy coding!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Cousens, R., 1985. A simple model relating yield loss to weed density. Annals of Applied Biology 107, 239–252. &lt;a href=&#34;https://doi.org/10.1111/j.1744-7348.1985.tb01567.x&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1111/j.1744-7348.1985.tb01567.x&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Jensen, S.M., Schaarschmidt, F., Onofri, A., Ritz, C., 2018. Experimental design matters for statistical analysis: how to handle blocking: Experimental design matters for statistical analysis. Pest Management Science 74, 523–534. &lt;a href=&#34;https://doi.org/10.1002/ps.4773&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1002/ps.4773&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Onofri, A., Carbonell, E.A., Piepho, H.-P., Mortimer, A.M., Cousens, R.D., 2010. Current statistical issues in Weed Research. Weed Research 50, 5–24.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Seed germination: fitting hydro-time models with R</title>
      <link>http://localhost:6346/2020/stat_seedgermination_ht1step/</link>
      <pubDate>Mon, 23 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2020/stat_seedgermination_ht1step/</guid>
      <description>


&lt;p&gt;&lt;strong&gt;THE CODE IN THIS POST WAS UPDATED ON JANUARY 2022&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I am locked at home, due to the COVID-19 emergency in Italy. Luckily I am healthy, but there is not much to do, inside. I thought it might be nice to spend some time to talk about seed germination models and the connections with survival analysis.&lt;/p&gt;
&lt;p&gt;We all know that seeds need water to germinate. Indeed, the absorption of water activates the hydrolytic enzymes, which break down food resources stored in seeds and provide energy for germination. As the consequence, there is a very close relationship between water content in the substrate and germination velocity: the higher the water content the quickest the germination, as long as the availability of oxygen does not become a problem (well, water and oxygen in soil may compete for space and a high water content may result in oxygen shortage).&lt;/p&gt;
&lt;p&gt;Indeed, it is relevant to build germination models, linking the proportion of germinated seeds to water availability in the substrate; these models are usually known as hydro-time (HT) models. The starting point is the famous equation of Bradford (1992), where the germination rate (GR) for the &lt;span class=&#34;math inline&#34;&gt;\(i-th\)&lt;/span&gt; seed in the lot is expressed as a linear function of water potential in the substrate (&lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ GR_i = \textrm{max} \left( \frac{\Psi - \Psi_{b(i)}}{\theta_H}; 0 \right) \quad \quad \quad \quad (1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In that equation, &lt;span class=&#34;math inline&#34;&gt;\(\Psi_{b(i)}\)&lt;/span&gt; is the base water potential for the &lt;span class=&#34;math inline&#34;&gt;\(i-th\)&lt;/span&gt; seed and &lt;span class=&#34;math inline&#34;&gt;\(\theta_H\)&lt;/span&gt; is the hydro-time constant, expressed as &lt;em&gt;MPa day&lt;/em&gt; or &lt;em&gt;MPa hour&lt;/em&gt;. The concept is relatively simple: we just need to remember that the water can only move from a position with a higher water potential to a position with a lower water potential. Therefore, a seed cannot germinate when its base water potential is higher than the water potential in the substrate.&lt;/p&gt;
&lt;p&gt;When &lt;span class=&#34;math inline&#34;&gt;\(\Psi &amp;gt; \Psi_b(i)\)&lt;/span&gt;, the germination rate of the &lt;span class=&#34;math inline&#34;&gt;\(i-th\)&lt;/span&gt; seed is linearly related to &lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;: the higher this latter value, the higher the germination rate. Now we should consider that the germination rate is the inverse of the germination time (&lt;span class=&#34;math inline&#34;&gt;\(GR = 1/t\)&lt;/span&gt;); thus, the higher the GR, the shortest the germination time. Germination is achieved at the time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; when:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ t \, \left( \Psi - \Psi_{b(i)} \right) = \theta_H \quad \quad \quad (2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.statforbiology.com/2021/stat_seedgermination_htt2step/&#34;&gt;Elsewhere in this website&lt;/a&gt;, I show that Equation 1 can be fitted to germination data in a two-steps fashion. In this page we will see how we can embed Equation 1 into a time-to-event model, to predict the proportion of germinated seeds, depending on time and water content in the substrate. As usual, let’s start from a practical example.&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;the-dataset&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The dataset&lt;/h1&gt;
&lt;p&gt;The germination of rapeseed (&lt;em&gt;Brassica napus&lt;/em&gt; L. var. &lt;em&gt;oleifera&lt;/em&gt;, cv. Excalibur) was tested at fourteen different water potentials (0, -0.03, -0.15, -0.3, -0.4, -0.5, -0.6, -0.7, -0.8, -0.9, -1, -1.1, -1.2, -1.5 MPa), which were created by using a polyethylene glycol solution (PEG 6000). For each water potential level, three replicated Petri dishes with 50 seeds were incubated at 20°C. Germinated seeds were counted and removed every 2-3 days for 14 days.&lt;/p&gt;
&lt;p&gt;The dataset was published by Pace et al. (2012) and it is available as &lt;code&gt;rape&lt;/code&gt; in the &lt;code&gt;drcSeedGerm&lt;/code&gt; package, which needs to be installed from github (see below). Furthermore, the package &lt;code&gt;drcte&lt;/code&gt; is necessary to fit time-to-event models and it should also be installed from gitHub. Please, make sure you have the most updated version for both packages.&lt;/p&gt;
&lt;p&gt;The following code loads the necessary packages, loads the dataset &lt;code&gt;rape&lt;/code&gt; and shows the first six lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools)
# install_github(&amp;quot;OnofriAndreaPG/drcSeedGerm&amp;quot;)
# install_github(&amp;quot;OnofriAndreaPG/drcte&amp;quot;)
library(drcSeedGerm)
library(drcte)
data(rape)
head(rape)
##   Psi Dish timeBef timeAf nSeeds nCum propCum
## 1   0    1       0      3     49   49    0.98
## 2   0    1       3      4      0   49    0.98
## 3   0    1       4      5      0   49    0.98
## 4   0    1       5      7      0   49    0.98
## 5   0    1       7     10      0   49    0.98
## 6   0    1      10     14      0   49    0.98&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that the data are grouped by assessment interval: ‘timeAf’ represents the moment when germinated seeds were counted, while ’timeBef’ represents the previous inspection time (or the beginning of the assay). The column ’nSeeds’ is the number of seeds that germinated during the time interval between ‘timeBef’ and ‘timeAf. The ’propCum’ column contains the cumulative proportions of germinated seeds and it is not necessary for time-to-event models.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;building-hydro-time-models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Building hydro-time models&lt;/h1&gt;
&lt;div id=&#34;models-based-on-the-distribution-of-germination-time&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Models based on the distribution of germination time&lt;/h2&gt;
&lt;p&gt;How can we rework Equation 1 to predict the proportion of germinated seeds, as a function of time and water potential? One line of attack follows the proposal we made in a relatively recent paper (Onofri at al., 2018). We start from the idea that the time course of the proportion of germinated seeds (&lt;span class=&#34;math inline&#34;&gt;\(P\)&lt;/span&gt;) is expected to increase over time, according to a S-shaped curve, such as the usual log-logistic cumulative probability function (other cumulative distribution functions can be used; see our original paper):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(t) = \frac{ d }{1 + \exp \left\{ b \left[ \log(t) - \log( e ) \right] \right\} } \quad \quad \quad (3)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is the median germination time, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the slope at the inflection point and &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the maximum germinated proportion. Considering that the germination rate is the inverse of germination time, we can write:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(t) = \frac{ d }{1 + \exp \left\{ b \left[ \log(t) - \log(1 / GR_{50} ) \right] \right\} } \quad \quad \quad (4)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(GR_{50}\)&lt;/span&gt; is the median germination rate in the population. We can now express &lt;span class=&#34;math inline&#34;&gt;\(GR_{50}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; as linear/nonlinear functions of &lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt; (temperature and other environmental variables can be included as well. See our original paper):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[P(t, \Psi) = \frac{ h_1(\Psi) }{1 + \exp \left\{ b \left[ \log(t) - \log(1 / \left[ GR_{50}(\Psi) \right] ) \right] \right\} } \quad \quad \quad (5)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In our paper, for &lt;span class=&#34;math inline&#34;&gt;\(GR_{50}\)&lt;/span&gt;, we slightly reparameterised Equation 1 above:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ GR_{50}(\Psi) = \textrm{max} \left( \frac{\Psi - \Psi_{b(50)}}{\theta_H}; 0 \right) \quad \quad \quad \quad (6)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\Psi_{b(50)}\)&lt;/span&gt; is the median base water potential in the population.&lt;/p&gt;
&lt;p&gt;For &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, we used a shifted exponential distribution, which implies that germination capability is fully determined by the distribution of base water potential within the population and no germination occurs at &lt;span class=&#34;math inline&#34;&gt;\(\Psi \leq \Psi_b\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d = h_1(\Psi ) = \textrm{max} \left\{ G \, \left[ 1 - \exp \left( \frac{ \Psi - \Psi_{b(50)} }{\sigma_{\Psi_b}} \right) \right]; 0 \right\} \quad \quad \quad (7)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In the above equation, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\Psi_b}\)&lt;/span&gt; represents the variability of &lt;span class=&#34;math inline&#34;&gt;\(\Psi_b\)&lt;/span&gt; within the population, which determines the steepness of the increase in &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt; increases. &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; is the germinable fraction, accounting for the fact that &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; may not reach 1, regardless of time and water potential.&lt;/p&gt;
&lt;p&gt;The parameter &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; was assumed to be constant and independent on &lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;. In the end, our hydro-time model is composed by four sub-models:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;a cumulative probability function (log-logistic, in our example), based on the three parameters &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e = 1/GR_{50}\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;a sub-model expressing &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; as a function of &lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;a sub-model expressing &lt;span class=&#34;math inline&#34;&gt;\(GR_{50}\)&lt;/span&gt; as a function of &lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;;&lt;/li&gt;
&lt;li&gt;a sub-model expressing &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; as a function of &lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt;, although, this was indeed a simple identity model &lt;span class=&#34;math inline&#34;&gt;\(b(\Psi) = b\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This hydro-time model was implemented in R as the &lt;code&gt;HTE1()&lt;/code&gt; function, and it is available within the &lt;code&gt;drcSeedGerm&lt;/code&gt; package, together with the appropriate self-starting routine. It can be fitting by using the &lt;code&gt;drmte()&lt;/code&gt; function in the &lt;code&gt;drcte&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modHTE &amp;lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, 
                data = rape, fct = HTE1())
summary(modHTE)
## 
## Model fitted: Hydro-time model with shifted exponential for Pmax and linear model for GR50
## 
## Robust estimation: no 
## 
## Parameter estimates:
## 
##                         Estimate Std. Error  t-value   p-value    
## G:(Intercept)          0.9577918  0.0063667  150.438 &amp;lt; 2.2e-16 ***
## Psib:(Intercept)      -1.0397239  0.0047017 -221.138 &amp;lt; 2.2e-16 ***
## sigmaPsib:(Intercept)  0.1108891  0.0087598   12.659 &amp;lt; 2.2e-16 ***
## thetaH:(Intercept)     0.9061385  0.0301594   30.045 &amp;lt; 2.2e-16 ***
## b:(Intercept)          4.0273963  0.1960845   20.539 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As seeds are clustered in Petri dishes, in order not to violate the independence assumption, it is preferable to get cluster robust standard errors. One possibility is to use the grouped version of the sandwich estimator, as available in the ‘sandwich’ package (Berger, 2017), which is implemented in the ‘drcte’ package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(modHTE, robust = T, units = Dish)
## 
## Model fitted: Hydro-time model with shifted exponential for Pmax and linear model for GR50
## 
## Robust estimation: Cluster robust sandwich SEs 
## 
## Parameter estimates:
## 
##                         Estimate Std. Error   t value  Pr(&amp;gt;|t|)    
## G:(Intercept)          0.9577918  0.0080923  118.3591 &amp;lt; 2.2e-16 ***
## Psib:(Intercept)      -1.0397239  0.0047063 -220.9206 &amp;lt; 2.2e-16 ***
## sigmaPsib:(Intercept)  0.1108891  0.0121879    9.0983 &amp;lt; 2.2e-16 ***
## thetaH:(Intercept)     0.9061385  0.0410425   22.0781 &amp;lt; 2.2e-16 ***
## b:(Intercept)          4.0273963  0.1934513   20.8187 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the model is fitted, we may be interested in using the resulting curve to retrieve some biologically relevant information. For example, it may be interesting to retrieve the germination rates for some selected percentiles (e.g., the 30th, 20th and 10th percentiles). This is possible using the &lt;code&gt;quantile()&lt;/code&gt; function in ‘drcte’ package, that is a wrapper for the original &lt;code&gt;ED()&lt;/code&gt; function in the package &lt;code&gt;drc&lt;/code&gt;. It works very much like the &lt;code&gt;ED()&lt;/code&gt; function, although the environmental covariates, such as the selected &lt;span class=&#34;math inline&#34;&gt;\(\Psi\)&lt;/span&gt; level, can be specified as a numeric value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Naive standard errors
quantile(modHTE, probs = c(0.30, 0.20, 0.10), rate = T, Psi = -1)
## 
## Estimated quantiles
## 
##       Estimate        SE
## 1:30% 0.000000 0.0000000
## 1:20% 0.035792 0.0058117
## 1:10% 0.051304 0.0062243&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this example, we see that the &lt;span class=&#34;math inline&#34;&gt;\(GR_{30}\)&lt;/span&gt; cannot be calculated, as the germination capacity did not reach 30% at the selected water potential level (&lt;span class=&#34;math inline&#34;&gt;\(-1 \,\, MPa\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;As we said, cluster robust standard errors are recommended, which can be requested by setting the ‘robust = TRUE’ argument and passing a vector for the grouping factor. If necessary, germination times can be obtained in a similar way, by removing the ‘rate’ argument&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Cluster robust standard errors
quantile(modHTE, probs = c(0.30, 0.20, 0.10), rate = T, Psi = -1, robust = T,
         units = Dish)
## 
## Estimated quantiles
## 
##       Estimate        SE
## 1:30% 0.000000 0.0000000
## 1:20% 0.035792 0.0054538
## 1:10% 0.051304 0.0058715
 r
#Germination times
quantile(modHTE, probs = c(0.30, 0.20, 0.10), Psi = -1, robust = T,
         units = Dish)
## 
## Estimated quantiles
## 
##       Estimate     SE
## 1:30%      Inf    NaN
## 1:20%   27.939 4.2572
## 1:10%   19.492 2.2308&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Last, but not least, we can predict the proportion of germinated seeds at given time and water potential level.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;predict(modHTE, se.fit=T, robust = T,
         units = Dish,
        newdata = data.frame(Time=c(10, 10, 10), 
                             Psi=c(-1.5, -0.75, 0))
        )
##   Time   Psi Prediction          SE
## 1   10 -1.50  0.0000000 0.000000000
## 2   10 -0.75  0.8794025 0.017562676
## 3   10  0.00  0.9576590 0.008070333&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;models-based-on-the-distribution-of-psi_b&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Models based on the distribution of &lt;span class=&#34;math inline&#34;&gt;\(\Psi_b\)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;Another type of hydro-time model was proposed by Bradford (2002) and later extended by Mesgaran et al (2013). This approach starts always from Equation 1; from that equation, considering that the germination time is the inverse of the GR, we can easily get to the following equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\Psi_b = \Psi - \frac{\theta_H}{t} \quad \quad \quad (8)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; is the germination time. What does this equation tell us? Let’s assume that the hydro-time to germination is 10 &lt;span class=&#34;math inline&#34;&gt;\(MPa \, d\)&lt;/span&gt; and the environmental water potential is -1 &lt;span class=&#34;math inline&#34;&gt;\(MPa\)&lt;/span&gt;. A single seed germinates in exactly one day, if its base water potential is &lt;span class=&#34;math inline&#34;&gt;\(-1 - 10/1 = -11\)&lt;/span&gt;. If the base water potential is higher, germination will take more than one day; if it is lower, germination will take less than one day. But now, the following questions come: how many seeds in a population will be able to germinate in one day? And in two days? And in &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; days?&lt;/p&gt;
&lt;p&gt;We know that the seeds within a population do not germinate altogether in the same moment, as they have different individual values of base water potential. If the population is big enough, we can describe the variation of &lt;span class=&#34;math inline&#34;&gt;\(\Psi_b\)&lt;/span&gt; within the population by using some density function, possibly parameterised by way of a location (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and a scale (&lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;) parameter:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \Psi_b \sim \phi \left( \frac{\Psi_b - \mu}{\sigma} \right) \quad \quad \quad (9)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is easier to understand if we make a specific example. Let’s assume that the distribution of &lt;span class=&#34;math inline&#34;&gt;\(\Psi_b\)&lt;/span&gt; values within the population is gaussian, with mean &lt;span class=&#34;math inline&#34;&gt;\(\mu = -9\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma = 1\)&lt;/span&gt;. Let’s also assume that the hydro-time parameter (&lt;span class=&#34;math inline&#34;&gt;\(\theta_H\)&lt;/span&gt;) is constant within the population. We have the situation depicted in the figure below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HT1step_files/figure-html/distribPsi-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The red left tail represents the proportion of seeds that germinate during the first day, as they have base water potentials equal to or lower than -11. By using the gaussian cumulative distribution function we can easily see that that proportion is 0.228:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pnorm(-1 - 10/1, mean = -9, sd = 1)
## [1] 0.02275013&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;More generally, we can write:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ P(t, \Psi) = \Phi \left\{ \frac{\Psi - (\theta_H / t) -\mu }{\sigma} \right\} \quad \quad \quad (10)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\Phi\)&lt;/span&gt; is the selected cumulative distribution function. The above model returns the proportion of germinated seeds (G), as a function of time and water potential in the substrate. According to Bradford (2002), &lt;span class=&#34;math inline&#34;&gt;\(\Phi\)&lt;/span&gt; is cumulative gaussian.&lt;/p&gt;
&lt;p&gt;Let’s think more deeply about Equation 9 (Bradford, 2002). This function was built to represent the cumulative distribution function of base water potential within the population. However, &lt;strong&gt;it can be as well taken to represent the cumulative distribution function of germination time within the population&lt;/strong&gt;. Obviously, while the first distribution is gaussian, the second one is not: indeed, the germination time appears at the denominator of the expression &lt;span class=&#34;math inline&#34;&gt;\(\theta_H / t\)&lt;/span&gt;. It doesn’t matter: every cumulative distribution function for germination time can be fit by using time-to-event methods!&lt;/p&gt;
&lt;p&gt;We implemented this model in R as the function &lt;code&gt;HTnorm()&lt;/code&gt; that is available within the &lt;code&gt;drcSeedGerm&lt;/code&gt; package and it is meant to be used with the &lt;code&gt;drm()&lt;/code&gt; function, in the &lt;code&gt;drc&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;Mesgaran et al (2013) suggested that the distribution of base water potential within the population may not be gaussian and proposed several alternatives, which we have all implemented within the package. In all, &lt;code&gt;drcSeedGerm&lt;/code&gt; contains six possible distributions:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;gaussian distribution (function &lt;code&gt;HTnorm()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;logistic distribution (function &lt;code&gt;HTL()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Gumbel (function &lt;code&gt;HTG()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;log-logistic (function &lt;code&gt;HTLL()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Weibull (Type I) (function &lt;code&gt;HTW1()&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Weibull (Type II) (function &lt;code&gt;HTW2()&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The equations are given at the end of this page; for gaussian, logistic and log-logistic distributions, &lt;span class=&#34;math inline&#34;&gt;\(\Psi_{b(50)}\)&lt;/span&gt; is the median base water potential within the population. For the gaussian distribution, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\Psi b}\)&lt;/span&gt; corresponds to the standard deviation of &lt;span class=&#34;math inline&#34;&gt;\(\Psi_b\)&lt;/span&gt; within the population.&lt;/p&gt;
&lt;p&gt;Distributions based on logarithms (the log-logistic and all other distributions thereafter) are only defined for positive amounts. On the contrary, we know that base water potential is mostly negative. Therefore, shifted distributions need to be used, by introducing a shifting parameter &lt;span class=&#34;math inline&#34;&gt;\(\delta\)&lt;/span&gt; which ‘moves’ the distribution to the left, along the x-axis, so that negative values are possible (see Mesgaran et al., 2013).&lt;/p&gt;
&lt;p&gt;Let’s fit the above functions to the ‘rape’ dataset. But, before, let me highlight that providing starting values is not necessary, as self-starting routines are already implemented for all models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod1 &amp;lt;- drmte(nSeeds ~ timeBef + timeAf + Psi, 
              data = rape, fct = HTnorm())
mod2 &amp;lt;- drmte(nSeeds ~ timeBef + timeAf + Psi,
              data = rape, fct = HTL())
mod3 &amp;lt;- drmte(nSeeds ~ timeBef + timeAf + Psi,
              data = rape, fct = HTG())
mod4 &amp;lt;- drmte(nSeeds ~ timeBef + timeAf + Psi,
            data = rape, fct = HTLL())
mod5 &amp;lt;- drmte(nSeeds ~ timeBef + timeAf + Psi,
            data = rape, fct = HTW1())
mod6 &amp;lt;- drmte(nSeeds ~ timeBef + timeAf + Psi,
            data = rape, fct = HTW2())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What is the best model for this dataset? Let’s use the Akaike’s Information Criterion (AIC) to decide:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AIC(mod1, mod2, mod3, mod4, mod5, mod6, modHTE)
##         df      AIC
## mod1   291 3516.914
## mod2   291 3300.824
## mod3   291 3097.775
## mod4   290 2886.608
## mod5   290 2889.306
## mod6   290 3009.023
## modHTE 289 2832.481&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first model &lt;code&gt;modHTE&lt;/code&gt; considers explicitly the distribution of germination times and it is the best fitting of all. The other models consider explicitly the distribution of base water potential, while the distribution of germination times is indirectly included. Among these models, the gaussian is the worse fitting, while the log-logistic is the best one (&lt;code&gt;mod4&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;For this latter model, we take a look at the value of estimated parameters, with cluster robust standard errors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(mod4, robust = T, units = Dish)
## 
## Model fitted: Hydrotime model with log-logistic distribution of Psib (Mesgaran et al., 2013)
## 
## Robust estimation: Cluster robust sandwich SEs 
## 
## Parameter estimates:
## 
##                     Estimate Std. Error  t value Pr(&amp;gt;|t|)    
## thetaH:(Intercept)  0.676804   0.074160   9.1263   &amp;lt;2e-16 ***
## delta:(Intercept)   1.136671   0.101804  11.1652   &amp;lt;2e-16 ***
## Psib50:(Intercept) -0.947798   0.020575 -46.0647   &amp;lt;2e-16 ***
## sigma:(Intercept)   0.371971   0.172825   2.1523   0.0322 *  
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Germination rates and times for a certain percentile (e.g. GR50, GR30), can be obtained as shown above.&lt;/p&gt;
&lt;p&gt;We can use the &lt;code&gt;predict()&lt;/code&gt; function to plot the ‘modHTE’ and ‘mod4’ objects together in the same graph.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_HT1step_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Berger, S., Graham, N., Zeileis, A., 2017. Various versatile variances: An object-oriented implementation of clustered covariances in R. Faculty of Economics and Statistics, University of Innsbruck, Innsbruck.&lt;/li&gt;
&lt;li&gt;Bradford, K.J., 2002. Applications of hydrothermal time to quantifying and modeling seed germination and dormancy. Weed Science 50, 248–260.&lt;/li&gt;
&lt;li&gt;Mesgaran, M.B., Mashhadi, H.R., Alizadeh, H., Hunt, J., Young, K.R., Cousens, R.D., 2013. Importance of distribution function selection for hydrothermal time models of seed germination. Weed Research 53, 89–101. &lt;a href=&#34;https://doi.org/10.1111/wre.12008&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1111/wre.12008&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Onofri, A., Benincasa, P., Mesgaran, M.B., Ritz, C., 2018. Hydrothermal-time-to-event models for seed germination. European Journal of Agronomy 101, 129–139.&lt;/li&gt;
&lt;li&gt;Onofri, A., Mesgaran, M.B., Neve, P., Cousens, R.D., 2014. Experimental design and parameter estimation for threshold models in seed germination. Weed Research 54, 425–435. &lt;a href=&#34;https://doi.org/10.1111/wre.12095&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1111/wre.12095&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Pace, R., Benincasa, P., Ghanem, M.E., Quinet, M., Lutts, S., 2012. Germination of untreated and primed seeds in rapeseed (brassica napus var oleifera del.) under salinity and low matric potential. Experimental Agriculture 48, 238–251.&lt;/li&gt;
&lt;li&gt;Ritz, C., Jensen, S. M., Gerhard, D., Streibig, J. C. (2019) Dose-Response Analysis Using R CRC Press.
Achim Zeileis, Torsten Hothorn (2002). Diagnostic Checking in Regression Relationships. R News 2(3), 7-10. URL: &lt;a href=&#34;https://CRAN.R-project.org/doc/Rnews/&#34; class=&#34;uri&#34;&gt;https://CRAN.R-project.org/doc/Rnews/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;some-further-detail&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Some further detail&lt;/h1&gt;
&lt;p&gt;Let us conclude this page by giving some detail on all equations.&lt;/p&gt;
&lt;p&gt;The equation for the model &lt;code&gt;HTnorm()&lt;/code&gt;. Here, we show all other equations, as implemented in our package.&lt;/p&gt;
&lt;div id=&#34;htl&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;HTL()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ P(t, \Psi) = \frac{1}{1 + exp \left[ - \frac{  \Psi  - \left( \theta _H/t \right) - \Psi_{b(50)} } {\sigma}  \right] }\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;htg&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;HTG()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ P(t, \Psi) = \exp \left\{ { - \exp \left[ { - \left( {\frac{{\Psi - (\theta _H / t ) - \mu }}{\sigma }} \right)} \right]} \right\} \]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;htll&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;HTLL()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ P(t, \Psi) = \frac{1}{1 + \exp \left\{ \frac{ \log \left[ \Psi  - \left( \frac{\theta _H}{t} \right) + \delta \right] - \log(\Psi_{b50} + \delta)  }{\sigma}\right\} }\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;htw1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;HTW1()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ P(t, \Psi) = exp \left\{ - \exp \left[ - \frac{ \log \left[ \Psi  - \left( \frac{\theta _H}{t} \right) + \delta \right] - \log(\Psi_{b50} + \delta)  }{\sigma}\right] \right\}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;htw2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;HTW2()&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ P(t, \Psi) = 1 - exp \left\{ - \exp \left[ \frac{ \log \left[ \Psi  - \left( \frac{\theta _H}{t} \right) + \delta \right] - \log(\Psi_{b50} + \delta)  }{\sigma}\right] \right\}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>A collection of self-starters for nonlinear regression in R</title>
      <link>http://localhost:6346/2020/stat_nls_usefulfunctions/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2020/stat_nls_usefulfunctions/</guid>
      <description>


&lt;p&gt;Usually, the first step of every nonlinear regression analysis is to select the function &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;, which best describes the phenomenon under study. The next step is to fit this function to the observed data, possibly by using some sort of nonlinear least squares algorithms. These algorithms are iterative, in the sense that they start from some initial values of model parameters and repeat a sequence of operations, which continuously improve the initial guesses, until the least squares solution is approximately reached.&lt;/p&gt;
&lt;p&gt;This is the main problem: we need to provide initial values for all model parameters! It is not irrelevant; indeed, if our guesses are not close enough to least squares estimates, the algorithm may freeze during the estimation process and may not reach convergence. Unfortunately, guessing good initial values for model parameters is not always easy, especially for students and practitioners. This is where self-starters come in handy.&lt;/p&gt;
&lt;p&gt;Self-starter functions can automatically calculate initial values for any given dataset and, therefore, they can make nonlinear regression analysis as smooth as linear regression analysis. From a teaching perspective, this means that the transition from linear to nonlinear models is immediate and hassle-free!&lt;/p&gt;
&lt;p&gt;In a recent post (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_nls_selfstarting/&#34;&gt;see here&lt;/a&gt;) I gave detail on how self-starters can be built, both for the ‘nls()’ function in the ‘stats’ package and for the ‘drm()’ function in the ‘drc’ package (Ritz et al., 2019). Both ‘nls()’ and ‘drm()’ can be used to fit nonlinear regression models in R and the respective packages already contain several robust self-starting functions. I am a long-time user of both ‘nls()’ and ‘drm()’ and I have little-by-little built a rather wide knowledge base of self-starters for both. I’ll describe them in this post; they are available within the package ‘aomisc’, that is the accompanying package for this blog.&lt;/p&gt;
&lt;p&gt;First of all, we need to install this package (if necessary) and load it, by using the code below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#installing package, if not yet available
# library(devtools)
# install_github(&amp;quot;onofriandreapg/aomisc&amp;quot;)

# loading package
library(aomisc)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;div id=&#34;functions-and-curve-shapes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Functions and curve shapes&lt;/h1&gt;
&lt;p&gt;Nonlinear regression functions are usually classified according to the shape they show when they are plotted in a XY-graph. Such an approach is taken, e.g., in the great book of Ratkowsky (1990). The following classification is heavily based on that book:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Polynomials
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#straight-line-function&#34;&gt;Straight line function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#quadratic-polynomial-function&#34;&gt;Quadratic polynomial function&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Concave/Convex curves (no inflection)
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#exponential-function&#34;&gt;Exponential function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#asymptotic-function&#34;&gt;Asymptotic function / Negative exponential function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#power-function&#34;&gt;Power curve function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#logarithmic-function&#34;&gt;Logarithmic function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rectangular-hyperbola&#34;&gt;Rectangular hyperbola&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Sigmoidal curves
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#logistic-function&#34;&gt;Logistic function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#gompertz-function&#34;&gt;Gompertz function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#modified-gompertz-function&#34;&gt;Modified Gompertz function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#log-logistic-function&#34;&gt;Log-logistic function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#weibull-function-type-1&#34;&gt;Weibull (type 1) function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#weibull-function-type-2&#34;&gt;Weibull (type 2) function&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Curves with maxima/minima
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#bragg-function&#34;&gt;Bragg function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lorentz-function&#34;&gt;Lorentz function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#beta-function&#34;&gt;Beta function&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s go through these functions and see how we can fit them both with ‘nls()’ and ‘drm()’, by using the appropriate self-starters. There are many functions and, therefore, the post is rather long… however, you can look at the graph below to spot the function you are interested in and use the link above to reach the relevant part in this web page.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span style=&#34;display:block;&#34; id=&#34;fig:unnamed-chunk-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-2-1.png&#34; alt=&#34;The shapes of the most important functions&#34; width=&#34;95%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: The shapes of the most important functions
&lt;/p&gt;
&lt;/div&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;polynomials&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Polynomials&lt;/h1&gt;
&lt;p&gt;Polynomials are a group on their own, as they are characterized by very flexible shapes, which can be used to describe several different biological processes. They are simple and, although they may be curvilinear, they are always linear in the parameters and can be fitted by using least squares methods. One disadvantage is that they cannot describe asymptotic processes, which are very common in biology. Furthermore, polynomials are prone to overfitting, as we may be tempted to add terms to improve the fit, with little care for biological realism.&lt;/p&gt;
&lt;p&gt;Nowadays, thanks to the wide availability of nonlinear regression algorithms, the use of polynomials has sensibly decreased; linear or quadratic polynomials are mainly used when we want to approximate the observed response within a narrow range of a quantitative predictor. On the other hand, higher order polynomials are very rarely seen, in practice.&lt;/p&gt;
&lt;div id=&#34;straight-line-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Straight line function&lt;/h2&gt;
&lt;p&gt;Among the polynomials, we should cite the straight line. Obviously, this is not a curve, although it deserves to be mentioned here. The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = b_0 + b_1 \, X \quad \quad \quad (1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(b_0\)&lt;/span&gt; is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b_1\)&lt;/span&gt; is the slope, i.e. the increase/decrease in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for a unit-increase in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The Y increases as X increases when &lt;span class=&#34;math inline&#34;&gt;\(b_1 &amp;gt; 0\)&lt;/span&gt;, otherwise it decreases. Straight lines are the most common functions for regression and they are most often used to approximate biological phenomena within a small range for the predictor.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quadratic-polynomial-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quadratic polynomial function&lt;/h2&gt;
&lt;p&gt;The quadratic polynomial is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = b_0 + b_1\, X + b_2 \, X^2 \quad \quad \quad (2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(b_0\)&lt;/span&gt; is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;, while &lt;span class=&#34;math inline&#34;&gt;\(b_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b_2\)&lt;/span&gt;, taken separately, lack a clear biological meaning. However, it is interesting to consider the first derivative, which measures the rate at which the value &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; changes with respect to the change of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. Calculating a derivative may be tricky for biologists; however, we can make use of the available facilities in R, represented by the D() function, which requires an expression as the argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a + b*X + c*X^2), &amp;quot;X&amp;quot;)
## b + c * (2 * X)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the first derivative is not constant, but it changes according to the level of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The stationary point, i.e. the point at which the derivative is zero, is &lt;span class=&#34;math inline&#34;&gt;\(X_m = - b_1 / 2 b_2\)&lt;/span&gt;; this point is a maximum when &lt;span class=&#34;math inline&#34;&gt;\(b_2 &amp;gt; 0\)&lt;/span&gt;, otherwise it is a minimum.&lt;/p&gt;
&lt;p&gt;The maximum/minimum value is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_m = \frac{4\,b_0\,b_2 - b_1^2}{4\,b_2}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;polynomial-fitting-in-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Polynomial fitting in R&lt;/h2&gt;
&lt;p&gt;In R, polynomials are fitted by using ‘lm()’. In a couple of cases, I found myself in the need of fitting a polynomial by using nonlinear regression with ‘nls()’ o ‘drm()’. I know, this is not efficient…, but some methods for ‘drc’ objects are rather handy. For these unusual cases, we can use the &lt;code&gt;NLS.linear()&lt;/code&gt;, &lt;code&gt;NLS.poly2()&lt;/code&gt;, &lt;code&gt;DRC.linear()&lt;/code&gt; and &lt;code&gt;DRC.poly2()&lt;/code&gt; self-starting functions, as available in the ‘aomisc’ package. An example of usage is given below: in this case, the polynomial has been used to describe a concave increasing trend.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- seq(5, 50, 5)
Y &amp;lt;- c(12.6, 74.1, 157.6, 225.5, 303.4, 462.8, 
       669.9, 805.3, 964.2, 1169)

# nls fit
model &amp;lt;- nls(Y ~ NLS.poly2(X, a, b, c))

#drc fit
model &amp;lt;- drm(Y ~ X, fct = DRC.poly2())
summary(model)
## 
## Model fitted: Second Order Polynomial (3 parms)
## 
## Parameter estimates:
## 
##                 Estimate Std. Error t-value  p-value    
## a:(Intercept) -23.515000  31.175143 -0.7543  0.47528    
## b:(Intercept)   5.466470   2.604011  2.0993  0.07395 .  
## c:(Intercept)   0.371561   0.046141  8.0527 8.74e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  26.50605 (7 degrees of freedom)
 r
plot(model, log = &amp;quot;&amp;quot;, main = &amp;quot;2nd order polynomial&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;concaveconvex-curves&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Concave/Convex curves&lt;/h1&gt;
&lt;div id=&#34;exponential-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exponential function&lt;/h2&gt;
&lt;p&gt;The exponential function describes an increasing/decreasing trend, with constant relative rate. The most common equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = a  e^{k X} \quad \quad \quad (3) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Two additional and equivalent parameterisations are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = a  b^X  =  e^{d + k X} \quad \quad \quad (4)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The Equations 3 and the two equations 4 are equivalent, as proved by setting &lt;span class=&#34;math inline&#34;&gt;\(b = e^k\)&lt;/span&gt; e &lt;span class=&#34;math inline&#34;&gt;\(a = e^d\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a  b^X  = a  (e^k)^{X} =  a  e^{kX}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a  e^{kX} = e^d \cdot e^{kX} =  e^{d + kX}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The meaning of &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is clear: this is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;. In order to understand the meaning of &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, we can calculate the first derivative of the exponential function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a * exp(k * X)), &amp;quot;X&amp;quot;)
## a * (exp(k * X) * k)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From there, we see that the ratio of increase/decrease of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{dY}{dX} = k \, a \, e^{k \, X} = k \, Y\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;That is, the relative ratio of increase/decrease is constant and equal to &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{dY}{dX} \frac{1}{Y} = k\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases if &lt;span class=&#34;math inline&#34;&gt;\(k &amp;gt; 0\)&lt;/span&gt; (exponential growth), while it decreases when &lt;span class=&#34;math inline&#34;&gt;\(k &amp;lt; 0\)&lt;/span&gt; (exponential decay). This curve is used to describe the growth of populations in non-limiting environmental conditions, or to describe the degradation of xenobiotics in the environment (first-order degradation kinetic).&lt;/p&gt;
&lt;p&gt;Another slightly different parameterisation exists, which is common in bioassay work and it is mainly used as an exponential decay model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = d \exp(-x/e) \quad \quad \quad (5)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the same as &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; in the model above and &lt;span class=&#34;math inline&#34;&gt;\(e = - 1/k\)&lt;/span&gt;. For all the aforementioned exponential decay equations &lt;span class=&#34;math inline&#34;&gt;\(Y \rightarrow 0\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow \infty\)&lt;/span&gt;. In the above curve, a lower asymptote &lt;span class=&#34;math inline&#34;&gt;\(c \neq 0\)&lt;/span&gt; can also be included, for those situations where the phenomenon under study does not approach 0 when the independent variable approaches infinity:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d -c) \exp(-x/e) \quad \quad \quad (6)\]&lt;/span&gt;
The exponential function is nonlinear in &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; and needs to be fitted by using ‘nls()’ or ‘drm()’. Several self-starting functions are available: in the package &lt;code&gt;aomisc&lt;/code&gt; you can find &lt;code&gt;NLS.expoGrowth()&lt;/code&gt;, &lt;code&gt;NLS.expoDecay()&lt;/code&gt;, &lt;code&gt;DRC.expoGrowth()&lt;/code&gt; and &lt;code&gt;DRC.expoDecay()&lt;/code&gt;, which can be used to fit the Equation 3, respectively with ‘nls()’ and ‘drm()’. The ‘drc’ package also contains the functions &lt;code&gt;EXD.2()&lt;/code&gt; and &lt;code&gt;EXD.3()&lt;/code&gt;, which can be used to fit, respectively, the Equations 5 and 6. Examples of usage are given below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(degradation)

# nls fit
model &amp;lt;- nls(Conc ~ NLS.expoDecay(Time, a, k),
             data = degradation)

# drm fit
model &amp;lt;- drm(Conc ~ Time, fct = DRC.expoDecay(),
             data = degradation)
summary(model)
## 
## Model fitted: Exponential Decay Model (2 parms)
## 
## Parameter estimates:
## 
##                  Estimate Std. Error t-value   p-value    
## C0:(Intercept) 99.6349312  1.4646680  68.026 &amp;lt; 2.2e-16 ***
## k:(Intercept)   0.0670391  0.0019089  35.120 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  2.621386 (22 degrees of freedom)
 r
plot(model, log = &amp;quot;&amp;quot;, main = &amp;quot;Exponential decay&amp;quot;, ylim = c(0, 110))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;asymptotic-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Asymptotic function&lt;/h2&gt;
&lt;p&gt;The asymptotic function can be used to model the growth of a population/individual, where &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; approaches an horizontal asymptote as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; tends to infinity. This function is used in several different parameterisations and it is also known as the monomolecular growth function, the Mitscherlich law or the von Bertalanffy law. Due to its biological meaning, the most widespread parameterisation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a - (a - b) \, \exp (- c  X) \quad \quad \quad (7)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is the maximum attainable value for &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; (plateau), &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the initial &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; value (at &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;) and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is proportional to the relative rate of increase for &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases. Indeed, we can see that the first derivative is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a - (a - b) * exp (- c * X)), &amp;quot;X&amp;quot;)
## (a - b) * (exp(-c * X) * c)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;that is, the absolute ratio of increase of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at a given &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is not constant, but depends on the attained value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{dY}{dX} = c \, (a - Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If we consider the relative rate of increase of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, we see that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{dY}{dX} \frac{1}{Y} = c \, \frac{(a - Y)}{Y}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It means that the relative rate of increase of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is maximum at the beginning and approaches 0 when &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; approaches the plateau &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In order to fit the asymptotic function, the ‘aomisc’ package contains the self-starting routines &lt;code&gt;NLS.asymReg()&lt;/code&gt; and &lt;code&gt;DRC.asymReg()&lt;/code&gt;, which can be used, respectively, with ‘nls()’ and ‘drm()’. The ‘drc’ package contains the function &lt;code&gt;AR.3()&lt;/code&gt;, that is a similar parameterisation where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(e = 1/c\)&lt;/span&gt;. The ‘nlme’ package also contains an alternative parameterisation, named &lt;code&gt;SSasymp()&lt;/code&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(\phi_3 = \log(c)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s see an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- c(1, 3, 5, 7, 9, 11, 13, 20)
Y &amp;lt;- c(8.22, 14.0, 17.2, 16.9, 19.2, 19.6, 19.4, 19.6)

# nls fit
model &amp;lt;- nls(Y ~ NLS.asymReg(X, init, m, plateau) )

# drm fit
model &amp;lt;- drm(Y ~ X, fct = DRC.asymReg())
plot(model, log=&amp;quot;&amp;quot;, main = &amp;quot;Asymptotic regression&amp;quot;, 
     ylim = c(0,25), xlim = c(0,20))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;If we take the asymptotic function and set &lt;span class=&#34;math inline&#34;&gt;\(b = 0\)&lt;/span&gt;, we get the negative exponential function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a [1 -  \exp (- c  X) ] \quad \quad \quad (8)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This function shows a similar shape as the asymptotic function, but &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is 0 when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is 0 (the curve passes through the origin). It is often used to model the absorbed Photosintetically Active Radiation (&lt;span class=&#34;math inline&#34;&gt;\(Y = PAR_a\)&lt;/span&gt;) as a function of Leaf Area Index (X = LAI). In this case, &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; represents the incident PAR (&lt;span class=&#34;math inline&#34;&gt;\(a = PAR_i\)&lt;/span&gt;), and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; represents the extinction coefficient.&lt;/p&gt;
&lt;p&gt;In order to fit the Equation 8, we can use the self-starters &lt;code&gt;NLS.negExp()&lt;/code&gt; with ‘nls()’ and &lt;code&gt;DRC.negExp()&lt;/code&gt; with ‘drm()’; both self-starters are available within the ‘aomisc’ package. The ‘drc’ package contains the function &lt;code&gt;AR.2()&lt;/code&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(e = 1/c\)&lt;/span&gt;. The ‘nlme’ package also contains an alternative parameterisation, named &lt;code&gt;SSasympOrig()&lt;/code&gt;, where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(\phi_3 = \log(c)\)&lt;/span&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;power-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Power function&lt;/h2&gt;
&lt;p&gt;The power function is also known as Freundlich function or allometric function and the most common parameterisation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a \, X^b \quad \quad \quad (9)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This curve is perfectly equivalent to an exponential curve on the logarithm of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. Indeed:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a\,X^b  = a\, e^{\log( X^b )}  = a\,e^{b \, \log(x)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This curve does not have an asymptote for &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow \infty\)&lt;/span&gt;. The slope (first derivative) of the curve is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a * X^b), &amp;quot;X&amp;quot;)
## a * (X^(b - 1) * b)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that both parameters relate to the ‘slope’ of the curve and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; dictates its shape. If &lt;span class=&#34;math inline&#34;&gt;\(0 &amp;lt; b &amp;lt; 1\)&lt;/span&gt;, the response &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases and the curve is convex up. If &lt;span class=&#34;math inline&#34;&gt;\(b &amp;lt; 0\)&lt;/span&gt;, the curve is concave up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; decreases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases. Otherwise, if &lt;span class=&#34;math inline&#34;&gt;\(b &amp;gt; 1\)&lt;/span&gt;, the curve is concave up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases. The three curve types are shown in Figure 1, above.&lt;/p&gt;
&lt;p&gt;The power function (Freundlich equation) is often used in agricultural chemistry, e.g. to model the sorption of xenobiotics in soil. It is also used to model the number of plant species as a function of sampling area (Muller-Dumbois method). The following example uses the &lt;code&gt;DRC.powerCurve()&lt;/code&gt; and &lt;code&gt;NLS.powerCurve()&lt;/code&gt; self starters in the ‘aomisc’ package to fit a species-area curve.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(speciesArea)

#nls fit
model &amp;lt;- nls(numSpecies ~ NLS.powerCurve(Area, a, b),
             data = speciesArea)

# drm fit
model &amp;lt;- drm(numSpecies ~ Area, fct = DRC.powerCurve(),
             data = speciesArea)
summary(model)
## 
## Model fitted: Power curve (Freundlich equation) (2 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## a:(Intercept) 4.348404   0.337197  12.896 3.917e-06 ***
## b:(Intercept) 0.329770   0.016723  19.719 2.155e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.9588598 (7 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;logarithmic-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logarithmic function&lt;/h2&gt;
&lt;p&gt;This is indeed a linear model on log-transformed &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y = a + b \, \log(X) \quad \quad \quad (10)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Due to the logarithmic function, it must be &lt;span class=&#34;math inline&#34;&gt;\(X &amp;gt; 0\)&lt;/span&gt;. The parameter &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; dictates the shape: if &lt;span class=&#34;math inline&#34;&gt;\(b &amp;gt; 0\)&lt;/span&gt;, the curve is convex up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases. If &lt;span class=&#34;math inline&#34;&gt;\(b &amp;lt; 0\)&lt;/span&gt;, the curve is concave up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; decreases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases, as shown in Figure 1 above.&lt;/p&gt;
&lt;p&gt;The logarithmic equation can be fit by using ‘lm()’. If necessary, it can also be fit by using ‘nls()’ and ‘drm()’: the self-starting functions &lt;code&gt;NLS.logCurve()&lt;/code&gt; and &lt;code&gt;DRC.logCurve()&lt;/code&gt; are available within the ‘aomisc’ package. We show an example of their usage in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- c(1,2,4,5,7,12)
Y &amp;lt;- c(1.97, 2.32, 2.67, 2.71, 2.86, 3.09)

# lm fit
model &amp;lt;- lm(Y ~ log(X) )

# nls fit
model &amp;lt;- nls(Y ~ NLS.logCurve(X, a, b) )

# drm fit
model &amp;lt;- drm(Y ~ X, fct = DRC.logCurve() )&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;rectangular-hyperbola&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rectangular hyperbola&lt;/h2&gt;
&lt;p&gt;This function is also known as the Michaelis-Menten function and it is often parameterised as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = \frac{a \, X} {b + X} \quad \quad \quad (11)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The curve is convex up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases, up to a plateau level. The parameter &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; represents the higher asymptote (for &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow \infty\)&lt;/span&gt;), while &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the X value giving a response equal to &lt;span class=&#34;math inline&#34;&gt;\(a/2\)&lt;/span&gt;. Indeed, it is easily shown that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{a}{2} = \frac{a\,X_{50} } {b + X_{50} } \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which leads to &lt;span class=&#34;math inline&#34;&gt;\(b = x_{50}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The slope (first derivative) is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression( (a*X) / (b + X) ), &amp;quot;X&amp;quot;)
## a/(b + X) - (a * X)/(b + X)^2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From there, we can see that the initial slope (at &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;) is $i = a/b $. The equation 11 is not defined for &lt;span class=&#34;math inline&#34;&gt;\(X = b\)&lt;/span&gt; and it makes no biological sense for &lt;span class=&#34;math inline&#34;&gt;\(X &amp;lt; b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;An alternative parameterisation is obtained considering that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = \frac{a \, X} {b + X} = \frac{a}{ \frac{b}{X} + \frac{X}{X}} = \frac{a}{1 + \frac{b}{X}} \quad \quad \quad (12)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This parameterisation is sometimes used in bioassays and it is parameterised with &lt;span class=&#34;math inline&#34;&gt;\(d = a\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e = b\)&lt;/span&gt;. From a strict mathematical point of view, the equation 12 is not defined for &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;, although it approaches 0 when &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The Michaelis-Menten function is used in pesticide chemistry, enzyme kinetics and in weed competition studies, to model yield losses as a function of weed density. In R, this model can be fit by using ‘nls()’ and the self-starting functions &lt;code&gt;SSmicmen()&lt;/code&gt;, within the package ‘nlme’. If you prefer a ‘drm()’ fit, you can use the &lt;code&gt;MM.2()&lt;/code&gt; function in the ‘drc’ package, which uses the parameterisation in Equation 12.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- c(0, 5, 7, 22, 28, 39, 46, 200)
Y &amp;lt;- c(12.74, 13.66, 14.11, 14.43, 14.78, 14.86, 14.78, 14.91)

#drm fit
model &amp;lt;- drm(Y ~ X, fct = MM.2())
summary(model)
## 
## Model fitted: Michaelis-Menten (2 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value  p-value   
## d:(Intercept) 14.93974    2.86695  5.2110 0.001993 **
## e:(Intercept)  0.45439    2.24339  0.2025 0.846183   
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  5.202137 (6 degrees of freedom)
 r
plot(model, log = &amp;quot;&amp;quot;, main = &amp;quot;Michaelis-Menten function&amp;quot;, 
     ylim = c(12, 15))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;sigmoidal-curves&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sigmoidal curves&lt;/h1&gt;
&lt;p&gt;Sigmoidal curves are S-shaped and they may be increasing, decreasing, symmetric or non-symmetric around the inflection point. They are parameterised in countless ways, which may often be confusing. I will show some widespread parameterisations, that are very useful for bioassays or growth studies. All curves can be turned from increasing to decreasing (and vice-versa) by reversing the sign of the &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; parameter.&lt;/p&gt;
&lt;div id=&#34;logistic-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic function&lt;/h2&gt;
&lt;p&gt;The logistic curve derives from the cumulative logistic distribution function; the curve is symmetric around the inflection point and it may be parameterised as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = c + \frac{d - c}{1 + exp(- b (X - e))} \quad \quad \quad (13)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the higher asymptote, &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is the lower asymptote, &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; value at the inflection point, while &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the slope at the inflection point. As the curve is symmetric, &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; represents also the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; value producing a response half-way between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; (usually known as the ED50, in biological assay). The parameter &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; can be positive or negative and, consequently, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; may increase or decrease as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;p&gt;The above function is known as the four-parameter logistic. If necessary, constraints can be put on parameter values, i.e. &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; can be constrained to 0 (three-parameter logistic) and, additionally, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; can be constrained to 1 (two-parameter logistic).&lt;/p&gt;
&lt;p&gt;In the ‘aomisc’ package, the three logistic curves (four-, three- and two-parameters) are available as &lt;code&gt;NLS.L4()&lt;/code&gt;, &lt;code&gt;NLS.L3()&lt;/code&gt; and &lt;code&gt;NLS.L2()&lt;/code&gt;, respectively. With ‘drm()’, we can use the self-starting functions &lt;code&gt;L.4()&lt;/code&gt; and &lt;code&gt;L.3()&lt;/code&gt; in the package ‘drc’, while the &lt;code&gt;L.2()&lt;/code&gt; function for the two-parameter logistic has been included in the ‘aomisc’ package. The only difference between the self-starters for ‘drm()’ and the self-starters for ‘nls()’ is that, in the former, the sign for the &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; parameter is reversed, i.e. it is negative for increasing curves and positive for decreasing curves.&lt;/p&gt;
&lt;p&gt;The four- and three-parameter logistic curves can also be fit with ‘nls()’, respectively with the self-starting functions &lt;code&gt;SSfpl()&lt;/code&gt; and &lt;code&gt;SSlogis()&lt;/code&gt;, in the ‘nlme’ package. In these functions, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(scal = -1/b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In the box below, I show an example, regarding the growth of a sugar-beet crop.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(beetGrowth)

# nls fit
model &amp;lt;- nls(weightInf ~ NLS.L3(DAE, b, d, e), data = beetGrowth)
model.2 &amp;lt;- nls(weightInf ~ NLS.L4(DAE, b, c, d, e), data = beetGrowth)
model.3 &amp;lt;- nls(weightInf/max(weightInf) ~ NLS.L2(DAE, b, e), data = beetGrowth)

# drm fit
model &amp;lt;- drm(weightInf ~ DAE, fct = L.3(), data = beetGrowth)
model.2 &amp;lt;- drm(weightInf ~ DAE, fct = L.4(), data = beetGrowth)
model.3 &amp;lt;- drm(weightInf/max(weightInf) ~ DAE, fct = L.2(), data = beetGrowth)
summary(model)
## 
## Model fitted: Logistic (ED50 as parameter) with lower limit fixed at 0 (3 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## b:(Intercept) -0.118771   0.018319 -6.4835 1.032e-05 ***
## d:(Intercept) 25.118357   1.279417 19.6327 4.127e-12 ***
## e:(Intercept) 58.029764   1.834414 31.6340 3.786e-15 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  2.219389 (15 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;, main = &amp;quot;Logistic function&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;gompertz-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gompertz function&lt;/h2&gt;
&lt;p&gt;The Gompertz curve is parameterised in very many ways. I tend to prefer a parameterisation that resembles the one used for the logistic function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \exp \left\{- \exp \left[ - b \, (X - e) \right] \right\} \quad \quad \quad (14)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The difference between the logistic and Gompertz functions is that this latter is not symmetric around the inflection point: it shows a longer lag at the beginning, but raises steadily afterwards. The parameters have the same meaning as those in the logistic function, apart from the fact that &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;, i.e. the abscissa of the inflection point, does not give a response half-way between &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. As for the logistic, we can have four-, three- and two-parameter Gompertz functions, which can be used to describe plant growth or several other biological processes.&lt;/p&gt;
&lt;p&gt;In R, the Gompertz equation can be fit by using ‘drm()’ and, respectively the &lt;code&gt;G.4()&lt;/code&gt;, &lt;code&gt;G.3()&lt;/code&gt; and &lt;code&gt;G.2()&lt;/code&gt; self-starters. With ‘nls’, the ‘aomisc’ package contains the corresponding functions &lt;code&gt;NLS.G4()&lt;/code&gt;, &lt;code&gt;NLS.G3()&lt;/code&gt; and &lt;code&gt;NLS.G2()&lt;/code&gt;. As for the logistic, the only difference between the self starters for ‘drm()’ and the self starters for ‘nls()’ is that, in the former, the sign for the &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; parameter is reversed, i.e. it is negative for increasing curves and positive for decreasing curves.&lt;/p&gt;
&lt;p&gt;The three-parameter Gompertz can also be fit with ‘nls()’, by using the &lt;code&gt;SSGompertz()&lt;/code&gt; self-starter in the ‘nlme’ package, although this is a different parameterisation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# nls fit
model &amp;lt;- nls(weightFree ~ NLS.G3(DAE, b, d, e), data = beetGrowth)
model.2 &amp;lt;- nls(weightFree ~ NLS.G4(DAE, b, c, d, e), data = beetGrowth)
model.3 &amp;lt;- nls(weightFree/max(weightFree) ~ NLS.G2(DAE, b, e), data = beetGrowth)

# drm fit
model &amp;lt;- drm(weightFree ~ DAE, fct = G.3(), data = beetGrowth)
model.2 &amp;lt;- drm(weightFree ~ DAE, fct = G.4(), data = beetGrowth)
model.3 &amp;lt;- drm(weightFree/max(weightFree) ~ DAE, fct = G.2(), data = beetGrowth)
summary(model)
## 
## Model fitted: Gompertz with lower limit at 0 (3 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## b:(Intercept) -0.122255   0.029938 -4.0836 0.0009783 ***
## d:(Intercept) 35.078529   1.668665 21.0219 1.531e-12 ***
## e:(Intercept) 49.008075   1.165191 42.0601 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  2.995873 (15 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;, main = &amp;quot;Gompertz function&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;modified-gompertz-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Modified Gompertz function&lt;/h2&gt;
&lt;p&gt;We have seen that the logistic curve is symmetric around the inflection point, while the Gompertz shows a longer lag at the beginning and raises steadily afterwards. We can describe a different pattern by modifying the Gompertz function as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \left\{ 1 - \exp \left\{- \exp \left[ b \, (X - e) \right] \right\} \right\} \quad \quad \quad (15)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The resulting curve increases steadily at the beginning, but slows down later on. Also for this function, we can put constraints on &lt;span class=&#34;math inline&#34;&gt;\(d = 1\)&lt;/span&gt; and/or &lt;span class=&#34;math inline&#34;&gt;\(c = 0\)&lt;/span&gt;, so that we have four-parameter, three-parameter and two-parameter modified Gompertz equations; these models can be fit by using ‘nls()’ and the self starters &lt;code&gt;NLS.E4()&lt;/code&gt;, &lt;code&gt;NLS.E3()&lt;/code&gt; and &lt;code&gt;NLS.E2()&lt;/code&gt; in the ‘aomisc’ package. Likewise, the modified Gompertz equations can be fit with ‘drm()’ and the self starters &lt;code&gt;E.4()&lt;/code&gt;, &lt;code&gt;E.3()&lt;/code&gt; and &lt;code&gt;E.2()&lt;/code&gt;, also available in the ‘aomisc’ package&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# nls fit
model &amp;lt;- nls(weightInf ~ NLS.E3(DAE, b, d, e), data = beetGrowth)
model.2 &amp;lt;- nls(weightFree ~ NLS.E4(DAE, b, c, d, e), data = beetGrowth)
model.3 &amp;lt;- nls(I(weightFree/max(weightFree)) ~ NLS.E2(DAE, b, e), data = beetGrowth)


# drm fit
model &amp;lt;- drm(weightInf ~ DAE, fct = E.3(), data = beetGrowth)
model.2 &amp;lt;- drm(weightFree ~ DAE, fct = E.4(), data = beetGrowth)
model.3 &amp;lt;- drm(weightFree/max(weightFree) ~ DAE, fct = E.2(), data = beetGrowth)
summary(model)
## 
## Model fitted: Modified Gompertz equation (3 parameters) (3 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## b:(Intercept)  0.092508   0.013231  6.9917 4.340e-06 ***
## d:(Intercept) 25.107004   1.304379 19.2482 5.493e-12 ***
## e:(Intercept) 63.004111   1.747087 36.0624 4.945e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  2.253878 (15 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;, main = &amp;quot;Modified Gompertz&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;log-logistic-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Log-logistic function&lt;/h2&gt;
&lt;p&gt;The log-logistic curve is symmetric on the logarithm of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; (a log-normal curve would be practically equivalent, but it is used far less often). For example, in biologic assays (but also in germination assays), the log-logistic curve is defined as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = c + \frac{d - c}{1 + \exp \left\{ - b \left[ \log(X) - \log(e) \right] \right\} } \quad \quad \quad (16)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The parameters have the same meaning as the logistic equation given above. In particular, &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; represents the X-level which gives a response half-way between &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; (ED50). It is easy to see that the above equation is equivalent to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = c + \frac{d - c}{1 + \left( \frac{X}{e} \right)^{-b}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Log-logistic functions are used for crop growth, seed germination and bioassay work and they can have the same constraints as the logistic function (four- three- and two-parameter log-logistic). They can be fit by ‘drm()’ and the self starters &lt;code&gt;LL.4()&lt;/code&gt; (four-parameter log-logistic), &lt;code&gt;LL.3()&lt;/code&gt; (three-parameter log-logistic, with &lt;span class=&#34;math inline&#34;&gt;\(c = 0\)&lt;/span&gt;) and &lt;code&gt;LL.2()&lt;/code&gt; (two-parameter log-logistic, with &lt;span class=&#34;math inline&#34;&gt;\(d = 1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c = 0\)&lt;/span&gt;), as available in the ‘drc’ package. With respect to Equation 16, in these self-starters the sign for &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is reversed, i.e. it is negative for the increasing log-logistic curve and positive for the decreasing curve. In the package ‘aomisc’, the corresponding self starters for ‘nls()’ are &lt;code&gt;NLS.LL4()&lt;/code&gt;, &lt;code&gt;NLS.LL3()&lt;/code&gt; and &lt;code&gt;NLS.LL2()&lt;/code&gt;, which are all derived from Equation 15 (i.e. the sign of &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is positive for increasing curves and negative for decreasing curves).&lt;/p&gt;
&lt;p&gt;We show an example of a log-logistic fit, relating to a bioassay with &lt;em&gt;Brassica rapa&lt;/em&gt; treated at increasing dosages of an herbicide.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(brassica)

model &amp;lt;- nls(FW ~ NLS.LL4(Dose, b, c, d, e), data = brassica)
model &amp;lt;- nls(FW ~ NLS.LL3(Dose, b, d, e), data = brassica)
model &amp;lt;- nls(FW/max(FW) ~ NLS.LL2(Dose, b, e), data = brassica)

model &amp;lt;- drm(FW ~ Dose, fct = LL.4(), data = brassica)
summary(model)
## 
## Model fitted: Log-logistic (ED50 as parameter) (4 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## b:(Intercept)  1.45113    0.24113  6.0181 1.743e-06 ***
## c:(Intercept)  0.34948    0.18580  1.8810   0.07041 .  
## d:(Intercept)  4.53636    0.20514 22.1140 &amp;lt; 2.2e-16 ***
## e:(Intercept)  2.46557    0.35111  7.0221 1.228e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.4067837 (28 degrees of freedom)
 r
plot(model, ylim = c(0,6), main = &amp;quot;Log-logistic function&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;weibull-function-type-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Weibull function (type 1)&lt;/h2&gt;
&lt;p&gt;The type 1 Weibull function corresponds to the Gompertz, but it is based on the logarithm of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The equation is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \exp \left\{- \exp \left[ - b \, (\log(X) - \log(e)) \right] \right\} \quad \quad \quad (17)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The parameters have the same meaning as the other sigmoidal curves given above, apart from the fact that &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is the abscissa of the inflection point, but it is not the ED50.&lt;/p&gt;
&lt;p&gt;The four-parameters, three-parameters and two-parameters Weibull functions can be fit by using ‘drm()’ and the self-starters available within the ‘drc’ package, i.e. &lt;code&gt;W1.4()&lt;/code&gt;, &lt;code&gt;W1.3()&lt;/code&gt; and &lt;code&gt;W1.2()&lt;/code&gt;. The ‘aomisc’ package contains the corresponding self-starters &lt;code&gt;NLS.W1.4()&lt;/code&gt;, &lt;code&gt;NLS.W1.3()&lt;/code&gt; and &lt;code&gt;NLS.W1.2()&lt;/code&gt;, which can be used with ‘nls()’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(brassica)

model &amp;lt;- nls(FW ~ NLS.W1.4(Dose, b, c, d, e), data = brassica)
model.2 &amp;lt;- nls(FW ~ NLS.W1.3(Dose, b, d, e), data = brassica)
model.3 &amp;lt;- nls(FW/max(FW) ~ NLS.W1.2(Dose, b, e), data = brassica)

model &amp;lt;- drm(FW ~ Dose, fct = W1.4(), data = brassica)
model.2 &amp;lt;- drm(FW ~ Dose, fct = W1.3(), data = brassica)
model.3 &amp;lt;- drm(FW/max(FW) ~ Dose, fct = W1.2(), data = brassica)
summary(model)
## 
## Model fitted: Weibull (type 1) (4 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## b:(Intercept)  1.01252    0.15080  6.7143 2.740e-07 ***
## c:(Intercept)  0.50418    0.14199  3.5507  0.001381 ** 
## d:(Intercept)  4.56137    0.19846 22.9841 &amp;lt; 2.2e-16 ***
## e:(Intercept)  3.55327    0.45039  7.8894 1.359e-08 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.3986775 (28 degrees of freedom)
 r
plot(model, ylim = c(0,6), main = &amp;quot;Weibull type 1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;weibull-function-type-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Weibull function (type 2)&lt;/h2&gt;
&lt;p&gt;The type 2 Weibull is similar to the type 1 Weibull, but describes a different type of asymmetry, corresponding to the modified Gompertz function above:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \left\{ 1 - \exp \left\{- \exp \left[ b \, (\log(X) - \log(e)) \right] \right\} \right\} \quad \quad \quad (18)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;As for fitting, the ‘drc’ package contains the self-starting functions &lt;code&gt;W2.4()&lt;/code&gt;, &lt;code&gt;W2.3()&lt;/code&gt; and &lt;code&gt;W2.2()&lt;/code&gt;, which can be used with ‘drm()’ (be careful: the sign for &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is reversed, with respect to Equation 18). The ‘aomisc’ package contains the corresponding self-starters &lt;code&gt;NLS.W2.4()&lt;/code&gt;, &lt;code&gt;NLS.W2.3()&lt;/code&gt; and &lt;code&gt;NLS.W2.2()&lt;/code&gt;, which can be used with ‘nls()’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(brassica)

model &amp;lt;- nls(FW ~ NLS.W2.4(Dose, b, c, d, e), data = brassica)
model.1 &amp;lt;- nls(FW ~ NLS.W2.3(Dose, b, d, e), data = brassica)
model.2 &amp;lt;- nls(FW/max(FW) ~ NLS.W2.2(Dose, b, e), data = brassica)

model &amp;lt;- drm(FW ~ Dose, fct = W2.4(), data = brassica)
summary(model)
## 
## Model fitted: Weibull (type 2) (4 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## b:(Intercept) -0.96191    0.17684 -5.4395 8.353e-06 ***
## c:(Intercept)  0.18068    0.25191  0.7173    0.4792    
## d:(Intercept)  4.53804    0.21576 21.0328 &amp;lt; 2.2e-16 ***
## e:(Intercept)  1.66342    0.25240  6.5906 3.793e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.4215551 (28 degrees of freedom)
 r
plot(model, ylim = c(0,6), main = &amp;quot;Weibull type 2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;curves-with-maximaminima&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Curves with maxima/minima&lt;/h1&gt;
&lt;p&gt;It is sometimes necessary to describe phenomena where the &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; variable reaches a maximum value at a certain level of the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; variable, and drops afterwords. For example, growth or germination rates are higher at optimal temperature levels and lower at supra-optimal or sub-optimal temperature levels. Another example relates to bioassays: in some cases, low doses of toxic substances induce a stimulation of growth (hormesis), which needs to be described by an appropriate model. Let’s see some functions which may turn out useful in these circumstances.&lt;/p&gt;
&lt;div id=&#34;bragg-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bragg function&lt;/h2&gt;
&lt;p&gt;This function is connected to the normal (Gaussian) distribution and has a symmetric shape with a maximum equal to &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, that is reached when &lt;span class=&#34;math inline&#34;&gt;\(X = e\)&lt;/span&gt; and two inflection points. In this model, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; relates to the slope at the inflection points; the response &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; approaches 0 when &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; approaches &lt;span class=&#34;math inline&#34;&gt;\(\pm \infty\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = d \, \exp \left[ - b (X - e)^2 \right] \quad \quad \quad (19)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If we would like to have lower asymptotes different from 0, we should add the parameter &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;, as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \, \exp \left[ - b (X - e)^2 \right] \quad \quad \quad (20)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The two Bragg curves have been used in applications relating to the science of carbon materials. We can fit them with ‘drm()’, by using the self starters &lt;code&gt;DRC.bragg.3()&lt;/code&gt; (Equation 19) and &lt;code&gt;DRC.bragg.4&lt;/code&gt; (Equation 20), in the ‘aomisc’ package. With ‘nls()’, you can use the corresponding self-starters &lt;code&gt;NLS.bragg.3()&lt;/code&gt; and &lt;code&gt;NLS.bragg.4&lt;/code&gt;, also in the ‘aomisc’ package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- c(5, 10, 15, 20, 25, 30, 35, 40, 45, 50)
Y1 &amp;lt;- c(0.1, 2, 5.7, 9.3, 19.7, 28.4, 20.3, 6.6, 1.3, 0.1)
Y2 &amp;lt;- Y1 + 2

# nls fit
mod.nls &amp;lt;- nls(Y1 ~ NLS.bragg.3(X, b, d, e) )
mod.nls2 &amp;lt;- nls(Y2 ~ NLS.bragg.4(X, b, c, d, e) )

# drm fit
mod.drc &amp;lt;- drm(Y1 ~ X, fct = DRC.bragg.3() )
mod.drc2 &amp;lt;- drm(Y2 ~ X, fct = DRC.bragg.4() )
plot(mod.drc, ylim = c(0, 30), log = &amp;quot;&amp;quot;) 
plot(mod.drc2, add = T, col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lorentz-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Lorentz function&lt;/h2&gt;
&lt;p&gt;The Lorentz function is similar to the Bragg function, although it has worse statistical properties (Ratkowsky, 1990). The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = \frac{d} { 1 + b (X - e)^2 } \quad \quad \quad (21)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can also allow for lower asymptotes different from 0, by adding a further parameter:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + \frac{d - c} { 1 + b (X - e)^2 } \quad \quad \quad (22)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The two Lorentz functions can be fit with ‘drm()’, by using the self-starters &lt;code&gt;DRC.lorentz.3()&lt;/code&gt; (Equation 21) and &lt;code&gt;DRC.lorentz.4&lt;/code&gt; (Equation 22), in the ‘aomisc’ package. With ‘nls()’, you can use the corresponding self-starters &lt;code&gt;NLS.lorentz.3()&lt;/code&gt; and &lt;code&gt;NLS.lorentz.4&lt;/code&gt;, also in the ‘aomisc’ package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- c(5, 10, 15, 20, 25, 30, 35, 40, 45, 50)
Y1 &amp;lt;- c(0.1, 2, 5.7, 9.3, 19.7, 28.4, 20.3, 6.6, 1.3, 0.1)
Y2 &amp;lt;- Y1 + 2

# nls fit
mod.nls &amp;lt;- nls(Y1 ~ NLS.lorentz.3(X, b, d, e) )
mod.nls2 &amp;lt;- nls(Y2 ~ NLS.lorentz.4(X, b, c, d, e) )

# drm fit
mod.drc &amp;lt;- drm(Y1 ~ X, fct = DRC.lorentz.3() )
mod.drc2 &amp;lt;- drm(Y2 ~ X, fct = DRC.lorentz.4() )
plot(mod.drc, ylim = c(0, 30), log = &amp;quot;&amp;quot;) 
plot(mod.drc2, add = T, col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;beta-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Beta function&lt;/h2&gt;
&lt;p&gt;The beta function derives from the beta density function and it has been adapted to describe phenomena taking place only within a minimum and a maximum threshold value (threshold model). One typical example is seed germination, where the germination rate (GR, i.e. the inverse of germination time) is 0 below the base temperature level and above the cutoff temperature level. Between these two extremes, the GR increases with temperature up to a maximum level, that is reached at the optimal temperature level.&lt;/p&gt;
&lt;p&gt;The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = d \,\left\{  \left( \frac{X - X_b}{X_o - X_b} \right) \left( \frac{X_c - X}{X_c - X_o} \right) ^ {\frac{X_c - X_o}{X_o - X_b}} \right\}^b \quad \quad \quad (23)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the maximum level for the expected response &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(X_b\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(X_c\)&lt;/span&gt; are, respectively, the minumum and maximum threshold levels, &lt;span class=&#34;math inline&#34;&gt;\(X_o\)&lt;/span&gt; is the abscissa at the maximum expected response level and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is a shape parameter. The above function is only defined for &lt;span class=&#34;math inline&#34;&gt;\(X_b &amp;lt; X &amp;lt; X_c\)&lt;/span&gt; and it returns 0 elsewhere.&lt;/p&gt;
&lt;p&gt;In R, the beta function can be fitted either with ‘drm()’ and the self-starter &lt;code&gt;DRC.beta()&lt;/code&gt;, or with ‘nls()’ and the self-starter &lt;code&gt;NLS.beta()&lt;/code&gt;. Both the self-starters are available within the ‘aomisc’ package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- c(1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50)
Y &amp;lt;- c(0, 0, 0, 7.7, 12.3, 19.7, 22.4, 20.3, 6.6, 0, 0)

model &amp;lt;- nls(Y ~ NLS.beta(X, b, d, Xb, Xo, Xc))
model &amp;lt;- drm(Y ~ X, fct = DRC.beta())
summary(model)
## 
## Model fitted: Beta function
## 
## Parameter estimates:
## 
##                Estimate Std. Error  t-value   p-value    
## b:(Intercept)   1.29834    0.26171   4.9609 0.0025498 ** 
## d:(Intercept)  22.30117    0.53645  41.5715 1.296e-08 ***
## Xb:(Intercept)  9.41770    1.15826   8.1309 0.0001859 ***
## Xo:(Intercept) 31.14068    0.58044  53.6504 2.815e-09 ***
## Xc:(Intercept) 40.47294    0.33000 122.6455 1.981e-11 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.7251948 (6 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;, main = &amp;quot;Beta function&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_usefulFunctions_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we are; I have discussed more than 20 models, which are commonly used for nonlinear regression. These models can be found in several different parameterisations and flavours; they can also be modified and combined to suit the needs of several disciplines in biology, chemistry and so on. However, this will require another post.&lt;/p&gt;
&lt;p&gt;Thanks for reading&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;further-readings&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Further readings&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Miguez, F., Archontoulis, S., Dokoohaki, H., Glaz, B., Yeater, K.M., 2018. Chapter 15: Nonlinear Regression Models and Applications, in: ACSESS Publications. American Society of Agronomy, Crop Science Society of America, and Soil Science Society of America, Inc. &lt;/li&gt;
&lt;li&gt;Ratkowsky, D.A., 1990. Handbook of nonlinear regression models. Marcel Dekker Inc., New York, USA.&lt;/li&gt;
&lt;li&gt;Ritz, C., Jensen, S. M., Gerhard, D., Streibig, J. C.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;2019&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Dose-Response Analysis Using R. CRC Press&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Self-starting routines for nonlinear regression models</title>
      <link>http://localhost:6346/2020/stat_nls_selfstarting/</link>
      <pubDate>Fri, 14 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2020/stat_nls_selfstarting/</guid>
      <description>


&lt;p&gt;(Post updated on 17/07/2023) In R, the &lt;code&gt;drc&lt;/code&gt; package represents one of the main solutions for nonlinear regression and dose-response analyses (Ritz et al., 2015). It comes with a lot of nonlinear models, which are useful to describe several biological processes, from plant growth to bioassays, from herbicide degradation to seed germination. These models are provided with self-starting functions, which free the user from the hassle of providing initial guesses for model parameters. Indeed, getting these guesses may be a tricky task, both for students and for practitioners.&lt;/p&gt;
&lt;p&gt;Obviously, we should not expect that all possible models and parameterisations are included in the ‘drc’ package; therefore, sooner or later, we may all find ourselves in the need of building a user-defined function, for some peculiar tasks of nonlinear regression analysis. I found myself in that position several times in the past and it took me awhile to figure out a solution.&lt;/p&gt;
&lt;p&gt;In this post, I’ll describe how we can simply build self-starters for our nonlinear regression analyses, to be used in connection with the ‘drm()’ function in the ‘drc’ package. In the end, I will also extend the approach to work with the ‘nls()’ function in the ‘stats’ package.&lt;/p&gt;
&lt;p&gt;Let’s consider the following dataset, depicting the relationship between temperature and growth rate. We may note that the response reaches a maximum value around 30°C, while it is lower below and above such an optimal value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(drc)
Temp &amp;lt;- c(5, 10, 15, 20, 25, 30, 35, 40, 45, 50)
RGR &amp;lt;- c(0.1, 2, 5.7, 9.3, 19.7, 28.4, 20.3, 6.6, 1.3, 0.1)
plot(RGR ~ Temp, xlim = c(5, 50), 
     xlab = &amp;quot;Temperature&amp;quot;, ylab = &amp;quot;Growth rate&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_selfStarting_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The Bragg equation can be a good candidate model for such a situation. It is characterized by a bell-like shape:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = d \, \exp \left[- b \, (X - e)^2 \right] \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is the observed growth rate, &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is the temperature, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the maximum level for the expected response, &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is the abscissa at which such maximum occurs and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the slope around the inflection points (the curve is bell-shaped and shows two inflection points around the maximum value). Unfortunately, such an equation is not already available within the &lt;code&gt;drc&lt;/code&gt; package. What should we do, then?&lt;/p&gt;
&lt;p&gt;First of all, let’s write this function in the usual R code. In my opinion, this is more convenient than writing it directly within the &lt;code&gt;drc&lt;/code&gt; framework; indeed, the usual R coding is not specific to any packages and can be used with all other nonlinear regression and plotting facilities, such as &lt;code&gt;nls()&lt;/code&gt;, or &lt;code&gt;nlme()&lt;/code&gt;. Let’s call this new function &lt;code&gt;bragg.3.fun()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Definition of Bragg function
bragg.3.fun &amp;lt;- function(X, b, d, e){
  d * exp(- b * (X - e)^2)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to transport ‘bragg.3.fun()’ into the &lt;code&gt;drc&lt;/code&gt; platform, we need to code a function returning a list of (at least) three components:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;a response function (fct)&lt;/li&gt;
&lt;li&gt;a self-starting routine (ssfct)&lt;/li&gt;
&lt;li&gt;a vector with the names of parameters (names)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Optionally, we can also include a descriptive text, the derivatives and other useful information. This is the skeleton code, which I use as the template.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MyNewDRCfun &amp;lt;- function(){

  fct &amp;lt;- function(x, parm) {
      # function code here
  }
  ssfct &amp;lt;- function(data){
     # Self-starting code here
  }
  names &amp;lt;- c()
  text &amp;lt;- &amp;quot;Descriptive text&amp;quot;
    
  ## Returning the function with self starter and names
  returnList &amp;lt;- list(fct = fct, ssfct = ssfct, names = names, text = text)
  class(returnList) &amp;lt;- &amp;quot;drcMean&amp;quot;
  invisible(returnList)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The two functions &lt;code&gt;fct()&lt;/code&gt; and &lt;code&gt;ssfct()&lt;/code&gt; are called internally by the &lt;code&gt;drm()&lt;/code&gt; function and, therefore, the list of arguments must be defined exactly as shown above. In detail, &lt;code&gt;fct()&lt;/code&gt; receives two arguments as inputs: the predictor &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and the dataframe of parameters, with one row and as many columns as there are parameters in the model. The predictor and parameters are used to return the vector of responses; in the code below, I am calling the function &lt;code&gt;bragg.3.fun()&lt;/code&gt; from within the function &lt;code&gt;fct()&lt;/code&gt;. Alternatively, the Bragg function can be directly coded within &lt;code&gt;fct()&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;fct &amp;lt;- function(x, parm) {
  bragg.3.fun(x, parm[,1], parm[,2], parm[,3])
  }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function &lt;code&gt;ssfct()&lt;/code&gt; receives one argument as input, that is a dataframe with the predictor in the first column and the observed response in the second. These two variables can be used to calculate the starting values for model parameters. In order to get a starting value for &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, we could take the maximum value for the observed response, by using the function &lt;code&gt;max()&lt;/code&gt;. Likewise, to get a starting value for &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;, we could take the positioning of the maximum value in the observed response and use it to index the predictor. Once we have obtained a starting value for &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;, we can note that, from the Bragg equation, with simple math, we can derive the following equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \log \left( \frac{Y}{d} \right) = - b \left( X - e\right)^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Therefore, if we transform the observed response and the predictor as above, we can use polynomial regression to estimate a starting value for &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;. In the end, this self starting routine can be coded as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ssftc &amp;lt;- function(data){
  # Get the data     
  x &amp;lt;- data[, 1]
  y &amp;lt;- data[, 2]
  
  d &amp;lt;- max(y)
  e &amp;lt;- x[which.max(y)]
  
  ## Linear regression on pseudo-y and pseudo-x
  pseudoY &amp;lt;- log( y / d )
  pseudoX &amp;lt;- (x - e)^2
  coefs &amp;lt;- coef( lm(pseudoY ~ pseudoX - 1) )
  b &amp;lt;- coefs[1]
  return( c(b, d, e) )
  }&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It may be worth to state that the self-starting function may be simply skipped by specifying starting values for model parameters, right inside &lt;code&gt;ssfct()&lt;/code&gt; (see Kniss et al., 2011).&lt;/p&gt;
&lt;p&gt;Now, let’s ‘encapsulate’ all components within the skeleton function given above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;DRC.bragg.3 &amp;lt;- function(){
  fct &amp;lt;- function(x, parm) {
    bragg.3.fun(x, parm[,1], parm[,2], parm[,3])
  }
  ssfct &amp;lt;- function(data){
    # Get the data     
    x &amp;lt;- data[, 1]
    y &amp;lt;- data[, 2]
    
    d &amp;lt;- max(y)
    e &amp;lt;- x[which.max(y)]
    
    ## Linear regression on pseudo-y and pseudo-x
    pseudoY &amp;lt;- log( y / d )
    pseudoX &amp;lt;- (x - e)^2
    coefs &amp;lt;- coef( lm(pseudoY ~ pseudoX - 1) )
    b &amp;lt;- - coefs[1]
    start &amp;lt;- c(b, d, e)
    return( start )
  }
  names &amp;lt;- c(&amp;quot;b&amp;quot;, &amp;quot;d&amp;quot;, &amp;quot;e&amp;quot;)
  text &amp;lt;- &amp;quot;Bragg equation&amp;quot;
    
  ## Returning the function with self starter and names
  returnList &amp;lt;- list(fct = fct, ssfct = ssfct, names = names, text = text)
  class(returnList) &amp;lt;- &amp;quot;drcMean&amp;quot;
  invisible(returnList)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once the &lt;code&gt;DRC.bragg.3()&lt;/code&gt; function is ready, it can be used as the value for the argument &lt;code&gt;fct&lt;/code&gt; in the &lt;code&gt;drm()&lt;/code&gt; function call.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod &amp;lt;- drm(RGR ~ Temp, fct = DRC.bragg.3())
summary(mod)
## 
## Model fitted: Bragg equation
## 
## Parameter estimates:
## 
##                 Estimate Std. Error t-value   p-value    
## b:(Intercept)  0.0115272  0.0014506  7.9466 9.513e-05 ***
## d:(Intercept) 27.4122086  1.4192874 19.3141 2.486e-07 ***
## e:(Intercept) 29.6392304  0.3872418 76.5393 1.710e-11 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  1.71838 (7 degrees of freedom)
 r
plot(mod, log = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_selfStarting_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;and-what-about-nls&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;And… what about nls()?&lt;/h1&gt;
&lt;p&gt;Yes, I know, some of you may prefer using the function &lt;code&gt;nls()&lt;/code&gt;, within the &lt;code&gt;stats&lt;/code&gt; package. In that platform, we can directly use &lt;code&gt;bragg.3.fun()&lt;/code&gt; as the response model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod.nls &amp;lt;- nls(RGR ~ bragg.3.fun(Temp, b, d, e),
               start = list (b = 0.01, d = 27, e = 30))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, we are forced to provide starting values for all estimands, which might be a tricky task, unless we build a self-starting routine, as we did before for the &lt;code&gt;drc&lt;/code&gt; platform. This is not an impossible task and we can also re-use part of the code we have already written above. We have to:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;build a self-starting function by using the appropriate coding (see below). In this step we should be careful to the command &lt;code&gt;sortedXyData(mCall[[&#34;X&#34;]], LHS, data)&lt;/code&gt;. The part in quotation marks (“X”) should correspond to the name of the predictor in the &lt;code&gt;bragg.3.fun()&lt;/code&gt; function definition.&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;selfStart()&lt;/code&gt; function to combine the function with its self-starting routine.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bragg.3.init &amp;lt;- function(mCall, LHS, data, ...) {
    xy &amp;lt;- sortedXyData(mCall[[&amp;quot;X&amp;quot;]], LHS, data)
    x &amp;lt;-  xy[, &amp;quot;x&amp;quot;]; y &amp;lt;- xy[, &amp;quot;y&amp;quot;]
    
    d &amp;lt;- max(y)
    e &amp;lt;- x[which.max(y)]

    ## Linear regression on pseudo-y and pseudo-x
    pseudoY &amp;lt;- log( y / d )
    pseudoX &amp;lt;- (x - e)^2
    coefs &amp;lt;- coef( lm(pseudoY ~ pseudoX - 1) )
    b &amp;lt;- - coefs[1]
    start &amp;lt;- c(b, d, e)
    names(start) &amp;lt;- mCall[c(&amp;quot;b&amp;quot;, &amp;quot;d&amp;quot;, &amp;quot;e&amp;quot;)]
    start
}

NLS.bragg.3 &amp;lt;- selfStart(bragg.3.fun, bragg.3.init, parameters=c(&amp;quot;b&amp;quot;, &amp;quot;d&amp;quot;, &amp;quot;e&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we can use the &lt;code&gt;NLS.bragg.3()&lt;/code&gt; function in the &lt;code&gt;nls()&lt;/code&gt; call:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod.nls &amp;lt;- nls(RGR ~ NLS.bragg.3(Temp, b, d, e) )
summary(mod.nls)
## 
## Formula: RGR ~ NLS.bragg.3(Temp, b, d, e)
## 
## Parameters:
##    Estimate Std. Error t value Pr(&amp;gt;|t|)    
## b  0.011527   0.001338   8.618 5.65e-05 ***
## d 27.411715   1.377361  19.902 2.02e-07 ***
## e 29.638976   0.382131  77.562 1.56e-11 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.718 on 7 degrees of freedom
## 
## Number of iterations to convergence: 8 
## Achieved convergence tolerance: 5.208e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have been building a lot of self-starters, both for &lt;code&gt;drm()&lt;/code&gt; and for &lt;code&gt;nls()&lt;/code&gt; and I have shared them within my &lt;code&gt;aomisc&lt;/code&gt; package. Therefore, should you need to fit some unusual nonlinear regression model, it may be worth to take a look at that package, to see whether you find something suitable.&lt;/p&gt;
&lt;p&gt;That’s it, thanks for reading!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Kniss, A.R., Vassios, J.D., Nissen, S.J., Ritz, C., 2011. Nonlinear Regression Analysis of Herbicide Absorption Studies. Weed Science 59, 601–610. &lt;a href=&#34;https://doi.org/10.1614/WS-D-11-00034.1&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1614/WS-D-11-00034.1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ritz, C., Baty, F., Streibig, J. C., Gerhard, D. (2015) Dose-Response Analysis Using R PLOS ONE, 10(12), e0146021&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Nonlinear combinations of model parameters in regression</title>
      <link>http://localhost:6346/2020/stat_nls_gnlht/</link>
      <pubDate>Thu, 09 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2020/stat_nls_gnlht/</guid>
      <description>


&lt;p&gt;Nonlinear regression plays an important role in my research and teaching activities. While I often use the ‘drm()’ function in the ‘drc’ package for my research work, I tend to prefer the ‘nls()’ function for teaching purposes, mainly because, in my opinion, the transition from linear models to nonlinear models is smoother, for beginners. One problem with ‘nls()’ is that, in contrast to ‘drm()’, it is not specifically tailored to the needs of biologists or students in biology. Therefore, now and then, I have to build some helper functions, to perform some specific tasks; I usually share these functions within the ‘aomisc’ package, that is available on github (&lt;a href=&#34;https://www.statforbiology.com/rpackages/&#34;&gt;see this link&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In this post, I would like to describe one of these helper functions, i.e. ‘gnlht()’, which is aimed at helping students (and practitioners; why not?) with one of their tasks, i.e. making some simple manipulations of model parameters, to obtain relevant biological information. Let’s see a typical example.&lt;/p&gt;
&lt;div id=&#34;motivating-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivating example&lt;/h1&gt;
&lt;p&gt;This is a real-life example, taken from a research published by Vischetti et al. in 1996. That research considered three herbicides for weed control in sugar beet, i.e. metamitron (M), phenmedipham (P) and cloridazon (C). Four soil samples were contaminated, respectively with: (i) M alone, (ii) M + P (iii) M + C and (iv) M + P + C. The aim was to assess whether the degradation speed of metamitron in soil depended on the presence of co-applied herbicides. To reach this aim, the soil samples were incubated at 20°C and sub-samples were taken in different times after the beginning of the experiment. The concentration of metamitron in those sub-samples was measured by HPLC analyses, performed in triplicate. The resulting dataset is available within the ‘aomisc’ package; we can load it and use the ‘lattice’ package to visualise the observed means over time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools)
# install_github(&amp;quot;OnofriAndreaPG/aomisc&amp;quot;)
library(aomisc)
library(lattice)
data(metamitron)
xyplot(Conc ~ Time|Herbicide, data = metamitron,
       xlab = &amp;quot;Time (d)&amp;quot;, ylab = &amp;quot;Concentration&amp;quot;,
       scales = list(alternating = F),
       panel = function(x, y, ...) { 
         panel.grid(h = -1, v = -1)
         fmy &amp;lt;- tapply(y, list(factor(x)), mean)
         fmx &amp;lt;- tapply(x, list(factor(x)), mean)
         panel.xyplot(fmx, fmy, col=&amp;quot;red&amp;quot;, type=&amp;quot;b&amp;quot;, cex = 1)
       })&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nls_gnlht_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Considering this exemplary dataset, let’s see how we can answer the following research questions.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;What is the degradation rate for metamitron, in the four combinations?&lt;/li&gt;
&lt;li&gt;Is there a significant difference between the degradation rate of metamitron alone and with co-applied herbicides?&lt;/li&gt;
&lt;li&gt;What is the half-life for metamitron, in the four combinations?&lt;/li&gt;
&lt;li&gt;What are the times to reach 70 and 30% of the initial concentration, for metamitron in the four combinations?&lt;/li&gt;
&lt;li&gt;Is there a significant difference between the half-life of metamitron alone and with co-applied herbicides?&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-a-degradation-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fitting a degradation model&lt;/h1&gt;
&lt;p&gt;The figure above shows a visible difference in the degradation pattern of metamitron, which could be attributed to the presence of co-applied herbicides. The degradation kinetics can be described by the following (first-order) model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ C(t, h) = A_h \, \exp \left(-k_h  \, t \right) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(C(t, h)\)&lt;/span&gt; is the concentration of metamitron at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; in each of the four combinations &lt;span class=&#34;math inline&#34;&gt;\(h\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(A_h\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k_h\)&lt;/span&gt; are, respectively, the initial concentration and degradation rate for metamitron in each combination.&lt;/p&gt;
&lt;p&gt;The model is nonlinear and, therefore, we can use the ‘nls()’ function for nonlinear least squares regression. The code is given below: please, note that the two parameters are followed by the name of the factor variable in square brackets (i.e.: A[Herbicide] and k[Herbicide]). This is necessary to fit a different parameter value for each level of the ‘Herbicide’ factor.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Fit nls grouped model
modNlin &amp;lt;- nls(Conc ~ A[Herbicide] * exp(-k[Herbicide] * Time), 
               start=list(A=rep(100, 4), k=rep(0.06, 4)), 
               data=metamitron)
summary(modNlin)
## 
## Formula: Conc ~ A[Herbicide] * exp(-k[Herbicide] * Time)
## 
## Parameters:
##     Estimate Std. Error t value Pr(&amp;gt;|t|)    
## A1 9.483e+01  4.796e+00   19.77   &amp;lt;2e-16 ***
## A2 1.021e+02  4.316e+00   23.65   &amp;lt;2e-16 ***
## A3 9.959e+01  4.463e+00   22.31   &amp;lt;2e-16 ***
## A4 1.116e+02  4.184e+00   26.68   &amp;lt;2e-16 ***
## k1 4.260e-02  4.128e-03   10.32   &amp;lt;2e-16 ***
## k2 2.574e-02  2.285e-03   11.26   &amp;lt;2e-16 ***
## k3 3.034e-02  2.733e-03   11.10   &amp;lt;2e-16 ***
## k4 2.186e-02  1.822e-03   12.00   &amp;lt;2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 9.701 on 88 degrees of freedom
## 
## Number of iterations to convergence: 5 
## Achieved convergence tolerance: 7.149e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the sake of simplicity, I will neglige an accurate model check, although I need to point out that this is highly wrong. I’ll come back to this issue in another post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;working-with-model-parameters&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Working with model parameters&lt;/h1&gt;
&lt;p&gt;Considering the research questions, it is clear that the above output answers the first one, as it gives the four degradation rates, &lt;span class=&#34;math inline&#34;&gt;\(k1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(k2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(k3\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k4\)&lt;/span&gt;. All the other questions can be translated into sets of linear/nonlinear functions (combinations) of model parameters. If we use the naming of parameter estimates in the nonlinear regression object, for the second question we can write the following functions: &lt;span class=&#34;math inline&#34;&gt;\(k1 - k2\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(k1 - k3\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(k1 - k4\)&lt;/span&gt;. The third question requires some slightly more complex math: if we invert the equation above for one herbicide, we get to the following inverse:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ t = \frac{- log \left[\frac{C(t)}{A} \right] }{k} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;I do not think this is complex enough to scare the biologists, is it? The half-life is the time required for C(t) to drop to half of the initial value, so that &lt;span class=&#34;math inline&#34;&gt;\(C(t)/A\)&lt;/span&gt; is equal to &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt;. Thus:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ t_{1/2} = \frac{- \log \left[0.5 \right] }{k} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Analogously, we can answer the question 4, by replacing &lt;span class=&#34;math inline&#34;&gt;\(0.5\)&lt;/span&gt; respectively with &lt;span class=&#34;math inline&#34;&gt;\(0.7\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(0.3\)&lt;/span&gt;. The difference between the half-lives of metamitron alone and combined with the second herbicide can be calculated by:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{- \log \left[0.5 \right] }{k_1} - \frac{- \log \left[0.5 \right] }{k_2} = \frac{k_2 - k_1}{k_1 \, k_2} \, \log(0.5)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The other differences are obtained analogously.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;inferences-and-hypotheses-testing&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Inferences and hypotheses testing&lt;/h1&gt;
&lt;p&gt;All parameter estimates are characterised by some uncertainty, which is summarised by way of the standard errors (see the code output above). Clearly, such an uncertainty propagates to their combinations. As for the first question, the combinations are linear, as only subtraction is involved. Therefore, the standard error for the difference can be easily calculated by the usual law of propagation of errors, which I have dealt with in &lt;a href=&#34;https://www.statforbiology.com/2019/stat_general_errorpropagation/&#34;&gt;this post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In R, linear combinations of model parameters can be built and tested by using the ‘glht()’ function in the ‘multcomp’ package. However, I wanted to find a general solution, that could handle both linear and nonlinear combinations of model parameters. Such a solution should be based on the ‘delta method’, which I have dealt with in &lt;a href=&#34;https://www.statforbiology.com/2019/stat_general_thedeltamethod/&#34;&gt;this post&lt;/a&gt;. Unfortunately, the function ‘deltaMethod()’ in the ‘car’ package is not flexible enough to the aims of my students and mine.&lt;/p&gt;
&lt;p&gt;Therefore, I wrote a wrapper for the ‘deltaMethod()’ function, which I named ‘gnlht()’, as it might play for nonlinear combinations the same role as ‘glht()’ for linear combinations. To use this function, apart from loading the ‘aomisc’ package, we need to prepare a list of formulas. Care needs to be taken to make sure that the element in the formulas correspond to the names of the estimated parameters in the model object, as returned by the ‘coef()’ method. In the box below, I show how we can calculate the differences between the degradation rates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~k1 - k2, ~k1 - k3, ~k1 - k4)
gnlht(modNlin, funList)
##      Form   Estimate          SE  t-value      p-value
## 1 k1 - k2 0.01686533 0.004718465 3.574325 5.727310e-04
## 2 k1 - k3 0.01226241 0.004951372 2.476568 1.517801e-02
## 3 k1 - k4 0.02074109 0.004512710 4.596150 1.430392e-05&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The very same code can be used for nonlinear combinations of model parameters. In order to calculate the half-lives, we can use the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ -log(0.5)/k1, ~ -log(0.5)/k2,
                ~ -log(0.5)/k3, ~ -log(0.5)/k4)
gnlht(modNlin, funList)
##           Form Estimate       SE  t-value      p-value
## 1 -log(0.5)/k1 16.27089 1.576827 10.31876 7.987828e-17
## 2 -log(0.5)/k2 26.93390 2.391121 11.26413 9.552912e-19
## 3 -log(0.5)/k3 22.84747 2.058588 11.09861 2.064093e-18
## 4 -log(0.5)/k4 31.70942 2.643330 11.99601 3.257068e-20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Instead of writing ‘0.5’, we can introduce a new model term, e.g. ‘prop’, as a ‘constant’, in the sense that it is not an estimated parameter. We can pass a value for this constant in a data frame, by using the ‘const’ argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ -log(prop)/k1, ~ -log(prop)/k2,
                ~ -log(prop)/k3, ~ -log(prop)/k4)
gnlht(modNlin, funList, const = data.frame(prop = 0.5))
##            Form prop Estimate       SE  t-value      p-value
## 1 -log(prop)/k1  0.5 16.27089 1.576827 10.31876 7.987828e-17
## 2 -log(prop)/k2  0.5 26.93390 2.391121 11.26413 9.552912e-19
## 3 -log(prop)/k3  0.5 22.84747 2.058588 11.09861 2.064093e-18
## 4 -log(prop)/k4  0.5 31.70942 2.643330 11.99601 3.257068e-20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is very flexible, because it lets us to calculate, altogether, the half-life and the times required for the concentration to drop to 70 and 30% of the initial value:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ -log(prop)/k1, ~ -log(prop)/k2,
                ~ -log(prop)/k3, ~ -log(prop)/k4)
gnlht(modNlin, funList, const = data.frame(prop = c(0.7, 0.5, 0.3)))
##             Form prop  Estimate        SE  t-value      p-value
## 1  -log(prop)/k1  0.7  8.372564 0.8113927 10.31876 7.987828e-17
## 2  -log(prop)/k2  0.7 13.859465 1.2304069 11.26413 9.552912e-19
## 3  -log(prop)/k3  0.7 11.756694 1.0592942 11.09861 2.064093e-18
## 4  -log(prop)/k4  0.7 16.316815 1.3601865 11.99601 3.257068e-20
## 5  -log(prop)/k1  0.5 16.270892 1.5768267 10.31876 7.987828e-17
## 6  -log(prop)/k2  0.5 26.933905 2.3911214 11.26413 9.552912e-19
## 7  -log(prop)/k3  0.5 22.847468 2.0585881 11.09861 2.064093e-18
## 8  -log(prop)/k4  0.5 31.709416 2.6433295 11.99601 3.257068e-20
## 9  -log(prop)/k1  0.3 28.261979 2.7388938 10.31876 7.987828e-17
## 10 -log(prop)/k2  0.3 46.783265 4.1532955 11.26413 9.552912e-19
## 11 -log(prop)/k3  0.3 39.685266 3.5756966 11.09861 2.064093e-18
## 12 -log(prop)/k4  0.3 55.078164 4.5913725 11.99601 3.257068e-20&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The differences between the half-lives (and other degradation times) can be calculated as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ (k2 - k1)/(k1 * k2) * log(prop),
                ~ (k3 - k1)/(k1 * k3) * log(prop), 
                ~ (k4 - k1)/(k1 * k4) * log(prop))
gnlht(modNlin, funList, const = data.frame(prop = c(0.7, 0.5, 0.3)))
##                              Form prop  Estimate       SE  t-value      p-value
## 1 (k2 - k1)/(k1 * k2) * log(prop)  0.7  5.486900 1.473859 3.722813 3.468973e-04
## 2 (k3 - k1)/(k1 * k3) * log(prop)  0.7  3.384130 1.334340 2.536183 1.297111e-02
## 3 (k4 - k1)/(k1 * k4) * log(prop)  0.7  7.944250 1.583814 5.015900 2.718444e-06
## 4 (k2 - k1)/(k1 * k2) * log(prop)  0.5 10.663013 2.864235 3.722813 3.468973e-04
## 5 (k3 - k1)/(k1 * k3) * log(prop)  0.5  6.576577 2.593100 2.536183 1.297111e-02
## 6 (k4 - k1)/(k1 * k4) * log(prop)  0.5 15.438524 3.077917 5.015900 2.718444e-06
## 7 (k2 - k1)/(k1 * k2) * log(prop)  0.3 18.521287 4.975078 3.722813 3.468973e-04
## 8 (k3 - k1)/(k1 * k3) * log(prop)  0.3 11.423287 4.504125 2.536183 1.297111e-02
## 9 (k4 - k1)/(k1 * k4) * log(prop)  0.3 26.816185 5.346236 5.015900 2.718444e-06&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The possibility of passing constants in a data.frame adds flexibility with respect to the ‘deltaMethod()’ function in the ‘car’ package. For example, we can use this method to make predictions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funList &amp;lt;- list(~ A1 * exp (- k1 * Time), ~ A2 * exp (- k2 * Time), 
                ~ A3 * exp (- k3 * Time), ~ A4 * exp (- k4 * Time))
pred &amp;lt;- gnlht(modNlin, funList, const = data.frame(Time = seq(0, 67, 1)))
head(pred)
##                   Form Time  Estimate       SE  t-value      p-value
## 1 A1 * exp(-k1 * Time)    0  94.83198 4.795948 19.77336 3.931106e-34
## 2 A2 * exp(-k2 * Time)    0 102.08592 4.316122 23.65223 6.671764e-40
## 3 A3 * exp(-k3 * Time)    0  99.58530 4.463418 22.31144 5.485452e-38
## 4 A4 * exp(-k4 * Time)    0 111.62446 4.183588 26.68151 5.980930e-44
## 5 A1 * exp(-k1 * Time)    1  90.87694 4.381511 20.74101 1.223613e-35
## 6 A2 * exp(-k2 * Time)    1  99.49225 4.062186 24.49229 4.617181e-41
 r
tail(pred)
##                     Form Time  Estimate       SE   t-value      p-value
## 267 A3 * exp(-k3 * Time)   66 13.446308 2.095933  6.415427 6.838561e-09
## 268 A4 * exp(-k4 * Time)   66 26.375174 2.618594 10.072266 2.555133e-16
## 269 A1 * exp(-k1 * Time)   67  5.462339 1.363509  4.006090 1.287737e-04
## 270 A2 * exp(-k2 * Time)   67 18.202556 2.358965  7.716331 1.752360e-11
## 271 A3 * exp(-k3 * Time)   67 13.044500 2.068082  6.307534 1.106297e-08
## 272 A4 * exp(-k4 * Time)   67 25.804886 2.607131  9.897810 5.827813e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although this is not very fast, in contrast to the ‘predict()’ method for ‘nls’ objects, it has the advantage of reporting standard errors.&lt;/p&gt;
&lt;p&gt;Hope this is useful. Happy coding!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;John Fox and Sanford Weisberg (2019). An {R} Companion to Applied Regression, Third Edition. Thousand Oaks CA:Sage. URL: &lt;a href=&#34;https://socialsciences.mcmaster.ca/jfox/Books/Companion/&#34; class=&#34;uri&#34;&gt;https://socialsciences.mcmaster.ca/jfox/Books/Companion/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Torsten Hothorn, Frank Bretz and Peter Westfall (2008). Simultaneous Inference in General Parametric Models. Biometrical Journal 50(3), 346–363.&lt;/li&gt;
&lt;li&gt;Ritz, C., Baty, F., Streibig, J. C., Gerhard, D. (2015) Dose-Response Analysis Using R PLOS ONE, 10(12), e0146021&lt;/li&gt;
&lt;li&gt;Vischetti, C., Marini, M., Businelli, M., Onofri, A., 1996. The effect of temperature and co-applied herbicides on the degradation rate of phenmedipham, chloridazon and metamitron in a clay loam soil in the laboratory, in: Re, A.D., Capri, E., Evans, S.P., Trevisan, M. (Eds.), “The Environmental Phate of Xenobiotics”, Proceedings X Symposium on Pesticide Chemistry, Piacenza. La Goliardica Pavese, Piacenza, pp. 287–294.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Testing for interactions in nonlinear regression</title>
      <link>http://localhost:6346/2019/stat_nlmm_interaction/</link>
      <pubDate>Fri, 13 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2019/stat_nlmm_interaction/</guid>
      <description>


&lt;p&gt;Factorial experiments are very common in agriculture and they are usually laid down to test for the significance of interactions between experimental factors. For example, genotype assessments may be performed at two different nitrogen fertilisation levels (e.g. high and low) to understand whether the ranking of genotypes depends on nutrient availability. For those of you who are not very much into agriculture, I will only say that such an assessment is relevant, because we need to know whether we can recommend the same genotypes, e.g., both in conventional agriculture (high nitrogen availability) and in organic agriculture (relatively lower nitrogen availability).&lt;/p&gt;
&lt;p&gt;Let’s consider an experiment where we have tested three genotypes (let’s call them A, B and C, for brevity), at two nitrogen rates (‘high’ an ‘low’) in a complete block factorial design, with four replicates. Biomass subsamples were taken from each of the 24 plots in eight different times (Days After Sowing: DAS), to evaluate the growth of biomass over time.&lt;/p&gt;
&lt;p&gt;The dataset is available on gitHub and the following code loads it and transforms the ‘Block’ variable into a factor. For this post, we will use several packages, including ‘aomisc’, the accompanying package for this blog. Please refer to &lt;a href=&#34;https://www.statforbiology.com/rpackages/&#34;&gt;this page for downloading and installing&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
library(lattice)
library(nlme)
library(aomisc)
dataset &amp;lt;- read.csv(&amp;quot;https://www.casaonofri.it/_datasets/growthNGEN.csv&amp;quot;,
  header=T)
dataset$Block &amp;lt;- factor(dataset$Block)
dataset$N &amp;lt;- factor(dataset$N)
dataset$GEN &amp;lt;- factor(dataset$GEN)
head(dataset)
##   Id DAS Block Plot GEN   N  Yield
## 1  1   0     1    1   A Low  2.786
## 2  2  15     1    1   A Low  5.871
## 3  3  30     1    1   A Low 13.265
## 4  4  45     1    1   A Low 16.926
## 5  5  60     1    1   A Low 22.812
## 6  6  75     1    1   A Low 25.346&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The dataset is composed by the following variables:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;‘Id’: a numerical code for observations&lt;/li&gt;
&lt;li&gt;‘DAS’: i.e., Days After Sowing. It is the moment when the sample was collected&lt;/li&gt;
&lt;li&gt;‘Block’, ‘Plot’, ‘GEN’ and ‘N’ represent respectively the block, plot, genotype and nitrogen level for each observation&lt;/li&gt;
&lt;li&gt;‘Yield’ represents the harvested biomass.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It may be useful to take a look at the observed growth data, as displayed on the graph below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nlmm_Interaction_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that the growth is sygmoidal (presumably logistic) and that the variance of observations increases over time, i.e. the variance is proportional to the expected response.&lt;/p&gt;
&lt;p&gt;The question is: how do we analyse this data? Let’s build a model in a sequential fashion.&lt;/p&gt;
&lt;div id=&#34;the-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The model&lt;/h1&gt;
&lt;p&gt;We could empirically assume that the relationship between biomass and time is logistic:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y_{ijkl} = \frac{d_{ijkl}}{1 + exp\left[b \left( X_{ijkl} - e_{ijkl}\right)\right]} + \varepsilon_{ijkl}\quad \quad (1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is the observed biomass yield at time &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, for the i-th genotype, j-th nitrogen level, k-th block and l-th plot, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the maximum asymptotic biomass level when time goes to infinity, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the slope at inflection point, while &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is the time when the biomass yield is equal to &lt;span class=&#34;math inline&#34;&gt;\(d/2\)&lt;/span&gt;. We are mostly interested in the parameters &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;: the first one describes the yield potential of a genotype, while the second one gives a measure of the speed of growth.&lt;/p&gt;
&lt;p&gt;There are repeated measures in each plot and, therefore, model parameters may show some variability, depending on the genotype, nitrogen level, block and plot. In particular, it may be acceptable to assume that &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is pretty constant and independent on the above factors, while &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; may change according to the following equations:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left\{ {\begin{array}{*{20}{c}}
d_{ijkl} = \mu_d + g_{di} + N_{dj} + gN_{dij} + \theta_{dk} + \zeta_{dl}\\
e_{ijkl} = \mu_e + q_{ei} + N_{ej} + gN_{eij} + \theta_{ek} + \zeta_{el}
\end{array}} \right. \quad \quad (2) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where, for each parameter, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the intercept, &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; is the fixed effect of the i-th genotype, &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; is the fixed effect of j-th nitrogen level, &lt;span class=&#34;math inline&#34;&gt;\(gN\)&lt;/span&gt; is the fixed interaction effect, &lt;span class=&#34;math inline&#34;&gt;\(\theta\)&lt;/span&gt; is the random effect of blocks, while &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt; is the random effect of plots within blocks. These two equations are totally equivalent to those commonly used for linear mixed models, in the case of a two-factor factorial block design, wherein &lt;span class=&#34;math inline&#34;&gt;\(\zeta\)&lt;/span&gt; would be the residual error term. Indeed, in principle, we could also think about a two-steps fitting procedure, where we:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;fit the logistic model to the data for each plot and obtain estimates for &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;use these estimates to fit a linear mixed model&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will not pursue this two-steps technique here and we will concentrate on one-step fitting.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-wrong-method&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A wrong method&lt;/h1&gt;
&lt;p&gt;If the observations were independent (i.e. no blocks and no repeated measures), this model could be fit by using conventional nonlinear regression. My preference goes to the ‘drm()’ function in the ‘drc’ package (Ritz et al., 2015).&lt;/p&gt;
&lt;p&gt;The coding is reported below: ‘Yield’ is a function of (&lt;span class=&#34;math inline&#34;&gt;\(\sim\)&lt;/span&gt;) DAS, by way of a three-parameters logistic function (‘fct = L.3()’). Different curves have to be fitted for different combinations of genotype and nitrogen levels (‘curveid = N:GEN’), although these curves should be partly based on common parameter values (‘pmodels = …). The ’pmodels’ argument requires a few additional comments. It must be a vector with as many element as there are parameters in the model (three, in this case: &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;). Each element represents a linear function of variables and refers to the parameters in alphabetical order, i.e. the first element refers to &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, the second refers to &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and the third to &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;. The parameter &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is not dependent on any variable (‘~ 1’) and thus a constant value is fitted across curves; &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; depend on a fully factorial combination of genotype and nitrogen level (~ N*GEN = ~N + GEN + N:GEN). Finally, we used the argument ‘bcVal = 0.5’ to specify that we intend to use a Transform-Both-Sides technique, where a logarithmic transformation is performed for both sides of the equations. This is necessary to account for heteroscedasticity, but it does not affect the scale of parameter estimates.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modNaive1 &amp;lt;- drm(Yield ~ DAS, fct = L.3(), data = dataset,
            curveid = GEN:N,
            pmodels = c( ~ 1,  ~ N*GEN,  ~ N*GEN), bcVal = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This model may be useful for other circumstances (no blocks and no repeated measures), but it is wrong in our example. Indeed, observations are clustered within blocks and plots; by neglecting this, we violate the assumption of independence of model residuals. A swift plot of residuals against fitted values shows that there are no problems with heteroscedasticity.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nlmm_Interaction_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Considering the above, we have to use a different model, here, although I will show that this naive fit may turn out useful.&lt;/p&gt;
&lt;div id=&#34;nonlinear-mixed-model-fitting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Nonlinear mixed model fitting&lt;/h2&gt;
&lt;p&gt;In order to account for the clustering of observations, we switch to a Nonlinear Mixed-Effect model (NLME). A good choice is the ‘nlme()’ function in the ‘nlme’ package (Pinheiro and Bates, 2000), although the syntax may be cumbersome, at times. I will try to help, listing and commenting the most important arguments for this function. We need to specify the following:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A deterministic function. In this case, we use the ‘nlsL.3()’ function in the ‘aomisc’ package, which provides a logistic growth model with the same parameterisation as the ‘L.3()’ function in the ‘drm’ package.&lt;/li&gt;
&lt;li&gt;Linear functions for model parameters. The ‘fixed’ argument in the ‘nlme’ function is very similar to the ‘pmodels’ argument in the ‘drm’ function above, in the sense that it requires a list, wherein each element is a linear function of variables. The only difference is that the parameter name needs to be specified on the left side of the function.&lt;/li&gt;
&lt;li&gt;Random effects for model parameters. These are specified by using the ‘random’ argument. In this case, the parameters &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; are expected to show random variability from block to block and from plot to plot, within a block. For the sake of simplicity, as the parameter &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is not affected by the genotype and nitrogen level, we also expect that it does not show any random variability across blocks and plots.&lt;/li&gt;
&lt;li&gt;Starting values for model parameters. Self starting routines are not used by ‘nlme()’ and thus we need to specify a named vector, holding the initial values of model parameters. In this case, I decided to use the output from the ‘naive’ nonlinear regression above, which, therefore, turns out useful.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The transformation of both sides of the equation is made explicitely.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(aomisc)
modnlme1 &amp;lt;- nlme(sqrt(Yield) ~ sqrt(NLS.L3(DAS, b, d, e)), 
                 data = dataset,
                    random = d + e ~ 1|Block/Plot,
                    fixed = list(b ~ 1, d ~ N*GEN, e ~ N*GEN),
                    start = coef(modNaive1), 
                 control = list(msMaxIter = 400))
summary(modnlme1)$tTable
##                     Value   Std.Error  DF    t-value      p-value
## b              0.05652837 0.002157629 228 26.1993017 1.044744e-70
## d.(Intercept) 33.91575345 1.222612873 228 27.7403863 5.073988e-75
## d.NLow        -3.18382833 1.592502937 228 -1.9992606 4.676721e-02
## d.GENB        18.90014652 1.864712716 228 10.1356881 3.602004e-20
## d.GENC        -1.15934036 1.686405289 228 -0.6874625 4.924900e-01
## d.NLow:GENB   -5.99216674 2.455759122 228 -2.4400466 1.544863e-02
## d.NLow:GENC   -5.82864839 2.217534817 228 -2.6284360 9.160827e-03
## e.(Intercept) 55.20071251 2.320784619 228 23.7853664 1.087154e-63
## e.NLow        -9.06217439 3.127165895 228 -2.8978873 4.123120e-03
## e.GENB        -4.47038044 2.761533560 228 -1.6188036 1.068720e-01
## e.GENC         4.00746113 3.084383636 228  1.2992745 1.951620e-01
## e.NLow:GENB   -4.71367433 4.055953643 228 -1.1621618 2.463848e-01
## e.NLow:GENC    2.23951083 4.609547667 228  0.4858418 6.275459e-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nlmm_Interaction_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_nlmm_Interaction_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From the plots above, we see that the overall fit is good. Fixed effects and variance components for random effects are obtained as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(modnlme1)$tTable
##                     Value   Std.Error  DF    t-value      p-value
## b              0.05652837 0.002157629 228 26.1993017 1.044744e-70
## d.(Intercept) 33.91575345 1.222612873 228 27.7403863 5.073988e-75
## d.NLow        -3.18382833 1.592502937 228 -1.9992606 4.676721e-02
## d.GENB        18.90014652 1.864712716 228 10.1356881 3.602004e-20
## d.GENC        -1.15934036 1.686405289 228 -0.6874625 4.924900e-01
## d.NLow:GENB   -5.99216674 2.455759122 228 -2.4400466 1.544863e-02
## d.NLow:GENC   -5.82864839 2.217534817 228 -2.6284360 9.160827e-03
## e.(Intercept) 55.20071251 2.320784619 228 23.7853664 1.087154e-63
## e.NLow        -9.06217439 3.127165895 228 -2.8978873 4.123120e-03
## e.GENB        -4.47038044 2.761533560 228 -1.6188036 1.068720e-01
## e.GENC         4.00746113 3.084383636 228  1.2992745 1.951620e-01
## e.NLow:GENB   -4.71367433 4.055953643 228 -1.1621618 2.463848e-01
## e.NLow:GENC    2.23951083 4.609547667 228  0.4858418 6.275459e-01
VarCorr(modnlme1)
##               Variance                     StdDev       Corr  
## Block =       pdLogChol(list(d ~ 1,e ~ 1))                    
## d.(Intercept) 4.134390e-08                 2.033320e-04 d.(In)
## e.(Intercept) 1.851943e-08                 1.360861e-04 -0.001
## Plot =        pdLogChol(list(d ~ 1,e ~ 1))                    
## d.(Intercept) 3.396536e-09                 5.827981e-05 d.(In)
## e.(Intercept) 1.023108e-09                 3.198605e-05 0     
## Residual      1.750623e-01                 4.184044e-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s go back to our initial aim: testing the significance of the ‘genotype x nitrogen’ interaction. Indeed, we have two available tests: on for the parameter &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and one for the parameter &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;. First of all, we code two ‘reduced’ models, where the genotype and nitrogen effects are purely addictive. To do so, we change the specification of the fixed effects from ’~ N*GEN’ to ‘~ N + GEN’. Also in this case, we use a ‘naive’ nonlinear regression fit to get starting values for model parameters, to be used in the following NLME model fitting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modNaive2 &amp;lt;- drm(Yield ~ DAS, fct = L.3(), 
                 data = dataset,
                 curveid = N:GEN,
                 pmodels = c( ~ 1,  ~ N + GEN,  ~ N * GEN), 
                 bcVal = 0.5)

modnlme2 &amp;lt;- nlme(sqrt(Yield) ~ sqrt(NLS.L3(DAS, b, d, e)), 
                 data = dataset,
                 random = d + e ~ 1|Block/Plot,
                 fixed = list(b ~ 1, d ~ N + GEN, e ~ N*GEN),
                 start = coef(modNaive2), 
                 control = list(msMaxIter = 200))

modNaive3 &amp;lt;- drm(Yield ~ DAS, fct = L.3(), data = dataset,
            curveid = N:GEN,
            pmodels = c( ~ 1,  ~ N*GEN,  ~ N + GEN), bcVal = 0.5)

modnlme3 &amp;lt;- nlme(sqrt(Yield) ~ sqrt(NLS.L3(DAS, b, d, e)),
                 data = dataset,
                 random = d + e ~ 1|Block/Plot,
                 fixed = list(b ~ 1, d ~ N*GEN, e ~ N + GEN),
                 start = coef(modNaive3), control = list(msMaxIter = 200))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s consider the first reduced model ‘modnlme2’. In this model, the ‘genotype x nitrogen’ interaction has been removed for the &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; parameter. We can compare this reduced model with the full model ‘modnlme1’, by using a Likelihood Ratio Test:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(modnlme1, modnlme2)
##          Model df      AIC      BIC    logLik   Test L.Ratio p-value
## modnlme1     1 20 329.1496 400.6686 -144.5748                       
## modnlme2     2 18 334.2187 398.5857 -149.1093 1 vs 2 9.06907  0.0107&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This test is significant, but the AIC value is very close for the two models. Considering that a LRT in mixed models is usually rather liberal, it should be possible to conclude that the ‘genotype x nitrogen’ interaction is not significant and, therefore, the ranking of genotypes in terms of yield potential, as measured by the &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; parameter should be independent on nitrogen level.&lt;/p&gt;
&lt;p&gt;Let’s now consider the second reduced model ‘modnlme3’. In this second model, the ‘genotype x nitrogen’ interaction has been removed for the ‘e’ parameter. We can compare also this reduced model with the full model ‘modnlme1’, by using a Likelihood Ratio Test:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(modnlme1, modnlme3)
##          Model df      AIC      BIC    logLik   Test  L.Ratio p-value
## modnlme1     1 20 329.1496 400.6686 -144.5748                        
## modnlme3     2 18 328.2446 392.6117 -146.1223 1 vs 2 3.095066  0.2128&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this second test, the lack of significance for the ‘genotype x nitrogen’ interaction seems to be less questionable than in the first one.&lt;/p&gt;
&lt;p&gt;I would like to conclude by drawing your attention to the ‘medrm’ function in the ‘medrc’ package, which can also be used to fit this type of nonlinear mixed-effects models.&lt;/p&gt;
&lt;p&gt;Happy coding with R!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Pinheiro, J.C., Bates, D.M., 2000. Mixed-Effects Models in S and S-Plus, Springer-Verlag Inc. ed. Springer-Verlag Inc., New York.&lt;/li&gt;
&lt;li&gt;Ritz, C., Baty, F., Streibig, J.C., Gerhard, D., 2015. Dose-Response Analysis Using R. PLOS ONE 10, e0146021. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0146021&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pone.0146021&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Germination data and time-to-event methods: comparing germination curves</title>
      <link>http://localhost:6346/2019/stat_seedgermination_comparinglots/</link>
      <pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2019/stat_seedgermination_comparinglots/</guid>
      <description>


&lt;p&gt;Very often, seed scientists need to compare the germination behaviour of different seed populations, e.g., different plant species, or one single plant species submitted to different temperatures, light conditions, priming treatments and so on. How should such a comparison be performed?&lt;/p&gt;
&lt;p&gt;Let’s take a practical approach and start from an appropriate example: a few years ago, some collegues studied the germination behaviour for seeds of a plant species (&lt;em&gt;Verbascum arcturus&lt;/em&gt;, BTW…), in different conditions. In detail, they considered the factorial combination of two storage periods (LONG and SHORT storage) and two temperature regimes (FIX: constant daily temperature of 20°C; ALT: alternating daily temperature regime, with 25°C during daytime and 15°C during night time, with a 12:12h photoperiod). If you are a seed scientist and are interested in this experiment, you’ll find detail in Catara &lt;em&gt;et al.&lt;/em&gt; (2016).&lt;/p&gt;
&lt;p&gt;If you are not a seed scientist you may wonder why my colleagues made such an assay; well, there is evidence that, for some plant species, the germination ability improves over time after seed maturation. Therefore, if we take seeds and store them for a different period of time, there might be an effect on their germination traits. Likewise, there is also evidence that some seeds may not germinate if they are not submitted to daily temperature fluctuations. These mechanisms are very interesting, as they permit to the seed to recognise that the environmental conditions are favourable for seedling survival.My colleagues wanted to discover whether this was the case for Verbascum.&lt;/p&gt;
&lt;p&gt;Let’s go back to our assay: the experimental design consisted of four combinations (LONG-FIX, LONG-ALT, SHORT-FIX and SHORT-ALT) and four replicates for each combination. One replicate consisted of a Petri dish, that is a small plastic box containing humid blotting paper, with 25 seeds of Verbascum. In all, there were 16 Petri dishes, put in climatic chambers with the appropriate conditions. During the assay, my collegues made daily inspections: germinated seeds were counted and removed from the dishes. Inspections were made for 15 days, until no more germinations could be observed.&lt;/p&gt;
&lt;p&gt;The dataset is available from a gitHub repository: let’s load it and have a look.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dataset &amp;lt;- read.csv(&amp;quot;https://raw.githubusercontent.com/OnofriAndreaPG/agroBioData/master/TempStorage.csv&amp;quot;, header = T, check.names = F)
head(dataset)
##   Dish Storage Temp 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15
## 1    1     Low  Fix 0 0 0 0 0 0 0 0 3  4  6  0  1  0  3
## 2    2     Low  Fix 0 0 0 0 1 0 0 0 2  7  2  3  0  5  1
## 3    3     Low  Fix 0 0 0 0 1 0 0 1 3  5  2  4  0  1  3
## 4    4     Low  Fix 0 0 0 0 1 0 3 0 0  3  1  1  0  4  4
## 5    5    High  Fix 0 0 0 0 0 0 0 0 1  2  5  4  2  3  0
## 6    6    High  Fix 0 0 0 0 0 0 0 0 2  2  7  8  1  2  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have one row per Petri dish; the first three columns show, respectively, dish number, storage and temperature conditions. The next 15 columns represent the inspection times (from 1 to 15) and contain the counts of germinated seeds. The research question is:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Is germination behaviour affected by storage and temperature conditions?&lt;/em&gt;&lt;/p&gt;
&lt;div id=&#34;response-feature-analyses&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Response feature analyses&lt;/h1&gt;
&lt;p&gt;One possible line of attack is to take a summary measure for each dish, e.g. the total number of germinated seeds. Taking a single value for each dish brings us back to more common methods of data analysis: for example, we can fit some sort of GLM to test the significance of effects (storage, temperature and their interaction), within a fully factorial design.&lt;/p&gt;
&lt;p&gt;Although the above method is not wrong, undoubtedly, it may be sub-optimal. Indeed, dishes may contain the same total number of germinated seeds, but, nonetheless, they may differ for some other germination traits, such as velocity or uniformity. Indeed, we do not want to express a judgment about one specific characteristic of the seed lot, we would like to express a judgment about the whole seed lot. In other words, we are not specifically asking: “do the seed lots differ for their germination capability?”. We are, more generally, asking “are the seed lots different?”.&lt;/p&gt;
&lt;p&gt;In order to get a general assessment, a different method of analysis should be sought, which considers the entire time series (from 1 to 15 days) and not only one single summary measure. This method exists and it is available within the time-to-event platform, which has shown very useful and appropriate for seed germination studies (Onofri et al., 2011; Ritz et al., 2013; Onofri et al., 2019).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-germination-time-course&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The germination time-course&lt;/h1&gt;
&lt;p&gt;It is necessary to re-organise the dataset in a more useful way. A good format can be obtained by using the ‘makeDrm()’ function in the ‘drcSeedGerm’ package, which can be installed from gitHub (see the code at: &lt;a href=&#34;https://www.statforbiology.com/seedgermination/index.html&#34;&gt;this link&lt;/a&gt;). The function needs to receive a dataframe storing the counts (dataset[,4:18]), a dataframe storing the factor variables (dataset[,2:3]), a vector with the number of seeds in each Petri dish (rep(25, 16)) and a vector of monitoring times.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(drcSeedGerm)
library(dplyr)
datasetR &amp;lt;- makeDrm(dataset[,4:18], dataset[,2:3], rep(25, 16), 1:15)
head(datasetR, 16)
##      Storage Temp Dish timeBef timeAf count nCum propCum
## 1        Low  Fix    1       0      1     0    0    0.00
## 1.1      Low  Fix    1       1      2     0    0    0.00
## 1.2      Low  Fix    1       2      3     0    0    0.00
## 1.3      Low  Fix    1       3      4     0    0    0.00
## 1.4      Low  Fix    1       4      5     0    0    0.00
## 1.5      Low  Fix    1       5      6     0    0    0.00
## 1.6      Low  Fix    1       6      7     0    0    0.00
## 1.7      Low  Fix    1       7      8     0    0    0.00
## 1.8      Low  Fix    1       8      9     3    3    0.12
## 1.9      Low  Fix    1       9     10     4    7    0.28
## 1.10     Low  Fix    1      10     11     6   13    0.52
## 1.11     Low  Fix    1      11     12     0   13    0.52
## 1.12     Low  Fix    1      12     13     1   14    0.56
## 1.13     Low  Fix    1      13     14     0   14    0.56
## 1.14     Low  Fix    1      14     15     3   17    0.68
## 1.15     Low  Fix    1      15    Inf     8   NA      NA
 r
datasetR &amp;lt;- datasetR %&amp;gt;% 
  mutate(across(c(Storage, Temp, Dish), .fns = factor))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The snippet above shows the first dish. Roughly speaking, we have gone from a WIDE format to a LONG format. The column ‘timeAf’ contains the time when the inspection was made and the column ‘count’ contains the number of germinated seeds (e.g. 9 seeds were counted at day 9). These seeds did not germinate exactly at day 9; they germinated within the interval between two inspections, that is between day 8 and day 9. The beginning of the interval is given in the variable ‘timeBef’. Apart from these columns, we have additional columns, which we are not going to use for our analyses. The cumulative counts of germinated seeds are in the column ‘nCum’; these cumulative counts have been converted into cumulative proportions by dividing by 25 (i.e., the total number of seeds in a dish; see the column ‘propCum’).&lt;/p&gt;
&lt;p&gt;We can use a time-to-event model to parameterise the germination time-course for this dish. This is easily done by using the ‘drm()’ function in the ‘drc’ package (Ritz et al., 2013):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modPre &amp;lt;- drm(count ~ timeBef + timeAf, fct = LL.3(), 
              data = datasetR, 
              type = &amp;quot;event&amp;quot;, subset = c(Dish == 1))
plot(modPre, log = &amp;quot;&amp;quot;, xlab = &amp;quot;Time&amp;quot;, 
     ylab = &amp;quot;Proportion of germinated seeds&amp;quot;,
     xlim = c(0, 15))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_ComparingLots_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Please, note the following:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;we are using the counts (‘count’) as the dependent variable&lt;/li&gt;
&lt;li&gt;as the independent variable: we are using the extremes of the inspection interval, within which germinations were observed (count ~ timeBef + time Af)&lt;/li&gt;
&lt;li&gt;we have assumed a log-logistic distribution of germination times (fct = LL.3()). A three parameter model is necessary, because there is a final fraction of ungerminated seeds (truncated distribution)&lt;/li&gt;
&lt;li&gt;we have set the argument ‘type = “event”’. Indeed, we are fitting a time-to-event model, not a nonlinear regression model, which would be incorrect, in this setting (see &lt;a href=&#34;https://www.statforbiology.com/seedgermination/timetoevent&#34;&gt;this link here&lt;/a&gt; ).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;As we have determined the germination time-course for dish 1, we can do the same for all dishes. However, we have to instruct ‘drm()’ to define a different curve for each combination of storage and temperature. It is necessary to make an appropriate use of the ‘curveid’ argument. Please, see below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod1 &amp;lt;- drm(count ~ timeBef + timeAf, fct = LL.3(),
            data = datasetR, type = &amp;quot;event&amp;quot;, 
            curveid = Temp:Storage)
## Warning in matrix(c(predVec, resVec), length(dose), 2): data length differs
## from size of matrix: [480 != 60 x 2]
 r
plot(mod1, log = &amp;quot;&amp;quot;, legendPos = c(2, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_ComparingLots_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It appears that there are visible differences between the curves (the legend considers the curves in alphabetical order, i.e. 1: Fix-Low, 2: Fix-High, 3: Alt-Low and 4: Alt-High). We can test that the curves are similar by coding a reduced model, where we have only one pooled curve for all treatment levels. It is enough to remove the ‘curveid’ argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;modNull &amp;lt;- drm(count ~ timeBef + timeAf, fct = LL.3(),
               data = datasetR, 
               type = &amp;quot;event&amp;quot;)
## Warning in matrix(c(predVec, resVec), length(dose), 2): data length differs
## from size of matrix: [480 != 15 x 2]
 r
anova(mod1, modNull, test = &amp;quot;Chisq&amp;quot;)
## 
## 1st model
##  fct:      LL.3()
##  pmodels: Temp:Storage (for all parameters)
## 2nd model
##  fct:      LL.3()
##  pmodels: 1 (for all parameters)
## ANOVA-like table
## 
##           ModelDf  Loglik Df LR value p value
## 1st model     244 -753.53                    
## 2nd model     253 -854.93  9    202.8       0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we can compare the full model (four curves) with the reduced model (one common curve) by using a Likelihood Ratio Test, which is approximately distributed as a Chi-square. The test is highly significant. Of course, we can also test some other hypotheses. For example, we can code a model with different curves for storage times, assuming that the effect of temperature is irrelevant:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod2 &amp;lt;- drm(count ~ timeBef + timeAf, fct = LL.3(), 
            data = datasetR, type = &amp;quot;event&amp;quot;, 
            curveid = Storage)
## Warning in matrix(c(predVec, resVec), length(dose), 2): data length differs
## from size of matrix: [480 != 30 x 2]
 r
anova(mod1, mod2, test = &amp;quot;Chisq&amp;quot;)
## 
## 1st model
##  fct:      LL.3()
##  pmodels: Temp:Storage (for all parameters)
## 2nd model
##  fct:      LL.3()
##  pmodels: Storage (for all parameters)
## ANOVA-like table
## 
##           ModelDf  Loglik Df LR value p value
## 1st model     244 -753.53                    
## 2nd model     250 -797.26  6   87.453       0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that such an assumption (temperature effect is irrelevant) is not supported by the data: the temperature effect cannot be removed without causing a significant decrease in the likelihood of the model. Similarly, we can test the effect of storage:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod3 &amp;lt;- drm(count ~ timeBef + timeAf, fct = LL.3(), 
            data = datasetR, type = &amp;quot;event&amp;quot;, 
            curveid = Temp)
## Warning in matrix(c(predVec, resVec), length(dose), 2): data length differs
## from size of matrix: [480 != 30 x 2]
 r
anova(mod1, mod3, test = &amp;quot;Chisq&amp;quot;)
## 
## 1st model
##  fct:      LL.3()
##  pmodels: Temp:Storage (for all parameters)
## 2nd model
##  fct:      LL.3()
##  pmodels: Temp (for all parameters)
## ANOVA-like table
## 
##           ModelDf  Loglik Df LR value p value
## 1st model     244 -753.53                    
## 2nd model     250 -849.48  6    191.9       0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again, we get significant results. So, we need to conclude that temperature and storage time caused a significant influence on the germination behavior for the species under study.&lt;/p&gt;
&lt;p&gt;Before concluding, it is necessary to mention that, in general, the above LR tests should be taken with care: the results are only approximate and the observed data are not totally independent, as multiple observations are taken in each experimental unit (Petri dish). In order to restore independence, we would need to add to the model a random effect for the Petri dish, which is not an easy task in a time-to-event framework (Onofri et al., 2019). However, we got very low p-levels, which leave us rather confident about the significance of effects. It may be a good suggestion, in general, to avoid formal hypothesis testing and compare the models by using the Akaike Information Criterion (AIC: the lowest is the best), which confirms that the complete model with four curves is, indeed, the best one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AIC(mod1, mod2, mod3, modNull)
##          df      AIC
## mod1    244 1995.066
## mod2    250 2094.519
## mod3    250 2198.961
## modNull 253 2215.862&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For those who are familiar with linear model parameterisation, it is possible to reach even a higher degree of flexibility by using the ‘pmodels’ argument, within the ‘drm()’ function. However, this will require another post. Thanks for reading!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Catara, S., Cristaudo, A., Gualtieri, A., Galesi, R., Impelluso, C., Onofri, A., 2016. Threshold temperatures for seed germination in nine species of Verbascum (Scrophulariaceae). Seed Science Research 26, 30–46.&lt;/li&gt;
&lt;li&gt;Onofri, A., Mesgaran, M.B., Tei, F., Cousens, R.D., 2011. The cure model: an improved way to describe seed germination? Weed Research 51, 516–524.&lt;/li&gt;
&lt;li&gt;Onofri, A., Piepho, H.-P., Kozak, M., 2019. Analysing censored data in agricultural research: A review with examples and software tips. Annals of Applied Biology 174, 3–13. &lt;a href=&#34;https://doi.org/10.1111/aab.12477&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1111/aab.12477&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Ritz, C., Pipper, C.B., Streibig, J.C., 2013. Analysis of germination data from agricultural experiments. European Journal of Agronomy 45, 1–6.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Survival analysis and germination data: an overlooked connection</title>
      <link>http://localhost:6346/2019/stat_seedgermination_germination/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/2019/stat_seedgermination_germination/</guid>
      <description>


&lt;div id=&#34;the-background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The background&lt;/h1&gt;
&lt;p&gt;Seed germination data describe the time until an event of interest occurs. In this sense, they are very similar to survival data, apart from the fact that we deal with a different (and less sad) event: germination instead of death. But, seed germination data are also similar to failure-time data, phenological data, time-to-remission data… the first point is: &lt;strong&gt;germination data are time-to-event data&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You may wonder: what’s the matter with time-to-event data? Do they have anything special? With few exceptions, all time-to-event data are affected by a certain form of uncertainty, which takes the name of ‘censoring’. It relates to the fact that the exact time of event may not be precisely know. I think it is good to give an example.&lt;/p&gt;
&lt;p&gt;Let’s take a germination assay, where we put, say, 100 seeds in a Petri dish and make daily inspections. At each inspection, we count the number of germinated seeds. In the end, what have we learnt about the germination time of each seed? It is easy to note that we do not have a precise value, we only have an uncertainty interval. Let’s make three examples.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;If we found a germinated seed at the first inspection time, we only know that germination took place before the inspection (left-censoring).&lt;/li&gt;
&lt;li&gt;If we find a germinated seed at the second inspection time, we only know that germination took place somewhere between the first and the second inspection (interval-censoring).&lt;/li&gt;
&lt;li&gt;If we find an ungerminated seed at the end of the experiment, we only know that its germination time, if any, is higher than the duration of the experiment (right-censoring).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Censoring implies a lot of uncertainty, which is additional to other more common sources of uncertainty, such as the individual seed-to-seed variability or random errors in the manipulation process. Is censoring a problem? Yes, it is, although it is usually overlooked in seed science research. I made this point in a recent review (Onofri et al., 2019) and I would like to come back to this issue here. The second point is that &lt;strong&gt;the analyses of data from germination assays should always account for censoring&lt;/strong&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;data-analyses-for-germination-assays&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data analyses for germination assays&lt;/h1&gt;
&lt;p&gt;A swift search of literature shows that seed scientists are often interested in describing the time-course of germinations, for different plant species, in different environmental conditions. In simple terms, if we take a population of seeds and give it enough water, the individual seeds will start germinating. Their germination times will be different, due to natural seed-to-seed variability and, therefore, the proportion of germinated seeds will progressively and monotonically increase over time. However, this proportion will almost never reach 1, because, there will often be a fraction of seeds that will not germinate in the given conditions, because it is either dormant or nonviable.&lt;/p&gt;
&lt;p&gt;In order to describe this progress to germination, a log-logistic function is often used:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
G(t) = \frac{d}{ 1 + exp \left\{ - b \right[ \log(t) - \log(e) \left] \right\}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; is the fraction of germinated seeds at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the germinable fraction, &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is the median germination time for the germinable fraction and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the slope around the inflection point. The above model is sygmoidally shaped and it is symmetric on a log-time scale. The three parameters are biologically relevant, as they describe the three main features of seed germination, i.e. capability (&lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;), speed (&lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;) and uniformity (&lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;My third point in this post is that &lt;strong&gt;The process of data analysis for germination data is often based on fitting a log-logistic (or similar) model to the observed counts&lt;/strong&gt;.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;motivating-example-a-simulated-dataset&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivating example: a simulated dataset&lt;/h1&gt;
&lt;p&gt;Considering the above, we can simulate the results of a germination assay. Let’s take a 100-seed-sample from a population where we have 85% of germinable seeds (&lt;span class=&#34;math inline&#34;&gt;\(d = 0.85\)&lt;/span&gt;), with a median germination time &lt;span class=&#34;math inline&#34;&gt;\(e = 4.5\)&lt;/span&gt; days and &lt;span class=&#34;math inline&#34;&gt;\(b = 1.6\)&lt;/span&gt;. Obviously, this sample will not necessarily reflect the characteristics of the population. We can do this sampling in R, by using a three-steps approach.&lt;/p&gt;
&lt;div id=&#34;step-1-the-ungerminated-fraction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: the ungerminated fraction&lt;/h2&gt;
&lt;p&gt;First, let’s simulate the number of germinated seeds, assuming a binomial distribution with a proportion of successes equal to 0.85. We use the random number generator ‘rbinom()’:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Monte Carlo simulation - Step 1
d &amp;lt;- 0.85
set.seed(1234)
nGerm &amp;lt;- rbinom(1, 100, d)
nGerm
## [1] 89&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that, in this instance, 89 seeds germinated out of 100, which is not the expected 85%. This is a typical random fluctuation: indeed, we were lucky in selecting a good sample of seeds.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-germination-times-for-the-germinated-fraction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: germination times for the germinated fraction&lt;/h2&gt;
&lt;p&gt;Second, let’s simulate the germination times for these 89 germinable seeds, by drawing from a log-logistic distribution with &lt;span class=&#34;math inline&#34;&gt;\(b = 1.6\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e = 4.5\)&lt;/span&gt;. To this aim, we use the ‘rllogis()’ function in the ‘actuar’ package (Dutang et al., 2008):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Monte Carlo simulation - Step 2
library(actuar)
b &amp;lt;- 1.6; e &amp;lt;- 4.5 
Gtimes &amp;lt;- rllogis(nGerm, shape = b, scale = e)
Gtimes &amp;lt;- c(Gtimes, rep(Inf, 100 - nGerm))
Gtimes
##   [1]  3.2936708  3.4089762  3.2842199  1.4401630  3.1381457 82.1611955
##   [7]  9.4906364  2.9226745  4.3424551  2.7006042  4.0202158  8.0519663
##  [13]  0.9492013  7.8199588  1.6163588  7.9661485  8.4641154 11.2879041
##  [19]  9.5014360  7.2786264  7.5809838 12.7421713 32.7999661  9.9691944
##  [25]  1.8137333  4.2197542  1.0218849  1.6604417 30.0352308  5.0235265
##  [31]  8.5085067  7.5367739  4.4185382 11.5555259  2.1919263 10.6509339
##  [37]  8.6857151  0.2185902  1.8377033  3.9362727  3.0864702  7.3804164
##  [43]  3.2978782  7.0100360  4.4775843  2.8328842  4.6721090  9.1258796
##  [49]  2.1485568 21.8749808  7.4265984  2.5148724  4.4491466 13.1132301
##  [55]  4.4559642  4.5684584  2.2556488 11.8783556  1.5338755  1.4106592
##  [61] 31.8419420  7.2666641 65.0154287  9.2798476  2.5988399  7.4612907
##  [67]  4.4048509 27.7439121  3.8257187 15.4967751  1.1960785 62.5152642
##  [73]  2.0169970 19.1134899  4.2891084  6.0420938 22.6521417  7.1946293
##  [79]  2.9028993  0.9241876  4.8277336 13.8068124  4.0273655 10.8651761
##  [85]  1.1509735  5.9593534  7.4009589 12.6839405  1.1698335        Inf
##  [91]        Inf        Inf        Inf        Inf        Inf        Inf
##  [97]        Inf        Inf        Inf        Inf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we have a vector hosting 100 germination times (‘Gtimes’). Please, note that I added 11 infinite germination times, to represent non-germinable seeds.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-counts-of-germinated-seeds&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: counts of germinated seeds&lt;/h2&gt;
&lt;p&gt;Unfortunately, due to the monitoring schedule, we cannot observe the exact germination time for each single seed in the sample; we can only count the seeds which have germinated between two assessment times. Therefore, as the third step, we simulate the observed counts, by assuming daily monitoring for 40 days.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obsT &amp;lt;- seq(1, 40, by=1) #Observation schedule
count &amp;lt;- table( cut(Gtimes, breaks = c(0, obsT)) )
count
## 
##   (0,1]   (1,2]   (2,3]   (3,4]   (4,5]   (5,6]   (6,7]   (7,8]   (8,9]  (9,10] 
##       3      11      10       8      13       2       1      12       4       5 
## (10,11] (11,12] (12,13] (13,14] (14,15] (15,16] (16,17] (17,18] (18,19] (19,20] 
##       2       3       2       2       0       1       0       0       0       1 
## (20,21] (21,22] (22,23] (23,24] (24,25] (25,26] (26,27] (27,28] (28,29] (29,30] 
##       0       1       1       0       0       0       0       1       0       0 
## (30,31] (31,32] (32,33] (33,34] (34,35] (35,36] (36,37] (37,38] (38,39] (39,40] 
##       1       1       1       0       0       0       0       0       0       0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that, e.g., 11 germinated seeds were counted at day 2; therefore they germinated between day 1 and day 2 and their real germination time is unknown, but included in the range between 1 and 2 (left-open and right-closed). This is a typical example of interval-censoring (see above).&lt;/p&gt;
&lt;p&gt;We can also see that, in total, we counted 86 germinated seeds and, therefore, 14 seeds were still ungerminated at the end of the assay. For this simulation exercise, we know that 11 seeds were non-germinable and three seeds were germinable, but were not allowed enough time to germinate (look at the table above: there are 3 seeds with germination times higher than 40). In real life, this is another source of uncertainty: we might be able to ascertain whether these 14 seeds are viable or not (e.g. by using a tetrazolium test), but, if they are viable, we would never be able to tell whether they are dormant or their germination time is simply longer than the duration of the assay. In real life, we can only reach an uncertain conclusion: the germination time of the 14 ungerminated seeds is comprised between 40 days to infinity; this is an example of right-censoring.&lt;/p&gt;
&lt;p&gt;The above uncertainty affects our capability of describing the germination time-course from the observed data. We can try to picture the situation in the graph below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_Germination_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What is the real germination time-course? The red one? The blue one? Something in between? We cannot really say this from our dataset, we are uncertain. The grey areas represent the uncertainty due to censoring. Do you think that we can reasonably neglect it?&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The question is: how do we fit a log-logistic function to this dataset? We can either neglect censoring or account for it. Let’s see the differences.&lt;/p&gt;
&lt;div id=&#34;ignoring-censoring&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Ignoring censoring&lt;/h2&gt;
&lt;p&gt;We have seen that the time-corse of germination can be described by using a log-logistic cumulative distribution function. Therefore, seed scientists are used to re-organising their data, as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts &amp;lt;- as.numeric( table( cut(Gtimes, breaks = c(0, obsT)) ) )
propCum &amp;lt;- cumsum(counts)/100
df &amp;lt;- data.frame(time = obsT, counts = counts, propCum = propCum) 
df
##    time counts propCum
## 1     1      3    0.03
## 2     2     11    0.14
## 3     3     10    0.24
## 4     4      8    0.32
## 5     5     13    0.45
## 6     6      2    0.47
## 7     7      1    0.48
## 8     8     12    0.60
## 9     9      4    0.64
## 10   10      5    0.69
## 11   11      2    0.71
## 12   12      3    0.74
## 13   13      2    0.76
## 14   14      2    0.78
## 15   15      0    0.78
## 16   16      1    0.79
## 17   17      0    0.79
## 18   18      0    0.79
## 19   19      0    0.79
## 20   20      1    0.80
## 21   21      0    0.80
## 22   22      1    0.81
## 23   23      1    0.82
## 24   24      0    0.82
## 25   25      0    0.82
## 26   26      0    0.82
## 27   27      0    0.82
## 28   28      1    0.83
## 29   29      0    0.83
## 30   30      0    0.83
## 31   31      1    0.84
## 32   32      1    0.85
## 33   33      1    0.86
## 34   34      0    0.86
## 35   35      0    0.86
## 36   36      0    0.86
## 37   37      0    0.86
## 38   38      0    0.86
## 39   39      0    0.86
## 40   40      0    0.86&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In practice, seed scientists often use the observed counts to determine the cumulative proportion (or percentage) of germinated seeds. The cumulative proportion (‘propCum’) is used as the response variable, while the observation time (‘time’) is used as the independent variable and a log-logistic function is fitted by non-linear least squares regression. &lt;strong&gt;Hope that you can clearly see that, by doing so, we totally neglect the grey areas in the figure above, we only look at the observed points&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We can fit a nonlinear regression model by using the ‘drm’ function, in the ‘drc’ package (Ritz et al., 2015). The argument ‘fct’ is used to set the fitted function to log-logistic with three parameters (the equation above).&lt;/p&gt;
&lt;p&gt;The ‘plot()’ and ‘summary()’ methods can be used to plot a graph and to retrieve the estimated parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(drc)
mod &amp;lt;- drm(propCum ~ time, data = df,
           fct = LL.3() )
plot(mod, log = &amp;quot;&amp;quot;,
      xlab = &amp;quot;Time (days)&amp;quot;,
      ylab = &amp;quot;Proportion of germinated seeds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/post/Stat_SeedGermination_Germination_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(mod)
## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)
## 
## Parameter estimates:
## 
##                 Estimate Std. Error t-value   p-value    
## b:(Intercept) -1.8497771  0.0702626 -26.327 &amp;lt; 2.2e-16 ***
## d:(Intercept)  0.8768793  0.0070126 125.044 &amp;lt; 2.2e-16 ***
## e:(Intercept)  5.2691575  0.1020457  51.635 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.01762168 (37 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that our estimates are very close to the real values (&lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; = 1.85 vs. 1.6; &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; = 5.27 vs. 4.5; &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; = 0.88 vs. 0.86) and we also see that standard errors are rather small (the coefficient of variability goes from 1 to 4%). There is a difference in sign for &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, which relates to the fact that the ‘LL.3()’ function in ‘drc’ removes the minus sign in the equation above. Please, disregard this aspect, which stems from the fact that the ‘drc’ package is rooted in pesticide bioassays.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;accounting-for-censoring&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Accounting for censoring&lt;/h2&gt;
&lt;p&gt;So far, we have totally neglected censoring. But, how can we account for it? The answer is simple: as with survival studies, we should use time-to-event methods, which are specifically devised to incorporate the uncertainty due to censoring. In medicine, the body of time-to-event methods goes under the name of survival analysis, which explains the title of my post. My colleagues and I have extensively talked about these methods in two of our recent papers and related appendices (Onofri et al., 2019; Onofri et al., 2018). Therefore, I will not go into detail, now.&lt;/p&gt;
&lt;p&gt;I will just say that time-to-event methods directly consider the observed counts as the response variable. As the independent variable, they consider the extremes of each time interval (‘timeBef’ and ‘timeAf’; see below). In contrast to nonlinear regression, we do not need to transform the observed counts into cumulative proportions, as we did before. Furthermore, by using an interval as the independent variable, we inject into the model the uncertainty due to censoring.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data.frame(timeBef = c(0, obsT), timeAf = c(obsT, Inf), counts = c(as.numeric(counts), 100 - sum(counts)) )
df
##    timeBef timeAf counts
## 1        0      1      3
## 2        1      2     11
## 3        2      3     10
## 4        3      4      8
## 5        4      5     13
## 6        5      6      2
## 7        6      7      1
## 8        7      8     12
## 9        8      9      4
## 10       9     10      5
## 11      10     11      2
## 12      11     12      3
## 13      12     13      2
## 14      13     14      2
## 15      14     15      0
## 16      15     16      1
## 17      16     17      0
## 18      17     18      0
## 19      18     19      0
## 20      19     20      1
## 21      20     21      0
## 22      21     22      1
## 23      22     23      1
## 24      23     24      0
## 25      24     25      0
## 26      25     26      0
## 27      26     27      0
## 28      27     28      1
## 29      28     29      0
## 30      29     30      0
## 31      30     31      1
## 32      31     32      1
## 33      32     33      1
## 34      33     34      0
## 35      34     35      0
## 36      35     36      0
## 37      36     37      0
## 38      37     38      0
## 39      38     39      0
## 40      39     40      0
## 41      40    Inf     14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time-to-event models can be easily fitted by using the same function as we used above (the ‘drm()’ function in the ‘drc’ package). However, there are some important differences in the model call. The first one relate to model definition: a nonlinear regression model is defined as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CumulativeProportion ~ timeAf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the other hand, a time-to-event model is defined as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Count ~ timeBef + timeAf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A second difference is that we need to explicitly set the argument ‘type’, to ‘event’:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Time-to-event model
modTE &amp;lt;- drm(counts ~ timeBef + timeAf, data = df, 
           fct = LL.3(), type = &amp;quot;event&amp;quot;)
summary(modTE)
## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## b:(Intercept) -1.826006   0.194579 -9.3844 &amp;lt; 2.2e-16 ***
## d:(Intercept)  0.881476   0.036928 23.8701 &amp;lt; 2.2e-16 ***
## e:(Intercept)  5.302109   0.565273  9.3797 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With respect to the nonlinear regression fit, the estimates from a time-to-event fit are very similar, but the standard errors are much higher (the coefficient of variability now goes from 4 to 11%).&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;neglecting-or-accounting-for-censoring&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Neglecting or accounting for censoring?&lt;/h1&gt;
&lt;p&gt;You may wonder which of the two analysis is right and which is wrong. We cannot say this from just one dataset. However, we can repeat the Monte Carlo simulation above to extract 1000 samples, fit the model by using the two methods and retrieve parameter estimates and standard errors for each sample and method. We do this by using the code below (please, be patient… it may take some time).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GermSampling &amp;lt;- function(nSeeds, timeLast, stepOss, e, b, d){
    
    #Draw a sample as above
    nGerm &amp;lt;- rbinom(1, nSeeds, d)
    Gtimes &amp;lt;- rllogis(nGerm, shape = b, scale = e)
    Gtimes &amp;lt;- c(Gtimes, rep(Inf, 100 - nGerm))

    
    #Generate the observed data
    obsT &amp;lt;- seq(1, timeLast, by=stepOss) 
    counts &amp;lt;- as.numeric( table( cut(Gtimes, breaks = c(0, obsT)) ) )
    propCum &amp;lt;- cumsum(counts)/nSeeds
    timeBef &amp;lt;- c(0, obsT)
    timeAf &amp;lt;- c(obsT, Inf)
    counts &amp;lt;- c(counts, nSeeds - sum(counts))
    
    #Calculate the T50 with two methods
    mod &amp;lt;- drm(propCum ~ obsT, fct = LL.3() )
    modTE &amp;lt;- drm(counts ~ timeBef + timeAf, 
           fct = LL.3(), type = &amp;quot;event&amp;quot;)
    c(b1 = summary(mod)[[3]][1,1],
      ESb1 = summary(mod)[[3]][1,2],
      b2 = summary(modTE)[[3]][1,1],
      ESb2 = summary(modTE)[[3]][1,2],
      d1 = summary(mod)[[3]][2,1],
      ESd1 = summary(mod)[[3]][2,2],
      d2 = summary(modTE)[[3]][2,1],
      ESd2 = summary(modTE)[[3]][2,2],
      e1 = summary(mod)[[3]][3,1],
      ESe1 = summary(mod)[[3]][3,2],
      e2 = summary(modTE)[[3]][3,1],
      ESe2 = summary(modTE)[[3]][3,2] )
}

set.seed(1234)
result &amp;lt;- data.frame()
for (i in 1:1000) {
  res &amp;lt;- GermSampling(100, 40, 1, 4.5, 1.6, 0.85)
  result &amp;lt;- rbind(result, res)
} 
names(result) &amp;lt;- c(&amp;quot;b1&amp;quot;, &amp;quot;ESb1&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;ESb2&amp;quot;,
                   &amp;quot;d1&amp;quot;, &amp;quot;ESd1&amp;quot;, &amp;quot;d2&amp;quot;, &amp;quot;ESd2&amp;quot;,
                   &amp;quot;e1&amp;quot;, &amp;quot;ESe1&amp;quot;, &amp;quot;e2&amp;quot;, &amp;quot;ESe2&amp;quot;)
result &amp;lt;- result[result$d2 &amp;gt; 0,]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have stored our results in the data frame ‘result’. The means of estimates obtained for both methods should be equal to the real values that we used for the simulation, which will ensure that estimators are unbiased. The means of standard errors (in brackets, below) should represent the real sample-to-sample variability, which may be obtained from the Monte Carlo standard deviation, i.e. from the standard deviation of the 1000 estimates for each parameter and method.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;b&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Nonlinear regression&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.63 (0.051)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.85 (0.006)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.55 (0.086)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Time-to-event method&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.62 (0.187)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.85 (0.041)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.55 (0.579)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Real values&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.60 (0.188)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.85 (0.041)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.55 (0.593)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We clearly see that both nonlinear regression and the time-to-event method lead to unbiased estimates of model parameters. However, standard errors from nonlinear regression are severely biased and underestimated. On the contrary, standard errors from time-to-event method are unbiased.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;take-home-message&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Take-home message&lt;/h1&gt;
&lt;p&gt;Censoring is peculiar to germination assays and other time-to-event studies. It may have a strong impact on the reliability of our standard errors and, consequently, on hypotheses testing. Therefore, censoring should never be neglected and time-to-event methods should necessarily be used for data analyses with germination assays. The body of time-to-event methods often goes under the name of ‘survival analysis’, which creates a direct link between survival data and germination data.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;#References&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;C. Dutang, V. Goulet and M. Pigeon (2008). actuar: An R Package for Actuarial Science. Journal of Statistical Software, vol. 25, no. 7, 1-37.&lt;/li&gt;
&lt;li&gt;Onofri, Andrea, Paolo Benincasa, M B Mesgaran, and Christian Ritz. 2018. Hydrothermal-Time-to-Event Models for Seed Germination. European Journal of Agronomy 101: 129–39.&lt;/li&gt;
&lt;li&gt;Onofri, Andrea, Hans Peter Piepho, and Marcin Kozak. 2019. Analysing Censored Data in Agricultural Research: A Review with Examples and Software Tips. Annals of Applied Biology, 174, 3-13.&lt;/li&gt;
&lt;li&gt;Ritz, C., F. Baty, J. C. Streibig, and D. Gerhard. 2015. Dose-Response Analysis Using R. PLOS ONE, 10 (e0146021, 12).&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Some useful equations for nonlinear regression in R</title>
      <link>http://localhost:6346/articles/usefulequations/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:6346/articles/usefulequations/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Very rarely, biological processes follow linear trends. Just think about how a crop grows, or responds to increasing doses of fertilisers/xenobiotics. Or think about how an herbicide degrades in the soil, or about the germination pattern of a seed population. It is very easy to realise that curvilinear trends are far more common than linear trends. Furthermore, asymptotes and/or inflection points are very common in nature. We can be sure: linear equations in biology are just a way to approximate a response over a very narrow range for the independent variable.&lt;/p&gt;
&lt;p&gt;Therefore, as biologists, we need to be able to describe our experimental data by using a wide range of curvilinear equations. We need to be able to ‘read’ those equations and use their parameters to interpret and understand biological processes. I thought that it would be useful to list the most commonly used curvilinear functions and show examples of how they can be fit by using R.&lt;/p&gt;
&lt;p&gt;When it comes to nonlinear regression, I have a strong personal preference for the ‘drc’ package and the ‘drm()’ function therein. However, it is also worth mentioning the traditional ‘nls()’ function in the ‘stats’ package. You may know that nonlinear least squares work iteratively: we need to provide initial guesses for model parameters and the algorithm adjusts them step by step, finally converging on the approximate least squares solution. To my experience, providing initial guesses may be troublesome. Therefore, it is very convenient to use R functions together with the appropriate self-starting routines, which can greatly semplify the fitting process. These self-starters can be found in the ‘drc’, ‘nlme’ and ‘aomisc’ packages.&lt;/p&gt;
&lt;p&gt;Let’s load the necessary packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(drc)
library(nlme)
library(aomisc)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;curve-shapes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Curve shapes&lt;/h1&gt;
&lt;p&gt;Functions can be easily classified by the shape they show when they are plotted in a graph. This is helpful to select the correct one, according to the trend of the process under study. We have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Polynomials
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Straight line&lt;/li&gt;
&lt;li&gt;Quadratic polynomial&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Concave/Convex curves (no inflection)
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Exponential function&lt;/li&gt;
&lt;li&gt;Asymptotic function&lt;/li&gt;
&lt;li&gt;Negative exponential function&lt;/li&gt;
&lt;li&gt;Power curve function&lt;/li&gt;
&lt;li&gt;Logarithmic function&lt;/li&gt;
&lt;li&gt;Rectangular hyperbola&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Sigmoidal curves
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Logistic function&lt;/li&gt;
&lt;li&gt;Gompertz function&lt;/li&gt;
&lt;li&gt;Modified Gompertz function&lt;/li&gt;
&lt;li&gt;Log-logistic function&lt;/li&gt;
&lt;li&gt;Weibull (type 1) function&lt;/li&gt;
&lt;li&gt;Weibull (type 2) function&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Curves with maxima/minima
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Bragg function&lt;/li&gt;
&lt;li&gt;Lorentz function&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;polynomials&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Polynomials&lt;/h1&gt;
&lt;p&gt;Polynomials are the most flexible tool to describe biological processes. They are simple and, although curvilinear, they are linear in the parameters and can be fitted by using linear regression. One disadvantage is that they cannot describe asymptotic processes, which are very common in biology. Furthermore, they are prone to overfitting, as we may be tempted to add terms to improve the fit, with little care for biological realism.&lt;/p&gt;
&lt;p&gt;Nowadays, thanks to the wide availability of nonlinear regression algorithms, the use of polynomials has sensibly decreased; linear or quadratic polynomials are mainly used when we want to approximate the observed response within a narrow range of a quantitative predictor. On the other hand, higher order polynomials are very rarely seen, in practice.&lt;/p&gt;
&lt;div id=&#34;straight-line&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Straight line&lt;/h2&gt;
&lt;p&gt;Obviously, this is not a curve, although it deserves to be mentioned here. The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = b_0 + b_1 \, X\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(b_0\)&lt;/span&gt; is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b_1\)&lt;/span&gt; is the slope, i.e. the increase/decrease in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for a unit-increase in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The Y increases as X increases when &lt;span class=&#34;math inline&#34;&gt;\(b_1 &amp;gt; 0\)&lt;/span&gt;, otherwise it decreases.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quadratic-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quadratic function&lt;/h2&gt;
&lt;p&gt;The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = b_0 + b_1\, X + b_2 \, X^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(b_0\)&lt;/span&gt; is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;, while &lt;span class=&#34;math inline&#34;&gt;\(b_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b_2\)&lt;/span&gt;, taken separately, lack a clear biological meaning. However, it is interesting to consider that the first derivative is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a + b*X + c*X^2), &amp;quot;X&amp;quot;)
## b + c * (2 * X)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which measures the increase/decrease in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for a unit-increase in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. We see that such an increase/decrease is not constant, but it changes according to the level of X. The stationary point is &lt;span class=&#34;math inline&#34;&gt;\(X_m = - b_1 / 2 b_2\)&lt;/span&gt;; it is a maximum when &lt;span class=&#34;math inline&#34;&gt;\(b_2 &amp;gt; 0\)&lt;/span&gt;, otherwise it is a minimum.&lt;/p&gt;
&lt;p&gt;At the maximum/minimum, it is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_m = \frac{4\,b_0\,b_2 - b_1^2}{4\,b_2}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;polynomial-fitting-in-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Polynomial fitting in R&lt;/h2&gt;
&lt;p&gt;Polynomials in R are fit by using the linear model function ‘lm()’. Although this is not efficient, in a couple of cases I found myself in the need of fitting a polynomial by using the ‘nls()’ o ‘drm()’ functions. For these unusual cases, one can use the ‘NLS.Linear()’, NLS.poly2(), ‘DRC.Linear()’ and DRC.Poly2() self-starting function, as available in the ‘aomisc’ package.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;concaveconvex-curves&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Concave/Convex curves&lt;/h1&gt;
&lt;div id=&#34;exponential-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exponential curve&lt;/h2&gt;
&lt;p&gt;The exponential function describes an increasing/decreasing &lt;em&gt;trend&lt;/em&gt;, with constant relative rate. The most common equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = a  e^{k X}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Other possible parameterisations are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = a  b^X  =  e^{d + k X}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above parameterisations are equivalent, as proved by setting &lt;span class=&#34;math inline&#34;&gt;\(b = e^k\)&lt;/span&gt; e &lt;span class=&#34;math inline&#34;&gt;\(a = e^d\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a  b^X  = a  (e^k)^{X} =  a  e^{kX}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a  e^{kX} = e^d \cdot e^{kX} =  e^{d + kX}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The meaning of parameters is clear: &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;, while &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; represents the relative increase/decrease of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for a unit increase of X. &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases if &lt;span class=&#34;math inline&#34;&gt;\(k &amp;gt; 0\)&lt;/span&gt; (exponential growth), while it decreases when &lt;span class=&#34;math inline&#34;&gt;\(k &amp;lt; 0\)&lt;/span&gt; (exponential decay). This curve is used to describe the growth of populations in unlimiting environmental conditions, or to describe the degradation of xenobiotics in the environment (first-order degradation kinetic).&lt;/p&gt;
&lt;p&gt;The exponential function is nonlinear in &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; and needs to be fitted by using ‘nls()’ or ‘drm()’. It is possible to make profit of the self-starting routines in ‘NLS.expoGrowth()’, ‘NLS.expoDecay()’, ‘DRC.expoGrowth()’ and ‘DRC.expoDecay()’. All these functions are available in the ‘aomisc’ package. The ‘drc’ package also contains the function ‘EXD.2()’, that fits an exponential decay model, with a slightly different parameterisation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = d \exp(-x/e) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the same as &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; in the model above and &lt;span class=&#34;math inline&#34;&gt;\(e = 1/k\)&lt;/span&gt;. For all the forementioned exponential decay equations &lt;span class=&#34;math inline&#34;&gt;\(Y \rightarrow 0\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow \infty\)&lt;/span&gt;. The function ‘EXD.3()’ in the ‘drc’ package also includes a lower asymptote &lt;span class=&#34;math inline&#34;&gt;\(c \neq 0\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d -c) \exp(-x/e) \]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(degradation)
degradation
##    Time    Conc
## 1     0  96.400
## 2    10  46.300
## 3    20  21.200
## 4    30  17.890
## 5    40  10.100
## 6    50   6.900
## 7    60   3.500
## 8    70   1.900
## 9     0 102.300
## 10   10  49.200
## 11   20  26.310
## 12   30  14.220
## 13   40   5.400
## 14   50   3.400
## 15   60   0.500
## 16   70   0.200
## 17    0 101.330
## 18   10  54.890
## 19   20  28.120
## 20   30  13.330
## 21   40   6.110
## 22   50   0.350
## 23   60   2.100
## 24   70   0.922
 r
model &amp;lt;- drm(Conc ~ Time, fct = DRC.expoDecay(),
             data = degradation)
summary(model)
## 
## Model fitted: Exponential Decay Model (2 parms)
## 
## Parameter estimates:
## 
##                  Estimate Std. Error t-value   p-value    
## C0:(Intercept) 99.6349312  1.4646680  68.026 &amp;lt; 2.2e-16 ***
## k:(Intercept)   0.0670391  0.0019089  35.120 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  2.621386 (22 degrees of freedom)
 r
plot(model, log = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;asymptotic-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Asymptotic regression model&lt;/h2&gt;
&lt;p&gt;The asymptotic regression model describes a limited growth, where Y approaches an horizontal asymptote as X tends to infinity. The rate of growth is maximum at the beginning and approaches 0 as Y approaches the plateau. This equation is used in several different parameterisations and it is also known as Monomolecular Growth, Mitscherlich law or von Bertalanffy law.&lt;/p&gt;
&lt;p&gt;Due to its biological meaning, the most widespread parameterisation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a - (a - b) \, \exp (- c  X)\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is the maximum attainable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at &lt;span class=&#34;math inline&#34;&gt;\(x = 0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is proportional to the relative rate of Y increase while X increases. Indeed, we can see that the first derivative is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a - (a - b) * exp (- c * X)), &amp;quot;X&amp;quot;)
## (a - b) * (exp(-c * X) * c)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;that is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y’ = c \, (a - Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This model can be fit with R by using the self starter functions ‘NLS.asymReg()’ and DRC.asymReg(), in the ‘aomisc’ package. The ‘drc’ package contains the function AR.3(), that is a similar parameterisation where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(e = 1/c\)&lt;/span&gt;. The ‘nlme’ package also contains an alternative parameterisation named ‘SSasymp()’, where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(\phi_3 = \log(c)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We simulate an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
X &amp;lt;- c(1, 3, 5, 7, 9, 11, 13, 20)
a &amp;lt;- 20; b &amp;lt;- 5; c &amp;lt;- 0.3
Ye &amp;lt;- asymReg.fun(X, a, b, c)
epsilon &amp;lt;- rnorm(8, 0, 0.5)
Y &amp;lt;- Ye + epsilon
model &amp;lt;- drm(Y ~ X, fct = DRC.asymReg())
plot(model, log = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we take the above equation and add the constraint that &lt;span class=&#34;math inline&#34;&gt;\(b = 0\)&lt;/span&gt;, we get the following equation, that is often known as negative exponential equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a [1 -  \exp (- c  X) ]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This equation has a similar shape to the asymptotic regression, but Y is 0 when X is 0 (the curve passes through the origin). It is often used to model the absorbed Photosintetically Active Radiation (&lt;span class=&#34;math inline&#34;&gt;\(Y = PAR_a\)&lt;/span&gt;) as a function of incident PAR (&lt;span class=&#34;math inline&#34;&gt;\(a = PAR_i\)&lt;/span&gt;), Leaf Area Index (X = LAI) and the extinction coefficient (c = k).&lt;/p&gt;
&lt;p&gt;This model can be fit with R by using the self starter functions ‘NLS.negExp()’ and DRC.negExp(), in the ‘aomisc’ package. The ‘drc’ package contains the function AR.2(), where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(e = 1/c\)&lt;/span&gt;. The ‘nlme’ package also contains an alternative parameterisation, named ‘SSasympOrig()’, where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(\phi_3 = \log(c)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;power-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Power curve&lt;/h2&gt;
&lt;p&gt;The power curve is also known as Freundlich equation or allometric function and the most common parameterisation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a \, X^b\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This curve is perfectly equivalent to an exponential curve on the
logarithm of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. Indeed:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a\,X^b  = a\, e^{\log( X^b )}  = a\,e^{b \, \log(x)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This curve does not have an asymptote for &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow \infty\)&lt;/span&gt;. The slope (first derivative) of the curve is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a * X^b), &amp;quot;X&amp;quot;)
## a * (X^(b - 1) * b)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that both paraeters relate to the slope of the curve and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; dictates its shape. If &lt;span class=&#34;math inline&#34;&gt;\(0 &amp;lt;- b &amp;lt; 1\)&lt;/span&gt;, Y increases as X increases and the curve is convex up. This is used, e.g., to model the number of plant species as a function of sampling area (Muller-Dumbois method).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(speciesArea)
speciesArea
##   Area numSpecies
## 1    1          4
## 2    2          5
## 3    4          7
## 4    8          8
## 5   16         10
## 6   32         14
## 7   64         19
## 8  128         22
## 9  256         26
 r
model &amp;lt;- drm(numSpecies ~ Area, fct = DRC.powerCurve(),
             data = speciesArea)
summary(model)
## 
## Model fitted: Power curve (Freundlich equation) (2 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## a:(Intercept) 4.348404   0.337197  12.896 3.917e-06 ***
## b:(Intercept) 0.329770   0.016723  19.719 2.155e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.9588598 (7 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(b &amp;lt; 0\)&lt;/span&gt;, the curve is concave up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; decreases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;curve(powerCurve.fun(x, coef(model)[1], -coef(model)[2]),
      xlab = &amp;quot;X&amp;quot;, ylab = &amp;quot;Y&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(b &amp;gt; 1\)&lt;/span&gt; is negative, the curve is concave up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;curve(powerCurve.fun(x, coef(model)[1], 2),
      xlab = &amp;quot;X&amp;quot;, ylab = &amp;quot;Y&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;logarithmic-equation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logarithmic equation&lt;/h2&gt;
&lt;p&gt;This is indeed a linear model on log-transformed X:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y = a + b \, \log(X)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Due to the logarithmic function, X must be $ &amp;gt; 0$. The parameter &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; dictates the shape: if &lt;span class=&#34;math inline&#34;&gt;\(b &amp;gt; 0\)&lt;/span&gt;, the curve is convex up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases. If &lt;span class=&#34;math inline&#34;&gt;\(b &amp;lt; 0\)&lt;/span&gt;, the curve is concave up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; decreases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;p&gt;The logarithmic equation can be fit by using ‘lm()’. If necessary, it can also be fit by using ‘nls()’ and ‘drm()’; the self-starting functions ‘NLS.logCurve()’ and ‘DRC.logCurve()’ are available within the ‘aomisc’ package. We show some simulated data as examples.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#b is positive
set.seed(5678)
X &amp;lt;- c(1,2,4,5,7,12)
a&amp;lt;-2; b&amp;lt;- 0.5
Ye &amp;lt;-  a + b*log(X)
res &amp;lt;- rnorm(6, 0, 0.1)
Y &amp;lt;- Ye + res
model &amp;lt;- lm(Y ~ log(X) )
summary(model)
## 
## Call:
## lm(formula = Y ~ log(X))
## 
## Residuals:
##         1         2         3         4         5         6 
## -0.025947  0.013207  0.050827 -0.011989 -0.008408 -0.017690 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  1.99653    0.02494   80.06 1.46e-07 ***
## log(X)       0.45088    0.01580   28.54 8.97e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.03146 on 4 degrees of freedom
## Multiple R-squared:  0.9951,	Adjusted R-squared:  0.9939 
## F-statistic: 814.7 on 1 and 4 DF,  p-value: 8.967e-06
 r
model &amp;lt;- drm(Y ~ X, fct = DRC.logCurve() )
summary(model)
## 
## Model fitted: Linear regression on log-transformed x (2 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## a:(Intercept) 1.996534   0.024939  80.058 1.459e-07 ***
## b:(Intercept) 0.450883   0.015797  28.543 8.967e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.03145785 (4 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#b is negative
X &amp;lt;- c(1,2,4,5,7,12)
a &amp;lt;- 2; b &amp;lt;- -0.5
Ye &amp;lt;-  a + b*log(X)
res &amp;lt;- rnorm(6, 0, 0.1)
Y &amp;lt;- Ye + res
model &amp;lt;- drm(Y ~ X, fct = DRC.logCurve() )
summary(model)
## 
## Model fitted: Linear regression on log-transformed x (2 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## a:(Intercept)  2.115759   0.103920 20.3595 3.437e-05 ***
## b:(Intercept) -0.569125   0.065826 -8.6459 0.0009843 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.1310851 (4 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-10-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;michaelis-menten-equation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Michaelis-Menten equation&lt;/h2&gt;
&lt;p&gt;This is a rectangular hyperbola, often parameterised as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = \frac{a \, X} {b + X}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This curve is convex up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases, up to a plateau level. The parameter &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; represents the higher asymptote (for &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow \infty\)&lt;/span&gt;), while &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the X value giving a response equal to &lt;span class=&#34;math inline&#34;&gt;\(a/2\)&lt;/span&gt;. Indeed, it is easily shown that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{a}{2} = \frac{a\,X_{50} } {b + X_{50} }\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which leads to &lt;span class=&#34;math inline&#34;&gt;\(b = x_{50}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The slope (first derivative) is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression( (a*X) / (b + X) ), &amp;quot;X&amp;quot;)
## a/(b + X) - (a * X)/(b + X)^2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From there, we can see that the initial slope (at &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;) is $i = a/b $.&lt;/p&gt;
&lt;p&gt;In R, this model can be fit by using ‘nls()’ and the self starting functions ‘SSmicmen()’, within the package ‘nlme’. If we prefer a ‘drm()’ fit, we can use the ‘MM.2()’ function in the package ‘drc’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
X &amp;lt;- c(3, 5, 7, 22, 28, 39, 46, 200)
a &amp;lt;- 15; b &amp;lt;- 0.5
Ye &amp;lt;- as.numeric( SSmicmen(X, a, b) )
res &amp;lt;- rnorm(8, 0, 0.1)
Y &amp;lt;- Ye + res

#nls fit
model &amp;lt;- nls(Y ~ SSmicmen(X, a, b))
summary(model)
## 
## Formula: Y ~ SSmicmen(X, a, b)
## 
## Parameters:
##   Estimate Std. Error t value Pr(&amp;gt;|t|)    
## a 14.97166    0.06057  247.17 2.96e-13 ***
## b  0.50207    0.03345   15.01 5.51e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.1196 on 6 degrees of freedom
## 
## Number of iterations to convergence: 0 
## Achieved convergence tolerance: 3.056e-06
 r
#drm fit
model &amp;lt;- drm(Y ~ X, fct = MM.2())
summary(model)
## 
## Model fitted: Michaelis-Menten (2 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## d:(Intercept) 14.971733   0.060492 247.499 2.936e-13 ***
## e:(Intercept)  0.502126   0.033359  15.052 5.418e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.1195748 (6 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The ‘drc’ package also contains the self starting function ‘MM.3()’, where &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is allowed to be equal to &lt;span class=&#34;math inline&#34;&gt;\(c \neq 0\)&lt;/span&gt;, when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;yield-loss-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Yield-loss curve&lt;/h2&gt;
&lt;p&gt;Weed-crop competition studies make use of a reparameterised Michaelis-Menten model. Indeed, th initial slope of a Michaelis-Menten can be assumed as a measure of competition, that is the reduction in yield (Y) when the first weed is added to the system. Therefore, the Michaelis-Methen model has been reparameterised to include &lt;span class=&#34;math inline&#34;&gt;\(i = a/b\)&lt;/span&gt; as an explicit parameter. The reparameterised equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = \frac{i \, X}{1 + \frac{i \, X}{a}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This model can be used to describe yield losses as a function of weed density. It can be fit by using the self starting functions ‘NLS.YL()’ or ‘DRC.YL()’ in the ‘aomisc’ package. Usually, competion studies produce yield data and, therefore, yield lossed need to be calculated by using the weed-free yield and the following equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_L  = \frac{Y_{WF}  - Y_w }{Y_{WF} } \times 100\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(Y_W\)&lt;/span&gt; is the observed yield and &lt;span class=&#34;math inline&#34;&gt;\(Y_{WF}\)&lt;/span&gt; is the weed-free yield. We show an example relating to sunflower grown at increasing densities of the weed &lt;em&gt;Sinapis arvensis&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(competition)
Ywf &amp;lt;- mean( competition$Yield[competition$Dens == 0] )
competition$YL &amp;lt;- ( Ywf - competition$Yield ) / Ywf * 100 

#nls fit
model &amp;lt;- nls(YL ~ NLS.YL(Dens, a, i), data = competition)
summary(model)
## 
## Formula: YL ~ NLS.YL(Dens, a, i)
## 
## Parameters:
##   Estimate Std. Error t value Pr(&amp;gt;|t|)    
## a    8.207      1.187   6.914 1.93e-08 ***
## i   75.048      2.353  31.894  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 6.061 on 42 degrees of freedom
## 
## Number of iterations to convergence: 2 
## Achieved convergence tolerance: 2.696e-06
 r
#drc fit
model &amp;lt;- drm(YL ~ Dens, fct = DRC.YL(), data = competition)
summary(model)
## 
## Model fitted: Yield-Loss function (Cousens, 1985) (2 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## i:(Intercept)   8.2068     1.1715  7.0056 1.427e-08 ***
## A:(Intercept)  75.0492     2.3298 32.2133 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  6.060578 (42 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above fit constrains the yield loss to be 0 when weed density is 0. This is logical, but, it has the important consequence that the weed-free yield is constrained to be equal to the observed weed-free yield, which is not realistic. Therefore, we can reparameterise the yield-loss function, in order to use the observed yield as the dependent variable.&lt;/p&gt;
&lt;p&gt;Indeed, from the above equation we derive:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_W  = Y_{WF}  - \frac{Y_L }{100}Y_{WF}  = Y_{WF} \left( {1 - \frac{Y_L }{100}} \right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and so:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_W  = Y_{WF} \left( 1 - \frac{i\, X}{100 \left( 1 + \frac{i \, X}{a} \right) } \right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This function can be fit with ‘drm()’, by using the ‘DRC.cousens85()’ self starting function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- drm(Yield ~ Dens, fct = DRC.cousens85(), 
             data = competition)
summary(model)
## 
## Model fitted: Yield-Weed Density function (Cousens, 1985) (3 parms)
## 
## Parameter estimates:
## 
##                 Estimate Std. Error t-value   p-value    
## YWF:(Intercept) 30.47211    0.92763 32.8493 &amp;lt; 2.2e-16 ***
## i:(Intercept)    8.24038    1.36541  6.0351 3.857e-07 ***
## a:(Intercept)   75.07312    2.40366 31.2328 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  1.866311 (41 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;sygmoidal-curves&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sygmoidal curves&lt;/h1&gt;
&lt;p&gt;Sygmoidal curves are S-shaped and they may be increasing, decreasing, symmetric or non-simmetric around the inflection point. They are parameterised in countless ways, which may be often confusing. Therefore, we will show a common parameterisation, that is very useful in biological terms.&lt;/p&gt;
&lt;div id=&#34;logistic-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic curve&lt;/h2&gt;
&lt;p&gt;The logistic curve derives from the cumulative logistic distribution function; the curve is symmetric around the inflection point and it it may be parameterised as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = c + \frac{d - c}{1 + exp(b (X - e))}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the higher asymptote, &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is the lower asymptote, &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; value producing a response half-way between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;, while &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the slope around the inflection point. The parameter &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; can be positive or negative and, consequently, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; may increase or decrease as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;p&gt;The above function is known as four-parameter logistic. If necessary, contraints can be put on parameter values, i.e. &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; can be constrained to 0 (three-parameter logistic). Furthermore, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; can be also contrained to 1 (two-parameter logistic).&lt;/p&gt;
&lt;p&gt;The four- and three-parameter logistic curves can be fit by ‘nls()’, respectively with the self-starting functions ‘SSfpl()’ and ‘SSlogis’ (‘nlme’ package). In these functions, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(scal = -1/b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;With ‘drm()’, we can use the self-starting functions ‘L.4()’ and ‘L.3()’, The ‘L.2()’ function has been included in the ‘aomisc’ package.&lt;/p&gt;
&lt;p&gt;Logistic functions are very useful, e.g., for plant growth studies.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(beetGrowth)
beetGrowth
##    DAE weightInf weightFree
## 1   21   0.06000  0.0715091
## 2   21   0.06000  0.0662547
## 3   21   0.11000  0.0747931
## 4   27   0.20000  0.3368074
## 5   27   0.20000  0.3952256
## 6   27   0.21000  0.2520960
## 7   38   2.13000  2.3225072
## 8   38   3.03000  1.7163224
## 9   38   1.27000  1.2189231
## 10  49   6.13000 11.7761096
## 11  49   5.76000 13.6191507
## 12  49   7.78000 12.1462931
## 13  65  17.05000 33.1067720
## 14  65  22.48000 24.9648226
## 15  65  12.66000 34.6577561
## 16 186  21.51010 38.8329912
## 17 186  26.25887 27.8375016
## 18 186  27.67733 37.7165427
 r
model &amp;lt;- drm(weightFree ~ DAE, fct = L.3(), data = beetGrowth)
summary(model)
## 
## Model fitted: Logistic (ED50 as parameter) with lower limit fixed at 0 (3 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## b:(Intercept) -0.179393   0.039059 -4.5929 0.0003519 ***
## d:(Intercept) 34.532001   1.676430 20.5985 2.057e-12 ***
## e:(Intercept) 52.384788   1.580269 33.1493 1.838e-15 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  2.970191 (15 degrees of freedom)
 r
plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gompertz-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gompertz Curve&lt;/h2&gt;
&lt;p&gt;The Gompertz curve is parameterised in very many ways. We favour a parameterisation that resambles the one used for the logistic function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \exp \left\{- \exp \left[ b \, (X - e) \right] \right\} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;were the parameters have the same meaning as those in the logistic function. The difference is that this curve is not symmetric around the inflection point. As for the logistic, we can have a four-, three- and two-parameter Gompertz functions, which can be fit by using ‘drm()’ and, respectively the ‘G.4()’, ‘G.3()’ and ‘G.2()’ sef-starters. The three-parameter Gompertz can also be fit with ‘nls()’, by using the ‘SSGompertz()’ self-starter in the ‘nlme’ package, although this is a different parameterisation.&lt;/p&gt;
&lt;p&gt;We give an example of the different shapes for the logistic (red) and Gompertz (black) functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;another-type-of-asimmetry&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Another type of asimmetry&lt;/h2&gt;
&lt;p&gt;We have seen that, with respect to the logistic, the Gompertz shows a longer lag at the beginning, but raises steadily afterwards. We could describe a different pattern by changing the Gompertz function as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \left\{ 1 - \exp \left\{- \exp \left[ b \, (X - e) \right] \right\} \right\} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We add to the previous graph this function (in blue), to show how it differs from the logistic and Gompertz.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- 10; c &amp;lt;- 2; e &amp;lt;- 7; b &amp;lt;- - 0.5
curve( G4.fun(x, b, c, d, e), xlim = c(0, 20) , xlab=&amp;quot;X&amp;quot;, ylab = &amp;quot;Y&amp;quot;)
curve( L4.fun(x, b, c, d, e), add = T, col = &amp;quot;red&amp;quot; )
curve( E4.fun(x, b, c, d, e), add = T, col = &amp;quot;blue&amp;quot; )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The self-starters for this function are not yet available, at least to the best of my knowledge.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;log-logistic-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Log-logistic curve&lt;/h2&gt;
&lt;p&gt;In many applications, the sigmoidal response curve is symmetric on the logarithm of x, which requires a log-logistic curve (a log-normal curve would be practically equivalent, but it is used far less often). For example, in biologic assays (but also in germination assays), the log-logistic curve is defined as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = c + \frac{d - c}{1 + \exp \left\{ b \left[ \log(X) - \log(e) \right] \right\} } \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the parameters have the very same meanng as the logistic equationn given above. It is easy to see that the above equation is equivalent to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = c + \frac{d - c}{1 + \left( \frac{X}{e} \right)^b}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Another possible parameterisation is the so-called Hill function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = \frac{a \, X^b}{ X^b + e^b} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Indeed:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{a \, X^b}{ X^b + e^b} =  \frac{a}{ \frac{X^b}{X^b} + \frac{c^b}{X^b}} = \frac{a}{ 1 + \left( \frac{c}{X} \right)^b} = \frac{a}{ 1 + \left( \frac{c}{X} \right)^b} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Log-logistic functions are used for crop growth, seed germination and bioassay work and they can have the same constraints as the logistic function. The four-parameter logistic is available as ‘LL.4()’ in the ‘drc’ package and as ‘SSfpl()’ in the ‘nlme’ package. This latter function replaces &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(scal = 1/b\)&lt;/span&gt;. Also in ‘drc’, we have ‘LL.3()’ (three-parameter logistic, with &lt;span class=&#34;math inline&#34;&gt;\(c = 0\)&lt;/span&gt;) and ‘LL.2()’ (two-parameter logistic, with &lt;span class=&#34;math inline&#34;&gt;\(d = 1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c = 0\)&lt;/span&gt;). In ‘nlme’ we have ‘SSlogis()’, that is a three-parameter logistic with &lt;span class=&#34;math inline&#34;&gt;\(scal = 1/b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We show an example of a log-logistic fit, relating to a bioassay with &lt;em&gt;Brassica rapa&lt;/em&gt; treated at increasing dosages of an herbicide.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(brassica)
model &amp;lt;- drm(FW ~ Dose, fct = LL.4(), data = brassica)
summary(model)
## 
## Model fitted: Log-logistic (ED50 as parameter) (4 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## b:(Intercept)  1.45113    0.24113  6.0181 1.743e-06 ***
## c:(Intercept)  0.34948    0.18580  1.8810   0.07041 .  
## d:(Intercept)  4.53636    0.20514 22.1140 &amp;lt; 2.2e-16 ***
## e:(Intercept)  2.46557    0.35111  7.0221 1.228e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.4067837 (28 degrees of freedom)
 r
plot(model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;weibull-curve-type-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Weibull curve (type 2)&lt;/h2&gt;
&lt;p&gt;The type 2 Weibull curve is for the Gompertz curve what the log-logistic curve is for the logistic curve. The equation is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \exp \left\{- \exp \left[ b \, (log(X) - log(e)) \right] \right\} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the parameters have the very same meaning as the other sygmoidal curves given above.&lt;/p&gt;
&lt;p&gt;As for fitting, the ‘drc’ package contains the self-starting functions ‘W2.2()’, ‘W2.3()’ and ‘W2.4()’ that can be used to fit respectively the two-, three- and four-parameter type 2 Weibull functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;weibull-curve-type-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Weibull curve (type 1)&lt;/h2&gt;
&lt;p&gt;The type 1 Weibull is similar to the type 2 Weibull, but describes a different type of asymmetry (see above):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \left\{ 1 - \exp \left\{- \exp \left[ b \, (log(X) - log(e)) \right] \right\} \right\}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- drm(FW ~ Dose, fct = W2.4(), data = brassica)
model2 &amp;lt;- drm(FW ~ Dose, fct = W1.4(), data = brassica)
plot(model)
plot(model2, add=T, col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:6346/Articles/usefulEquations_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>