<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Nonlinear_regression on The broken bridge between biologists and statisticians</title>
    <link>/tags/nonlinear_regression/</link>
    <description>Recent content in Nonlinear_regression on The broken bridge between biologists and statisticians</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2018, @AndreaOnofri</copyright>
    <lastBuildDate>Tue, 02 Jul 2019 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="/tags/nonlinear_regression/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Survival analysis and germination data: an overlooked connection</title>
      <link>/2019/stat_survival_germination/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/stat_survival_germination/</guid>
      <description>


&lt;div id=&#34;the-background&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The background&lt;/h1&gt;
&lt;p&gt;Seed germination data describe the time until an event of interest occurs. In this sense, they are very similar to survival data, apart from the fact that we deal with a different (and less sad) event: germination instead of death. But, seed germination data are also similar to failure-time data, phenological data, time-to-remission data… the first point is: &lt;strong&gt;germination data are time-to-event data&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;You may wonder: what’s the matter with time-to-event data? Do they have anything special? With few exceptions, all time-to-event data are affected by a certain form of uncertainty, which takes the name of ‘censoring’. It relates to the fact that the exact time of event may not be precisely know. I think it is good to give an example.&lt;/p&gt;
&lt;p&gt;Let’s take a germination assay, where we put, say, 100 seeds in a Petri dish and make daily inspections. At each inspection, we count the number of germinated seeds. In the end, what have we learnt about the germination time of each seed? It is easy to note that we do not have a precise value, we only have an uncertainty interval. Let’s make three examples.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;If we found a germinated seed at the first inspection time, we only know that germination took place before the inspection (left-censoring).&lt;/li&gt;
&lt;li&gt;If we find a germinated seed at the second inspection time, we only know that germination took place somewhere between the first and the second inspection (interval-censoring).&lt;/li&gt;
&lt;li&gt;If we find an ungerminated seed at the end of the experiment, we only know that its germination time, if any, is higher than the duration of the experiment (right-censoring).&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;censoring-implies-a-lot-of-uncertainty-which-is-additional-to-other-more-common-sources-of-uncertainty-such-as-the-individual-seed-to-seed-variability-or-random-errors-in-the-manipulation-process.-is-censoring-a-problem-yes-it-is-although-it-is-usually-overlooked-in-seed-science-research.-i-made-this-point-in-a-recent-review-onofri-et-al.-2019-and-i-would-like-to-come-back-to-this-issue-here.-the-second-point-is-that-the-analyses-of-data-from-germination-assays-should-always-account-for-censoring.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Censoring implies a lot of uncertainty, which is additional to other more common sources of uncertainty, such as the individual seed-to-seed variability or random errors in the manipulation process. Is censoring a problem? Yes, it is, although it is usually overlooked in seed science research. I made this point in a recent review (Onofri et al., 2019) and I would like to come back to this issue here. The second point is that &lt;strong&gt;the analyses of data from germination assays should always account for censoring&lt;/strong&gt;.&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-analyses-for-germination-assays&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data analyses for germination assays&lt;/h1&gt;
&lt;p&gt;A swift search of literature shows that seed scientists are often interested in describing the time-course of germinations, for different plant species, in different environmental conditions. In simple terms, if we take a population of seeds and give it enough water, the individual seeds will start germinating. Their germination times will be different, due to natural seed-to-seed variability and, therefore, the proportion of germinated seeds will progressively and monotonically increase over time. However, this proportion will almost never reach 1, because, there will often be a fraction of seeds that will not germinate in the given conditions, because it is either dormant or nonviable.&lt;/p&gt;
&lt;p&gt;In order to describe this progress to germination, a log-logistic function is often used:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
G(t) = \frac{d}{ 1 + exp \left\{ - b \right[ \log(t) - \log(e) \left] \right\}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(G\)&lt;/span&gt; is the fraction of germinated seeds at time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the germinable fraction, &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is the median germination time for the germinable fraction and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the slope around the inflection point. The above model is sygmoidally shaped and it is symmetric on a log-time scale. The three parameters are biologically relevant, as they describe the three main features of seed germination, i.e. capability (&lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;), speed (&lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;) and uniformity (&lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;).&lt;/p&gt;
&lt;div id=&#34;my-third-point-in-this-post-is-that-the-process-of-data-analysis-for-germination-data-is-often-based-on-fitting-a-log-logistic-or-similar-model-to-the-observed-counts.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;My third point in this post is that &lt;strong&gt;The process of data analysis for germination data is often based on fitting a log-logistic (or similar) model to the observed counts&lt;/strong&gt;.&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;motivating-example-a-simulated-dataset&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Motivating example: a simulated dataset&lt;/h1&gt;
&lt;p&gt;Considering the above, we can simulate the results of a germination assay. Let’s take a 100-seed-sample from a population where we have 85% of germinable seeds (&lt;span class=&#34;math inline&#34;&gt;\(d = 0.85\)&lt;/span&gt;), with a median germination time &lt;span class=&#34;math inline&#34;&gt;\(e = 4.5\)&lt;/span&gt; days and &lt;span class=&#34;math inline&#34;&gt;\(b = 1.6\)&lt;/span&gt;. Obviously, this sample will not necessarily reflect the characteristics of the population. We can do this sampling in R, by using a three-steps approach.&lt;/p&gt;
&lt;div id=&#34;step-1-the-ungerminated-fraction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 1: the ungerminated fraction&lt;/h2&gt;
&lt;p&gt;First, let’s simulate the number of germinated seeds, assuming a binomial distribution with a proportion of successes equal to 0.85. We use the random number generator ‘rbinom()’:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Monte Carlo simulation - Step 1
d &amp;lt;- 0.85
set.seed(1234)
nGerm &amp;lt;- rbinom(1, 100, d)
nGerm
## [1] 89&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that, in this instance, 89 seeds germinated out of 100, which is not the expected 85%. This is a typical random fluctuation: indeed, we were lucky in selecting a good sample of seeds.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-2-germination-times-for-the-germinated-fraction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 2: germination times for the germinated fraction&lt;/h2&gt;
&lt;p&gt;Second, let’s simulate the germination times for these 89 germinable seeds, by drawing from a log-logistic distribution with &lt;span class=&#34;math inline&#34;&gt;\(b = 1.6\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(e = 4.5\)&lt;/span&gt;. To this aim, we use the ‘rllogis()’ function in the ‘actuar’ package (Dutang et al., 2008):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Monte Carlo simulation - Step 2
library(actuar)
b &amp;lt;- 1.6; e &amp;lt;- 4.5 
Gtimes &amp;lt;- rllogis(nGerm, shape = b, scale = e)
Gtimes &amp;lt;- c(Gtimes, rep(Inf, 100 - nGerm))
Gtimes
##   [1]  3.2936708  3.4089762  3.2842199  1.4401630  3.1381457 82.1611955
##   [7]  9.4906364  2.9226745  4.3424551  2.7006042  4.0202158  8.0519663
##  [13]  0.9492013  7.8199588  1.6163588  7.9661485  8.4641154 11.2879041
##  [19]  9.5014360  7.2786264  7.5809838 12.7421713 32.7999661  9.9691944
##  [25]  1.8137333  4.2197542  1.0218849  1.6604417 30.0352308  5.0235265
##  [31]  8.5085067  7.5367739  4.4185382 11.5555259  2.1919263 10.6509339
##  [37]  8.6857151  0.2185902  1.8377033  3.9362727  3.0864702  7.3804164
##  [43]  3.2978782  7.0100360  4.4775843  2.8328842  4.6721090  9.1258796
##  [49]  2.1485568 21.8749808  7.4265984  2.5148724  4.4491466 13.1132301
##  [55]  4.4559642  4.5684584  2.2556488 11.8783556  1.5338755  1.4106592
##  [61] 31.8419420  7.2666641 65.0154287  9.2798476  2.5988399  7.4612907
##  [67]  4.4048509 27.7439121  3.8257187 15.4967751  1.1960785 62.5152642
##  [73]  2.0169970 19.1134899  4.2891084  6.0420938 22.6521417  7.1946293
##  [79]  2.9028993  0.9241876  4.8277336 13.8068124  4.0273655 10.8651761
##  [85]  1.1509735  5.9593534  7.4009589 12.6839405  1.1698335        Inf
##  [91]        Inf        Inf        Inf        Inf        Inf        Inf
##  [97]        Inf        Inf        Inf        Inf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we have a vector hosting 100 germination times (‘Gtimes’). Please, note that I added 11 infinite germination times, to represent non-germinable seeds.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;step-3-counts-of-germinated-seeds&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Step 3: counts of germinated seeds&lt;/h2&gt;
&lt;p&gt;Unfortunately, due to the monitoring schedule, we cannot observe the exact germination time for each single seed in the sample; we can only count the seeds which have germinated between two assessment times. Therefore, as the third step, we simulate the observed counts, by assuming daily monitoring for 40 days.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;obsT &amp;lt;- seq(1, 40, by=1) #Observation schedule
count &amp;lt;- table( cut(Gtimes, breaks = c(0, obsT)) )
count
## 
##   (0,1]   (1,2]   (2,3]   (3,4]   (4,5]   (5,6]   (6,7]   (7,8]   (8,9] 
##       3      11      10       8      13       2       1      12       4 
##  (9,10] (10,11] (11,12] (12,13] (13,14] (14,15] (15,16] (16,17] (17,18] 
##       5       2       3       2       2       0       1       0       0 
## (18,19] (19,20] (20,21] (21,22] (22,23] (23,24] (24,25] (25,26] (26,27] 
##       0       1       0       1       1       0       0       0       0 
## (27,28] (28,29] (29,30] (30,31] (31,32] (32,33] (33,34] (34,35] (35,36] 
##       1       0       0       1       1       1       0       0       0 
## (36,37] (37,38] (38,39] (39,40] 
##       0       0       0       0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see that, e.g., 11 germinated seeds were counted at day 2; therefore they germinated between day 1 and day 2 and their real germination time is unknown, but included in the range between 1 and 2 (left-open and right-closed). This is a typical example of interval-censoring (see above).&lt;/p&gt;
&lt;p&gt;We can also see that, in total, we counted 86 germinated seeds and, therefore, 14 seeds were still ungerminated at the end of the assay. For this simulation exercise, we know that 11 seeds were non-germinable and three seeds were germinable, but were not allowed enough time to germinate (look at the table above: there are 3 seeds with germination times higher than 40). In real life, this is another source of uncertainty: we might be able to ascertain whether these 14 seeds are viable or not (e.g. by using a tetrazolium test), but, if they are viable, we would never be able to tell whether they are dormant or their germination time is simply longer than the duration of the assay. In real life, we can only reach an uncertain conclusion: the germination time of the 14 ungerminated seeds is comprised between 40 days to infinity; this is an example of right-censoring.&lt;/p&gt;
&lt;p&gt;The above uncertainty affects our capability of describing the germination time-course from the observed data. We can try to picture the situation in the graph below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/Stat_Survival_Germination_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-the-real-germination-time-course-the-red-one-the-blue-one-something-in-between-we-cannot-really-say-this-from-our-dataset-we-are-uncertain.-the-grey-areas-represent-the-uncertainty-due-to-censoring.-do-you-think-that-we-can-reasonably-neglect-it&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is the real germination time-course? The red one? The blue one? Something in between? We cannot really say this from our dataset, we are uncertain. The grey areas represent the uncertainty due to censoring. Do you think that we can reasonably neglect it?&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;The question is: how do we fit a log-logistic function to this dataset? We can either neglect censoring or account for it. Let’s see the differences.&lt;/p&gt;
&lt;div id=&#34;ignoring-censoring&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Ignoring censoring&lt;/h2&gt;
&lt;p&gt;We have seen that the time-corse of germination can be described by using a log-logistic cumulative distribution function. Therefore, seed scientists are used to re-organising their data, as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;counts &amp;lt;- as.numeric( table( cut(Gtimes, breaks = c(0, obsT)) ) )
propCum &amp;lt;- cumsum(counts)/100
df &amp;lt;- data.frame(time = obsT, counts = counts, propCum = propCum) 
df
##    time counts propCum
## 1     1      3    0.03
## 2     2     11    0.14
## 3     3     10    0.24
## 4     4      8    0.32
## 5     5     13    0.45
## 6     6      2    0.47
## 7     7      1    0.48
## 8     8     12    0.60
## 9     9      4    0.64
## 10   10      5    0.69
## 11   11      2    0.71
## 12   12      3    0.74
## 13   13      2    0.76
## 14   14      2    0.78
## 15   15      0    0.78
## 16   16      1    0.79
## 17   17      0    0.79
## 18   18      0    0.79
## 19   19      0    0.79
## 20   20      1    0.80
## 21   21      0    0.80
## 22   22      1    0.81
## 23   23      1    0.82
## 24   24      0    0.82
## 25   25      0    0.82
## 26   26      0    0.82
## 27   27      0    0.82
## 28   28      1    0.83
## 29   29      0    0.83
## 30   30      0    0.83
## 31   31      1    0.84
## 32   32      1    0.85
## 33   33      1    0.86
## 34   34      0    0.86
## 35   35      0    0.86
## 36   36      0    0.86
## 37   37      0    0.86
## 38   38      0    0.86
## 39   39      0    0.86
## 40   40      0    0.86&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In practice, seed scientists often use the observed counts to determine the cumulative proportion (or percentage) of germinated seeds. The cumulative proportion (‘propCum’) is used as the response variable, while the observation time (‘time’) is used as the independent variable and a log-logistic function is fitted by non-linear least squares regression. &lt;strong&gt;Hope that you can clearly see that, by doing so, we totally neglect the grey areas in the figure above, we only look at the observed points&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We can fit a nonlinear regression model by using the ‘drm’ function, in the ‘drc’ package (Ritz et al., 2015). The argument ‘fct’ is used to set the fitted function to log-logistic with three parameters (the equation above).&lt;/p&gt;
&lt;p&gt;The ‘plot()’ and ‘summary()’ methods can be used to plot a graph and to retrieve the estimated parameters.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(drc)
mod &amp;lt;- drm(propCum ~ time, data = df,
           fct = LL.3() )
plot(mod, log = &amp;quot;&amp;quot;,
      xlab = &amp;quot;Time (days)&amp;quot;,
      ylab = &amp;quot;Proportion of germinated seeds&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/Stat_Survival_Germination_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(mod)
## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)
## 
## Parameter estimates:
## 
##                 Estimate Std. Error t-value   p-value    
## b:(Intercept) -1.8497771  0.0702626 -26.327 &amp;lt; 2.2e-16 ***
## d:(Intercept)  0.8768793  0.0070126 125.044 &amp;lt; 2.2e-16 ***
## e:(Intercept)  5.2691575  0.1020457  51.635 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.01762168 (37 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that our estimates are very close to the real values (&lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; = 1.85 vs. 1.6; &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; = 5.27 vs. 4.5; &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; = 0.88 vs. 0.86) and we also see that standard errors are rather small (the coefficient of variability goes from 1 to 4%). There is a difference in sign for &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, which relates to the fact that the ‘LL.3()’ function in ‘drc’ removes the minus sign in the equation above. Please, disregard this aspect, which stems from the fact that the ‘drc’ package is rooted in pesticide bioassays.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;accounting-for-censoring&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Accounting for censoring&lt;/h2&gt;
&lt;p&gt;So far, we have totally neglected censoring. But, how can we account for it? The answer is simple: as with survival studies, we should use time-to-event methods, which are specifically devised to incorporate the uncertainty due to censoring. In medicine, the body of time-to-event methods goes under the name of survival analysis, which explains the title of my post. My colleagues and I have extensively talked about these methods in two of our recent papers and related appendices (Onofri et al., 2019; Onofri et al., 2018). Therefore, I will not go into detail, now.&lt;/p&gt;
&lt;p&gt;I will just say that time-to-event methods directly consider the observed counts as the response variable. As the independent variable, they consider the extremes of each time interval (‘timeBef’ and ‘timeAf’; see below). In contrast to nonlinear regression, we do not need to transform the observed counts into cumulative proportions, as we did before. Furthermore, by using an interval as the independent variable, we inject into the model the uncertainty due to censoring.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- data.frame(timeBef = c(0, obsT), timeAf = c(obsT, Inf), counts = c(as.numeric(counts), 100 - sum(counts)) )
df
##    timeBef timeAf counts
## 1        0      1      3
## 2        1      2     11
## 3        2      3     10
## 4        3      4      8
## 5        4      5     13
## 6        5      6      2
## 7        6      7      1
## 8        7      8     12
## 9        8      9      4
## 10       9     10      5
## 11      10     11      2
## 12      11     12      3
## 13      12     13      2
## 14      13     14      2
## 15      14     15      0
## 16      15     16      1
## 17      16     17      0
## 18      17     18      0
## 19      18     19      0
## 20      19     20      1
## 21      20     21      0
## 22      21     22      1
## 23      22     23      1
## 24      23     24      0
## 25      24     25      0
## 26      25     26      0
## 27      26     27      0
## 28      27     28      1
## 29      28     29      0
## 30      29     30      0
## 31      30     31      1
## 32      31     32      1
## 33      32     33      1
## 34      33     34      0
## 35      34     35      0
## 36      35     36      0
## 37      36     37      0
## 38      37     38      0
## 39      38     39      0
## 40      39     40      0
## 41      40    Inf     14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Time-to-event models can be easily fitted by using the same function as we used above (the ‘drm()’ function in the ‘drc’ package). However, there are some important differences in the model call. The first one relate to model definition: a nonlinear regression model is defined as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CumulativeProportion ~ timeAf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the other hand, a time-to-event model is defined as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Count ~ timeBef + timeAf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A second difference is that we need to explicitly set the argument ‘type’, to ‘event’:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Time-to-event model
modTE &amp;lt;- drm(counts ~ timeBef + timeAf, data = df, 
           fct = LL.3(), type = &amp;quot;event&amp;quot;)
summary(modTE)
## 
## Model fitted: Log-logistic (ED50 as parameter) with lower limit at 0 (3 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## b:(Intercept) -1.826006   0.194579 -9.3844 &amp;lt; 2.2e-16 ***
## d:(Intercept)  0.881476   0.036928 23.8701 &amp;lt; 2.2e-16 ***
## e:(Intercept)  5.302109   0.565273  9.3797 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;with-respect-to-the-nonlinear-regression-fit-the-estimates-from-a-time-to-event-fit-are-very-similar-but-the-standard-errors-are-much-higher-the-coefficient-of-variability-now-goes-from-4-to-11.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;With respect to the nonlinear regression fit, the estimates from a time-to-event fit are very similar, but the standard errors are much higher (the coefficient of variability now goes from 4 to 11%).&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;neglecting-or-accounting-for-censoring&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Neglecting or accounting for censoring?&lt;/h1&gt;
&lt;p&gt;You may wonder which of the two analysis is right and which is wrong. We cannot say this from just one dataset. However, we can repeat the Monte Carlo simulation above to extract 1000 samples, fit the model by using the two methods and retrieve parameter estimates and standard errors for each sample and method. We do this by using the code below (please, be patient… it may take some time).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GermSampling &amp;lt;- function(nSeeds, timeLast, stepOss, e, b, d){
    
    #Draw a sample as above
    nGerm &amp;lt;- rbinom(1, nSeeds, d)
    Gtimes &amp;lt;- rllogis(nGerm, shape = b, scale = e)
    Gtimes &amp;lt;- c(Gtimes, rep(Inf, 100 - nGerm))

    
    #Generate the observed data
    obsT &amp;lt;- seq(1, timeLast, by=stepOss) 
    counts &amp;lt;- as.numeric( table( cut(Gtimes, breaks = c(0, obsT)) ) )
    propCum &amp;lt;- cumsum(counts)/nSeeds
    timeBef &amp;lt;- c(0, obsT)
    timeAf &amp;lt;- c(obsT, Inf)
    counts &amp;lt;- c(counts, nSeeds - sum(counts))
    
    #Calculate the T50 with two methods
    mod &amp;lt;- drm(propCum ~ obsT, fct = LL.3() )
    modTE &amp;lt;- drm(counts ~ timeBef + timeAf, 
           fct = LL.3(), type = &amp;quot;event&amp;quot;)
    c(b1 = summary(mod)[[3]][1,1],
      ESb1 = summary(mod)[[3]][1,2],
      b2 = summary(modTE)[[3]][1,1],
      ESb2 = summary(modTE)[[3]][1,2],
      d1 = summary(mod)[[3]][2,1],
      ESd1 = summary(mod)[[3]][2,2],
      d2 = summary(modTE)[[3]][2,1],
      ESd2 = summary(modTE)[[3]][2,2],
      e1 = summary(mod)[[3]][3,1],
      ESe1 = summary(mod)[[3]][3,2],
      e2 = summary(modTE)[[3]][3,1],
      ESe2 = summary(modTE)[[3]][3,2] )
}

set.seed(1234)
result &amp;lt;- data.frame()
for (i in 1:1000) {
  res &amp;lt;- GermSampling(100, 40, 1, 4.5, 1.6, 0.85)
  result &amp;lt;- rbind(result, res)
} 
names(result) &amp;lt;- c(&amp;quot;b1&amp;quot;, &amp;quot;ESb1&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;ESb2&amp;quot;,
                   &amp;quot;d1&amp;quot;, &amp;quot;ESd1&amp;quot;, &amp;quot;d2&amp;quot;, &amp;quot;ESd2&amp;quot;,
                   &amp;quot;e1&amp;quot;, &amp;quot;ESe1&amp;quot;, &amp;quot;e2&amp;quot;, &amp;quot;ESe2&amp;quot;)
result &amp;lt;- result[result$d2 &amp;gt; 0,]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have stored our results in the data frame ‘result’. The means of estimates obtained for both methods should be equal to the real values that we used for the simulation, which will ensure that estimators are unbiased. The means of standard errors (in brackets, below) should represent the real sample-to-sample variability, which may be obtained from the Monte Carlo standard deviation, i.e. from the standard deviation of the 1000 estimates for each parameter and method.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;b&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Nonlinear regression&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.63 (0.051)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.85 (0.006)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.55 (0.086)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Time-to-event method&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.62 (0.187)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.85 (0.041)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.55 (0.579)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Real values&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1.60 (0.188)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.85 (0.041)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.55 (0.593)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div id=&#34;we-clearly-see-that-both-nonlinear-regression-and-the-time-to-event-method-lead-to-unbiased-estimates-of-model-parameters.-however-standard-errors-from-nonlinear-regression-are-severely-biased-and-underestimated.-on-the-contrary-standard-errors-from-time-to-event-method-are-unbiased.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We clearly see that both nonlinear regression and the time-to-event method lead to unbiased estimates of model parameters. However, standard errors from nonlinear regression are severely biased and underestimated. On the contrary, standard errors from time-to-event method are unbiased.&lt;/h2&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;take-home-message&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Take-home message&lt;/h1&gt;
&lt;p&gt;Censoring is peculiar to germination assays and other time-to-event studies. It may have a strong impact on the reliability of our standard errors and, consequently, on hypotheses testing. Therefore, censoring should never be neglected and time-to-event methods should necessarily be used for data analyses with germination assays. The body of time-to-event methods often goes under the name of ‘survival analysis’, which creates a direct link between survival data and germination data.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;C. Dutang, V. Goulet and M. Pigeon (2008). actuar: An R Package for Actuarial Science. Journal of Statistical Software, vol. 25, no. 7, 1-37.&lt;/li&gt;
&lt;li&gt;Onofri, Andrea, Paolo Benincasa, M B Mesgaran, and Christian Ritz. 2018. Hydrothermal-Time-to-Event Models for Seed Germination. European Journal of Agronomy 101: 129–39.&lt;/li&gt;
&lt;li&gt;Onofri, Andrea, Hans Peter Piepho, and Marcin Kozak. 2019. Analysing Censored Data in Agricultural Research: A Review with Examples and Software Tips. Annals of Applied Biology, 174, 3-13.&lt;/li&gt;
&lt;li&gt;Ritz, C., F. Baty, J. C. Streibig, and D. Gerhard. 2015. Dose-Response Analysis Using R. PLOS ONE, 10 (e0146021, 12).&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Some useful equations for nonlinear regression in R</title>
      <link>/articles/usefulequations/</link>
      <pubDate>Tue, 08 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/articles/usefulequations/</guid>
      <description>


&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Very rarely, biological processes follow linear trends. Just think about how a crop grows, or responds to increasing doses of fertilisers/xenobiotics. Or think about how an herbicide degrades in the soil, or about the germination pattern of a seed population. It is very easy to realise that curvilinear trends are far more common than linear trends. Furthermore, asymptotes and/or inflection points are very common in nature. We can be sure: linear equations in biology are just a way to approximate a response over a very narrow range for the independent variable.&lt;/p&gt;
&lt;p&gt;Therefore, as biologists, we need to be able to describe our experimental data by using a wide range of curvilinear equations. We need to be able to ‘read’ those equations and use their parameters to interpret and understand biological processes. I thought that it would be useful to list the most commonly used curvilinear functions and show examples of how they can be fit by using R.&lt;/p&gt;
&lt;p&gt;When it comes to nonlinear regression, I have a strong personal preference for the ‘drc’ package and the ‘drm()’ function therein. However, it is also worth mentioning the traditional ‘nls()’ function in the ‘stats’ package. You may know that nonlinear least squares work iteratively: we need to provide initial guesses for model parameters and the algorithm adjusts them step by step, finally converging on the approximate least squares solution. To my experience, providing initial guesses may be troublesome. Therefore, it is very convenient to use R functions together with the appropriate self-starting routines, which can greatly semplify the fitting process. These self-starters can be found in the ‘drc’, ‘nlme’ and ‘aomisc’ packages.&lt;/p&gt;
&lt;p&gt;Let’s load the necessary packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(drc)
library(nlme)
library(aomisc)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;curve-shapes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Curve shapes&lt;/h1&gt;
&lt;p&gt;Curves can be easily classified by their shape, which is very helpful to select the correct one, according to the trend of the process under study. We have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Polynomials
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Straight line&lt;/li&gt;
&lt;li&gt;Quadratic polynomial&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Concave/Convex curves (no inflection)
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Exponential curve&lt;/li&gt;
&lt;li&gt;Asymptotic regression&lt;/li&gt;
&lt;li&gt;Negative exponential function&lt;/li&gt;
&lt;li&gt;Power curve&lt;/li&gt;
&lt;li&gt;Logarithmic equation&lt;/li&gt;
&lt;li&gt;Rectangular hyperbola&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;Sygmoidal curves
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Logistic curve&lt;/li&gt;
&lt;li&gt;Gompertz curve&lt;/li&gt;
&lt;li&gt;Extreme value equation&lt;/li&gt;
&lt;li&gt;Log-logistic curve (Hill equation)&lt;/li&gt;
&lt;li&gt;Weibull-type 1&lt;/li&gt;
&lt;li&gt;Weibull-type 2&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;polynomials&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Polynomials&lt;/h1&gt;
&lt;p&gt;Polynomials are the most flexible tool to describe biological processes. They are simple and, although curvilinear, they are linear in the parameters and can be fitted by using linear regression. One disadvantage is that they cannot describe asymptotic processes, which are very common in biology. Furthermore, they are prone to overfitting, as we may be tempted to add terms to improve the fit, with little care for biological realism.&lt;/p&gt;
&lt;p&gt;Nowadays, thanks to the wide availability of nonlinear regression algorithms, the use of polynomials has sensibly decreased; linear or quadratic polynomials are mainly used when we want to approximate the observed response within a narrow range of a quantitative predictor. On the other hand, higher order polynomials are very rarely seen, in practice.&lt;/p&gt;
&lt;div id=&#34;straight-line&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Straight line&lt;/h2&gt;
&lt;p&gt;Obviously, this is not a curve, although it deserves to be mentioned here. The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = b_0 + b_1 \, X\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(b_0\)&lt;/span&gt; is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b_1\)&lt;/span&gt; is the slope, i.e. the increase/decrease in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for a unit-increase in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The Y increases as X increases when &lt;span class=&#34;math inline&#34;&gt;\(b_1 &amp;gt; 0\)&lt;/span&gt;, otherwise it decreases.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quadratic-function&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Quadratic function&lt;/h2&gt;
&lt;p&gt;The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = b_0 + b_1\, X + b_2 \, X^2\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(b_0\)&lt;/span&gt; is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;, while &lt;span class=&#34;math inline&#34;&gt;\(b_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b_2\)&lt;/span&gt;, taken separately, lack a clear biological meaning. However, it is interesting to consider that the first derivative is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a + b*X + c*X^2), &amp;quot;X&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## b + c * (2 * X)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which measures the increase/decrease in &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for a unit-increase in &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. We see that such an increase/decrease is not constant, but it changes according to the level of X. The stationary point is &lt;span class=&#34;math inline&#34;&gt;\(X_m = - b_1 / 2 b_2\)&lt;/span&gt;; it is a maximum when &lt;span class=&#34;math inline&#34;&gt;\(b_2 &amp;gt; 0\)&lt;/span&gt;, otherwise it is a minimum.&lt;/p&gt;
&lt;p&gt;At the maximum/minimum, it is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_m = \frac{4\,b_0\,b_2 - b_1^2}{4\,b_2}\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;polynomial-fitting-in-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Polynomial fitting in R&lt;/h2&gt;
&lt;p&gt;Polynomials in R are fit by using the linear model function ‘lm()’. Although this is not efficient, in a couple of cases I found myself in the need of fitting a polynomial by using the ‘nls()’ o ‘drm()’ functions. For these unusual cases, one can use the ‘NLS.Linear()’, NLS.poly2(), ‘DRC.Linear()’ and DRC.Poly2() self-starting function, as available in the ‘aomisc’ package.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;concaveconvex-curves&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Concave/Convex curves&lt;/h1&gt;
&lt;div id=&#34;exponential-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Exponential curve&lt;/h2&gt;
&lt;p&gt;The exponential function describes an increasing/decreasing &lt;em&gt;trend&lt;/em&gt;, with constant relative rate. The most common equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = a  e^{k X}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Other possible parameterisations are:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = a  b^X  =  e^{d + k X}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The above parameterisations are equivalent, as proved by setting &lt;span class=&#34;math inline&#34;&gt;\(b = e^k\)&lt;/span&gt; e &lt;span class=&#34;math inline&#34;&gt;\(a = e^d\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a  b^X  = a  (e^k)^{X} =  a  e^{kX}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a  e^{kX} = e^d \cdot e^{kX} =  e^{d + kX}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The meaning of parameters is clear: &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is the value of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;, while &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; represents the relative increase/decrease of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for a unit increase of X. &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases if &lt;span class=&#34;math inline&#34;&gt;\(k &amp;gt; 0\)&lt;/span&gt; (exponential growth), while it decreases when &lt;span class=&#34;math inline&#34;&gt;\(k &amp;lt; 0\)&lt;/span&gt; (exponential decay). This curve is used to describe the growth of populations in unlimiting environmental conditions, or to describe the degradation of xenobiotics in the environment (first-order degradation kinetic).&lt;/p&gt;
&lt;p&gt;The exponential function is nonlinear in &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; and needs to be fitted by using ‘nls()’ or ‘drm()’. It is possible to make profit of the self-starting routines in ‘NLS.expoGrowth()’, ‘NLS.expoDecay()’, ‘DRC.expoGrowth()’ and ‘DRC.expoDecay()’. All these functions are available in the ‘aomisc’ package. The ‘drc’ package also contains the function ‘EXD.2()’, that fits an exponential decay model, with a slightly different parameterisation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = d \exp(-x/e) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the same as &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; in the model above and &lt;span class=&#34;math inline&#34;&gt;\(e = 1/k\)&lt;/span&gt;. For all the forementioned exponential decay equations &lt;span class=&#34;math inline&#34;&gt;\(Y \rightarrow 0\)&lt;/span&gt; as &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow \infty\)&lt;/span&gt;. The function ‘EXD.3()’ in the ‘drc’ package also includes a lower asymptote &lt;span class=&#34;math inline&#34;&gt;\(c \neq 0\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d -c) \exp(-x/e) \]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(degradation)
degradation&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Time    Conc
## 1     0  96.400
## 2    10  46.300
## 3    20  21.200
## 4    30  17.890
## 5    40  10.100
## 6    50   6.900
## 7    60   3.500
## 8    70   1.900
## 9     0 102.300
## 10   10  49.200
## 11   20  26.310
## 12   30  14.220
## 13   40   5.400
## 14   50   3.400
## 15   60   0.500
## 16   70   0.200
## 17    0 101.330
## 18   10  54.890
## 19   20  28.120
## 20   30  13.330
## 21   40   6.110
## 22   50   0.350
## 23   60   2.100
## 24   70   0.922&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- drm(Conc ~ Time, fct = DRC.expoDecay(),
             data = degradation)
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Exponential Decay Model (2 parms)
## 
## Parameter estimates:
## 
##                    Estimate Std. Error t-value   p-value    
## init:(Intercept) 99.6349312  1.4646680  68.026 &amp;lt; 2.2e-16 ***
## k:(Intercept)     0.0670391  0.0019089  35.120 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  2.621386 (22 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;asymptotic-regression-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Asymptotic regression model&lt;/h2&gt;
&lt;p&gt;The asymptotic regression model describes a limited growth, where Y approaches an horizontal asymptote as X tends to infinity. The rate of growth is maximum at the beginning and approaches 0 as Y approaches the plateau. This equation is used in several different parameterisations and it is also known as Monomolecular Growth, Mitscherlich law or von Bertalanffy law.&lt;/p&gt;
&lt;p&gt;Due to its biological meaning, the most widespread parameterisation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a - (a - b) \, \exp (- c  X)\]&lt;/span&gt;
where &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is the maximum attainable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at &lt;span class=&#34;math inline&#34;&gt;\(x = 0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is proportional to the relative rate of Y increase while X increases. Indeed, we can see that the first derivative is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a - (a - b) * exp (- c * X)), &amp;quot;X&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (a - b) * (exp(-c * X) * c)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;that is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y&amp;#39; = c \, (a - Y)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This model can be fit with R by using the self starter functions ‘NLS.asymReg()’ and DRC.asymReg(), in the ‘aomisc’ package. The ‘drc’ package contains the function AR.3(), that is a similar parameterisation where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(e = 1/c\)&lt;/span&gt;. The ‘nlme’ package also contains an alternative parameterisation named ‘SSasymp()’, where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(\phi_3 = \log(c)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We simulate an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
X &amp;lt;- c(1, 3, 5, 7, 9, 11, 13, 20)
a &amp;lt;- 20; b &amp;lt;- 5; c &amp;lt;- 0.3
Ye &amp;lt;- asymReg.fun(X, a, b, c)
epsilon &amp;lt;- rnorm(8, 0, 0.5)
Y &amp;lt;- Ye + epsilon
model &amp;lt;- drm(Y ~ X, fct = DRC.asymReg())
plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we take the above equation and add the constraint that &lt;span class=&#34;math inline&#34;&gt;\(b = 0\)&lt;/span&gt;, we get the following equation, that is often known as negative exponential equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a [1 -  \exp (- c  X) ]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This equation has a similar shape to the asymptotic regression, but Y is 0 when X is 0 (the curve passes through the origin). It is often used to model the absorbed Photosintetically Active Radiation (&lt;span class=&#34;math inline&#34;&gt;\(Y = PAR_a\)&lt;/span&gt;) as a function of incident PAR (&lt;span class=&#34;math inline&#34;&gt;\(a = PAR_i\)&lt;/span&gt;), Leaf Area Index (X = LAI) and the extinction coefficient (c = k).&lt;/p&gt;
&lt;p&gt;This model can be fit with R by using the self starter functions ‘NLS.negExp()’ and DRC.negExp(), in the ‘aomisc’ package. The ‘drc’ package contains the function AR.2(), where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(e = 1/c\)&lt;/span&gt;. The ‘nlme’ package also contains an alternative parameterisation, named ‘SSasympOrig()’, where &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(\phi_3 = \log(c)\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;power-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Power curve&lt;/h2&gt;
&lt;p&gt;The power curve is also known as Freundlich equation or allometric function and the most common parameterisation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = a \, X^b\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This curve is perfectly equivalent to an exponential curve on the
logarithm of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. Indeed:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[a\,X^b  = a\, e^{\log( X^b )}  = a\,e^{b \, \log(x)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This curve does not have an asymptote for &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow \infty\)&lt;/span&gt;. The slope (first derivative) of the curve is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression(a * X^b), &amp;quot;X&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## a * (X^(b - 1) * b)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that both paraeters relate to the slope of the curve and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; dictates its shape. If &lt;span class=&#34;math inline&#34;&gt;\(0 &amp;lt;- b &amp;lt; 1\)&lt;/span&gt;, Y increases as X increases and the curve is convex up. This is used, e.g., to model the number of plant species as a function of sampling area (Muller-Dumbois method).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(speciesArea)
speciesArea&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   Area numSpecies
## 1    1          4
## 2    2          5
## 3    4          7
## 4    8          8
## 5   16         10
## 6   32         14
## 7   64         19
## 8  128         22
## 9  256         26&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- drm(numSpecies ~ Area, fct = DRC.powerCurve(),
             data = speciesArea)
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Power curve (Freundlich equation) (2 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## a:(Intercept) 4.348404   0.337197  12.896 3.917e-06 ***
## b:(Intercept) 0.329770   0.016723  19.719 2.155e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.9588598 (7 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(b &amp;lt; 0\)&lt;/span&gt;, the curve is concave up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; decreases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;curve(powerCurve.fun(x, coef(model)[1], -coef(model)[2]),
      xlab = &amp;quot;X&amp;quot;, ylab = &amp;quot;Y&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If &lt;span class=&#34;math inline&#34;&gt;\(b &amp;gt; 1\)&lt;/span&gt; is negative, the curve is concave up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;curve(powerCurve.fun(x, coef(model)[1], 2),
      xlab = &amp;quot;X&amp;quot;, ylab = &amp;quot;Y&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;logarithmic-equation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logarithmic equation&lt;/h2&gt;
&lt;p&gt;This is indeed a linear model on log-transformed X:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y = a + b \, \log(X)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Due to the logarithmic function, X must be $ &amp;gt; 0$. The parameter &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; dictates the shape: if &lt;span class=&#34;math inline&#34;&gt;\(b &amp;gt; 0\)&lt;/span&gt;, the curve is convex up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases. If &lt;span class=&#34;math inline&#34;&gt;\(b &amp;lt; 0\)&lt;/span&gt;, the curve is concave up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; decreases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;p&gt;The logarithmic equation can be fit by using ‘lm()’. If necessary, it can also be fit by using ‘nls()’ and ‘drm()’; the self-starting functions ‘NLS.logCurve()’ and ‘DRC.logCurve()’ are available within the ‘aomisc’ package. We show some simulated data as examples.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#b is positive
set.seed(5678)
X &amp;lt;- c(1,2,4,5,7,12)
a&amp;lt;-2; b&amp;lt;- 0.5
Ye &amp;lt;-  a + b*log(X)
res &amp;lt;- rnorm(6, 0, 0.1)
Y &amp;lt;- Ye + res
model &amp;lt;- lm(Y ~ log(X) )
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## lm(formula = Y ~ log(X))
## 
## Residuals:
##         1         2         3         4         5         6 
## -0.025947  0.013207  0.050827 -0.011989 -0.008408 -0.017690 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)  1.99653    0.02494   80.06 1.46e-07 ***
## log(X)       0.45088    0.01580   28.54 8.97e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.03146 on 4 degrees of freedom
## Multiple R-squared:  0.9951, Adjusted R-squared:  0.9939 
## F-statistic: 814.7 on 1 and 4 DF,  p-value: 8.967e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- drm(Y ~ X, fct = DRC.logCurve() )
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Linear regression on log-transformed x (2 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## a:(Intercept) 1.996534   0.024939  80.058 1.459e-07 ***
## b:(Intercept) 0.450883   0.015797  28.543 8.967e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.03145785 (4 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#b is negative
X &amp;lt;- c(1,2,4,5,7,12)
a &amp;lt;- 2; b &amp;lt;- -0.5
Ye &amp;lt;-  a + b*log(X)
res &amp;lt;- rnorm(6, 0, 0.1)
Y &amp;lt;- Ye + res
model &amp;lt;- drm(Y ~ X, fct = DRC.logCurve() )
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Linear regression on log-transformed x (2 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## a:(Intercept)  2.115759   0.103920 20.3595 3.437e-05 ***
## b:(Intercept) -0.569125   0.065826 -8.6459 0.0009843 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.1310851 (4 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-10-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;michaelis-menten-equation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Michaelis-Menten equation&lt;/h2&gt;
&lt;p&gt;This is a rectangular hyperbola, often parameterised as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = \frac{a \, X} {b + X}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This curve is convex up and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increases as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases, up to a plateau level. The parameter &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; represents the higher asymptote (for &lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow \infty\)&lt;/span&gt;), while &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the X value giving a response equal to &lt;span class=&#34;math inline&#34;&gt;\(a/2\)&lt;/span&gt;. Indeed, it is easily shown that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\frac{a}{2} = \frac{a\,X_{50} } {b + X_{50} }\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which leads to &lt;span class=&#34;math inline&#34;&gt;\(b = x_{50}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The slope (first derivative) is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;D(expression( (a*X) / (b + X) ), &amp;quot;X&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## a/(b + X) - (a * X)/(b + X)^2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From there, we can see that the initial slope (at &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;) is $i = a/b $.&lt;/p&gt;
&lt;p&gt;In R, this model can be fit by using ‘nls()’ and the self starting functions ‘SSmicmen()’, within the package ‘nlme’. If we prefer a ‘drm()’ fit, we can use the ‘MM.2()’ function in the package ‘drc’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1234)
X &amp;lt;- c(3, 5, 7, 22, 28, 39, 46, 200)
a &amp;lt;- 15; b &amp;lt;- 0.5
Ye &amp;lt;- as.numeric( SSmicmen(X, a, b) )
res &amp;lt;- rnorm(8, 0, 0.1)
Y &amp;lt;- Ye + res

#nls fit
model &amp;lt;- nls(Y ~ SSmicmen(X, a, b))
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Formula: Y ~ SSmicmen(X, a, b)
## 
## Parameters:
##   Estimate Std. Error t value Pr(&amp;gt;|t|)    
## a 14.97166    0.06057  247.17 2.96e-13 ***
## b  0.50207    0.03345   15.01 5.51e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 0.1196 on 6 degrees of freedom
## 
## Number of iterations to convergence: 0 
## Achieved convergence tolerance: 3.043e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#drm fit
model &amp;lt;- drm(Y ~ X, fct = MM.2())
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Michaelis-Menten (2 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## d:(Intercept) 14.971733   0.060492 247.499 2.936e-13 ***
## e:(Intercept)  0.502126   0.033359  15.052 5.418e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.1195748 (6 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The ‘drc’ package also contains the self starting function ‘MM.3()’, where &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is allowed to be equal to &lt;span class=&#34;math inline&#34;&gt;\(c \neq 0\)&lt;/span&gt;, when &lt;span class=&#34;math inline&#34;&gt;\(X = 0\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;yield-loss-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Yield-loss curve&lt;/h2&gt;
&lt;p&gt;Weed-crop competition studies make use of a reparameterised Michaelis-Menten model. Indeed, th initial slope of a Michaelis-Menten can be assumed as a measure of competition, that is the reduction in yield (Y) when the first weed is added to the system. Therefore, the Michaelis-Methen model has been reparameterised to include &lt;span class=&#34;math inline&#34;&gt;\(i = a/b\)&lt;/span&gt; as an explicit parameter. The reparameterised equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = \frac{i \, X}{1 + \frac{i \, X}{a}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This model can be used to describe yield losses as a function of weed density. It can be fit by using the self starting functions ‘NLS.YL()’ or ‘DRC.YL()’ in the ‘aomisc’ package. Usually, competion studies produce yield data and, therefore, yield lossed need to be calculated by using the weed-free yield and the following equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_L  = \frac{Y_{WF}  - Y_w }{Y_{WF} } \times 100\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(Y_W\)&lt;/span&gt; is the observed yield and &lt;span class=&#34;math inline&#34;&gt;\(Y_{WF}\)&lt;/span&gt; is the weed-free yield. We show an example relating to sunflower grown at increasing densities of the weed &lt;em&gt;Sinapis arvensis&lt;/em&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(competition)
Ywf &amp;lt;- mean( competition$Yield[competition$Dens == 0] )
competition$YL &amp;lt;- ( Ywf - competition$Yield ) / Ywf * 100 

#nls fit
model &amp;lt;- nls(YL ~ NLS.YL(Dens, a, i), data = competition)
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Formula: YL ~ NLS.YL(Dens, a, i)
## 
## Parameters:
##   Estimate Std. Error t value Pr(&amp;gt;|t|)    
## a    8.207      1.187   6.914 1.93e-08 ***
## i   75.048      2.353  31.894  &amp;lt; 2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 6.061 on 42 degrees of freedom
## 
## Number of iterations to convergence: 2 
## Achieved convergence tolerance: 2.685e-06&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#drc fit
model &amp;lt;- drm(YL ~ Dens, fct = DRC.YL(), data = competition)
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Yield-Loss function (Cousens, 1985) (2 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## i:(Intercept)   8.2068     1.1715  7.0056 1.427e-08 ***
## A:(Intercept)  75.0492     2.3298 32.2133 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  6.060578 (42 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The above fit constrains the yield loss to be 0 when weed density is 0. This is logical, but, it has the important consequence that the weed-free yield is constrained to be equal to the observed weed-free yield, which is not realistic. Therefore, we can reparameterise the yield-loss function, in order to use the observed yield as the dependent variable.&lt;/p&gt;
&lt;p&gt;Indeed, from the above equation we derive:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_W  = Y_{WF}  - \frac{Y_L }{100}Y_{WF}  = Y_{WF} \left( {1 - \frac{Y_L }{100}} \right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and so:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_W  = Y_{WF} \left( 1 - \frac{i\, X}{100 \left( 1 + \frac{i \, X}{a} \right) } \right)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This function can be fit with ‘drm()’, by using the ‘DRC.cousens85()’ self starting function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- drm(Yield ~ Dens, fct = DRC.cousens85(), 
             data = competition)
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Yield-Weed Density function (Cousens, 1985) (3 parms)
## 
## Parameter estimates:
## 
##                 Estimate Std. Error t-value   p-value    
## YWF:(Intercept) 30.47211    0.92763 32.8493 &amp;lt; 2.2e-16 ***
## i:(Intercept)    8.24038    1.36541  6.0351 3.857e-07 ***
## a:(Intercept)   75.07312    2.40366 31.2328 &amp;lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  1.866311 (41 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;sygmoidal-curves&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sygmoidal curves&lt;/h1&gt;
&lt;p&gt;Sygmoidal curves are S-shaped and they may be increasing, decreasing, symmetric or non-simmetric around the inflection point. They are parameterised in countless ways, which may be often confusing. Therefore, we will show a common parameterisation, that is very useful in biological terms.&lt;/p&gt;
&lt;div id=&#34;logistic-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic curve&lt;/h2&gt;
&lt;p&gt;The logistic curve derives from the cumulative logistic distribution function; the curve is symmetric around the inflection point and it it may be parameterised as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = c + \frac{d - c}{1 + exp(b (X - e))}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is the higher asymptote, &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; is the lower asymptote, &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; value producing a response half-way between &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;, while &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is the slope around the inflection point. The parameter &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; can be positive or negative and, consequently, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; may increase or decrease as &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; increases.&lt;/p&gt;
&lt;p&gt;The above function is known as four-parameter logistic. If necessary, contraints can be put on parameter values, i.e. &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; can be constrained to 0 (three-parameter logistic). Furthermore, &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; can be also contrained to 1 (two-parameter logistic).&lt;/p&gt;
&lt;p&gt;The four- and three-parameter logistic curves can be fit by ‘nls()’, respectively with the self-starting functions ‘SSfpl()’ and ‘SSlogis’ (‘nlme’ package). In these functions, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(scal = -1/b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;With ‘drm()’, we can use the self-starting functions ‘L.4()’ and ‘L.3()’, The ‘L.2()’ function has been included in the ‘aomisc’ package.&lt;/p&gt;
&lt;p&gt;Logistic functions are very useful, e.g., for plant growth studies.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(beetGrowth)
beetGrowth&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    DAE weightInf weightFree
## 1   21   0.06000  0.0715091
## 2   21   0.06000  0.0662547
## 3   21   0.11000  0.0747931
## 4   27   0.20000  0.3368074
## 5   27   0.20000  0.3952256
## 6   27   0.21000  0.2520960
## 7   38   2.13000  2.3225072
## 8   38   3.03000  1.7163224
## 9   38   1.27000  1.2189231
## 10  49   6.13000 11.7761096
## 11  49   5.76000 13.6191507
## 12  49   7.78000 12.1462931
## 13  65  17.05000 33.1067720
## 14  65  22.48000 24.9648226
## 15  65  12.66000 34.6577561
## 16 186  21.51010 38.8329912
## 17 186  26.25887 27.8375016
## 18 186  27.67733 37.7165427&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- drm(weightFree ~ DAE, fct = L.3(), data = beetGrowth)
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Logistic (ED50 as parameter) with lower limit fixed at 0 (3 parms)
## 
## Parameter estimates:
## 
##                Estimate Std. Error t-value   p-value    
## b:(Intercept) -0.179393   0.039059 -4.5929 0.0003519 ***
## d:(Intercept) 34.532001   1.676430 20.5985 2.057e-12 ***
## e:(Intercept) 52.384788   1.580269 33.1493 1.838e-15 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  2.970191 (15 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model, log=&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;gompertz-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Gompertz Curve&lt;/h2&gt;
&lt;p&gt;The Gompertz curve is parameterised in very many ways. We favour a parameterisation that resambles the one used for the logistic function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \exp \left\{- \exp \left[ b \, (X - e) \right] \right\} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;were the parameters have the same meaning as those in the logistic function. The difference is that this curve is not symmetric around the inflection point. As for the logistic, we can have a four-, three- and two-parameter Gompertz functions, which can be fit by using ‘drm()’ and, respectively the ‘G.4()’, ‘G.3()’ and ‘G.2()’ sef-starters. The three-parameter Gompertz can also be fit with ‘nls()’, by using the ‘SSGompertz()’ self-starter in the ‘nlme’ package, although this is a different parameterisation.&lt;/p&gt;
&lt;p&gt;We give an example of the different shapes for the logistic (red) and Gompertz (black) functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;another-type-of-asimmetry&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Another type of asimmetry&lt;/h2&gt;
&lt;p&gt;We have seen that, with respect to the logistic, the Gompertz shows a longer lag at the beginning, but raises steadily afterwards. We could describe a different pattern by changing the Gompertz function as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \left\{ 1 - \exp \left\{- \exp \left[ b \, (X - e) \right] \right\} \right\} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We add to the previous graph this function (in blue), to show how it differs from the logistic and Gompertz.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- 10; c &amp;lt;- 2; e &amp;lt;- 7; b &amp;lt;- - 0.5
curve( G.fun(x, b, c, d, e), xlim = c(0, 20) , xlab=&amp;quot;X&amp;quot;, ylab = &amp;quot;Y&amp;quot;)
curve( L.fun(x, b, c, d, e), add = T, col = &amp;quot;red&amp;quot; )
curve( E.fun(x, b, c, d, e), add = T, col = &amp;quot;blue&amp;quot; )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The self-starters for this function are not yet available, at least to the best of my knowledge.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;log-logistic-curve&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Log-logistic curve&lt;/h2&gt;
&lt;p&gt;In many applications, the sigmoidal response curve is symmetric on the logarithm of x, which requires a log-logistic curve (a log-normal curve would be practically equivalent, but it is used far less often). For example, in biologic assays (but also in germination assays), the log-logistic curve is defined as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = c + \frac{d - c}{1 + \exp \left\{ b \left[ \log(X) - \log(e) \right] \right\} } \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;the parameters have the very same meanng as the logistic equationn given above. It is easy to see that the above equation is equivalent to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = c + \frac{d - c}{1 + \left( \frac{X}{e} \right)^b}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Another possible parameterisation is the so-called Hill function:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = \frac{a \, X^b}{ X^b + e^b} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Indeed:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \frac{a \, X^b}{ X^b + e^b} =  \frac{a}{ \frac{X^b}{X^b} + \frac{c^b}{X^b}} = \frac{a}{ 1 + \left( \frac{c}{X} \right)^b} = \frac{a}{ 1 + \left( \frac{c}{X} \right)^b} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Log-logistic functions are used for crop growth, seed germination and bioassay work and they can have the same constraints as the logistic function. The four-parameter logistic is available as ‘LL.4()’ in the ‘drc’ package and as ‘SSfpl()’ in the ‘nlme’ package. This latter function replaces &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(scal = 1/b\)&lt;/span&gt;. Also in ‘drc’, we have ‘LL.3()’ (three-parameter logistic, with &lt;span class=&#34;math inline&#34;&gt;\(c = 0\)&lt;/span&gt;) and ‘LL.2()’ (two-parameter logistic, with &lt;span class=&#34;math inline&#34;&gt;\(d = 1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(c = 0\)&lt;/span&gt;). In ‘nlme’ we have ‘SSlogis()’, that is a three-parameter logistic with &lt;span class=&#34;math inline&#34;&gt;\(scal = 1/b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We show an example of a log-logistic fit, relating to a bioassay with &lt;em&gt;Brassica rapa&lt;/em&gt; treated at increasing dosages of an herbicide.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(brassica)
model &amp;lt;- drm(FW ~ Dose, fct = LL.4(), data = brassica)
summary(model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Model fitted: Log-logistic (ED50 as parameter) (4 parms)
## 
## Parameter estimates:
## 
##               Estimate Std. Error t-value   p-value    
## b:(Intercept)  1.45113    0.24113  6.0181 1.743e-06 ***
## c:(Intercept)  0.34948    0.18580  1.8810   0.07041 .  
## d:(Intercept)  4.53636    0.20514 22.1140 &amp;lt; 2.2e-16 ***
## e:(Intercept)  2.46557    0.35111  7.0221 1.228e-07 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error:
## 
##  0.4067837 (28 degrees of freedom)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;weibull-curve-type-2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Weibull curve (type 2)&lt;/h2&gt;
&lt;p&gt;The type 2 Weibull curve is for the Gompertz curve what the log-logistic curve is for the logistic curve. The equation is as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \exp \left\{- \exp \left[ b \, (log(X) - log(e)) \right] \right\} \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the parameters have the very same meaning as the other sygmoidal curves given above.&lt;/p&gt;
&lt;p&gt;As for fitting, the ‘drc’ package contains the self-starting functions ‘W2.2()’, ‘W2.3()’ and ‘W2.4()’ that can be used to fit respectively the two-, three- and four-parameter type 2 Weibull functions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;weibull-curve-type-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Weibull curve (type 1)&lt;/h2&gt;
&lt;p&gt;The type 1 Weibull is similar to the type 2 Weibull, but describes a different type of asymmetry (see above):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ Y = c + (d - c) \left\{ 1 - \exp \left\{- \exp \left[ b \, (log(X) - log(e)) \right] \right\} \right\}\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model &amp;lt;- drm(FW ~ Dose, fct = W2.4(), data = brassica)
model2 &amp;lt;- drm(FW ~ Dose, fct = W1.4(), data = brassica)
plot(model)
plot(model2, add=T, col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/articles/usefulEquations_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>