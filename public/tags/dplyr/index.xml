<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>dplyr on The broken bridge between biologists and statisticians</title>
    <link>https://www.statforbiology.com/tags/dplyr/</link>
    <description>Recent content in dplyr on The broken bridge between biologists and statisticians</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2023, @AndreaOnofri</copyright>
    <lastBuildDate>Fri, 11 Dec 2020 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://www.statforbiology.com/tags/dplyr/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>From &#39;&#39;for()&#39;&#39; loops to the &#39;&#39;split-apply-combine&#39;&#39; paradigm for column-wise tasks: the transition for a dinosaur</title>
      <link>https://www.statforbiology.com/2020/stat_r_tidyverse_columnwise/</link>
      <pubDate>Fri, 11 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2020/stat_r_tidyverse_columnwise/</guid>
      <description>


&lt;p&gt;I have been involved with data crunching for 30 years, and, due to my age, I see myself as a dinosaur within the R-users community. I must admit, I’m rather slow to incorporate new paradigms in my programming workflow … I’m pretty busy and the time I save today is often more important than the time I could save in the future, by picking up new techniques. However, resisting to progress is not necessarily a good idea and, from time to time, also a dinosaur feels like living more dangerously and exploring new ideas and views.&lt;/p&gt;
&lt;p&gt;Today, I want to talk about column-wise tasks in relatively big datasets. These tasks are rather common with agricultural and biological experiments, where we have several subjects in different treatment groups and we record, for each subject, a high number of traits. In these conditions, the very first step to data analyses is to calculate several descriptive stats for each group of subjects and each variable. What is the best method to write simple and reusable code? As I will show later, the most natural approach to me may not necessarily be the most fashionable one.&lt;/p&gt;
&lt;div id=&#34;the-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The example&lt;/h1&gt;
&lt;p&gt;A few days ago, I met a colleague from the plant pathology group, who asked my co-operation for an experiment where he studied the content in 62 mycotoxins in wheat caryopses, as recorded in 70 samples coming from different Italian regions. The dataset was structured as 70 x 64 table, as shown in the scheme below: there is one row for each wheat sample, while the first column represents the sample id, the second column represents the region from where that sample was collected and the other columns represent the concentrations of the 62 toxins (one column per toxin).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/_Figures/Stat_general_tidyverse.png&#34; width=&#34;75%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That colleague wanted me to calculate, for each toxin and for each region, the following stats:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;number of collected samples&lt;/li&gt;
&lt;li&gt;mean concentration value&lt;/li&gt;
&lt;li&gt;maximum concentration value&lt;/li&gt;
&lt;li&gt;standard error&lt;/li&gt;
&lt;li&gt;number of contaminated samples (concentration higher than 0)&lt;/li&gt;
&lt;li&gt;percentage of contaminated samples&lt;/li&gt;
&lt;li&gt;mean value for contaminated samples&lt;/li&gt;
&lt;li&gt;standard error for contaminated samples&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;He also wanted me to return to him a list of 62 tables (one per toxin), with all the regions along with their descriptive stats.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-have-already-done-something-like-this&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;I have already done something like this!&lt;/h1&gt;
&lt;p&gt;When facing this task, my first reaction was to search in my ‘computer’s attic’, looking for previously written codes to accomplish the very same task. As I said, this is a fairly common task in my everyday work and I could find several examples of old codes. Looking at those, I realised that, when the number of variables is high, I have so far made an extensive use of &lt;code&gt;for&lt;/code&gt; loops to repeat the same task across columns. This is indeed no wonder, as I came across R in 2000, after an extensive usage of general purpose languages, such as Quick Basic and Visual Basic.&lt;/p&gt;
&lt;p&gt;In practise, most of my earliest R codes were based on the &lt;code&gt;tapply()&lt;/code&gt; function to calculate statistics for grouped data and &lt;code&gt;for&lt;/code&gt; loops to iterate over columns. In the box below I show an example of such an approach, by using a factitious dataset, with the very same structure as my colleague’s dataset.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list = ls())
dataset &amp;lt;- read.csv(&amp;quot;https://casaonofri.it/_datasets/Mycotoxins.csv&amp;quot;, header = T)
# str(dataset)
# &amp;#39;data.frame&amp;#39;: 70 obs. of  64 variables:
#  $ Sample : int  1 2 3 4 5 6 7 8 9 10 ...
#  $ Region : chr  &amp;quot;Lombardy&amp;quot; &amp;quot;Lombardy&amp;quot; &amp;quot;Lombardy&amp;quot; &amp;quot;Lombardy&amp;quot; ...
#  $ DON    : num  8.62 16.2 18.19 27.08 10.97 ...
#  $ DON3G  : num  21.7 28.4 34.7 26.9 26.4 ...
#  $ NIV    : num  23.5 25.3 22.6 27.8 29.4 ...
#  $ NIVG   : num  38.6 26.2 13.5 21.4 15.4 ...
#  $ T2     : num  23.9 23.6 19.7 25.7 21.7 ...
#  $ HT2    : num  19 37.6 32.1 22.3 25.6 ...
#  $ HT2G   : num  13.7 25.7 25.8 33.4 32.7 ...
#  $ NEO    : num  29.06 7.56 27.52 32.91 24.49 ...

returnList &amp;lt;- list()
for(i in 1:(length(dataset[1,]) - 3)){
  y &amp;lt;- as.numeric( unlist(dataset[, i + 3]) )
  Count &amp;lt;- tapply(y, dataset$Region, length)
  Mean &amp;lt;- tapply(y, dataset$Region, mean)
  Max &amp;lt;- tapply(y, dataset$Region, max)
  SE &amp;lt;- tapply(y, dataset$Region, sd)/sqrt(Count)
  nPos &amp;lt;- tapply(y != 0, dataset$Region, sum)
  PercPos &amp;lt;- tapply(y != 0, dataset$Region, mean)*100
  muPos &amp;lt;- tapply(ifelse(y &amp;gt; 0, y, NA), dataset$Region, mean, na.rm = T)
  muPos[is.na(muPos)] &amp;lt;- 0
  sdPos &amp;lt;- tapply(ifelse(y &amp;gt; 0, y, NA), dataset$Region, sd, na.rm = T)
  SEpos &amp;lt;- sdPos/sqrt(nPos)
  returnList[[i]] &amp;lt;- data.frame(cbind(Count, Mean, Max, SE, nPos, PercPos, muPos, SEpos))
  names(returnList)[[i]] &amp;lt;- colnames(dataset)[i + 3]
}
print(returnList$CRV, digits = 2)
##                 Count Mean Max   SE nPos PercPos muPos SEpos
## Abruzzo             4   28  30 0.85    4     100    28  0.85
## Apulia              9   25  40 2.67    9     100    25  2.67
## Campania            2   20  21 0.74    2     100    20  0.74
## Emilia Romagna      8   23  33 2.80    8     100    23  2.80
## Latium              7   20  33 2.76    7     100    20  2.76
## Lombardy            4   25  32 5.12    4     100    25  5.12
## Molise              1   18  18   NA    1     100    18    NA
## Sardinia            6   25  38 3.32    6     100    25  3.32
## Sicily              6   21  30 2.94    6     100    21  2.94
## The Marche          5   19  23 1.58    5     100    19  1.58
## Tuscany             5   30  34 1.22    5     100    30  1.22
## Umbria              9   21  32 2.83    9     100    21  2.83
## Veneto              4   23  28 1.99    4     100    23  1.99&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I must admit that the above code is ugly: first, &lt;code&gt;for&lt;/code&gt; loops in R are not very efficient and, second, reusing that code requires quite a bit of editing and it is prone to errors. Therefore, I asked myself how I could write more efficient code …&lt;/p&gt;
&lt;p&gt;First of all, I thought I should use &lt;code&gt;apply()&lt;/code&gt; instead of the &lt;code&gt;for&lt;/code&gt; loop. Thus I wrote a function to calculate the required stats for each column and &lt;code&gt;apply()-ed&lt;/code&gt; that function to all columns of my data-frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;funBec &amp;lt;- function(y, group){
  # y &amp;lt;- as.numeric( unlist(dataset[, i + 3]) )
  Count &amp;lt;- tapply(y, group, length)
  Mean &amp;lt;- tapply(y, group, mean)
  Max &amp;lt;- tapply(y, group, max)
  SE &amp;lt;- tapply(y, group, sd)/sqrt(Count)
  nPos &amp;lt;- tapply(y != 0, group, sum)
  PercPos &amp;lt;- tapply(y != 0, group, mean)*100
  muPos &amp;lt;- tapply(ifelse(y &amp;gt; 0, y, NA),group, mean, na.rm = T)
  muPos[is.na(muPos)] &amp;lt;- 0
  sdPos &amp;lt;- tapply(ifelse(y &amp;gt; 0, y, NA), group, sd, na.rm = T)
  SEpos &amp;lt;- sdPos/sqrt(nPos)
  data.frame(cbind(Count, Mean, Max, SE, nPos, PercPos, muPos, SEpos))
}
returnList2 &amp;lt;- apply(dataset[3:length(dataset[1,])], 2,
                     function(col) funBec(col, dataset$Region))
# kable(returnList2$CRV, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I am pretty happy with the above approach; it feels ‘natural’, to me and the coding appears to be pretty clear and easily reusable. However, it makes only use of the &lt;code&gt;base&lt;/code&gt; R implementation and, therefore, it looks a bit out-fashioned… a dinosaur’s code…&lt;/p&gt;
&lt;p&gt;What could I possibly do to write more ‘modern’ code? A brief survey of posts from the R world suggested the ultimate solution: “I must use the ‘tidyverse’!”. Therefore, I tried to perform my column-wise task by using &lt;code&gt;dplyr&lt;/code&gt; and related packages and I must admit that I could not immediately find an acceptable solution. After some careful thinking, it was clear that the tidyverse requires a strong change in programming habits, which is not always simple for those who are over a certain age. Or, at least, that is not simple for me…&lt;/p&gt;
&lt;p&gt;Eventually, I thought I should switch from a &lt;code&gt;for&lt;/code&gt; attitude to a &lt;code&gt;split-apply-combine&lt;/code&gt; attitude; indeed, I discovered that, if I ‘melted’ the dataset so that the variables were stacked one above the other, I could, consequently:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;split the dataset in several groups, consisting of one toxin and one region,&lt;/li&gt;
&lt;li&gt;calculate the stats for each group, and&lt;/li&gt;
&lt;li&gt;combine the results for all groups.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I’d like to share the final code: I used the &lt;code&gt;pivot_longer()&lt;/code&gt; function to melt the dataset, the &lt;code&gt;group_by()&lt;/code&gt; function to create an ‘internal’ grouping structure by regions and toxins, the &lt;code&gt;summarise()&lt;/code&gt; and &lt;code&gt;across()&lt;/code&gt; functions to calculate the required stats for each group. In the end, I obtained a tibble, that I split into a list of tibbles, by using the &lt;code&gt;group_split()&lt;/code&gt; function. The code is shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
returnList6 &amp;lt;- dataset %&amp;gt;%
  select(-Sample) %&amp;gt;% 
  pivot_longer(names_to = &amp;quot;Toxin&amp;quot;, values_to = &amp;quot;Conc&amp;quot;,
               cols = c(3:length(dataset[1,]) - 1)) %&amp;gt;% 
  group_by(Toxin, Region) %&amp;gt;% 
  summarise(across(&amp;quot;Conc&amp;quot;, .fns =
               list(Mean = mean,
                    Max = max,
                    SE = function(df) sd(df)/sqrt(length(df)),
                    nPos = function(df) length(df[df &amp;gt; 0]),
                    percPos = function(df) length(df[df &amp;gt; 0])/length(df)*100,
                    muPos =  function(df) mean(df[df &amp;gt; 0]),
                    SEpos =  function(df) sd(df[df &amp;gt; 0])/sqrt(length(df[df &amp;gt; 0]))
                    ))) %&amp;gt;% 
  ungroup() %&amp;gt;%
  group_split(Toxin, .keep = F)
names(returnList6) &amp;lt;- names(dataset)[3:64]
# returnList6$CRV&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, I can say that with the above code I have, at least, tried not to be a dinosaur… but, I am sure that many young scientists out there can suggest better solutions. If so, please drop me a line at the email address below. Thanks for reading!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
email: &lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;[UPDATE: 13/12/2020]&lt;/p&gt;
&lt;p&gt;Bryan Hutchinson from the UK proposed an alternative solution based on the ‘data.table’ and ‘DescTools’ libraries. I have never used these libraries before, but the code looks very efficient and elegant. At the end, some examples of how the dataset can be filtered are given. Thanks, Bryan!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(data.table)
library(DescTools)
 
dataset &amp;lt;- fread(&amp;quot;https://casaonofri.it/_datasets/Mycotoxins.csv&amp;quot;, header = T)
tnames &amp;lt;- names(dataset[,-c(1:2)])
 
sum_stats &amp;lt;- function(var) {
  # convert integer to double
  var &amp;lt;- as.numeric(var)
  list(
    mean = mean(var, na.rm = TRUE),
    max = max(var, na.rm = TRUE),
    se = sd(var, na.rm = TRUE) / sqrt(length(var)),
    nPos = length(var &amp;gt;0),
    percPos = length(var &amp;gt;0)/length(var)*100,
    muPos =  mean(var &amp;gt; 0),
    SEpos =  sd(var &amp;gt; 0)/sqrt(length(var &amp;gt; 0))
  )
}
 
df_long &amp;lt;- melt(dataset,
                measure.vars = list(tnames),
                variable.name = &amp;quot;Toxin&amp;quot;,
                value.name = &amp;quot;Conc&amp;quot;)
 
 
# df_long[, sum_stats(Conc), .(Toxin, Region)]
# df_long[Toxin == &amp;quot;FLAG&amp;quot;, sum_stats(Conc), .(Toxin, Region)]
# df_long[Region == &amp;quot;Lombardy&amp;quot;, sum_stats(Conc), .(Region, Toxin)]&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;[UPDATE: 14/12/2020]&lt;/p&gt;
&lt;p&gt;A younger collegue (Renzo Bonifazi) suggested some changes to the code, which I am happy to share here. Setting the range of columns at the beginning seems to be wise and removing the ‘ungroup()’ function is correct. I did not know about the ‘setNames()’ function, which was used at the end. Thanks, Renzo!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define here the range of cols to apply upon the code
range_cols &amp;lt;- c(3:length(dataset[1,]))

results &amp;lt;- dataset %&amp;gt;%
  select(-Sample) %&amp;gt;% 
  pivot_longer(names_to = &amp;quot;Toxin&amp;quot;, values_to = &amp;quot;Conc&amp;quot;,
               cols = range_cols - 1) %&amp;gt;% # use user defined range of cols
  group_by(Toxin, Region) %&amp;gt;% 
  summarise(across(&amp;quot;Conc&amp;quot;, .fns =
                     list(Mean = mean,
                          Max = max,
                          SE = function(df) sd(df)/sqrt(length(df)),
                          nPos = function(df) length(df[df &amp;gt; 0]),
                          percPos = function(df) length(df[df &amp;gt; 0])/length(df)*100,
                          muPos =  function(df) mean(df[df &amp;gt; 0]),
                          SEpos =  function(df) sd(df[df &amp;gt; 0])/sqrt(length(df[df &amp;gt; 0]))
                     ))) %&amp;gt;%
   group_split(.keep = F) %&amp;gt;% # This fun by default seems to split based on the first defined group var, i.e. &amp;quot;Toxin&amp;quot; in this case
setNames(names(dataset)[range_cols]) # define the names internally&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Some everyday data tasks: a few hints with R (revisited)</title>
      <link>https://www.statforbiology.com/2020/stat_r_shapingdata2/</link>
      <pubDate>Tue, 28 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2020/stat_r_shapingdata2/</guid>
      <description>


&lt;p&gt;One year ago, I published a post titled ‘Some everyday data tasks: a few hints with R’. In that post, I considered four data tasks, that we all need to accomplish daily, i.e.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;subsetting&lt;/li&gt;
&lt;li&gt;sorting&lt;/li&gt;
&lt;li&gt;casting&lt;/li&gt;
&lt;li&gt;melting&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In that post, I used the methods I was more familiar with. And, as a long-time R user, I have mainly incorporated in my workflow all the functions from the base R implementation.&lt;/p&gt;
&lt;p&gt;But now, the tidyverse is with us! Well, as far as I know, the tidyverse has been around long before my post. However, for a long time, I did not want to surrender to such a new paradygm. I am no longer a young scientist and, therefore, picking up new techniques is becoming more difficult: why should I abandon my effective workflow in favour of new techniques, which I am not familiar with? Yes I know, the young scientists are thinking that I am just an old dinosaur, who is trying to resist to progress by all means… It is a good point! I see that reading the code produced by my younger collegues is becoming difficult, due to the massive use of the tidyverse and the pipes. I still have a few years to go, before retirement and I do not yet fell like being set aside. Therefore, a few weeks ago I finally surrendered and ‘embraced’ the tidyverse. Here is how I revisited my previous post.&lt;/p&gt;
&lt;div id=&#34;subsetting-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Subsetting the data&lt;/h1&gt;
&lt;p&gt;Subsetting means selecting the records (rows) or the variables (columns) which satisfy certain criteria. Let’s take the ‘students.csv’ dataset, which is available on one of my repositories. It is a database of student’s marks in a series of exams for different subjects and, obviously, I will use the ‘readr’ package to read it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(readr)
library(dplyr)
library(tidyr)
students &amp;lt;- read_csv(&amp;quot;https://www.casaonofri.it/_datasets/students.csv&amp;quot;)
students
## # A tibble: 232 x 6
##       Id Subject  Date        Mark  Year HighSchool 
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;      
##  1     1 AGRONOMY 10/06/2002    30  2001 HUMANITIES 
##  2     2 AGRONOMY 08/07/2002    24  2001 AGRICULTURE
##  3     3 AGRONOMY 24/06/2002    30  2001 AGRICULTURE
##  4     4 AGRONOMY 24/06/2002    26  2001 HUMANITIES 
##  5     5 AGRONOMY 23/01/2003    30  2001 HUMANITIES 
##  6     6 AGRONOMY 09/09/2002    28  2001 AGRICULTURE
##  7     7 AGRONOMY 24/02/2003    26  2001 HUMANITIES 
##  8     8 AGRONOMY 09/09/2002    26  2001 SCIENTIFIC 
##  9     9 AGRONOMY 09/09/2002    23  2001 ACCOUNTING 
## 10    10 AGRONOMY 08/07/2002    27  2001 HUMANITIES 
## # … with 222 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With respect to the usual &lt;code&gt;read.csv&lt;/code&gt; function I saved some typing, as I did not need to specify the ‘header = T’ argument. Furthermore, printing the tibble only shows the first ten rows, which makes the ‘head()’ function no longer needed.&lt;/p&gt;
&lt;p&gt;Let’s go ahead and try to subset this tibble: we want to extract the good students, with marks higher than 28. In my previous post, I used the ‘subset()’ function. Now, I will use the ‘filter()’ function in the ‘dplyr’ package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subData &amp;lt;- subset(students, Mark &amp;gt;= 28)
subData &amp;lt;- filter(students, Mark &amp;gt;= 28)
subData
## # A tibble: 87 x 6
##       Id Subject  Date        Mark  Year HighSchool  
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       
##  1     1 AGRONOMY 10/06/2002    30  2001 HUMANITIES  
##  2     3 AGRONOMY 24/06/2002    30  2001 AGRICULTURE 
##  3     5 AGRONOMY 23/01/2003    30  2001 HUMANITIES  
##  4     6 AGRONOMY 09/09/2002    28  2001 AGRICULTURE 
##  5    11 AGRONOMY 09/09/2002    28  2001 SCIENTIFIC  
##  6    17 AGRONOMY 10/06/2002    30  2001 HUMANITIES  
##  7    18 AGRONOMY 10/06/2002    30  2001 AGRICULTURE 
##  8    19 AGRONOMY 09/09/2002    30  2001 AGRICULTURE 
##  9    20 AGRONOMY 09/09/2002    30  2001 OTHER SCHOOL
## 10    22 AGRONOMY 23/01/2003    30  2001 ACCOUNTING  
## # … with 77 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I have noted that all other subsetting examples in my previous post can be solved by simply replacing ‘subset()’ with ‘filter()’, with no other changes. However, differences appear when I try to select the columns. Indeed, ‘dplyr’ has a specific function ‘select()’, which should be used for this purpose. Therefore, in the case that I want to select the students with marks ranging from 26 to 28 in Maths or Chemistry and, at the same time, I want to report only the three columns ‘Subject’, ‘Mark’ and ‘Date’, I need to split the process in two steps (filter and, then, select):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# subData &amp;lt;- subset(students, Mark &amp;lt;= 28 &amp;amp; Mark &amp;gt;=26 &amp;amp; 
#                     Subject == &amp;quot;MATHS&amp;quot; | 
#                     Subject == &amp;quot;CHEMISTRY&amp;quot;,
#                   select = c(Subject, Mark, HighSchool))
subData1 &amp;lt;- filter(students, Mark &amp;lt;= 28 &amp;amp; Mark &amp;gt;=26 &amp;amp; 
                    Subject == &amp;quot;MATHS&amp;quot; | 
                    Subject == &amp;quot;CHEMISTRY&amp;quot;)
subData &amp;lt;- select(subData1, c(Subject, Mark, HighSchool))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at the above two-steps process I could easily understand the meaning of the pipe operator: it simply replaces the word ‘then’ between the two steps (&lt;code&gt;filter&lt;/code&gt; and then &lt;code&gt;select&lt;/code&gt; is translated into &lt;code&gt;filter %&amp;gt;% select&lt;/code&gt;). Here is the resulting code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;subData &amp;lt;- students %&amp;gt;%
  filter(Mark &amp;lt;= 28 &amp;amp; Mark &amp;gt;=26 &amp;amp; 
                    Subject == &amp;quot;MATHS&amp;quot; | 
                    Subject == &amp;quot;CHEMISTRY&amp;quot;) %&amp;gt;%
  select(c(Subject, Mark, HighSchool))
subData
## # A tibble: 50 x 3
##    Subject    Mark HighSchool  
##    &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       
##  1 CHEMISTRY    20 AGRICULTURE 
##  2 CHEMISTRY    21 HUMANITIES  
##  3 CHEMISTRY    21 HUMANITIES  
##  4 CHEMISTRY    18 AGRICULTURE 
##  5 CHEMISTRY    28 OTHER SCHOOL
##  6 CHEMISTRY    23 ACCOUNTING  
##  7 CHEMISTRY    26 ACCOUNTING  
##  8 CHEMISTRY    27 AGRICULTURE 
##  9 CHEMISTRY    27 SCIENTIFIC  
## 10 CHEMISTRY    23 ACCOUNTING  
## # … with 40 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the end: there is not much difference between ‘subset()’ and ‘filter()’. However, I must admit I am seduced by the ‘pipe’ operator… my younger collegues may be right: it should be possible to chain several useful data management steps, producing highly readable code. But… how about debugging?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sorting-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Sorting the data&lt;/h1&gt;
&lt;p&gt;In my previous post I showed how to sort a data frame by using the ‘order()’ function. Now, I can use the ‘arrange()’ function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sortedData &amp;lt;- students[order(-students$Mark, students$Subject), ]
# head(sortedData)
sortedData &amp;lt;- arrange(students, desc(Mark), Subject)
sortedData
## # A tibble: 232 x 6
##       Id Subject  Date        Mark  Year HighSchool  
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       
##  1     1 AGRONOMY 10/06/2002    30  2001 HUMANITIES  
##  2     3 AGRONOMY 24/06/2002    30  2001 AGRICULTURE 
##  3     5 AGRONOMY 23/01/2003    30  2001 HUMANITIES  
##  4    17 AGRONOMY 10/06/2002    30  2001 HUMANITIES  
##  5    18 AGRONOMY 10/06/2002    30  2001 AGRICULTURE 
##  6    19 AGRONOMY 09/09/2002    30  2001 AGRICULTURE 
##  7    20 AGRONOMY 09/09/2002    30  2001 OTHER SCHOOL
##  8    22 AGRONOMY 23/01/2003    30  2001 ACCOUNTING  
##  9    38 BIOLOGY  28/02/2002    30  2001 AGRICULTURE 
## 10    42 BIOLOGY  28/02/2002    30  2001 ACCOUNTING  
## # … with 222 more rows
# sortedData &amp;lt;- students[order(-students$Mark, -xtfrm(students$Subject)), ]
# head(sortedData)
sortedData &amp;lt;- arrange(students, desc(Mark), desc(Subject))
sortedData
## # A tibble: 232 x 6
##       Id Subject Date        Mark  Year HighSchool  
##    &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;   &amp;lt;chr&amp;gt;      &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;       
##  1   116 MATHS   01/07/2002    30  2001 OTHER SCHOOL
##  2   117 MATHS   18/06/2002    30  2001 ACCOUNTING  
##  3   118 MATHS   09/07/2002    30  2001 AGRICULTURE 
##  4   121 MATHS   18/06/2002    30  2001 ACCOUNTING  
##  5   123 MATHS   09/07/2002    30  2001 HUMANITIES  
##  6   130 MATHS   07/02/2002    30  2001 SCIENTIFIC  
##  7   131 MATHS   09/07/2002    30  2001 AGRICULTURE 
##  8   134 MATHS   26/02/2002    30  2001 AGRICULTURE 
##  9   135 MATHS   11/02/2002    30  2001 AGRICULTURE 
## 10   143 MATHS   04/02/2002    30  2001 ACCOUNTING  
## # … with 222 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As for sorting, there is no competition! The ‘arrange()’ function, together with the ‘desc()’ function for descending order, represents a much clearer way to sort the data, with respect to the traditional ‘order()’ function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;casting-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Casting the data&lt;/h1&gt;
&lt;p&gt;When we have a dataset in the LONG format, we might be interested in reshaping it into the WIDE format. This is the same as what the ‘pivot table’ function in Excel does. For example, take the ‘rimsulfuron.csv’ dataset in my repository. This contains the results of a randomised block experiment, where we have 16 herbicides in four blocks. The dataset is in the LONG format, with one row per plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rimsulfuron &amp;lt;- read_csv(&amp;quot;https://www.casaonofri.it/_datasets/rimsulfuron.csv&amp;quot;)
## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   Herbicide = col_character(),
##   Plot = col_double(),
##   Code = col_double(),
##   Block = col_double(),
##   Box = col_double(),
##   WeedCover = col_double(),
##   Yield = col_double()
## )
rimsulfuron
## # A tibble: 64 x 7
##    Herbicide                              Plot  Code Block   Box WeedCover Yield
##    &amp;lt;chr&amp;gt;                                 &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Rimsulfuron (40)                          1     1     1     1      27.8  85.9
##  2 Rimsulfuron (45)                          2     2     1     1      27.8  93.0
##  3 Rimsulfuron (50)                          3     3     1     1      23    86.9
##  4 Rimsulfuron (60)                          4     4     1     1      42.8  53.0
##  5 Rimsulfuron (50+30 split)                 5     5     1     2      15.1  71.4
##  6 Rimsulfuron + thyfensulfuron              6     6     1     2      22.9  75.3
##  7 Rimsulfuron + hoeing                      7     7     1     2      17.7  73.2
##  8 Pendimethalin (pre) + rimsulfuron (p…     8     8     1     2      10.2  65.5
##  9 Pendimethalin (post) + rimsuulfuron …     9     9     1     1       5.4  94.8
## 10 Rimsulfuron + Atred                      10    10     1     1      40.3  94.1
## # … with 54 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s put this data frame in the WIDE format, with one row per herbicide and one column per block. In my previous post, I used to the ‘cast()’ function in the ‘reshape’ package. Now I can use the ‘pivot_wider()’ function in the ‘tidyr’ package: the herbicide goes in the first column, the blocks (B1, B2, B3, B4) should go in the next four columns, and each unique level of yield should go in each cell, at the crossing of the correct herbicide row and block column. The ‘Height’ variable is not needed and it should be removed. Again, a two steps process, that is made easier by using the pipe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(reshape)
# castData &amp;lt;- cast(Herbicide ~ Block, data = rimsulfuron,
#      value = &amp;quot;Yield&amp;quot;)
# head(castData)

castData &amp;lt;- rimsulfuron %&amp;gt;%
  select(-Plot, - Code, -Box, - WeedCover) %&amp;gt;%
  pivot_wider(names_from = Block, values_from = Yield)
castData
## # A tibble: 16 x 5
##    Herbicide                                    `1`   `2`   `3`   `4`
##    &amp;lt;chr&amp;gt;                                      &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Rimsulfuron (40)                            85.9  91.1 111.   93.2
##  2 Rimsulfuron (45)                            93.0 105    89.2  79.0
##  3 Rimsulfuron (50)                            86.9 106.  110.   89.1
##  4 Rimsulfuron (60)                            53.0 103.  101.   97.0
##  5 Rimsulfuron (50+30 split)                   71.4  77.6 116.   92.2
##  6 Rimsulfuron + thyfensulfuron                75.3  82.6  95.0  85.8
##  7 Rimsulfuron + hoeing                        73.2  86.1 118.   98.3
##  8 Pendimethalin (pre) + rimsulfuron (post)    65.5  88.7  95.5  82.4
##  9 Pendimethalin (post) + rimsuulfuron (post)  94.8  87.7 102.  102. 
## 10 Rimsulfuron + Atred                         94.1  89.9 104.   99.6
## 11 Thifensulfuron                              78.5  42.3  62.5  24.3
## 12 Metolachlor + terbuthylazine (pre)          51.8  52.1  49.5  34.7
## 13 Alachlor + terbuthylazine                   12.1  49.6  41.3  16.4
## 14 Hand-Weeded                                 77.6  92.1  86.6  99.6
## 15 Unweeded 1                                  10.9  31.8  23.9  20.8
## 16 Unweeded 2                                  27.6  51.6  25.1  38.6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, I am not clear with which it is more advantageous than which. Simply, I do not see much difference: none of the two methods is as clear as I would expect it to be!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;melting-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Melting the data&lt;/h1&gt;
&lt;p&gt;In this case we do the reverse: we transform the dataset from WIDE to LONG format. In my previous post I used the ‘melt()’ function in the ‘reshape2’ package; now, I will use the ‘pivot_longer()’ function in ‘tidyr’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(reshape2)
# castData &amp;lt;- as.data.frame(castData)
# mdati &amp;lt;- melt(castData,
#               variable.name = &amp;quot;Block&amp;quot;,
#               value.name = &amp;quot;Yield&amp;quot;,
#               id=c(&amp;quot;Herbicide&amp;quot;))
# 
# head(mdati)
# 
pivot_longer(castData, names_to = &amp;quot;Block&amp;quot;, values_to = &amp;quot;Yield&amp;quot;,
             cols = c(2:5))
## # A tibble: 64 x 3
##    Herbicide        Block Yield
##    &amp;lt;chr&amp;gt;            &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Rimsulfuron (40) 1      85.9
##  2 Rimsulfuron (40) 2      91.1
##  3 Rimsulfuron (40) 3     111. 
##  4 Rimsulfuron (40) 4      93.2
##  5 Rimsulfuron (45) 1      93.0
##  6 Rimsulfuron (45) 2     105  
##  7 Rimsulfuron (45) 3      89.2
##  8 Rimsulfuron (45) 4      79.0
##  9 Rimsulfuron (50) 1      86.9
## 10 Rimsulfuron (50) 2     106. 
## # … with 54 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As before with casting, neither ‘melt()’, nor ‘pivot_longer()’ let me completely satisfied.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tidyverse-or-not-tidyverse&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Tidyverse or not tidyverse?&lt;/h1&gt;
&lt;p&gt;This post is the result of using some functions coming from the ‘tidyverse’ and related packages, to replace other functions from more traditional packages, which I was more accustomed to, as a long-time R user. What’s my feeling about this change? Let me try to figure it out.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;First of all, it didn’t take much time to adjust. I need to thank the authors of ‘tidyverse’ for being very respectful of tradition.&lt;/li&gt;
&lt;li&gt;In one case (ordering), adjusting to the new paradigm brought to a easier coding. In all other cases, the ease of coding was not affected.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Will I stick to the new paradigm or will I go back to my familiar approaches? Should I only consider the simple tasks above, my answer would be: “I’ll go back!”. However, this would be an unfair answer. Indeed, my data tasks are not as simple as those above. More frequently, my data tasks are made of several different steps. For example:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Take the ‘students’ dataset&lt;/li&gt;
&lt;li&gt;Filter the marks included between 26 and 28&lt;/li&gt;
&lt;li&gt;Remove the ‘Id’, ‘date’ and ‘high-school’ columns&lt;/li&gt;
&lt;li&gt;Calculate the mean mark for each subject in each year&lt;/li&gt;
&lt;li&gt;Spread those means along Years&lt;/li&gt;
&lt;li&gt;Get the overall mean for each subject across years&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s try to accomplish this task by using both a ‘base’ approach and a ‘tidyverse’ approach.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Traditional approach
library(reshape)
students2 &amp;lt;- subset(students, Mark &amp;gt;= 26 | Mark &amp;lt;= 28, 
                    select = c(-Id, -Date, -HighSchool))
mstudents2 &amp;lt;- cast(Subject ~ Year, data = students2,
      value = &amp;quot;Mark&amp;quot;, fun.aggregate = mean)
mstudents2$Mean &amp;lt;- apply(mstudents2[,2:3], 1, mean)
mstudents2
##       Subject     2001     2002     Mean
## 1    AGRONOMY 26.69565 26.25000 26.47283
## 2     BIOLOGY 26.48000 26.41379 26.44690
## 3   CHEMISTRY 24.21429 22.19048 23.20238
## 4   ECONOMICS 27.73077 27.11111 27.42094
## 5 FRUIT TREES      NaN 26.92857      NaN
## 6       MATHS 26.59259 25.00000 25.79630
# Tidyverse approach
students %&amp;gt;%
  filter(Mark &amp;gt;= 26 | Mark &amp;lt;= 28) %&amp;gt;%
  select(c(-Id,-Date,-HighSchool)) %&amp;gt;%
  group_by(Subject, Year) %&amp;gt;%
  summarise(Mark = mean(Mark)) %&amp;gt;%
  pivot_wider(names_from = Year, values_from = Mark) %&amp;gt;%
  mutate(Mean = (`2001` + `2002`)/2)
## # A tibble: 6 x 4
## # Groups:   Subject [6]
##   Subject     `2001` `2002`  Mean
##   &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 AGRONOMY      26.7   26.2  26.5
## 2 BIOLOGY       26.5   26.4  26.4
## 3 CHEMISTRY     24.2   22.2  23.2
## 4 ECONOMICS     27.7   27.1  27.4
## 5 FRUIT TREES   NA     26.9  NA  
## 6 MATHS         26.6   25    25.8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I must admit the second piece of code flows much more smooothly and it is much closer to my natural way of thinking. A collegue of mine said that, when it comes to operating on big tables and making really complex operations, the tidyverse is currently considered ‘the most powerful tool in the world’. I will have to dedicate another post to such situations. So far, I have started to reconsider my attitute towards the tidyverse.&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>