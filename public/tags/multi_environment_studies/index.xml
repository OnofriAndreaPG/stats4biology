<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Multi_environment_studies on The broken bridge between biologists and statisticians</title>
    <link>https://www.statforbiology.com/tags/multi_environment_studies/</link>
    <description>Recent content in Multi_environment_studies on The broken bridge between biologists and statisticians</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2018, @AndreaOnofri</copyright>
    <lastBuildDate>Fri, 05 Mar 2021 00:00:00 +0000</lastBuildDate>
    
        <atom:link href="https://www.statforbiology.com/tags/multi_environment_studies/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>lmDiallel: a new R package to fit diallel models. Multienvironment diallel experiments</title>
      <link>https://www.statforbiology.com/2021/stat_met_diallelmet/</link>
      <pubDate>Fri, 05 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2021/stat_met_diallelmet/</guid>
      <description>
&lt;script src=&#34;https://www.statforbiology.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In recent times, a few colleagues at my Department and I have devoted some research effort to data management for diallel mating experiments, which we have summarised in a paper (&lt;a href=&#34;https://link.springer.com/article/10.1007/s00122-020-03716-8&#34;&gt;Onofri et al., 2020&lt;/a&gt;) and a series of five blog posts (&lt;a href=&#34;https://www.statforbiology.com/tags/diallel_models/&#34;&gt;see here&lt;/a&gt;). A final topic that remains to be covered relates to the frequent possibility that these diallel experiments are repeated across years and/or locations. How should the resulting dataset be analysed?&lt;/p&gt;
&lt;p&gt;We will start from a multi-environment full diallel experiment with 5 parental lines, in four blocks and 10 environments. The dataset is factitious and it was generated by Monte Carlo simulation, starting from the results reported in Zhang, et al. (2005; &lt;a href=&#34;https://acsess.onlinelibrary.wiley.com/doi/abs/10.2134/agronj2004.0260&#34;&gt;see here&lt;/a&gt;). The following box shows how we can load the data, after installing (if necessary) and loading the ‘lmDiallel’ package. In the same box, we use ‘dplyr’ to transform the explanatory variables into factors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools) # Install if necessary
# install_github(&amp;quot;OnofriAndreaPG/lmDiallel&amp;quot;)
library(lmDiallel)
library(dplyr)

dataset &amp;lt;- read.csv(&amp;quot;https://www.casaonofri.it/_datasets/diallelMET.csv&amp;quot;, header = T)
dataset &amp;lt;- dataset %&amp;gt;% 
  dplyr::mutate(across(c(Env, Block, Par1, Par2), .fns = factor))
head(dataset)
##   Env Block Par1 Par2 Yield
## 1   1     1    1    1 10.78
## 2   1     1    1    2 12.78
## 3   1     1    1    3 15.23
## 4   1     1    1    4 10.66
## 5   1     1    1    5 14.42
## 6   1     1    2    1 11.84&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;fixed-model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fixed model fitting&lt;/h1&gt;
&lt;p&gt;For this full diallel experiment (withe selfs and reciprocals) we can fit the Griffing’s model 1, including the General combining Abilities (GCA), total Specific Combining Abilities (tSCA) and reciprocal effects (REC). We also include the environment effect, the block within environment effect and all interactions between genetical effects and the environment. If we regard all effects as fixed, we can code the final model either by using the &lt;code&gt;lm()&lt;/code&gt; function, or by using the &lt;code&gt;lm.diallel()&lt;/code&gt; wrapper in the ‘lmDiallel’ package, as shown in the box below. The two parameterisations are slightly different, although variance partitioning is totally equivalent.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dMod &amp;lt;- lm(Yield ~ Env/Block + GCA(Par1, Par2) + tSCA(Par1, Par2) + 
            REC(Par1, Par2) + GCA(Par1, Par2):Env + 
             tSCA(Par1, Par2):Env + REC(Par1, Par2):Env,
           data = dataset)
# anova(dMod)

dMod2 &amp;lt;- lm.diallel(Yield ~ Par1 + Par2,
                    data = dataset, fct = &amp;quot;GRIFFING1&amp;quot;,
                    Env = Env, Block = Block)
anova(dMod2)
## Analysis of Variance Table
## 
## Response: Yield
##                  Df Sum Sq Mean Sq  F value Pr(&amp;gt;F)    
## Environment       9   10.6    1.17   0.1550 0.9978    
## Env:Block        30 3195.1  106.50  14.0554 &amp;lt;2e-16 ***
## GCA               4 8673.7 2168.42 286.1657 &amp;lt;2e-16 ***
## GCA:Env          36  187.7    5.21   0.6882 0.9175    
## tSCA             10 3021.3  302.13  39.8725 &amp;lt;2e-16 ***
## tSCA:Env         90  108.8    1.21   0.1596 1.0000    
## Reciprocals      10 4379.7  437.97  57.7989 &amp;lt;2e-16 ***
## Reciprocals:Env  90  352.6    3.92   0.5170 0.9999    
## Residuals       720 5455.8    7.58                    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Considering the ‘diallel’ object ‘dMod2, the full list of genetical parameters (in each environment) is retrieved by using the &lt;code&gt;glht()&lt;/code&gt; function in the ’multcomp’ package. In the box below we show an excerpt of the output.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(multcomp)
gh &amp;lt;- glht(linfct = diallel.eff(dMod2))
# summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))
#                Estimate Std. Error t value Pr(&amp;gt;|t|)    
# g_1:1 == 0     -3.67200    0.38929  -9.432 7.06e-10 ***
# g_2:1 == 0     -0.63850    0.38929  -1.640 0.113019    
# g_3:1 == 0      1.28950    0.38929   3.312 0.002723 ** 
# g_4:1 == 0      0.03025    0.38929   0.078 0.938658    
# g_5:1 == 0      2.99075    0.38929   7.682 3.75e-08 ***
# ts_1:1:1 == 0   1.73500    1.10109   1.576 0.127184    
# ts_1:2:1 == 0   0.29150    0.80255   0.363 0.719379    
# ts_1:3:1 == 0  -1.43150    0.80255  -1.784 0.086153 .  
# ts_1:4:1 == 0  -2.10225    0.80255  -2.619 0.014504 *  
# ts_1:5:1 == 0   1.50725    0.80255   1.878 0.071631 .  
# ts_2:1:1 == 0   0.29150    0.80255   0.363 0.719379    
# ts_2:2:1 == 0   1.03050    1.10109   0.936 0.357942   &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The ANOVA table above shows that genetical effects did not significantly interact with the environment and, therefore, we might be interested in getting estimates of average genetical effects, which can be done by using the &lt;code&gt;glht()&lt;/code&gt; function and passing the &lt;code&gt;type = &#34;means&#34;&lt;/code&gt; argument in the &lt;code&gt;diallel.eff()&lt;/code&gt; call. An excerpt of the result is given in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gh &amp;lt;- glht(linfct = diallel.eff(dMod2, type = &amp;quot;means&amp;quot;))
# summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))
#    Simultaneous Tests for General Linear Hypotheses
# 
# Linear Hypotheses:
#               Estimate Std. Error t value Pr(&amp;gt;|t|)    
# g_1:1 == 0    -3.46259    0.12311 -28.127  &amp;lt; 2e-16 ***
# g_2:1 == 0    -0.55351    0.12311  -4.496 0.000127 ***
# g_3:1 == 0     0.64251    0.12311   5.219 1.89e-05 ***
# g_4:1 == 0     0.40521    0.12311   3.292 0.002868 ** 
# g_5:1 == 0     2.96838    0.12311  24.112  &amp;lt; 2e-16 ***
# ts_1:1:1 == 0  1.53104    0.34820   4.397 0.000165 ***
# ts_1:2:1 == 0  0.21247    0.25379   0.837 0.410125    
# ts_1:3:1 == 0 -1.39756    0.25379  -5.507 8.87e-06 ***
# ....
# ....
# r_1:2:1 == 0  -0.20075    0.30776  -0.652 0.519943    
# r_1:3:1 == 0   2.06700    0.30776   6.716 3.98e-07 ***
# r_1:4:1 == 0  -1.33550    0.30776  -4.339 0.000192 ***
# r_1:5:1 == 0  -3.97250    0.30776 -12.908 8.19e-13 ***
# ....
# ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mixed-model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Mixed model fitting&lt;/h1&gt;
&lt;p&gt;In most cases we might be willing to regard the environment effect as random, so that all the interactions between genetical effects and the environment are random as well. A mixed model can be fitted by using the &lt;code&gt;mmer.diallel()&lt;/code&gt; wrapper, that is is available in the ‘lmDiallel’ package. The call is very similar to a &lt;code&gt;lm.diallel()&lt;/code&gt; call, as shown in the box above; we can use the ‘type = “environment”’ argument to specify that we want to include random environment effects. The fit can take quite a few seconds (or minutes, depending on your device…). Fixed effects and variance components can be easily retrieved from the model object, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dMod3 &amp;lt;- mmer.diallel(Yield ~ Par1 + Par2,
                    data = dataset, fct = &amp;quot;GRIFFING1&amp;quot;,
                    Env = Env, Block = Block, type = &amp;quot;environment&amp;quot;)
dMod3$beta #fixed effects
##    Trait                 Effect  Estimate Std.Error     t.value
## 1      Y            (Intercept) 16.272390 0.2800709  58.1009636
## 2      Y     GCA(Par1, Par2)g_1 -3.462590 0.1005471 -34.4374961
## 3      Y     GCA(Par1, Par2)g_2 -0.553515 0.1005471  -5.5050326
## 4      Y     GCA(Par1, Par2)g_3  0.642510 0.1005471   6.3901402
## 5      Y     GCA(Par1, Par2)g_4  0.405210 0.1005471   4.0300520
## 6      Y tSCA(Par1, Par2)ts_1:1  1.531040 0.3246046   4.7166305
## 7      Y tSCA(Par1, Par2)ts_1:2  0.212465 0.2365942   0.8980143
## 8      Y tSCA(Par1, Par2)ts_1:3 -1.397560 0.2365942  -5.9069910
## 9      Y tSCA(Par1, Par2)ts_1:4 -1.866010 0.2365942  -7.8869632
## 10     Y tSCA(Par1, Par2)ts_2:2  1.946890 0.3246046   5.9977275
## 11     Y tSCA(Par1, Par2)ts_2:3  0.896115 0.2365942   3.7875606
## 12     Y tSCA(Par1, Par2)ts_2:4 -3.674085 0.2365942 -15.5290556
## 13     Y tSCA(Par1, Par2)ts_3:3 -0.187160 0.3246046  -0.5765784
## 14     Y tSCA(Par1, Par2)ts_3:4  1.134515 0.2365942   4.7951930
## 15     Y tSCA(Par1, Par2)ts_4:4  4.228940 0.3246046  13.0279727
## 16     Y   REC(Par1, Par2)r_1:2 -0.200750 0.2869127  -0.6996903
## 17     Y   REC(Par1, Par2)r_1:3  2.067000 0.2869127   7.2042832
## 18     Y   REC(Par1, Par2)r_1:4 -1.335500 0.2869127  -4.6547268
## 19     Y   REC(Par1, Par2)r_1:5 -3.972500 0.2869127 -13.8456774
## 20     Y   REC(Par1, Par2)r_2:3  1.345250 0.2869127   4.6887092
## 21     Y   REC(Par1, Par2)r_2:4 -1.277750 0.2869127  -4.4534460
## 22     Y   REC(Par1, Par2)r_2:5 -2.285625 0.2869127  -7.9662747
## 23     Y   REC(Par1, Par2)r_3:4  4.424875 0.2869127  15.4223768
## 24     Y   REC(Par1, Par2)r_3:5 -0.038625 0.2869127  -0.1346229
## 25     Y   REC(Par1, Par2)r_4:5 -2.149875 0.2869127  -7.4931342
dMod3$varcomp #variance components
##               VarComp  VarCompSE
## Env        0.00000000 0.42671998
## Env:Block  2.99662037 0.84276821
## GCA:Env   -0.03826627 0.03707895
## tSCA:Env   0.00000000 0.14493517
## REC:Env    0.00000000 0.13004754
## Residuals  6.58550954 0.34464357&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;random-model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Random model fitting&lt;/h1&gt;
&lt;p&gt;In other instances, our aim is to estimate variance components for all genetical effects and, therefore, we might like to regard all effects as random. This is easily done by changing the call to &lt;code&gt;mmer.diallel()&lt;/code&gt; and replacing &lt;code&gt;type = &#34;environment&#34;&lt;/code&gt; with &lt;code&gt;type = &#34;all&#34;&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dMod4 &amp;lt;- mmer.diallel(Yield ~ Par1 + Par2,
                    data = dataset, fct = &amp;quot;GRIFFING1&amp;quot;,
                    Env = Env, Block = Block, type = &amp;quot;all&amp;quot;)
dMod4$beta #fixed effects
##   Trait      Effect Estimate Std.Error  t.value
## 1     Y (Intercept) 16.45538  1.920185 8.569682
dMod4$varcomp #variance components
##               VarComp  VarCompSE
## Env        0.00000000 0.42621427
## Env:Block  2.99608118 0.84185447
## GCA        4.11923254 3.41043097
## tSCA       4.68884763 2.14244233
## REC        5.39232126 2.44832836
## GCA:Env   -0.03828058 0.03706453
## tSCA:Env   0.00000000 0.14494177
## REC:Env    0.00000000 0.13005751
## Residuals  6.58560305 0.34466898&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Obviously, a similar procedure can be used to fit all other diallel models to multi-environment diallel experiments.&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Luigi Russi&lt;br /&gt;
Niccolò Terzaroli&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
&lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Covarrubias-Pazaran, G., 2016. Genome-Assisted Prediction of Quantitative Traits Using the R Package sommer. PLOS ONE 11, e0156744. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0156744&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pone.0156744&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Griffing, B., 1956. Concept of general and specific combining ability in relation to diallel crossing systems. Australian Journal of Biological Science 9, 463–493.&lt;/li&gt;
&lt;li&gt;Hayman, B.I., 1954. The Analysis of Variance of Diallel Tables. Biometrics 10, 235. &lt;a href=&#34;https://doi.org/10.2307/3001877&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2307/3001877&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Zhang, Y., Kang, M.S., Lamkey, K.R., 2005. DIALLEL-SAS05: A Comprehensive Program for Griffing’s and Gardner-Eberhart Analyses. Agronomy Journal 97, 1097–1106. &lt;a href=&#34;https://doi.org/10.2134/agronj2004.0260&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2134/agronj2004.0260&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>lmDiallel: a new R package to fit diallel models. The Gardner-Eberhart models</title>
      <link>https://www.statforbiology.com/2021/stat_met_diallel_gardner/</link>
      <pubDate>Mon, 22 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2021/stat_met_diallel_gardner/</guid>
      <description>
&lt;script src=&#34;https://www.statforbiology.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Another post for this series about diallel mating experiments. So far, we have published a paper in Plant Breeding (&lt;a href=&#34;https://link.springer.com/article/10.1007/s00122-020-03716-8&#34;&gt;Onofri et al., 2020&lt;/a&gt;), where we presented &lt;code&gt;lmDiallel&lt;/code&gt;, a new R package to fit diallel models. We followed up this paper with a series of four blog posts, giving more detail about the package (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel1/&#34;&gt;see here&lt;/a&gt;), about the Hayman’s models type 1 (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel_hayman1/&#34;&gt;see here&lt;/a&gt;) and type 2 (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel_hayman2/&#34;&gt;see here&lt;/a&gt;) and about the Griffing’s family of models (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_met_diallel_griffing/&#34;&gt;see here&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;In this post we are going to talk about the Gardner-Eberarth models, which are particularly suitable to describe heterotic effects. The peculiar trait of these models is that they consider different means for crosses and selfed parents and, therefore, they are reserved for the mating designs 2 (selfed parents and crosses, but no reciprocals) or 1 (selfed parents, crosses and reciprocals). The first model is know as GE2 model and it is specified as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ijk} = \mu_{\nu} + \gamma_k + 0.5 \, \left( v_i + v_j \right) + \bar{h} +  h_i + h_j + s_{ij} + \varepsilon_{ijk} \quad\quad\quad (1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\gamma_k\)&lt;/span&gt; is the effect of block &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mu_{\nu}\)&lt;/span&gt; is the overall mean for all selfed parents (not the overall mean, as in other diallel models). The parameters &lt;span class=&#34;math inline&#34;&gt;\(v\)&lt;/span&gt; (&lt;span class=&#34;math inline&#34;&gt;\(v_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(v_j\)&lt;/span&gt;) represent the differences between the expected value for the selfed parents &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and the mean for all selfed parents (&lt;span class=&#34;math inline&#34;&gt;\(\mu_{\nu}\)&lt;/span&gt;). According to the authors, this would be the Variety Effect (VE); as a consequence, the expected value for the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; selfed parent is &lt;span class=&#34;math inline&#34;&gt;\(\mu_{\nu} + v_i\)&lt;/span&gt;, while the expected value for the cross &lt;span class=&#34;math inline&#34;&gt;\(ij\)&lt;/span&gt;, in absence of any dominance/heterosis effects, would be &lt;span class=&#34;math inline&#34;&gt;\(\mu_{\nu} + 0.5 \, \left( v_i + v_j \right)\)&lt;/span&gt;, that is the mean value of its parents. There is a close relationship between &lt;span class=&#34;math inline&#34;&gt;\(g_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(g_j\)&lt;/span&gt; in Griffing’s equations (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_met_diallel_griffing/&#34;&gt;see here&lt;/a&gt;) and &lt;span class=&#34;math inline&#34;&gt;\(v_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(v_j\)&lt;/span&gt; in the GE2 equation (Eq. 1), that is: &lt;span class=&#34;math inline&#34;&gt;\(v_i = 2\, g_i + (n - 2) d_i\)&lt;/span&gt;; therefore, the sum of squares for the GCA and VE effects are the same, although the estimates are different.&lt;/p&gt;
&lt;p&gt;Since a cross does not necessarily respond according to the mean value of its parents, the parameter &lt;span class=&#34;math inline&#34;&gt;\(\bar{h}\)&lt;/span&gt; represents the average heterosis (H.BAR) contributed by the the whole set of genotypes used in crosses. In the balanced case, &lt;span class=&#34;math inline&#34;&gt;\(\bar{h}\)&lt;/span&gt; represents the difference between the overall mean for selfed parents and the overall mean for crosses, under the constraint that &lt;span class=&#34;math inline&#34;&gt;\(\bar{h} = 0\)&lt;/span&gt; for all selfed parents. Besides, the parameters &lt;span class=&#34;math inline&#34;&gt;\(h_i\)&lt;/span&gt; represent the average heterosis contributed by the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; parent in its crosses (Hi), while &lt;span class=&#34;math inline&#34;&gt;\(s_{ij}\)&lt;/span&gt; is the Specific Combining Ability (SCA) for the cross between the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j^{th}\)&lt;/span&gt; parents, that is totally equivalent to the corresponding parameter in Griffing’s models.&lt;/p&gt;
&lt;p&gt;It is clear that both the Hayman’s model type 2 and the GE2 model account for the heterosis effect, although they do it in a different way: in Hayman’s model type 2 the specific effect of heterosis is assessed with reference to the overall mean, while in GE2 it is assessed by comparing the mean of a cross with the means of its parents. Indeed, the sum of squares for the ‘MDD’ effect in Hayman’s model and ‘Hi’ effect in GE2 model are perfectly the same, although the parameters are different.&lt;/p&gt;
&lt;p&gt;Gardner and Eberhart proposed another model (GE3), which we have slightly modified to maintain a consistent notation in the frame of GLMs:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\left\{ {\begin{array}{ll}
y_{ijk} = \mu_{\nu} + \gamma_k + \bar{h} + \textrm{gc}_i + \textrm{gc}_j + s_{ij} &amp;amp; \textrm{if} \quad i \neq j\\
y_{ijk} = \mu_{\nu} + \gamma_k + \textrm{sp}_i &amp;amp; \textrm{if} \quad i = j
\end{array}} \right. \quad\quad\quad (2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Equation 2 is an array of two separate elements for crosses and selfed parents. For the crosses (equation above), the parameters &lt;span class=&#34;math inline&#34;&gt;\(\textrm{gc}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\textrm{gc}_j\)&lt;/span&gt; represent the GCA for the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; parents in all their crosses (GCAC); it should be noted that GCA &lt;span class=&#34;math inline&#34;&gt;\(\neq\)&lt;/span&gt; GCAC, as this latter effect is estimated without considering the selfed parents. The parameters &lt;span class=&#34;math inline&#34;&gt;\(s{ij}\)&lt;/span&gt; are the same as in the previous models (Hayman’s and Griffing’s models: SCA effect), while &lt;span class=&#34;math inline&#34;&gt;\(\textrm{sp}_i\)&lt;/span&gt; represent the effects of selfed parents (SP): they are numerically equivalent to the corresponding effects in Equation 1, but the sum of squares are different (see Murray et al., 2003). Therefore, we use different names for these two effects (SP and Hi).&lt;/p&gt;
&lt;div id=&#34;example-1-a-half-diallel-no-reciprocals&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 1: a half-diallel (no reciprocals)&lt;/h1&gt;
&lt;p&gt;As an example of a diallel experiments with no reciprocals, we consider the data reported in Lonnquist and Gardner (1961) relating to the yield of 21 maize genotypes, obtained from six male and six female parentals. The dataset is available as &lt;code&gt;lonnquist61&lt;/code&gt; in the &lt;code&gt;lmDiallel&lt;/code&gt; package; in the box below we load the data, after installing (if necessary) and loading the ‘lmDiallel’ package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools) # Install if necessary
# install_github(&amp;quot;OnofriAndreaPG/lmDiallel&amp;quot;)
library(lmDiallel)
library(multcomp)
data(&amp;quot;lonnquist61&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this complete diallel experiment we can fit equation 1 (model GE2), by including the functions &lt;code&gt;H.BAR()&lt;/code&gt;, &lt;code&gt;VEi()&lt;/code&gt;, &lt;code&gt;Hi()&lt;/code&gt; and &lt;code&gt;SCA()&lt;/code&gt;; we can use either the &lt;code&gt;lm()&lt;/code&gt; or the &lt;code&gt;lm.diallel()&lt;/code&gt; functions, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dMod &amp;lt;- lm(Yield ~ H.BAR(Par1, Par2) + VEi(Par1, Par2) + 
             Hi(Par1, Par2) + SCA(Par1, Par2),
           data = lonnquist61)
dMod2 &amp;lt;- lm.diallel(Yield ~ Par1 + Par2,
                    data = lonnquist61, fct = &amp;quot;GE2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case the dataset has no replicates and, therefore, we need to provide an estimate of the residual mean square and degrees of freedom. If we have fitted the model by using the &lt;code&gt;lm()&lt;/code&gt; function, the resulting ‘lm’ object can be explored by using the &lt;code&gt;summary.diallel()&lt;/code&gt; and &lt;code&gt;anova.diallel()&lt;/code&gt; functions. Otherwise, if we have fitted the model with the &lt;code&gt;lm.diallel()&lt;/code&gt; function, the resulting ‘diallel’ object can be explored by using the &lt;code&gt;summary()&lt;/code&gt; and &lt;code&gt;anova()&lt;/code&gt; methods. See the box below for an example: the results are, obviously, the same.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# summary.diallel(dMod, MSE = 7.1, dfr = 60)
anova.diallel(dMod, MSE = 7.1, dfr = 60)
## Analysis of Variance Table
## 
## Response: Yield
##                   Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## H.BAR(Par1, Par2)  1 115.440 115.440 16.2592 0.0001583 ***
## VEi(Par1, Par2)    5 234.230  46.846  6.5980 5.923e-05 ***
## Hi(Par1, Par2)     5  59.720  11.944  1.6823 0.1527246    
## SCA(Par1, Par2)    9  63.781   7.087  0.9981 0.4515416    
## Residuals         60           7.100                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
# summary(dMod2, MSE = 7.1, dfr = 60)
anova(dMod2, MSE = 7.1, dfr = 60)
## Analysis of Variance Table
## 
## Response: Yield
##           Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## h.bar      1 115.440 115.440 16.2592 0.0001583 ***
## Variety    5 234.230  46.846  6.5980 5.923e-05 ***
## h.i        5  59.720  11.944  1.6823 0.1527246    
## SCA        9  63.781   7.087  0.9981 0.4515416    
## Residuals 60           7.100                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also for the diallel object, we can retrieve the full list of genetical parameters with the &lt;code&gt;glht()&lt;/code&gt; function, by using the same syntax as shown above.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gh &amp;lt;- glht(linfct = diallel.eff(dMod2, MSE = 7.1, dfr = 60))
summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))
#    Simultaneous Tests for General Linear Hypotheses
# 
# Linear Hypotheses:
#                Estimate Std. Error t value Pr(&amp;gt;|t|)    
# Intercept == 0   92.450      1.088  84.987  &amp;lt; 2e-16 ***
# h.bar == 0        5.190      1.287   4.032  0.00043 ***
# v_B == 0          4.150      2.432   1.706  0.09991 .  
# v_G == 0         -4.550      2.432  -1.871  0.07270 .  
# v_H == 0         -0.750      2.432  -0.308  0.76028    
# v_K == 0         -1.150      2.432  -0.473  0.64031    
# v_K2 == 0         3.750      2.432   1.542  0.13524    
# v_M == 0         -1.450      2.432  -0.596  0.55625    
#...
#...
# s_K2:K == 0       0.585      2.064   0.283  0.77909    
# s_K2:M == 0      -1.115      2.064  -0.540  0.59364    
# s_M:B == 0       -1.040      2.064  -0.504  0.61859    
# s_M:G == 0       -2.290      2.064  -1.110  0.27737    
# s_M:H == 0        3.385      2.064   1.640  0.11304    
# s_M:K == 0        1.060      2.064   0.514  0.61189    
# s_M:K2 == 0      -1.115      2.064  -0.540  0.59364 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want to fit Equation 2 (model GE3), we can follow a very similar approach, by using the functions &lt;code&gt;H.BAR()&lt;/code&gt;, &lt;code&gt;SP()&lt;/code&gt;, &lt;code&gt;GCAC()&lt;/code&gt; and &lt;code&gt;SCA()&lt;/code&gt;. The box below shows an example either with the &lt;code&gt;lm()&lt;/code&gt; or the with the &lt;code&gt;lm.diallel()&lt;/code&gt; functions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dMod &amp;lt;- lm(Yield ~ H.BAR(Par1, Par2) + SP(Par1, Par2)
           + GCAC(Par1, Par2) + SCA(Par1, Par2),
           data = lonnquist61)
dMod2 &amp;lt;- lm.diallel(Yield ~ Par1 + Par2,
                    data = lonnquist61, fct = &amp;quot;GE3&amp;quot;)

# summary.diallel(dMod, MSE = 7.1, dfr = 60)
anova.diallel(dMod, MSE = 7.1, dfr = 60)
## Analysis of Variance Table
## 
## Response: Yield
##                   Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## H.BAR(Par1, Par2)  1 115.440 115.440 16.2592 0.0001583 ***
## SP(Par1, Par2)     5  55.975  11.195  1.5768 0.1804080    
## GCAC(Par1, Par2)   5 237.975  47.595  6.7035 5.069e-05 ***
## SCA(Par1, Par2)    9  63.781   7.087  0.9981 0.4515416    
## Residuals         60           7.100                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
# summary(dMod2, MSE = 7.1, dfr = 60)
anova(dMod2, MSE = 7.1, dfr = 60)
## Analysis of Variance Table
## 
## Response: Yield
##             Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## h.bar        1 115.440 115.440 16.2592 0.0001583 ***
## Selfed par.  5  55.975  11.195  1.5768 0.1804080    
## Varieties    5 237.975  47.595  6.7035 5.069e-05 ***
## SCA          9  63.781   7.087  0.9981 0.4515416    
## Residuals   60           7.100                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also for the diallel object, we can retrieve the full list of genetical parameters with the &lt;code&gt;glht()&lt;/code&gt; function, by using the same syntax as shown above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gh &amp;lt;- glht(linfct = diallel.eff(dMod2, MSE = 7.1, dfr = 60))
summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))
## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Linear Hypotheses:
##                Estimate Std. Error t value Pr(&amp;gt;|t|)    
## Intercept == 0   92.450      1.088  84.987  &amp;lt; 2e-16 ***
## h.bar == 0        5.190      1.287   4.032  0.00043 ***
## sp_B == 0         4.150      2.432   1.706  0.09991 .  
## sp_G == 0        -4.550      2.432  -1.871  0.07270 .  
## sp_H == 0        -0.750      2.432  -0.308  0.76028    
## sp_K == 0        -1.150      2.432  -0.473  0.64031    
## sp_K2 == 0        3.750      2.432   1.542  0.13524    
## sp_M == 0        -1.450      2.432  -0.596  0.55625    
## gc_B == 0         0.900      1.216   0.740  0.46593    
## gc_G == 0        -2.050      1.216  -1.686  0.10385    
## gc_H == 0        -0.025      1.216  -0.021  0.98376    
## gc_K == 0        -3.000      1.216  -2.467  0.02055 *  
## gc_K2 == 0        6.375      1.216   5.242 1.78e-05 ***
## gc_M == 0        -2.200      1.216  -1.809  0.08205 .  
## s_B:G == 0        4.810      2.064   2.330  0.02781 *  
## s_B:H == 0       -1.415      2.064  -0.686  0.49905    
## s_B:K == 0       -0.140      2.064  -0.068  0.94644    
## s_B:K2 == 0      -2.215      2.064  -1.073  0.29305    
## s_B:M == 0       -1.040      2.064  -0.504  0.61859    
## s_G:B == 0        4.810      2.064   2.330  0.02781 *  
## s_G:H == 0       -2.865      2.064  -1.388  0.17689    
## s_G:K == 0       -0.990      2.064  -0.480  0.63548    
## s_G:K2 == 0       1.335      2.064   0.647  0.52342    
## s_G:M == 0       -2.290      2.064  -1.110  0.27737    
## s_H:B == 0       -1.415      2.064  -0.686  0.49905    
## s_H:G == 0       -2.865      2.064  -1.388  0.17689    
## s_H:K == 0       -0.515      2.064  -0.250  0.80492    
## s_H:K2 == 0       1.410      2.064   0.683  0.50056    
## s_H:M == 0        3.385      2.064   1.640  0.11304    
## s_K:B == 0       -0.140      2.064  -0.068  0.94644    
## s_K:G == 0       -0.990      2.064  -0.480  0.63548    
## s_K:H == 0       -0.515      2.064  -0.250  0.80492    
## s_K:K2 == 0       0.585      2.064   0.283  0.77909    
## s_K:M == 0        1.060      2.064   0.514  0.61189    
## s_K2:B == 0      -2.215      2.064  -1.073  0.29305    
## s_K2:G == 0       1.335      2.064   0.647  0.52342    
## s_K2:H == 0       1.410      2.064   0.683  0.50056    
## s_K2:K == 0       0.585      2.064   0.283  0.77909    
## s_K2:M == 0      -1.115      2.064  -0.540  0.59364    
## s_M:B == 0       -1.040      2.064  -0.504  0.61859    
## s_M:G == 0       -2.290      2.064  -1.110  0.27737    
## s_M:H == 0        3.385      2.064   1.640  0.11304    
## s_M:K == 0        1.060      2.064   0.514  0.61189    
## s_M:K2 == 0      -1.115      2.064  -0.540  0.59364    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## (Adjusted p values reported -- none method)
#    Simultaneous Tests for General Linear Hypotheses
# 
# Linear Hypotheses:
#                Estimate Std. Error t value Pr(&amp;gt;|t|)    
# Intercept == 0   92.450      1.088  84.987  &amp;lt; 2e-16 ***
# h.bar == 0        5.190      1.287   4.032  0.00043 ***
# sp_B == 0         4.150      2.432   1.706  0.09991 .  
# sp_G == 0        -4.550      2.432  -1.871  0.07270 .  
# sp_H == 0        -0.750      2.432  -0.308  0.76028    
# sp_K == 0        -1.150      2.432  -0.473  0.64031    
# sp_K2 == 0        3.750      2.432   1.542  0.13524    
# ...
# ...
# s_K2:H == 0       1.410      2.064   0.683  0.50056    
# s_K2:K == 0       0.585      2.064   0.283  0.77909    
# s_K2:M == 0      -1.115      2.064  -0.540  0.59364    
# s_M:B == 0       -1.040      2.064  -0.504  0.61859    
# s_M:G == 0       -2.290      2.064  -1.110  0.27737    
# s_M:H == 0        3.385      2.064   1.640  0.11304    
# s_M:K == 0        1.060      2.064   0.514  0.61189    
# s_M:K2 == 0      -1.115      2.064  -0.540  0.59364   &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2-a-full-diallel-experiment&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 2: a full diallel experiment&lt;/h1&gt;
&lt;p&gt;If we have a full diallel experiment (with reciprocals), we can fit Equations 1 and 2, but we should also include the reciprocal effects, in order to avoid that the residual term is inflated and no longer provides a reliable estimate of the experimental error. We provide an example with the data in Hayman (1954), relating to a complete diallel experiment with eight parental lines, producing 64 combinations (8 selfs + 28 crosses with 2 reciprocals each). The R dataset is included in the ‘lmDiallel’ package and the models are fitted by using the same coding as above, apart from the fact that the function &lt;code&gt;REC()&lt;/code&gt; is included in the &lt;code&gt;lm()&lt;/code&gt; call and the arguments “GE2r” and “GE3r” are used instead of “GE2” and “GE3” in the &lt;code&gt;lm.diallel()&lt;/code&gt; call.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;hayman54&amp;quot;)
contrasts(hayman54$Block) &amp;lt;- &amp;quot;contr.sum&amp;quot;
dMod &amp;lt;- lm(Ftime ~ Block + H.BAR(Par1, Par2) + VEi(Par1, Par2) + 
             Hi(Par1, Par2) + SCA(Par1, Par2) + REC(Par1, Par2),
           data = hayman54)
dMod2 &amp;lt;- lm.diallel(Ftime ~ Par1 + Par2, Block = Block,
                    data = hayman54, fct = &amp;quot;GE2r&amp;quot;)
# summary(dMod2)
anova(dMod2)
## Analysis of Variance Table
## 
## Response: Ftime
##             Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Block        1    142     142  0.3416   0.56100    
## h.bar        1  30797   30797 73.8840 3.259e-12 ***
## Variety      7 277717   39674 95.1805 &amp;lt; 2.2e-16 ***
## h.i          7  34153    4879 11.7050 1.957e-09 ***
## SCA         20  37289    1864  4.4729 2.560e-06 ***
## Reciprocals 28  19112     683  1.6375   0.05369 .  
## Residuals   63  26260                              
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;gh &amp;lt;- glht(linfct = diallel.eff(dMod2))
summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))
#    Simultaneous Tests for General Linear Hypotheses
# 
# Linear Hypotheses:
#                  Estimate Std. Error t value Pr(&amp;gt;|t|)    
# Intercept == 0  2.039e+02  5.104e+00  39.956  &amp;lt; 2e-16 ***
# h.bar == 0     -4.690e+01  5.456e+00  -8.596 4.48e-09 ***
# v_A == 0        8.506e+01  1.350e+01   6.299 1.14e-06 ***
# v_B == 0       -3.344e+01  1.350e+01  -2.476 0.020115 *  
# v_C == 0        1.841e+02  1.350e+01  13.630 2.37e-13 ***
# v_D == 0        3.706e+01  1.350e+01   2.745 0.010839 *  
# v_E == 0       -3.794e+01  1.350e+01  -2.809 0.009301 ** 
# v_F == 0       -3.394e+01  1.350e+01  -2.513 0.018499 *  
# v_G == 0       -1.509e+02  1.350e+01 -11.177 1.99e-11 ***
# v_H == 0       -4.994e+01  1.350e+01  -3.698 0.001023 ** 
# h_A == 0        4.885e+00  7.797e+00   0.627 0.536380    
# ...
# ...
# r_H:C == 0     -5.500e+00  1.021e+01  -0.539 0.594620    
# r_H:D == 0     -5.000e+00  1.021e+01  -0.490 0.628380    
# r_H:E == 0     -8.500e+00  1.021e+01  -0.833 0.412617    
# r_H:F == 0     -1.750e+01  1.021e+01  -1.714 0.098370 .  
# r_H:G == 0     -1.400e+01  1.021e+01  -1.371 0.181956    &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code for the GE3 model with reciprocal effects is shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dMod &amp;lt;- lm(Ftime ~ Block + H.BAR(Par1, Par2) + SP(Par1, Par2)
           + GCAC(Par1, Par2) + SCA(Par1, Par2) + REC(Par1, Par2),
           data = hayman54)
dMod2 &amp;lt;- lm.diallel(Ftime ~ Par1 + Par2, Block = Block,
                    data = hayman54, fct = &amp;quot;GE3r&amp;quot;)
# summary(dMod2)
anova(dMod2)
## Analysis of Variance Table
## 
## Response: Ftime
##             Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Block        1    142   142.4  0.3416   0.56100    
## h.bar        1  30797 30796.9 73.8840 3.259e-12 ***
## gcac         7 168923 24131.9 57.8941 &amp;lt; 2.2e-16 ***
## Selfed par.  7 142946 20420.9 48.9913 &amp;lt; 2.2e-16 ***
## SCA         20  37289  1864.4  4.4729 2.560e-06 ***
## Reciprocals 28  19112   682.6  1.6375   0.05369 .  
## Residuals   63  26260                              
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
# anova(dMod)
gh &amp;lt;- glht(linfct = diallel.eff(dMod2))
# summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;estimation-of-variance-components-random-genetic-effects&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimation of variance components (random genetic effects)&lt;/h1&gt;
&lt;p&gt;If we intend to regard the genetic effects as random and to estimate variance components, we can use the &lt;code&gt;mmer()&lt;/code&gt; function in the ‘sommer’ package (Covarrubias-Pazaran, 2016), although we need to code a bunch of dummy variables. In order to make things simpler for routine experiments, we have coded the &lt;code&gt;mmer.diallel()&lt;/code&gt; wrapper using the same syntax as the &lt;code&gt;lm.diallel()&lt;/code&gt; function. The exemplary code is given in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Random genetic effects
mod1m &amp;lt;- mmer.diallel(Yield ~ Par1 + Par2,
                      data = lonnquist61,
                      fct = &amp;quot;GE2&amp;quot;)
mod1m$varcomp
##          VarComp VarCompSE
## Variety 2.344044  2.333869
## h.i     5.172099  4.905691
## SCA     6.142047  2.789668
mod2m &amp;lt;- mmer.diallel(Yield ~ Par1 + Par2,
                      data = lonnquist61,
                      fct = &amp;quot;GE3&amp;quot;)
mod2m$varcomp
##               VarComp VarCompSE
## GCAC        10.125567  7.563026
## Selfed par.  4.107823  7.830039
## SCA          7.087220  3.342822
mod3m &amp;lt;- mmer.diallel(Ftime ~ Par1 + Par2,
                      data = hayman54,
                      fct = &amp;quot;GE2r&amp;quot;)
mod3m$varcomp
##                VarComp  VarCompSE
## Variety     2347.35935 1279.94018
## h.i          634.70067  408.56286
## SCA          362.24772  148.53288
## Reciprocals   66.78085   49.16288
## Residuals    415.44775   73.43871
mod4m &amp;lt;- mmer.diallel(Ftime ~ Par1 + Par2,
                      data = hayman54,
                      fct = &amp;quot;GE3r&amp;quot;)
mod4m$varcomp
##                 VarComp  VarCompSE
## GCAC          927.78740  537.89968
## Selfed par. 10003.93261 5456.47108
## SCA           362.96912  148.50097
## Reciprocals    67.50895   49.11942
## Residuals     412.54141   72.93144&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Luigi Russi&lt;br /&gt;
Niccolò Terzaroli&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
&lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Covarrubias-Pazaran, G., 2016. Genome-Assisted Prediction of Quantitative Traits Using the R Package sommer. PLOS ONE 11, e0156744. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0156744&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pone.0156744&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Gardner, C.O., Eberhart, S.A., 1966. Analysis and Interpretation of the Variety Cross Diallel and Related Populations. Biometrics 22, 439. &lt;a href=&#34;https://doi.org/10.2307/2528181&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2307/2528181&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Griffing, B., 1956. Concept of general and specific combining ability in relation to diallel crossing systems. Australian Journal of Biological Science 9, 463–493.&lt;/li&gt;
&lt;li&gt;Hayman, B.I., 1954. The Analysis of Variance of Diallel Tables. Biometrics 10, 235. &lt;a href=&#34;https://doi.org/10.2307/3001877&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2307/3001877&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Möhring, J., Melchinger, A.E., Piepho, H.P., 2011b. REML-Based Diallel Analysis. Crop Science 51, 470–478. &lt;a href=&#34;https://doi.org/10.2135/cropsci2010.05.0272&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2135/cropsci2010.05.0272&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>lmDiallel: a new R package to fit diallel models. The Griffing&#39;s models (1956)</title>
      <link>https://www.statforbiology.com/2021/stat_met_diallel_griffing/</link>
      <pubDate>Tue, 12 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2021/stat_met_diallel_griffing/</guid>
      <description>
&lt;script src=&#34;https://www.statforbiology.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;Diallel mating designs are often used by plant breeders to compare the possible crosses between a set of genotypes. In spite of such widespread usage, the process of data analysis in R is not yet strightforward and it is not clear which tool should be routinely used. We recently gave a small contribution by publishing a paper in Plant Breeding (&lt;a href=&#34;https://link.springer.com/article/10.1007/s00122-020-03716-8&#34;&gt;Onofri et al., 2020&lt;/a&gt; ), where we advocated the idea that models for diallel crosses are just a class of general linear models, that should be fit by Ordinary Least Squares (OLS) or REstricted Maximum Likelihood methods (REML).&lt;/p&gt;
&lt;p&gt;In that paper, we presented &lt;code&gt;lmDiallel&lt;/code&gt;, a new R package to fit diallel models, which we followed up with a series of three blog posts, giving more detail about the package (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel1/&#34;&gt;see here&lt;/a&gt;), about the Hayman’s models type 1 (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel_hayman1/&#34;&gt;see here&lt;/a&gt;) and type 2 (&lt;a href=&#34;https://www.statforbiology.com/2021/stat_met_diallel_hayman2/&#34;&gt;see here&lt;/a&gt;). These latter models can be used to describe the data from full diallel experiments.&lt;/p&gt;
&lt;p&gt;In this fourth post we are going to talk about a very flexible family of models, that was introduced by Griffing in 1956 and it is still very used in plant breeding, to estimate General Combining Ability (GCA) and Specific Combining Ability (SCAs). The equations take different forms, to account for all possible mating schemes.&lt;/p&gt;
&lt;p&gt;With full diallel experiments (including selfs and reciprocals; &lt;strong&gt;mating scheme 1&lt;/strong&gt;), the model is very similar to Hayman’s model type 1, except that reciprocal effects are not parted into RGCA and RSCA (Reciprocal General Combining Ability and Reciprocal Specific Combining Ability). The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y _{ijk} = \mu + \textrm{g}_i + \textrm{g}_j + \textrm{ts}_{ij} + r_{ij} + \varepsilon_{ijk} \quad\quad\quad (1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the expected value (the overall mean, in the balanced case) and &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon_{ijk}\)&lt;/span&gt; is the residual random error term for the observation in the &lt;span class=&#34;math inline&#34;&gt;\(k^{th}\)&lt;/span&gt; block and with the parentals &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;. All the other terms correspond to genetic effects, namely:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;the &lt;span class=&#34;math inline&#34;&gt;\(\textrm{g}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\textrm{g}_j\)&lt;/span&gt; terms are the General Combining Abilities (GCAs) of the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j^{th}\)&lt;/span&gt; parents.&lt;/li&gt;
&lt;li&gt;The &lt;span class=&#34;math inline&#34;&gt;\(ts_{ij}\)&lt;/span&gt; term is the total Specific Combining Ability (SCA) for the combination &lt;span class=&#34;math inline&#34;&gt;\(ij\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;span class=&#34;math inline&#34;&gt;\(r_{ij}\)&lt;/span&gt; term is the reciprocal effect for a specific &lt;span class=&#34;math inline&#34;&gt;\(ij\)&lt;/span&gt; combination.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When the reciprocal crosses are not available (&lt;strong&gt;mating scheme 2&lt;/strong&gt;), the term &lt;span class=&#34;math inline&#34;&gt;\(\textrm{r}_{ij}\)&lt;/span&gt; needs to be dropped, so that the model reduces to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y _{ijk} = \mu + \textrm{g}_i + \textrm{g}_j + \textrm{ts}_{ij} + \varepsilon_{ijk} \quad\quad\quad (2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When the reciprocals are available, but selfs are missing (&lt;strong&gt;mating scheme 3&lt;/strong&gt;), the model is similar to equation 1, but the term &lt;span class=&#34;math inline&#34;&gt;\(\textrm{ts}_{ij}\)&lt;/span&gt; is replaced by &lt;span class=&#34;math inline&#34;&gt;\(\textrm{s}_{ij}\)&lt;/span&gt; (we use a different symbol, because the design matrix is slightly different and needs a different coding):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y _{ijk} = \mu + \textrm{g}_i + \textrm{g}_j + \textrm{s}_{ij} + r_{ij} + \varepsilon_{ijk} \quad\quad\quad (3)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Finally, when neither selfs nor reciprocals are available (&lt;strong&gt;mating scheme 4&lt;/strong&gt;), the equation reduces to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y _{ijk} = \mu + \textrm{g}_i + \textrm{g}_j + \textrm{s}_{ij} + \varepsilon_{ijk} \quad\quad\quad (4)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let’s see how to fit the above models by using a set of examples with different mating schemes.&lt;/p&gt;
&lt;div id=&#34;example-1-a-full-diallel-experiment&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 1: a full diallel experiment&lt;/h1&gt;
&lt;p&gt;The example in Hayman (1954) relates to a complete diallel experiment with eight parental lines, producing 64 combinations (8 selfs + 28 crosses with 2 reciprocals each). The R dataset is included in the ‘lmDiallel’ package; in the box below we load the data, after installing (if necessary) and loading the ‘lmDiallel’ package (see box below). For brevity, some R commands are shown but not executed (they are commented out)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools) # Install if necessary
# install_github(&amp;quot;OnofriAndreaPG/lmDiallel&amp;quot;)
library(lmDiallel)
data(&amp;quot;hayman54&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this complete diallel experiment we can fit equation 1, by including GCAs, tSCAs and reciprocal effects. Please, note that excluding any of these effects results in unreliable estimates of the residual mean square. We can use either the &lt;code&gt;lm()&lt;/code&gt; or the &lt;code&gt;lm.diallel()&lt;/code&gt; functions, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;contrasts(hayman54$Block) &amp;lt;- &amp;quot;contr.sum&amp;quot;
dMod &amp;lt;- lm(Ftime ~ Block + GCA(Par1, Par2) + tSCA(Par1, Par2) +
             REC(Par1, Par2), data = hayman54)
dMod2 &amp;lt;- lm.diallel(Ftime ~ Par1 + Par2, Block = Block,
                    data = hayman54, fct = &amp;quot;GRIFFING1&amp;quot;)
# summary(dMod2)
anova(dMod2)
## Analysis of Variance Table
## 
## Response: Ftime
##             Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Block        1    142     142  0.3416   0.56100    
## GCA          7 277717   39674 95.1805 &amp;lt; 2.2e-16 ***
## tSCA        28 102238    3651  8.7599 6.656e-13 ***
## Reciprocals 28  19112     683  1.6375   0.05369 .  
## Residuals   63  26260                              
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to obtain the full list of genetical parameters, we can use the &lt;code&gt;glht()&lt;/code&gt; function in the &lt;code&gt;multcomp&lt;/code&gt; package, together with the &lt;code&gt;diallel.eff()&lt;/code&gt; function in the ‘lmDiallel’ package. An excerpt of the results is shown below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(multcomp)
gh &amp;lt;- glht(linfct = diallel.eff(dMod2))
# summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))
#    Simultaneous Tests for General Linear Hypotheses
# 
# Linear Hypotheses:
#                  Estimate Std. Error t value Pr(&amp;gt;|t|)    
# Intercept == 0  1.629e+02  1.805e+00  90.270  &amp;lt; 2e-16 ***
# g_A == 0        4.620e+01  3.376e+00  13.683 2.17e-13 ***
# g_B == 0       -2.459e+01  3.376e+00  -7.282 9.83e-08 ***
# g_C == 0        4.963e+01  3.376e+00  14.702 4.13e-14 ***
# g_D == 0        1.835e+01  3.376e+00   5.436 1.07e-05 ***
# g_E == 0       -2.093e+01  3.376e+00  -6.199 1.47e-06 ***
# g_F == 0        2.445e+00  3.376e+00   0.724 0.475340    
# g_G == 0       -4.471e+01  3.376e+00 -13.244 4.57e-13 ***
# g_H == 0       -2.640e+01  3.376e+00  -7.819 2.71e-08 ***
# ts_A:A == 0     3.371e+01  1.263e+01   2.669 0.012941 *  
# ts_A:B == 0    -3.151e+01  9.023e+00  -3.492 0.001731 ** 
# ...
# ...&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2-no-reciprocals&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 2: no reciprocals&lt;/h1&gt;
&lt;p&gt;As an example of a diallel experiments with no reciprocals, we consider the data reported in Lonnquist and Gardner (1961) relating to the yield of 21 maize genotypes, obtained from six male and six female parentals. The dataset is available as &lt;code&gt;lonnquist61&lt;/code&gt; in the &lt;code&gt;lmDiallel&lt;/code&gt; package and the model fitting process is very similar to that shown before for the mating scheme 1, apart from the fact that we fit equation 2 instead of equation 1. In the ‘lm()’ call, we use the &lt;code&gt;GCA()&lt;/code&gt; and &lt;code&gt;tSCA()&lt;/code&gt; functions, while in the &lt;code&gt;lm.diallel()&lt;/code&gt; call, we set the argument ‘fct’ to “GRIFFING2”.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
data(lonnquist61)
dMod &amp;lt;- lm(Yield ~ GCA(Par1, Par2) + tSCA(Par1, Par2), 
           data = lonnquist61)
dMod2 &amp;lt;- lm.diallel(Yield ~ Par1 + Par2,
                    data = lonnquist61, fct = &amp;quot;GRIFFING2&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case the dataset has no replicates and, for the inferences, we need to provide an estimate of the residual mean square and degrees of freedom (see box below). If we have fitted the model by using the &lt;code&gt;lm()&lt;/code&gt; function, the resulting ‘lm’ object can be explored by using the &lt;code&gt;summary.diallel()&lt;/code&gt; and &lt;code&gt;anova.diallel()&lt;/code&gt; functions. Otherwise, if we have fitted the model with the &lt;code&gt;lm.diallel()&lt;/code&gt; function, the resulting ‘diallel’ object can be explored by using the &lt;code&gt;summary()&lt;/code&gt; and &lt;code&gt;anova()&lt;/code&gt; methods. See the box below for an example: the results are, obviously, the same.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# summary.diallel(dMod, MSE = 7.1, dfr = 60)
anova.diallel(dMod, MSE = 7.1, dfr = 60)
## Analysis of Variance Table
## 
## Response: Yield
##                  Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## GCA(Par1, Par2)   5 234.23  46.846  6.5980 5.923e-05 ***
## tSCA(Par1, Par2) 15 238.94  15.929  2.2436   0.01411 *  
## Residuals        60          7.100                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
# summary(dMod2, MSE = 7.1, dfr = 60)
anova(dMod2, MSE = 7.1, dfr = 60)
## Analysis of Variance Table
## 
## Response: Yield
##           Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## GCA        5 234.23  46.846  6.5980 5.923e-05 ***
## tSCA      15 238.94  15.929  2.2436   0.01411 *  
## Residuals 60          7.100                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also for the diallel object, we can retrieve the full list of genetical parameters with the &lt;code&gt;glht()&lt;/code&gt; function, by using the same syntax as shown above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gh &amp;lt;- glht(linfct = diallel.eff(dMod2, MSE = 7.1, dfr = 60))
# summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-3-no-selfs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 3: no selfs&lt;/h1&gt;
&lt;p&gt;When the experimental design includes the reciprocal crosses but not the selfs, we can fit Equation 3. As an example, we take the same dataset as before (‘hayman54’), but we remove the selfs by using ‘dplyr’. The fitting process is the same as shown above and only the model specification is changed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
data(hayman54)
hayman54b &amp;lt;- hayman54  %&amp;gt;% 
  filter(Par1 != Par2)

dMod &amp;lt;- lm(Ftime ~ Block + GCA(Par1, Par2) + 
             SCA.G3(Par1, Par2) + REC.G3(Par1, Par2), 
           data = hayman54b)
dMod2 &amp;lt;- lm.diallel(Ftime ~ Par1 + Par2, Block = Block,
                    data = hayman54b, fct = &amp;quot;GRIFFING3&amp;quot;)
anova(dMod2)
## Analysis of Variance Table
## 
## Response: Ftime
##             Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Block        1    329   329.1  0.8367   0.36432    
## GCA          7 168923 24131.9 61.3479 &amp;lt; 2.2e-16 ***
## tSCA        20  37289  1864.4  4.7398 2.318e-06 ***
## Reciprocals 28  19112   682.6  1.7352   0.04052 *  
## Residuals   55  21635                              
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
gh &amp;lt;- glht(linfct = diallel.eff(dMod2))
# summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-4-no-reciprocals-no-selfs&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Example 4: no reciprocals, no selfs&lt;/h1&gt;
&lt;p&gt;In this final example, we consider a mating scheme where neither the reciprocal crosses nor the selfs are included (mating scheme 4). The dataset is taken from the original Griffing’s paper (Griffing, 1956) and it is available as ‘Griffing56’ in the ‘lmDiallel’ package. The analysis proceeds in the very same fashion as above, apart from the fact that we fit Equation 4, instead of 3 and that we input the appropriate residual error term to obtain the correct inferences, as the original dataset does not contain the replicated data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;griffing56&amp;quot;)

dMod &amp;lt;- lm(Yield ~ GCA(Par1, Par2) + SCA.G3(Par1, Par2), 
           data = griffing56)
anova.diallel(dMod, MSE = 21.05, dfr = 2558)
## Analysis of Variance Table
## 
## Response: Yield
##                      Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## GCA(Par1, Par2)       8 18606.0 2325.75 110.487 &amp;lt; 2.2e-16 ***
## SCA.G3(Par1, Par2)   27  9164.9  339.44  16.125 &amp;lt; 2.2e-16 ***
## Residuals          2558           21.05                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
dMod2 &amp;lt;- lm.diallel(Yield ~ Par1 + Par2,
                    data = griffing56, fct = &amp;quot;GRIFFING4&amp;quot;)
anova(dMod2, MSE = 21.05, dfr = 2558)
## Analysis of Variance Table
## 
## Response: Yield
##             Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## GCA          8 18606.0 2325.75 110.487 &amp;lt; 2.2e-16 ***
## tSCA        27  9164.9  339.44  16.125 &amp;lt; 2.2e-16 ***
## Residuals 2558           21.05                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
# summary(dMod2, MSE = 21.05, dfr = 2558)

gh &amp;lt;- glht(linfct = diallel.eff(dMod2, MSE = 21.05, dfr = 2558))
# summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;estimation-of-variance-components-random-genetic-effects&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimation of variance components (random genetic effects)&lt;/h1&gt;
&lt;p&gt;If we intend to regard the genetic effects as random and to estimate variance components, we can use the &lt;code&gt;mmer()&lt;/code&gt; function in the ‘sommer’ package (Covarrubias-Pazaran, 2016), although we need to code a bunch of dummy variables. In order to make things simpler for routine experiments, we have coded the &lt;code&gt;mmer.diallel()&lt;/code&gt; wrapper using the same syntax as the &lt;code&gt;lm.diallel()&lt;/code&gt; function. The exemplary code is given in the box below, relating to Equation 2, although the other equations can be fitted in a similar manner.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Random genetic effects
mod1m &amp;lt;- mmer.diallel(Yield ~ Par1 + Par2,
                      data = lonnquist61,
                      fct = &amp;quot;GRIFFING2&amp;quot;)
mod1m$varcomp
##        VarComp VarCompSE
## GCA   3.863695  3.769373
## tSCA 15.930144  5.819217&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next post we will consider another important family of models, devised by Gardner and Eberarth in 1966, which accounts for heterotic effects. Please, stay tuned!&lt;/p&gt;
&lt;p&gt;Thanks for reading&lt;/p&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Dr. Niccolò Terzaroli&lt;br /&gt;
Prof. Gino Russi&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
&lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Covarrubias-Pazaran, G., 2016. Genome-Assisted Prediction of Quantitative Traits Using the R Package sommer. PLOS ONE 11, e0156744.&lt;/li&gt;
&lt;li&gt;Griffing, B., 1956. Concept of general and specific combining ability in relation to diallel crossing systems. Australian Journal of Biological Science 9, 463–493.&lt;/li&gt;
&lt;li&gt;Möhring, J., Melchinger, A.E., Piepho, H.P., 2011b. REML-Based Diallel Analysis. Crop Science 51, 470–478. &lt;a href=&#34;https://doi.org/10.2135/cropsci2010.05.0272&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2135/cropsci2010.05.0272&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Onofri, A., Terzaroli, N., Russi, L., 2020. Linear models for diallel crosses: a review with R functions. Theor Appl Genet. &lt;a href=&#34;https://doi.org/10.1007/s00122-020-03716-8&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1007/s00122-020-03716-8&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>lmDiallel: a new R package to fit diallel models. The Hayman&#39;s model (type 2)</title>
      <link>https://www.statforbiology.com/2021/stat_met_diallel_hayman2/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2021/stat_met_diallel_hayman2/</guid>
      <description>
&lt;script src=&#34;https://www.statforbiology.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;This posts follows two other previously published posts, where we presented our new ‘lmDiallel’ package (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel1/&#34;&gt;see here&lt;/a&gt;) and showed how we can use it to fit the Hayman’s model type 1, as proposed in Hayman (1954) (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel_hayman1/&#34;&gt;see here&lt;/a&gt;). In this post, we will give a further example relating to another very widespread model from the same author, the Hayman’s model type 2. We apologise for some overlapping with previous posts: we think this is necessary so that each post can be read on its own.&lt;/p&gt;
&lt;p&gt;The model we are going to talk about is used to describe the results of full (complete) diallel experiments, where we have crosses + reciprocals + selfs. If you are not sure what a diallel experiment is, we suggest you go back to one of our previous posts on this sequence, where we give some preliminary information for beginners. Otherwise, we can proceed to the motivating example.&lt;/p&gt;
&lt;div id=&#34;the-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The example&lt;/h1&gt;
&lt;p&gt;In this post we will use the same example as provided in the original Hayman’s paper (Hayman, 1954), relating to a complete diallel experiment with eight parental lines. The R dataset is included in the ‘lmDiallel’ package; in the box below we load the data, after installing (if necessary) and loading the ‘lmDiallel’ package (see the box below).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools) # Install if necessary
# install_github(&amp;quot;OnofriAndreaPG/lmDiallel&amp;quot;)
library(lmDiallel)
data(&amp;quot;hayman54&amp;quot;)
head(hayman54)
##   Block Par1 Par2 Ftime
## 1     1    A    A   276
## 2     1    A    B   156
## 3     1    A    C   322
## 4     1    A    D   250
## 5     1    A    E   162
## 6     1    A    F   193&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-haymans-model-type-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Hayman’s model type 2&lt;/h1&gt;
&lt;p&gt;The Hayman’s model type 2 is derived from type 1 (see our previous post), by partitioning the tSCA effect in three additive components. The equation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ijk} = \left\{ {\begin{array}{ll}
\mu + \gamma_k + \textrm{g}_i + \textrm{g}_j + m + d_i + d_j + s_{ij} + rg^a_i + rg^b_j + rs_{ij} + \varepsilon_{ijk} &amp;amp; \textrm{for} \quad i \neq j\\
\mu + \gamma_k + 2\, \textrm{g}_i - (n - 1)m - (n - 2)d_i + \varepsilon_{ijk} &amp;amp; \textrm{for} \quad i = j \end{array}} \right.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the expected value (the overall mean, in the case of fully orthogonal designs), &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of parentals and &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon_{ijk}\)&lt;/span&gt; is the residual random error term. All the other terms correspond to genetic effects, namely:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;the &lt;span class=&#34;math inline&#34;&gt;\(\textrm{g}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\textrm{g}_j\)&lt;/span&gt; terms are the &lt;strong&gt;general combining abilities&lt;/strong&gt; (GCAs) of the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j^{th}\)&lt;/span&gt; parents (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel_hayman1/&#34;&gt;see here&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;The &lt;span class=&#34;math inline&#34;&gt;\(rg^a_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(rg^b_j\)&lt;/span&gt; terms are the &lt;strong&gt;reciprocal general combining abilities&lt;/strong&gt; (RGCAs) for the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j^{th}\)&lt;/span&gt; parents (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel_hayman1/&#34;&gt;see here&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;The &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; term relates to the difference between the average value of all observations and the average values of crosses (&lt;strong&gt;Mean Dominance Deviation&lt;/strong&gt;; MDD).&lt;/li&gt;
&lt;li&gt;The &lt;span class=&#34;math inline&#34;&gt;\(d_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(d_j\)&lt;/span&gt; terms relate to the differences between the yield of each selfed parent (&lt;span class=&#34;math inline&#34;&gt;\(Y_{ij}\)&lt;/span&gt;, with &lt;span class=&#34;math inline&#34;&gt;\(i = j\)&lt;/span&gt;) and the average yield of all selfed parents (&lt;strong&gt;dominance deviation&lt;/strong&gt; for the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; parent; DD).&lt;/li&gt;
&lt;li&gt;The term &lt;span class=&#34;math inline&#34;&gt;\(s_{ij}\)&lt;/span&gt; is the SCA effect for the combination &lt;span class=&#34;math inline&#34;&gt;\(ij\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;span class=&#34;math inline&#34;&gt;\(rs_{ij}\)&lt;/span&gt; term is the &lt;strong&gt;reciprocal specific combining ability&lt;/strong&gt; (RSCA) for a specific &lt;span class=&#34;math inline&#34;&gt;\(ij\)&lt;/span&gt; combination, that is the discrepancy between the performances of the two reciprocals (e.g, A &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; B vs. B &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; A)(&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel_hayman1/&#34;&gt;see here&lt;/a&gt;).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Similarly to type 1, the Hayman’s model type 2 considers the genetical effects as differences with respect to the intercept &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, that is the mean of all observations (when the design is orthogonal). However, with respect to type 1, this latter model permits the estimation of a higher number of genetic effects (GCAs, RGCAs, MDD, DDs, SCAs and RSCAs) and provides an approach to quantify heterotic effects. We should consider that, due to unbalance (the number of crosses is never equal to the number of selfs), it is necessary to introduce some coefficients (i.e. &lt;span class=&#34;math inline&#34;&gt;\(n - 1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(n - 2\)&lt;/span&gt; in Equation 1), which do not have an obvious meaning. In future posts we will see that other diallel models were proposed, which account for heterotic effects in a different manner (Gardner and Eberhart, 1966).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-with-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting with R&lt;/h1&gt;
&lt;p&gt;Let’s assume that all effects are fixed, apart from the residual error effect. Consequently, Equation 1 is a specific parameterisation of a general linear model, which we can fit by the usual &lt;code&gt;lm()&lt;/code&gt; function and related methods. However, we need to exploit some of the facilities in our new ‘lmDiallel’ extension package, which consist of the &lt;code&gt;GCA()&lt;/code&gt;, &lt;code&gt;MDD()&lt;/code&gt;, &lt;code&gt;DD()&lt;/code&gt;, &lt;code&gt;SCA()&lt;/code&gt;, &lt;code&gt;RGCA()&lt;/code&gt; and &lt;code&gt;RSCA()&lt;/code&gt; functions (see the box below). The resulting &lt;code&gt;lm&lt;/code&gt; object can be explored by the usual R methods, such as &lt;code&gt;summary()&lt;/code&gt; and &lt;code&gt;anova()&lt;/code&gt; (the output of the &lt;code&gt;summary()&lt;/code&gt; method is partly hidden, for brevity)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;contrasts(hayman54$Block) &amp;lt;- &amp;quot;contr.sum&amp;quot;
dMod &amp;lt;- lm(Ftime ~ Block + GCA(Par1, Par2) + MDD(Par1, Par2) +
             DD(Par1, Par2) + SCA(Par1, Par2) +
             RGCA(Par1, Par2) + RSCA(Par1, Par2), data = hayman54)
summary(dMod)$coef[1:6,]
##                      Estimate Std. Error    t value     Pr(&amp;gt;|t|)
## (Intercept)        162.898437   1.804567 90.2700843 2.381071e-68
## Block1              -1.054688   1.804567 -0.5844545 5.610017e-01
## GCA(Par1, Par2)g_A  46.195312   3.376036 13.6832990 1.558468e-20
## GCA(Par1, Par2)g_B -24.585938   3.376036 -7.2824864 6.421946e-10
## GCA(Par1, Par2)g_C  49.632812   3.376036 14.7015049 4.900927e-22
## GCA(Par1, Par2)g_D  18.351563   3.376036  5.4358311 9.415231e-07
# ...
# ...
anova(dMod)
## Analysis of Variance Table
## 
## Response: Ftime
##                  Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Block             1    142     142  0.3416   0.56100    
## GCA(Par1, Par2)   7 277717   39674 95.1805 &amp;lt; 2.2e-16 ***
## MDD(Par1, Par2)   1  30797   30797 73.8840 3.259e-12 ***
## DD(Par1, Par2)    7  34153    4879 11.7050 1.957e-09 ***
## SCA(Par1, Par2)  20  37289    1864  4.4729 2.560e-06 ***
## RGCA(Par1, Par2)  7   6739     963  2.3097   0.03671 *  
## RSCA(Par1, Par2) 21  12373     589  1.4135   0.14668    
## Residuals        63  26260     417                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the sake of simplicity, we also built a wrapper function named &lt;code&gt;lm.diallel()&lt;/code&gt;, which can be used in the very same fashion as &lt;code&gt;lm()&lt;/code&gt;. The syntax is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lm.diallel(formula, Block, Env, data, fct)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where ‘formula’ specifies the response variable and the two variables for parentals (e.g., Yield ~ Par1 + Par2) and the two arguments ‘Block’ and ‘Env’ are used to specify optional variables, coding for blocks and environments, respectively. The argument ‘data’ is a ‘dataframe’ where to look for the explanatory variables and, finally, ‘fct’ is a string variable coding for the selected model (“HAYMAN2”, for this example; see below).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dMod2 &amp;lt;- lm.diallel(Ftime ~ Par1 + Par2, Block = Block,
                    data = hayman54, fct = &amp;quot;HAYMAN2&amp;quot;)
# summary(dMod2)
anova(dMod2)
## Analysis of Variance Table
## 
## Response: Ftime
##           Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Block      1    142     142  0.3416   0.56100    
## MDD        1  30797   30797 73.8840 3.259e-12 ***
## GCA        7 277717   39674 95.1805 &amp;lt; 2.2e-16 ***
## DD         7  34153    4879 11.7050 1.957e-09 ***
## SCA       20  37289    1864  4.4729 2.560e-06 ***
## RGCA       7   6739     963  2.3097   0.03671 *  
## RSCA      21  12373     589  1.4135   0.14668    
## Residuals 63  26260                              
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above function works very much like the &lt;code&gt;lm()&lt;/code&gt; function and makes use of the general purpose linear model solver &lt;code&gt;lm.fit()&lt;/code&gt;. Apart from simplicity, another advantage is that the call to &lt;code&gt;lm.diallel()&lt;/code&gt; returns an object of both ‘lm’ and ‘diallel’ classes. For this latter class, we built several specific S3 methods, such as the usual &lt;code&gt;anova()&lt;/code&gt;, &lt;code&gt;summary()&lt;/code&gt; and &lt;code&gt;model.matrix()&lt;/code&gt; methods, partly shown in the box above.&lt;/p&gt;
&lt;p&gt;Considering that diallel models are usually fitted to determine genetical parameters, we also built the &lt;code&gt;glht.diallelMod()&lt;/code&gt; method and the &lt;code&gt;diallel.eff()&lt;/code&gt; function, which can be used with the ‘multcomp’ package, to retrieve the complete list of genetical parameters. An excerpt is shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(multcomp)
gh &amp;lt;- glht(linfct = diallel.eff(dMod2))
# summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;))
#    Simultaneous Tests for General Linear Hypotheses
# 
# Linear Hypotheses:
#                Estimate Std. Error t value Pr(&amp;gt;|t|)    
# Intercept == 0 162.8984     1.8046  90.270  &amp;lt; 2e-16 ***
# m == 0          -5.8627     0.6821  -8.596 4.48e-09 ***
# g_A == 0        46.1953     3.3760  13.683 2.17e-13 ***
# g_B == 0       -24.5859     3.3760  -7.282 9.83e-08 ***
# g_C == 0        49.6328     3.3760  14.702 4.13e-14 ***
# g_D == 0        18.3516     3.3760   5.436 1.07e-05 ***
# g_E == 0       -20.9297     3.3760  -6.199 1.47e-06 ***
# g_F == 0         2.4453     3.3760   0.724 0.475340    
# g_G == 0       -44.7109     3.3760 -13.244 4.57e-13 ***
# g_H == 0       -26.3984     3.3760  -7.819 2.71e-08 ***
# d_A == 0         1.2213     1.9492   0.627 0.536380    
# d_B == 0        -2.6224     1.9492  -1.345 0.190113    
# ...
# ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a previous post (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel_hayman1/&#34;&gt;see here&lt;/a&gt;) we have shown that, when diallel models are fitted to the genotype means (and thus we have no replicates), an appropriate estimate of residual mean square and degrees of freedom can be passed as arguments to the &lt;code&gt;summary()&lt;/code&gt;, &lt;code&gt;anova()&lt;/code&gt; and &lt;code&gt;diallel.eff()&lt;/code&gt; methods.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;estimation-of-variance-components-random-genetic-effects&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimation of variance components (random genetic effects)&lt;/h1&gt;
&lt;p&gt;If we intend to regard the genetic effects as random and to estimate variance components, we can use the &lt;code&gt;mmer()&lt;/code&gt; function in the ‘sommer’ package (Covarrubias-Pazaran, 2016), although we need to code a bunch of dummy variables. In order to make things simpler for routine experiments, we have coded the &lt;code&gt;mmer.diallel()&lt;/code&gt; wrapper using the same syntax as the &lt;code&gt;lm.diallel()&lt;/code&gt; function. The exemplary code is given in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Random genetic effects
mod1m &amp;lt;- mmer.diallel(Ftime ~ Par1 + Par2, Block = Block, 
                      data = hayman54,
                      fct = &amp;quot;HAYMAN2&amp;quot;)
mod1m$varcomp
##              VarComp   VarCompSE
## Block        0.00000    9.188298
## MDD       1783.96081 3118.893561
## GCA       1005.92052  574.893353
## RGCA        17.97898   19.920016
## DD         659.53567  468.205470
## SCA        351.74035  144.688653
## RSCA        32.02325   46.361581
## Residuals  412.54051   73.506382&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s all about the Hayman’s models; you may have noted that both models (type 1 and 2) were devised for full diallel experiments, which are not so widespread in ‘genetical’ literature. A few years later, in 1956, the Australian scientist B. Griffing made the relevant effort of creating a comprehensive set of models which can be fitted to all types of diallel experiments. We will talk about these models in a future post.&lt;/p&gt;
&lt;p&gt;Thanks for reading (and happy 2021!)&lt;/p&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Prof. Luigi Russi&lt;br /&gt;
Dr. Niccolò Terzaroli&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Send comments to: &lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Covarrubias-Pazaran, G., 2016. Genome-Assisted Prediction of Quantitative Traits Using the R Package sommer. PLOS ONE 11, e0156744. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0156744&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pone.0156744&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hayman, B.I., 1954. The Analysis of Variance of Diallel Tables. Biometrics 10, 235. &lt;a href=&#34;https://doi.org/10.2307/3001877&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2307/3001877&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Möhring, J., Melchinger, A.E., Piepho, H.P., 2011b. REML-Based Diallel Analysis. Crop Science 51, 470–478. &lt;a href=&#34;https://doi.org/10.2135/cropsci2010.05.0272&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2135/cropsci2010.05.0272&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Onofri, A., Terzaroli, N., Russi, L., 2020. Linear models for diallel crosses: a review with R functions. Theor Appl Genet. &lt;a href=&#34;https://doi.org/10.1007/s00122-020-03716-8&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1007/s00122-020-03716-8&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>lmDiallel: a new R package to fit diallel models. The Hayman&#39;s model (type 1)</title>
      <link>https://www.statforbiology.com/2020/stat_met_diallel_hayman1/</link>
      <pubDate>Thu, 26 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2020/stat_met_diallel_hayman1/</guid>
      <description>
&lt;script src=&#34;https://www.statforbiology.com/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;In a previous post we have presented our new ‘lmDiallel’ package (&lt;a href=&#34;https://www.statforbiology.com/2020/stat_met_diallel1/&#34;&gt;see this link here&lt;/a&gt; and see also the original paper in &lt;a href=&#34;https://rdcu.be/caxZh&#34;&gt;Theoretical and Applied Genetics&lt;/a&gt;). This package provides an extensions to fit a class of linear models of interest for plant breeders or geneticists, the so-called diallel models. In this post and other future posts we would like to present some examples of how to use this package: please, sit back and relax and, if you have comments, let us know, using the email link at the bottom of this post.&lt;/p&gt;
&lt;div id=&#34;but-what-is-a-diallel&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;But… what is a ‘diallel’?&lt;/h1&gt;
&lt;p&gt;If you are not a plant breeder or a geneticist in general, you may be asking this question. From the ancient Greek language, the ‘diallel’ word means ‘reciprocating’ and a diallel cross is a set of several possible crosses and selfs between some parental lines. For example, if we take the male lines A, B and C together with the same female lines A, B and C and we imagine to cross those lines with one another, we obtain:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;the selfs A&lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt;A, B&lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt;B and C&lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt;C,&lt;/li&gt;
&lt;li&gt;the crosses A&lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt;B, A&lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt;C and B&lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt;C,&lt;/li&gt;
&lt;li&gt;and, in some instances, the reciprocals B&lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt;A, C&lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt;A and C&lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt;B (where the father and mother are swapped).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The performances of crosses and/or selfs and/or reciprocals can be compared by planning field experiments, usually known as &lt;strong&gt;diallel experiments&lt;/strong&gt; and designed as randomised complete blocks with 3-4 replicates.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-example&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The example&lt;/h1&gt;
&lt;p&gt;Depending on how the experiment is planned, we can have four experimental methods:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Crosses + reciprocals + selfs (complete diallel)&lt;/li&gt;
&lt;li&gt;Crosses and reciprocals (no selfs)&lt;/li&gt;
&lt;li&gt;Crosses and selfs (no reciprocals)&lt;/li&gt;
&lt;li&gt;Only crosses (no selfs, no reciprocals)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this post we will concentrate on the first design (complete diallel) and we will use a simple example with three parental lines (A, B and C). The csv file (‘diallel1.csv’) is available in an external repository; in the box below we load the data and we use the &lt;code&gt;group_by()&lt;/code&gt; function in the ‘dplyr’ package to obtain the means for all crosses and selfs.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
rm(list = ls())
df &amp;lt;- read_csv(&amp;quot;https://www.casaonofri.it/_datasets/diallel1.csv&amp;quot;)
df$Block &amp;lt;- factor(df$Block)
dfM &amp;lt;- df %&amp;gt;% 
  group_by(Par1, Par2) %&amp;gt;% 
  summarise(YieldM = mean(Yield), SEs = sd(Yield/sqrt(4)))
dfM
## # A tibble: 9 x 4
## # Groups:   Par1 [3]
##   Par1  Par2  YieldM   SEs
##   &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 A     A         12 0.740
## 2 A     B         13 0.600
## 3 A     C         14 0.498
## 4 B     A         11 1.00 
## 5 B     B         15 0.332
## 6 B     C         21 0.273
## 7 C     A         17 0.295
## 8 C     B         16 0.166
## 9 C     C         19 1.90&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-model-do-we-use&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What model do we use?&lt;/h1&gt;
&lt;p&gt;In order to describe the above dataset, we might think of a two-way ANOVA model, where the ‘father’ and ‘mother’ lines (the ‘Par1’ and ‘Par2’ variables, respectively) are used as the explanatory factors.&lt;/p&gt;
&lt;p&gt;This is a very tempting solution, but we should resist: a two way ANOVA model regards the ‘father’ and ‘mother’ effects as two completely different series of treatments, neglecting the fact that they are, indeed, the same genotypes in different combinations. That is exactly why we need specific &lt;strong&gt;diallel models&lt;/strong&gt; to describe the results of diallel experiments!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-haymans-model-type-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Hayman’s model type 1&lt;/h1&gt;
&lt;p&gt;The first diallel model was proposed by Hayman (1954) and it was devised for complete diallel experiments, where reciprocals are available. Neglecting the design effects (blocks and/or environments), the Hayman’s model is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y _{ijk} = \mu + \textrm{g}_i + \textrm{g}_j + \textrm{ts}_{ij} + \textrm{rg}^a_{i} + \textrm{rg}^b_{j} + rs_{ij} + \varepsilon_{ijk} \quad\quad\quad (Eq. 1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is expected value (the overall mean, in the balanced case) and &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon_{ijk}\)&lt;/span&gt; is the residual random error terms for the observation in the &lt;span class=&#34;math inline&#34;&gt;\(k^{th}\)&lt;/span&gt; block and with the parentals &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;. All the other terms correspond to genetic effects, namely:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;the &lt;span class=&#34;math inline&#34;&gt;\(\textrm{g}_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\textrm{g}_j\)&lt;/span&gt; terms are the &lt;strong&gt;general combining abilities&lt;/strong&gt; (GCAs) of the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j^{th}\)&lt;/span&gt; parents. Each term relates to the average performances of a parental line in all its hybrid combination, under the sum-to-zero constraint (i.e. the sum of &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; values for all parentals must be zero). For example, with our balanced experiment, the overall mean is &lt;span class=&#34;math inline&#34;&gt;\(\mu = 15.33\)&lt;/span&gt;, while the mean for the A parent when used as the ‘father’ is &lt;span class=&#34;math inline&#34;&gt;\(\mu_{A.} = 13\)&lt;/span&gt; and the mean for the same parent A when used as the ‘mother’ is &lt;span class=&#34;math inline&#34;&gt;\(\mu_{.A} = 13.33\)&lt;/span&gt;. Consequently:
&lt;span class=&#34;math display&#34;&gt;\[g_A = \left(13 + 13.33 \right)/2 - 15.33 = -2.167\]&lt;/span&gt; Analogously, it is &lt;span class=&#34;math inline&#34;&gt;\(g_B = -0.167\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;span class=&#34;math inline&#34;&gt;\(rg^a_i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(rg^b_j\)&lt;/span&gt; terms are the &lt;strong&gt;reciprocal general combining abilities&lt;/strong&gt; (RGCAs) for the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j^{th}\)&lt;/span&gt; parents. Each term relates to the discrepancy between the effect of a parent when it is used as father/mother and its average effect in all its combinations. For example, considering the parent A, the term &lt;span class=&#34;math inline&#34;&gt;\(rg^a_A\)&lt;/span&gt; is: &lt;span class=&#34;math display&#34;&gt;\[rg^a_A = \mu_{A.} - \frac{\mu_{A.} + \mu_{.A}}{2} = 13 - 13.167 = -0.167\]&lt;/span&gt; Obviously, it must be &lt;span class=&#34;math inline&#34;&gt;\(rg^a_A = - rg^b_B\)&lt;/span&gt; and it must also be that the sum of all &lt;span class=&#34;math inline&#34;&gt;\(rg^a\)&lt;/span&gt; terms is zero (sum-to-zero constraint).&lt;/li&gt;
&lt;li&gt;The &lt;span class=&#34;math inline&#34;&gt;\(\textrm{ts}_{ij}\)&lt;/span&gt; term is the total &lt;strong&gt;specific combining ability&lt;/strong&gt; (tSCA) for the combination between the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j^{th}\)&lt;/span&gt; parents. It relates to the discrepancy from additivity for a specific combination of two parentals. For example, considering the ‘A &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; B’ cross, the expected yield under additivity would be: &lt;span class=&#34;math display&#34;&gt;\[\mu_{A:B} = \mu + \textrm{g}_A + \textrm{g}_B +\textrm{rg}^a_{A} + \textrm{rg}^b_{B} =\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[ = 15.33 - 2.167 - 0.167 - 0.167 - 0.5 = 12.333\]&lt;/span&gt; while the observed yield is 13, with a with a difference of &lt;span class=&#34;math inline&#34;&gt;\(-0.667\)&lt;/span&gt;. On the other hand, considering the ‘B &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; A’ reciprocal cross, the expected yield under additivity would be: &lt;span class=&#34;math display&#34;&gt;\[\mu_{A:B} = \mu + \textrm{g}_A + \textrm{g}_B +\textrm{rg}^a_{B} + \textrm{rg}^b_{A} =\]&lt;/span&gt; &lt;span class=&#34;math display&#34;&gt;\[= 15.33 - 2.167 - 0.167 + 0.167 + 0.5 = 13.667\]&lt;/span&gt; while the observed yield is 11, with a difference of &lt;span class=&#34;math inline&#34;&gt;\(2.667\)&lt;/span&gt;. The tSCA for the cross between A and B (regardless of the reciprocal) is the average difference, that is &lt;span class=&#34;math inline&#34;&gt;\(\textrm{ts}_{AB} = (-0.667 + 2.667)/2 = 1\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;span class=&#34;math inline&#34;&gt;\(rs_{ij}\)&lt;/span&gt; term is the &lt;strong&gt;reciprocal specific combining ability&lt;/strong&gt; (RSCA) for a specific &lt;span class=&#34;math inline&#34;&gt;\(ij\)&lt;/span&gt; combination, that is the discrepancy between the performances of the two reciprocals (e.g, A &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; B vs. B &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; A). For example, the &lt;span class=&#34;math inline&#34;&gt;\(\textrm{rs}_{AB}\)&lt;/span&gt; term is equal to &lt;span class=&#34;math inline&#34;&gt;\(-0.667 - 1 = -1.667\)&lt;/span&gt;, that is the opposite of &lt;span class=&#34;math inline&#34;&gt;\(\textrm{rs}_{BA}\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-with-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting with R&lt;/h1&gt;
&lt;p&gt;Hands-calculations based on means may be useful to understand the meaning of genetical effects, although they are biased with unbalanced designs and, above all, they are totally uninteresting from a practical point of view: we’d rather fit the model by using a statistical software.&lt;/p&gt;
&lt;p&gt;Let’s assume that all effects are fixed, apart from the residual standard error. This is a reasonable assumption, as we have a very low number of parentals, which would make the estimation of variance components totally unreliable. We clearly see that the Hayman’s model above is a specific parameterisation of a general linear model and we should be able to fit it by the usual &lt;code&gt;lm()&lt;/code&gt; function and related methods. We can, indeed, do so by using our ‘lmDiallel’ extension package, that provides the facilities to generate the correct design matrices for the Hayman’s model (and for other diallel models, as we will show in future posts).&lt;/p&gt;
&lt;p&gt;At the beginning, we have to install (if necessary) and load the ‘lmDiallel’ package (see box below). Model fitting can be performed by using the &lt;code&gt;GCA()&lt;/code&gt;, &lt;code&gt;tSCA()&lt;/code&gt;, &lt;code&gt;RGCA()&lt;/code&gt; and &lt;code&gt;RSCA()&lt;/code&gt; functions as shown in the box below: the resulting &lt;code&gt;lm&lt;/code&gt; object can be explored by the usual R methods, such as &lt;code&gt;summary()&lt;/code&gt; and &lt;code&gt;anova()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# library(devtools) # Install if necessary
# install_github(&amp;quot;OnofriAndreaPG/lmDiallel&amp;quot;)
library(lmDiallel)
dMod &amp;lt;- lm(Yield ~ Block + GCA(Par1, Par2) + tSCA(Par1, Par2) +
              RGCA(Par1, Par2) + RSCA(Par1, Par2), data = df)
summary(dMod)
## 
## Call:
## lm(formula = Yield ~ Block + GCA(Par1, Par2) + tSCA(Par1, Par2) + 
##     RGCA(Par1, Par2) + RSCA(Par1, Par2), data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3500 -0.5644  0.0606  0.4722  2.7911 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&amp;gt;|t|)    
## (Intercept)             1.558e+01  5.780e-01  26.962  &amp;lt; 2e-16 ***
## Block2                 -3.772e-01  8.174e-01  -0.461 0.648613    
## Block3                 -3.011e-01  8.174e-01  -0.368 0.715830    
## Block4                 -3.261e-01  8.174e-01  -0.399 0.693458    
## GCA(Par1, Par2)g_A     -2.167e+00  2.890e-01  -7.497 9.77e-08 ***
## GCA(Par1, Par2)g_B     -1.667e-01  2.890e-01  -0.577 0.569516    
## tSCA(Par1, Par2)ts_A:A  1.000e+00  5.780e-01   1.730 0.096457 .  
## tSCA(Par1, Par2)ts_A:B -1.000e+00  4.570e-01  -2.188 0.038609 *  
## tSCA(Par1, Par2)ts_B:B  1.634e-16  5.780e-01   0.000 1.000000    
## RGCA(Par1, Par2)rg_A   -1.667e-01  2.890e-01  -0.577 0.569516    
## RGCA(Par1, Par2)rg_B    1.333e+00  3.389e-01   3.934 0.000622 ***
## RSCA(Par1, Par2)        2.500e+00  5.309e-01   4.709 8.71e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.734 on 24 degrees of freedom
## Multiple R-squared:  0.8269, Adjusted R-squared:  0.7476 
## F-statistic: 10.42 on 11 and 24 DF,  p-value: 1.129e-06
anova(dMod)
## Analysis of Variance Table
## 
## Response: Yield
##                  Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Block             3   0.784   0.261  0.0869    0.9665    
## GCA(Par1, Par2)   2 244.000 122.000 40.5743 1.999e-08 ***
## tSCA(Par1, Par2)  3  24.000   8.000  2.6606    0.0710 .  
## RGCA(Par1, Par2)  2   9.333   4.667  1.5520    0.2323    
## RSCA(Par1, Par2)  1  66.667  66.667 22.1717 8.710e-05 ***
## Residuals        24  72.164   3.007                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the sake of simplicity, we also built a wrapper function named &lt;code&gt;lm.diallel()&lt;/code&gt;, which can be used in the very same fashion as &lt;code&gt;lm()&lt;/code&gt;. The syntax is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lm.diallel(formula, Block, Env, data, fct)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where ‘formula’ specifies the response variable and the two variables for parentals (e.g., Yield ~ Par1 + Par2) and the two arguments ‘Block’ and ‘Env’ are used to specify optional variables, coding for blocks and environments, respectively. The argument ‘data’ is a ‘dataframe’ where to look for the explanatory variables and, finally, ‘fct’ is a string variable coding for the selected model (“HAYMAN1”, for this example; see below).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dMod2 &amp;lt;- lm.diallel(Yield ~ Par1 + Par2, Block = Block,
                    data = df, fct = &amp;quot;HAYMAN1&amp;quot;)
summary(dMod2)
## 
## Call:
## lm.diallel(formula = Yield ~ Par1 + Par2, Block = Block, fct = &amp;quot;HAYMAN1&amp;quot;, 
##     data = df)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.3500 -0.5644  0.0606  0.4722  2.7911 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&amp;gt;|t|)    
## Intercept  1.533e+01  2.890e-01  53.056  &amp;lt; 2e-16 ***
## Block1     2.511e-01  5.006e-01   0.502 0.620484    
## Block2    -1.261e-01  5.006e-01  -0.252 0.803236    
## Block3    -5.000e-02  5.006e-01  -0.100 0.921264    
## g_A       -2.167e+00  2.890e-01  -7.497 9.77e-08 ***
## g_B       -1.667e-01  2.890e-01  -0.577 0.569516    
## ts_A:A     1.000e+00  5.780e-01   1.730 0.096457 .  
## ts_A:B    -1.000e+00  4.570e-01  -2.188 0.038609 *  
## ts_B:B     7.155e-16  5.780e-01   0.000 1.000000    
## rg_A      -1.667e-01  2.890e-01  -0.577 0.569516    
## rg_B       1.333e+00  3.389e-01   3.934 0.000622 ***
## rs_A:B     2.500e+00  5.309e-01   4.709 8.71e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 1.734 on 24 degrees of freedom
## Multiple R-squared:  0.8269, Adjusted R-squared:  0.7476 
## F-statistic: 10.42 on 11 and 24 DF,  p-value: 1.129e-06
anova(dMod2)
## Analysis of Variance Table
## 
## Response: Yield
##           Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Block      3   0.784   0.261  0.0869    0.9665    
## GCA        2 244.000 122.000 40.5743 1.999e-08 ***
## tSCA       3  24.000   8.000  2.6606    0.0710 .  
## RGCA       2   9.333   4.667  1.5520    0.2323    
## RSCA       1  66.667  66.667 22.1717 8.710e-05 ***
## Residuals 24  72.164                              
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above function works very much like the &lt;code&gt;lm()&lt;/code&gt; function and makes use of the general purpose linear model solver &lt;code&gt;lm.fit()&lt;/code&gt;. Apart from simplicity, another advantage is that the call to &lt;code&gt;lm.diallel()&lt;/code&gt; returns an object of both ‘lm’ and ‘diallel’ classes. For this latter class, we built several specific S3 methods, such as the usual &lt;code&gt;anova()&lt;/code&gt;, &lt;code&gt;summary()&lt;/code&gt; and &lt;code&gt;model.matrix()&lt;/code&gt; methods, partly shown in the box above.&lt;/p&gt;
&lt;p&gt;Considering that diallel models are usually fitted to determine genetical parameters, we also built the &lt;code&gt;glht.diallelMod()&lt;/code&gt; method and the &lt;code&gt;diallel.eff()&lt;/code&gt; function, which can be used with the ‘multcomp’ package, to retrieve the complete list of genetical parameters, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(multcomp)
gh &amp;lt;- glht(linfct = diallel.eff(dMod2))
summary(gh, test = adjusted(type = &amp;quot;none&amp;quot;)) 
## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Linear Hypotheses:
##                  Estimate Std. Error t value Pr(&amp;gt;|t|)    
## Intercept == 0  1.533e+01  2.890e-01  53.056  &amp;lt; 2e-16 ***
## g_A == 0       -2.167e+00  2.890e-01  -7.497 5.85e-08 ***
## g_B == 0       -1.667e-01  2.890e-01  -0.577 0.569106    
## g_C == 0        2.333e+00  2.890e-01   8.074 1.49e-08 ***
## ts_A:A == 0     1.000e+00  5.780e-01   1.730 0.095471 .  
## ts_A:B == 0    -1.000e+00  4.570e-01  -2.188 0.037819 *  
## ts_A:C == 0     9.992e-16  4.570e-01   0.000 1.000000    
## ts_B:A == 0    -1.000e+00  4.570e-01  -2.188 0.037819 *  
## ts_B:B == 0     7.155e-16  5.780e-01   0.000 1.000000    
## ts_B:C == 0     1.000e+00  4.570e-01   2.188 0.037819 *  
## ts_C:A == 0     9.992e-16  4.570e-01   0.000 1.000000    
## ts_C:B == 0     1.000e+00  4.570e-01   2.188 0.037819 *  
## ts_C:C == 0    -1.000e+00  5.780e-01  -1.730 0.095471 .  
## rg_A == 0      -1.667e-01  2.890e-01  -0.577 0.569106    
## rg_B == 0       1.333e+00  3.389e-01   3.934 0.000555 ***
## rg_C == 0      -1.167e+00  3.389e-01  -3.443 0.001962 ** 
## rs_A:B == 0     2.500e+00  5.309e-01   4.709 7.25e-05 ***
## rs_A:C == 0    -2.500e+00  5.309e-01  -4.709 7.25e-05 ***
## rs_B:A == 0    -2.500e+00  5.309e-01  -4.709 7.25e-05 ***
## rs_C:A == 0     2.500e+00  5.309e-01   4.709 7.25e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## (Adjusted p values reported -- none method)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting-in-two-steps&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting in two steps&lt;/h1&gt;
&lt;p&gt;In some cases, the analysis is performed in two steps and a diallel model is fitted to the means of selfs and crosses, which are calculated in the first step. Under the assumption of variance homogeneity and equal number of replicates, we can fit the Hayman’s model by using the &lt;code&gt;lm.diallel()&lt;/code&gt; function without the ‘Block’ argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dMod3 &amp;lt;- lm.diallel(YieldM ~ Par1 + Par2, 
                    data = dfM, fct = &amp;quot;HAYMAN1&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, we have no reliable estimate of residual error, but the &lt;code&gt;summary()&lt;/code&gt; and &lt;code&gt;anova()&lt;/code&gt; methods have been enhanced to give us the possibility of passing some information from the first step, i.e. an appropriate estimate of the residual mean square and degrees of freedom; the residual mean square from the first step needs to be appropriately weighted for the number of replicates (i.e., for this example, MSE = 3.007/4 with 24 degrees of freedom).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;anova(dMod3, MSE = 3.007/4, dfr = 24)
## Analysis of Variance Table
## 
## Response: YieldM
##           Df Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## GCA        2 61.000 30.5000 40.5720 2.000e-08 ***
## tSCA       3  6.000  2.0000  2.6605   0.07101 .  
## RGCA       2  2.333  1.1667  1.5519   0.23236    
## RSCA       1 16.667 16.6667 22.1705 8.713e-05 ***
## Residuals 24         0.7518                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
summary(dMod3, MSE = 3.007/4, dfr = 24)
##                Estimate        SE       t value     Pr(&amp;gt;|t|)
## Intercept  1.533333e+01 0.2890117  5.305436e+01 2.157713e-26
## g_A       -2.166667e+00 0.2890117 -7.496812e+00 9.771159e-08
## g_B       -1.666667e-01 0.2890117 -5.766779e-01 5.695269e-01
## ts_A:A     1.000000e+00 0.5780235  1.730034e+00 9.646589e-02
## ts_A:B    -1.000000e+00 0.4569677 -2.188339e+00 3.861373e-02
## ts_B:B     2.294461e-15 0.5780235  3.969495e-15 1.000000e+00
## rg_A      -1.666667e-01 0.2890117 -5.766779e-01 5.695269e-01
## rg_B       1.333333e+00 0.3388963  3.934340e+00 6.219023e-04
## rs_A:B     2.500000e+00 0.5309484  4.708555e+00 8.712864e-05&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The genetical parameters can be obtained by using the &lt;code&gt;glht()&lt;/code&gt; function and passing the information from the first step within the call to the &lt;code&gt;diallel.eff()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gh2 &amp;lt;- glht(linfct = diallel.eff(dMod3, MSE = 3.007/4, dfr = 24))
summary(gh2, test = adjusted(type = &amp;quot;none&amp;quot;)) 
## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Linear Hypotheses:
##                  Estimate Std. Error t value Pr(&amp;gt;|t|)    
## Intercept == 0  1.533e+01  2.890e-01  53.054  &amp;lt; 2e-16 ***
## g_A == 0       -2.167e+00  2.890e-01  -7.497 5.85e-08 ***
## g_B == 0       -1.667e-01  2.890e-01  -0.577 0.569117    
## g_C == 0        2.333e+00  2.890e-01   8.073 1.49e-08 ***
## ts_A:A == 0     1.000e+00  5.780e-01   1.730 0.095480 .  
## ts_A:B == 0    -1.000e+00  4.570e-01  -2.188 0.037824 *  
## ts_A:C == 0    -1.110e-15  4.570e-01   0.000 1.000000    
## ts_B:A == 0    -1.000e+00  4.570e-01  -2.188 0.037824 *  
## ts_B:B == 0     2.294e-15  5.780e-01   0.000 1.000000    
## ts_B:C == 0     1.000e+00  4.570e-01   2.188 0.037824 *  
## ts_C:A == 0    -1.110e-15  4.570e-01   0.000 1.000000    
## ts_C:B == 0     1.000e+00  4.570e-01   2.188 0.037824 *  
## ts_C:C == 0    -1.000e+00  5.780e-01  -1.730 0.095480 .  
## rg_A == 0      -1.667e-01  2.890e-01  -0.577 0.569117    
## rg_B == 0       1.333e+00  3.389e-01   3.934 0.000555 ***
## rg_C == 0      -1.167e+00  3.389e-01  -3.443 0.001962 ** 
## rs_A:B == 0     2.500e+00  5.309e-01   4.709 7.25e-05 ***
## rs_A:C == 0    -2.500e+00  5.309e-01  -4.709 7.25e-05 ***
## rs_B:A == 0    -2.500e+00  5.309e-01  -4.709 7.25e-05 ***
## rs_C:A == 0     2.500e+00  5.309e-01   4.709 7.25e-05 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## (Adjusted p values reported -- none method)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;estimation-of-variance-components-random-genetic-effects&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Estimation of variance components (random genetic effects)&lt;/h1&gt;
&lt;p&gt;In some cases, genetic effects are regarded as random and the aim is to estimate variance components. For this, we can use the &lt;code&gt;mmer()&lt;/code&gt; function in the ‘sommer’ package (Covarrubias-Pazaran, 2016), although we need to code a few dummy variables, which may make the task difficult for practitioners. Therefore, we coded a wrapper for the &lt;code&gt;mmer()&lt;/code&gt; function (&lt;code&gt;mmer.diallel()&lt;/code&gt;)that uses the same syntax as &lt;code&gt;lm.diallel()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;It would make no sense to estimate the variance components for genetic effects with a diallel experiment based on three parentals and, therefore, we give an example based on the ‘hayman54’ dataset, as available in the ‘lmDiallel’ package and relating to a complete diallel experiment with eight parentals (Hayman, 1954).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
data(hayman54)
mod.ran &amp;lt;- mmer.diallel(Ftime ~ Par1 + Par2, Block = Block,
                        data = hayman54, fct = &amp;quot;HAYMAN1&amp;quot;)
mod.ran$varcomp
##              VarComp  VarCompSE
## Block        0.00000   9.321698
## GCA       1276.73142 750.174164
## RGCA        17.97647  19.909911
## tSCA      1110.99398 330.172943
## RSCA        30.53937  46.467163
## Residuals  418.47875  74.563526&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We do hope that you enjoyed this post; if you are interested in diallel models, please, stay tuned: we have other examples on the way.&lt;/p&gt;
&lt;p&gt;Thanks for reading&lt;/p&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Prof. Luigi Russi&lt;br /&gt;
Dr. Niccolò Terzaroli&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Send comments to: &lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Covarrubias-Pazaran, G., 2016. Genome-Assisted Prediction of Quantitative Traits Using the R Package sommer. PLOS ONE 11, e0156744. &lt;a href=&#34;https://doi.org/10.1371/journal.pone.0156744&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1371/journal.pone.0156744&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hayman, B.I., 1954. The Analysis of Variance of Diallel Tables. Biometrics 10, 235. &lt;a href=&#34;https://doi.org/10.2307/3001877&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2307/3001877&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Möhring, J., Melchinger, A.E., Piepho, H.P., 2011b. REML-Based Diallel Analysis. Crop Science 51, 470–478. &lt;a href=&#34;https://doi.org/10.2135/cropsci2010.05.0272&#34; class=&#34;uri&#34;&gt;https://doi.org/10.2135/cropsci2010.05.0272&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Onofri, A., Terzaroli, N., Russi, L., 2020. Linear models for diallel crosses: a review with R functions. Theoretical Applied Genetics, &lt;a href=&#34;https://doi.org/10.1007/s00122-020-03716-8&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1007/s00122-020-03716-8&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>lmDiallel: a new R package to fit diallel models. Introduction</title>
      <link>https://www.statforbiology.com/2020/stat_met_diallel1/</link>
      <pubDate>Wed, 11 Nov 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2020/stat_met_diallel1/</guid>
      <description>


&lt;p&gt;Together with some colleagues from the plant breeding group, we have just published a new paper, where we presented a bunch of R functions to analyse the data from diallel experiments. The paper is titled ‘&lt;em&gt;Linear models for diallel crosses: a review with R functions&lt;/em&gt;’ and it is published in the ‘&lt;em&gt;Theoretical and Applied Genetics&lt;/em&gt;’ Journal. If you are interested, you can take a look &lt;a href=&#34;https://rdcu.be/caxZh&#34;&gt;here at this link&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Diallel experiments are based on a set of possible crosses between some homozygous (inbred) lines. For example, if we have the male lines A, B and C and the female lines A, B and C (same lines used, alternatively, as male and female), we would have the following selfed parents: AA, BB and CC and the following crosses: AB, AC, BC. In some instances, we might also have the reciprocals BA, CA and CB. Selfed parents and crosses are compared on a Randomised Complete Block Design, usually replicated across seasons and/or locations.&lt;/p&gt;
&lt;p&gt;For these diallel experiments, six main diallel models are available in literature, to quantify genetic effects, such as general combining ability (GCA), specific combining ability (SCA), reciprocal (maternal) effects and heterosis. If you are an expert in plant breeding, you do not need any other explanation; if you are not an expert, well… you are like me: we only need to know that these effects are determined as linear combinations of means for crosses, means for selfed parents and reciprocals. However, as I recently discovered, fitting diallel models to experimental data from diallel experiments is a relevant task for plant breeders.&lt;/p&gt;
&lt;p&gt;When I started dealing with diallel models, I was very surprised by the fact that they are often presented as separate entities, to be fitted by using specialised software; indeed, to the eyes of a biostatistician, it would appear that all diallel models are only different parameterisations of the same general linear model (Mohring et al., 2011). Therefore, it seemed to me very strange that we could not fit diallel models by simply using the &lt;code&gt;lm()&lt;/code&gt; function in R and related platform.&lt;/p&gt;
&lt;p&gt;A deeper diving in this subject showed me that the main implementation problem was that certain effects, such as the GCA effect, require the definition of unconventional design matrices, which were not yet available in R. Indeed, the packages ‘asreml-R’ and ‘sommer’ permit, e.g., the overlay of design matrices (function &lt;code&gt;and()&lt;/code&gt; in ‘asreml’ and &lt;code&gt;overlay()&lt;/code&gt; in ‘sommer’), which is useful to code GCA effects, but none of the two packages played well with the &lt;code&gt;lm()&lt;/code&gt; function in R. Therefore, together with Niccolò and Luigi, we decided to enhance the &lt;code&gt;model.matrix()&lt;/code&gt; function in R, building a handful of new R functions, aimed at producing the correct design matrices for all types of diallel models. All these functions are available within the ‘lmDiallel’ package, which is available on gitHub; it can be installed by using the ‘install_github()’ function, as available in the ‘devtools’ package. Therefore, if necessary, install this package first. The code is as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;devtools&amp;quot;) # Only at first instance
library(devtools)
install_github(&amp;quot;OnofriAndreaPG/lmDiallel&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The core functions for ‘lmDiallel’ are named after the corresponding genetic effects, i.e.: &lt;code&gt;GCA()&lt;/code&gt; (general combining ability), &lt;code&gt;tSCA()&lt;/code&gt; (total Specific Combining Ability), &lt;code&gt;RGCA()&lt;/code&gt; (reciprocal general combining ability), &lt;code&gt;RSCA()&lt;/code&gt; (reciprocal specific combining ability), &lt;code&gt;REC()&lt;/code&gt; (RECiprocal effects = RGCA + RSCA), &lt;code&gt;DD()&lt;/code&gt; (Dominance Deviation), &lt;code&gt;MDD()&lt;/code&gt; (Mean Dominance Deviation), &lt;code&gt;H.BAR()&lt;/code&gt; (Average Heterosis), &lt;code&gt;Hi()&lt;/code&gt; (Average hetorosis for one parent), &lt;code&gt;VEi()&lt;/code&gt; (Variety Effect), &lt;code&gt;SP()&lt;/code&gt; (effect of Selfed Parents) and &lt;code&gt;GCAC()&lt;/code&gt; (GCA for parents in their crosses). The usage of these functions is very simple. For example, let’s assume that we have the two variables ‘Par1’ and ‘Par2’ in a dataset, to represent the two parental lines (father and mother); the GCA effect is coded as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;GCA(Par1, Par2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;while the SCA effect is coded as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SCA(Par1, Par2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By using these R functions as building blocks, we can fit all diallel models inside the &lt;code&gt;lm()&lt;/code&gt; and &lt;code&gt;lme()&lt;/code&gt; functions. For example, the following line of code fits a diallel model containing the GCA and SCA effects, to the data contained in the ‘df’ dataframe:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lm(yield ~ GCA(Par1, Par2) + SCA(Par1, Par2), data = df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similarly, the effect of reciprocals and random blocks can be introduced by the following code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lme(yield ~ GCA(Par1, Par2) + SCA(Par1, Par2) +
            REC(Par1, Par2),
            random = ~1|Block, data = df)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The model building process outlined above is clearly rooted in the frame of general linear models, although we recognise that plant breeders usually refer to certain relevant parameterisations of diallel models by using the name of the authors. In this respect, it is very common to use the terms “HAYMAN1”, “GRIFFING1”, “GRIFFING2”, “HAYMAN2”, “GE2” and “GE3” to refer to the main six diallel models available in literature (see Hayman, 1954; Griffing, 1956; Gardner and Eberhart, 1966). Although these models can be built and fit by using the above method, we thought it might be useful to simplify the whole process. For this reason, we also built a wrapper function named &lt;code&gt;lm.diallel()&lt;/code&gt;, which can be used in the very same fashion as &lt;code&gt;lm()&lt;/code&gt;. The syntax is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lm.diallel(formula, Block, Env, data, fct)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where ‘formula’ uses the regular R syntax to specify the response variable and the two variables for parentals (e.g., Yield ~ Par1 + Par2). The two arguments ‘Block’ and ‘Env’ are used to specify optional variables, coding for blocks and environments, respectively. The argument ‘data’ is a ‘dataframe’ where to look for explanatory variables. Finally, ‘fct’ is a string variable coding for the selected model, i.e. “HAYMAN1”, “GRIFFING1”, “GRIFFING2”, “HAYMAN2”, “GE2”, “GE3”, according to the existing literature.&lt;/p&gt;
&lt;p&gt;We have also built the &lt;code&gt;summary()&lt;/code&gt;, &lt;code&gt;vcov(),&lt;/code&gt; &lt;code&gt;anova()&lt;/code&gt; and &lt;code&gt;predict()&lt;/code&gt; methods for ‘lm.diallel’ objects, in order to obey to some peculiar aspects of diallel models.&lt;/p&gt;
&lt;p&gt;In our paper (&lt;a href=&#34;https://rdcu.be/caxZh&#34;&gt;‘Linear models for diallel crosses: a review with R functions’&lt;/a&gt;) we have reviewed diallel models and gave examples on how they can be fitted with our new package ‘lmDiallel’. We have also shown how the facilities we provide can be used to fit random effects diallel models with ‘jags’. We intend to provide a more lengthy documentation for our package in a coming series of posts; thus, if you are interested, please, stay tuned.&lt;/p&gt;
&lt;p&gt;I believe that increasing the usability of existing packages that have gained a wide popularity may be an advantageous programming strategy, compared to the usual strategy of building brand new platforms. From the point of view of the developer, it is efficient, as it requires a minor programming effort. From the point of view of the users (professionals, technicians and students), it is handy to be put in the conditions of making statistical analyses, without the need of learning new softwares and/or languages and/or syntaxes. Due to its open-source nature, the R environment is often overwhelming for users, that are confused by the extremely wide availability of alternative methods to perform the same task. In this regard, a programming strategy aimed at supporting some existing reference platforms might help build a more comfortable environment for statistical analyses.&lt;/p&gt;
&lt;p&gt;Thanks for reading and, please, stay tuned! If you have comments, please, drop me a line at the email address below. Best wishes,&lt;/p&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA
&lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Covarrubias-Pazaran G (2016) Genome-assisted prediction of quantitative traits using the R package sommer. PLoS ONE 11:e0156744.&lt;/li&gt;
&lt;li&gt;Gardner CO, Eberhart SA (1966) Analysis and interpretation of the variety cross diallel and related populations. Biometrics 22:439–452.&lt;/li&gt;
&lt;li&gt;Gilmoure A, Gogel BJ, Cullis BR, Whelam SJ, Thompson R (2015) ASReml user guide release 4.1 structural specification. VSN International Ltd, Hemel Hempstead, HP1 1ES, UK&lt;/li&gt;
&lt;li&gt;Griffing B (1956) Concept of general and specific combining ability in relation to diallel crossing systems. Aust J Biol Sci 9:463–493&lt;/li&gt;
&lt;li&gt;Möhring J, Melchinger AE, Piepho HP (2011) REML-based diallel analysis. Crop Sci 51:470–478.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Building ANOVA-models for long-term experiments in agriculture</title>
      <link>https://www.statforbiology.com/2020/stat_lte_modelbuilding/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2020/stat_lte_modelbuilding/</guid>
      <description>


&lt;p&gt;This is the follow-up of a manuscript that we (some colleagues and I) have published in 2016 in the European Journal of Agronomy (Onofri et al., 2016). I thought that it might be a good idea to rework some concepts to make them less formal, simpler to follow and more closely related to the implementation with R. Please, be patient: this lesson may be longer than usual.&lt;/p&gt;
&lt;div id=&#34;what-are-long-term-experiments&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What are long-term experiments?&lt;/h1&gt;
&lt;p&gt;Agricultural experiments have to deal with long-term effects of cropping practices. Think about fertilisation: certain types of organic fertilisers may give effects on soil fertility, which are only observed after a relatively high number of years (say: 10-15). In order to observe those long-term effects, we need to plan Long Term Experiments (LTEs), wherein each plot is regarded as a small cropping system, with the selected combination of rotation, fertilisation, weed control and other cropping practices. Due to the fact that yield and other relevant variables are repeatedly recorded over time, LTEs represent a particular class of multi-environment experiments with repeated measures.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-main-problem-with-ltes-lack-of-independence&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The main problem with LTEs: lack of independence&lt;/h1&gt;
&lt;p&gt;We know that, with linear models, once the effects of experimental factors have been accounted for, the residuals must be independent. Otherwise, inferences are invalid.&lt;/p&gt;
&lt;p&gt;With LTEs, observations are repeatedly taken on the same plot and, therefore, the residuals cannot be independent. Indeed, all measurements taken on one specific plot will be affected by the peculiar characteristics of that plot and they will be more alike than measurements taken in different plots. Thus, there will be a ‘plot’ effect, which will induce a within-plot correlation. The problem is: how do we restore the necessary independence of residuals?&lt;/p&gt;
&lt;p&gt;At the basic level, the main way to account for the ‘plot’ effect is by including a random term in the model; in this way, we recognise that there is a plot-to-plot variability, following a gaussian distribution, with mean equal to 0 and standard deviation equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_B\)&lt;/span&gt; (‘plot’ error). This plot-to-plot variability is additional to the usual residual variability (within-plot error), that is also gaussian with mean equal to 0 and standard deviation equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;As the result, if we take one observation, the variance will be equal to the sum &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_B + \sigma^2\)&lt;/span&gt;. If we take two observations in different plots, they will have different random ‘plot’ effects and, thus, they will be independent. Otherwise, if we take two observations in the same plot, they will share the same random plot effect and they will ‘co-vary’, showing a positive covariance equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_B\)&lt;/span&gt;. The correlation among observations in the same plot will be quantified by the ratio &lt;span class=&#34;math inline&#34;&gt;\(\rho = \sigma^2_B / (\sigma^2_B + \sigma^2)\)&lt;/span&gt; (intra-class correlation).&lt;/p&gt;
&lt;p&gt;In simple words, adding a random plot effect to the model accounts for the fact that observations in the same plot are correlated. This would be similar to a split-plot design (indeed, we talk about split-plot in time) with the important difference that the sub-plot factor (year) is not randomised. The correlation of observations in one plot will always be the same, independent from the year, which is known as Compound Symmetry (CS) correlation structure. Be careful: &lt;strong&gt;it may be more reasonable to assume that observations close in time are more correlated than observations distant in time&lt;/strong&gt;, but we will address this point elsewhere.&lt;/p&gt;
&lt;p&gt;It is necessary to remember that, apart from plots, the experimental design may be characterised by other grouping structures, such as blocks or main plots. All these grouping structures must be appropriately referenced in the model, to account for intra-group correlation. I’ll be back into this in a few moments.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;another-problem-with-ltes-rotation-treatments&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Another problem with LTEs: rotation treatments&lt;/h1&gt;
&lt;p&gt;In many instances, the aim of LTEs is to compare different cropping systems, which are allocated to different plots, possibly in different blocks. When the different cropping systems involve rotations, we need to consider a very important rule, that was pointed out by W.G. Cochran in a seminal paper dating back to 1937: “&lt;em&gt;The most important rule about rotation experiments is that each crop in the rotation must be grown every year&lt;/em&gt;”. If we do not follow this rule, “&lt;em&gt;the experiment has to last longer to obtain equal information on the long-term effects of the treatments&lt;/em&gt;” and “&lt;em&gt;the effects of the treatments on the separate crops are obtained under different seasonal conditions, so that a compact summary of the results of the experiment as a whole is made exceedingly difficult&lt;/em&gt;”.&lt;/p&gt;
&lt;p&gt;The above rule has important consequences: first of all, with, e.g., a three year rotation, we need three plots per treatment and per block in each year, which increases the size of the experiment (that’s why some LTEs are designed without within-year replicates; Patterson, 1964). Secondly, if we want to consider only one crop in the rotation, the experiment becomes unbalanced, as not all plots contribute useful data in each one year. Last, but not least, in long rotations the test crop may return onto the same plot after a relatively long period of time, which may create a totally different correlation structure, compared to short rotations.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-do-we-build-anova-like-models-for-ltes&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;How do we build ‘ANOVA-like’ models for LTEs?&lt;/h1&gt;
&lt;p&gt;For the reasons explained above, building ANOVA-like models for data analyses may be a daunting task and it is useful to follow a structured procedure. First of all, we need to remember that ANOVA models are based on classification variables, commonly known as factors. There are three types of factors:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;treatment factors, which are randomly allocated to randomisation units (e.g. rotations, fertilisations, management of crop residues);&lt;/li&gt;
&lt;li&gt;block factors, which group the observations according to some ‘innate’ (not randomly allocated) criterion (e.g. by position), such as the blocks, the locations, the main-plots, the sub-plots and so on. Block factors may represent the randomisation units, to which treatments are randomly allocated;&lt;/li&gt;
&lt;li&gt;repeated factors, which relate to time and thus cannot be randomised (e.g. years, cycles …).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In order to build a model, the starting point is to list all factors (treatment, grouping and repeated) and their relationships. We can follow the general method proposed by Piepho et al. (2003), which we have slightly modified, to make it more ‘R-centric’. The relationships among factors can be specified by using the following operators:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;the ‘colon’ operator denotes an interaction of crossed effects (e.g. A:B means that A and B are crossed factors);&lt;/li&gt;
&lt;li&gt;the ‘nesting’ operator denotes nested effects (e.g. A/B means that B is nested within A and it is equal to A + A:B);&lt;/li&gt;
&lt;li&gt;the ‘crossing’ operator denotes the full factorial model for two terms (A*B = A + B + A:B).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;When building models we need to pay attention to properly code interactions. Let’s have a look at a simple two-way ANOVA, with the ‘JohnsonGrass.csv’ dataset. In this case we have the two crossed effects Length and Timing and we could build a model as: ‘RIZOMEWEIGHT ~ LENGTH + TIMING + LENGTH:TIMING’ that is shortened as: ’RIZOMEWEIGHT ~ LENGTH*TIMING’. However, if we build our model as: ‘RIZOMEWEIGHT ~ LENGTH:TIMING’, the two main effects are ‘absorbed’ by the term ‘LENGTH:TIMING’, which is no longer an interaction. The code below may clear up what I mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
dataset &amp;lt;- readr::read_csv(&amp;quot;https://www.casaonofri.it/_datasets/JohnsonGrass.csv&amp;quot;)

mod1 &amp;lt;- lm(RizomeWeight ~ Length + Timing + Length:Timing, data = dataset)
anova(mod1)
## Analysis of Variance Table
## 
## Response: RizomeWeight
##               Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Length         2  1762.2   881.1  9.4795 0.0002961 ***
## Timing         5 16927.9  3385.6 36.4241 3.896e-16 ***
## Length:Timing 10   952.7    95.3  1.0250 0.4354263    
## Residuals     54  5019.2    92.9                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
mod2 &amp;lt;- lm(RizomeWeight ~ Length:Timing, data = dataset)
anova(mod2)
## Analysis of Variance Table
## 
## Response: RizomeWeight
##               Df  Sum Sq Mean Sq F value    Pr(&amp;gt;F)    
## Length:Timing 17 19642.8 1155.46  12.431 4.766e-13 ***
## Residuals     54  5019.2   92.95                      
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;steps-to-model-building&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Steps to model building&lt;/h1&gt;
&lt;p&gt;The steps to model building may be summarised as follows:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Select the repeated factor.&lt;/li&gt;
&lt;li&gt;Consider one fixed level of the repeated factor and build a treatment model for the randomized treatment factors.&lt;/li&gt;
&lt;li&gt;Consider one fixed level of the repeated factor and build a block model for block factors.&lt;/li&gt;
&lt;li&gt;Check whether randomised treatment factors might interact with block effects: if such an interaction is to be expected it should be added to the model.&lt;/li&gt;
&lt;li&gt;Include the unrandomised repeated factor into the model.&lt;/li&gt;
&lt;li&gt;Combine treatment model and repeated factor model, by crossing or nesting as appropriate.&lt;/li&gt;
&lt;li&gt;Consider which effects in the block model reference randomisation units, i.e. those units which receive the levels of a factor or factor combination by a randomisation process. It should be clear that randomisation units can be seen as randomly selected from a wider population. Therefore, the corresponding terms should be assigned a separate random effect, as explicitly recommended in Piepho (2004).&lt;/li&gt;
&lt;li&gt;Excluding the terms for randomisation units, nest the repeated factor in all the other terms in the block model.&lt;/li&gt;
&lt;li&gt;Combine random effects for randomisation units with the repeated factor, by using the colon operator, in order to derive the correct error terms to accommodate correlation structures.&lt;/li&gt;
&lt;li&gt;Apart from randomisation units (see #7), decide which factors are random and which are fixed. In our examples, the random model will include all random terms for randomisation units (terms at steps 7 and 9), while the fixed model will include all the other terms. Several extensions/changes to this basic approach are possible.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The key idea for the above approach is that for a properly designed experiment, valid analyses should be possible for the data at each single level of the repeated factor. Such a basic requirement should never be taken for granted, but it should be carefully checked before the beginning of the model building process (see later for Example 3).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;some-further-definitions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Some further definitions&lt;/h1&gt;
&lt;p&gt;It is perhaps important to clear up some definitions, which we will use afterwards. Each crop component in a rotation is usually known as a phase; e.g., in the rotation Maize-Wheat-Wheat, Maize is phase 1, Wheat is phase 2 and Wheat is phase 3. The number of phases defines the period (duration) of the rotation. All phases need to be contemporarily present in any one year and, therefore, we can define the so-called sequences: i.e. each of the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; possible arrangements for a rotation of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; years, having the same crop ordering, but different initial phases (e.g Maize - Wheat - Wheat, Wheat - Wheat - Maize and Wheat - Maize - Wheat). Each sequences is uniquely identified by its starting phase, which needs to be randomly allocated to each plot at the start of the experiment.&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;div id=&#34;examples&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Examples&lt;/h1&gt;
&lt;p&gt;In order to give a practical demonstration, we have selected five exemplary datasets, relating to LTEs with different designs. If you are in a hurry, you can follow the links below to jump directly to the example that is most relevant for you.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Example 1. &lt;a href=&#34;#example-1-ltes-with-monocultures-or-perennial-crops&#34;&gt;LTEs to compare monocultures or perennial crops&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Example 2. &lt;a href=&#34;#example-2.-ltes-with-different-rotations-of-the-same-length-and-one-test-crop-per-rotation-cycle&#34;&gt;LTEs to compare rotations of the same length and one test crop per rotation cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Example 3. &lt;a href=&#34;#example-3.-ltes-with-a-fixed-rotation-one-test-crop-per-cycle-and-different-treatments&#34;&gt;LTEs with a fixed rotation (one test crop per cycle) and different treatments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Example 4. &lt;a href=&#34;#example-4.-lte-with-a-fixed-rotation-different-treatments-and-more-than-one-phase-per-crop-and-cycle&#34;&gt;LTE with a fixed rotation, different treatments and more than one phase per crop and cycle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Example 5. &lt;a href=&#34;#example-5-ltes-with-several-rotations-of-different-lengths-and-different-number-of-phases-per-crop-and-rotation-cycle&#34;&gt;LTEs with several rotations of different lengths and different number of phases per crop and rotation cycle&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We will analyse all examples, using the ‘tidyverse’ (Wickham, 2019) for data management and the ‘nlme’ package to fit random effect models (Pinheiro et al., 2019). We will also use the ‘asreml-R’ (Butler, 2019) package, for those of you who own a licence. Let’s load those packages in the R environment.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list = ls())
library(tidyverse)
library(nlme)
# library(asreml)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;example-1-ltes-with-monocultures-or-perennial-crops&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 1: LTEs with monocultures or perennial crops&lt;/h2&gt;
&lt;p&gt;Wheat is grown in continuous cropping from 1983 to 2012, with three fertilisation levels (150, 200 and 250 kg N ha&lt;span class=&#34;math inline&#34;&gt;\(^{-1}\)&lt;/span&gt;), randomly assigned to three plots in each of three blocks. In all, there are nine plots with yearly sampling, with a total of 270 wheat yield observations in 30 years. The following figure shows the design for one block: the spatial split for each plot represents the actual temporal split.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/_Figures/Stat_lte_ModelBuildingFigure1.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For this example, the repeated factor is the year (YEAR). In one year, the treatment factor is nitrogen fertilisation (N) and there are two block factors, i.e. the blocks (BLOCK) and the plots within each block (PLOT). Therefore, the block model is BLOCK + BLOCK:PLOT.&lt;/p&gt;
&lt;p&gt;We now introduce the repeated factor YEAR and combine it with the treatment model, by including N*YEAR = N + YEAR + N:YEAR. The term BLOCK:PLOT references the randomisation units and receives a random effect. As the year might interact with the block, we add the term BLOCK:YEAR. We also combine the year with the random effect for plots (BLOCK:PLOT:YEAR), although this residual term does not need to be explicitly coded when implementing the model. The final model is (the operator ~ means ‘is modelled as’):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;YIELD ~ N + BLOCK + YEAR + N:YEAR + BLOCK:YEAR
RANDOM = BLOCK:PLOT + BLOCK:PLOT:YEAR&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can use the above notation in R, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
dataset &amp;lt;- read_csv(&amp;quot;https://www.casaonofri.it/_datasets/LTE1.csv&amp;quot;)

dataset &amp;lt;- dataset %&amp;gt;% 
  mutate(across(c(Block, Plot, Year, N), factor))
head(dataset)
## # A tibble: 6 x 5
##   Plot  N     Year  Block Yield
##   &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt;
## 1 33    fn150 1983  1      4.54
## 2 98    fn150 1983  3      4.18
## 3 162   fn150 1983  2      3.7 
## 4 33    fn150 1984  1      4.57
## 5 98    fn150 1984  3      5.04
## 6 162   fn150 1984  2      5.06
# Implementation with lme
mod &amp;lt;- lme(Yield ~ Block + Year + N + N:Year + Block:Year,
           random = ~ 1|Plot, data = dataset)
anova(mod)
##             numDF denDF  F-value p-value
## (Intercept)     1   116 5434.427  &amp;lt;.0001
## Block           2     4    0.300  0.7564
## Year           29   116   36.496  &amp;lt;.0001
## N               2     4    1.304  0.3664
## Year:N         58   116    1.663  0.0105
## Block:Year     58   116    2.545  &amp;lt;.0001
# Implementation with asreml (the residual statement is unnecessary, here)
# Need to sort the data according to the residual statement
# datasetS &amp;lt;- dataset %&amp;gt;% 
#  arrange(Plot, Year)
# mod &amp;lt;- asreml(Yield ~ Block + Year + N + N:Year + Block:Year,
#           random = ~ Plot, 
#           residual = ~ Plot:Year, data = datasetS)
# wald(mod)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is worth to notice that the same model may be fitted in an alternative way, i.e. by dropping the BLOCK:PLOT random effects and using the residual term BLOCK:PLOT:YEAR to accommodate the CS structure into the model. This may be done very intuitively with ‘asreml’, by using the following notation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Code not run
# mod &amp;lt;- asreml(Yield ~ Block + Year + N + N:Year + Block:Year,
#           residual = ~ Plot:cor(Year), data = datasetS)
# summary(mod)$varcomp&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the final command returns the correlation between observations in the same plot. With ‘lme’ package, the notation is different, as we have to switch from the ‘lme()’ to the ‘gls()’ function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod &amp;lt;- gls(Yield ~ Block + Year + N + N:Year + Block:Year,
           correlation = corCompSymm(form = ~1|Plot), data = dataset)
mod$modelStruct$corStruct
## Correlation structure of class corCompSymm representing
##       Rho 
## 0.1269864&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This alternative coding can be used to implement different correlation structures for the cases when a simple CS correlation structure is not satisfactory. For example, when the observations close in time are more correlated than those distant in time, we can implement a serial correlation structure by appropriately changing the ‘residual’ argument in ‘asreml()’ or the ‘correlation’ argument in ‘lme()’.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-2.-ltes-with-different-rotations-of-the-same-length-and-one-test-crop-per-rotation-cycle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 2. LTEs with different rotations of the same length and one test crop per rotation cycle&lt;/h2&gt;
&lt;p&gt;Wheat is grown in five types of two-year rotations, with either pea (&lt;em&gt;Pisum sativum&lt;/em&gt; L), grain sorghum (&lt;em&gt;Sorghum bicolor&lt;/em&gt; (L.) Moench), sugar beet (&lt;em&gt;Beta vulgaris&lt;/em&gt; L. subsp. &lt;em&gt;saccharifera&lt;/em&gt;), sunflower (&lt;em&gt;Helianthus annuus&lt;/em&gt; L.) and faba bean (&lt;em&gt;Vicia faba&lt;/em&gt; L. subsp. &lt;em&gt;minor&lt;/em&gt;). For each rotation, there are two possible sequences (wheat in odd years and wheat in even years) and the ten combinations (five rotations by two sequences) are completely randomised to ten plots per each of three blocks (Figure 2). Therefore, five wheat plots out of the available ten plots are used from each block and year, for a total of 450 observations, from 1983 to 2012. The experimental design for one block is shown in the figure below.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/_Figures/Stat_lte_ModelBuildingFigure2.png&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this example we have two crops in a rotation and both crops are grown in different plots in the same year. Thus, for each rotation, we have two sequences in time (e.g., maize-sunflower and sunflower-maize). If we consider only one of the two crops, the main difference with respect to Example 1 is that the data obtained in two consecutive years for the same treatment and block are independent, in the sense that they are obtained in different plots. Otherwise, data obtained in a two-year interval (on different rotation cycles) on the same block are correlated, as they originate from the same plot.&lt;/p&gt;
&lt;p&gt;Which is the repeated factor? Indeed, if we look only at one phase in the rotation (in this case wheat), we note that observations are repeated every second year on the same plot (Figure above), according to the sequence they belong to. In other words, observations are repeated on each rotation cycle (CYC; two years) in the same plot, while there is neither a within-cycle repetition nor a within-cycle phase difference: we have only one observation per plot per cycle. Therefore, it is natural to take the rotation cycle as the repeated factor (CYC instead of YEAR).&lt;/p&gt;
&lt;p&gt;As the next step, we should look at what happens in one fixed level of CYC: what did we randomize to the ten plots in a two-years time slot? It is clear that, considering only wheat, we randomised each combination of rotation (ROT) and positioning in the sequence (SEQ; i.e. wheat as the first crop of the sequence and wheat as the second crop of the sequence). Therefore, the treatment factors are ROT and SEQ. Now we can cross the repeated factor with the treatment factors. Accordingly, The model is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;YIELD ~ SEQ*ROT + BLOCK + CYC + ROT:CYC + BLOCK:CYC
RANDOM: BLOCK:PLOT + BLOCK:PLOT:CYC &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code below shows how to fit the model with R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
dataset &amp;lt;- read_csv(&amp;quot;https://www.casaonofri.it/_datasets/LTE2.csv&amp;quot;)

dataset &amp;lt;- dataset %&amp;gt;% 
  mutate(across(c(1:7), factor))
head(dataset)
## # A tibble: 6 x 8
##   Block Main  Plot  Rot   Year  Sequence Cycle Yield
##   &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt;    &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt;
## 1 1     1_1   4     SBW   1983  1        1      5.1 
## 2 3     3_1   70    SBW   1983  1        1      4.5 
## 3 2     2_1   135   SBW   1983  1        1      4.53
## 4 1     1_0   27    SBW   1984  0        1      5.83
## 5 3     3_0   95    SBW   1984  0        1      6.26
## 6 2     2_0   160   SBW   1984  0        1      6.22
# Implementation with lme
mod &amp;lt;- lme(Yield ~ Block + Rot*Sequence + Block:Sequence +
             Cycle + Cycle:Sequence + Rot:Cycle + 
             Rot:Sequence:Cycle + Cycle:Block +
             Cycle:Block:Sequence,
             random = ~1|Plot,
           data = dataset)
anova(mod)
##                      numDF denDF   F-value p-value
## (Intercept)              1   224 115809.71  &amp;lt;.0001
## Block                    2    16     42.68  &amp;lt;.0001
## Rot                      4    16      4.19  0.0165
## Sequence                 1    16     26.14  0.0001
## Cycle                   14   224    133.43  &amp;lt;.0001
## Rot:Sequence             4    16      3.60  0.0283
## Block:Sequence           2    16      2.24  0.1384
## Sequence:Cycle          14   224    119.86  &amp;lt;.0001
## Rot:Cycle               56   224      1.74  0.0025
## Block:Cycle             28   224      8.77  &amp;lt;.0001
## Rot:Sequence:Cycle      56   224      1.61  0.0081
## Block:Sequence:Cycle    28   224      6.85  &amp;lt;.0001&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This approach is commonly suggested in literature (see Yates, 1954) and it is convenient, mainly because the resulting model is orthogonal and may be fitted by ordinary least squares. Indeed, for Dataset 2 (and similar experiments), there is only one observation for each block, treatment, cycle, sequence and no missing data (in our case: 3 blocks x 5 rotations x 2 sequences x 15 cycles = 450 observations). The phase should not enter into this model, as we are looking only at one of the two crops (only one phase).&lt;/p&gt;
&lt;p&gt;However, the drawback is that such an approach cannot be immediately extended to the other more complex examples (e.g. rotations with different lengths and/or with a different number of test-crops). Furthermore, the effect of years is partitioned into three components, i.e. ‘cycles’, ‘sequences’ and ‘cycle x sequences’, which might make modeling possible ‘fertility’ trends over time less immediate. In this respect, we should note that possible differences between sequences for a given cycle (wheat as the first crop of the sequence and wheat as the second crop of the sequence, i.e. wheat in even years and wheat in odd years) do not carry any meaning that helps understand the behaviour of rotations.&lt;/p&gt;
&lt;p&gt;An alternative and more natural approach is to take the year as the repeated factor; indeed, for Example 2, the year effect is totally confounded with the factorial combination of ‘cycle’ and ‘sequence’ (15 cycles x 2 sequences = 30 years). If we consider the YEAR as the repeated factor, in one year the treatment model is composed only by the rotation (ROT), that is allocated to plots (PLOT), within blocks. The block model for one year is BLOCK/PLOT = BLOCK + BLOCK:PLOT. We can combine the treatment model with the repeated factor (ROT:YEAR) and add the term BLOCK:YEAR. The final model is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;YIELD ~ ROT + BLOCK + YEAR + ROT:YEAR + BLOCK:YEAR
RANDOM: BLOCK:PLOT + BLOCK:PLOT:YEAR &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Apart from random effects for randomisation units, this model is totally similar to the one used for multi-environment genotype experiments and, represents a convenient and clear platform for the analyses of LTE data. We remind the reader that the residual term (BLOCK:PLOT:YEAR) does not need to be explicitly coded when implementing the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Implementation with lme
mod &amp;lt;- lme(Yield ~ Block + Rot + Year + Rot:Year + Block:Year,
             random = ~1|Plot,
           data = dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This gives us a good common modelling platform for all datasets, although it may be argued that the models are no longer orthogonal, as not all plots produce data in all years. It should be recognised, however, that the lack of orthogonality can easily be accommodated within mixed models.&lt;/p&gt;
&lt;p&gt;The situation is totally different if we look at both the phases of the rotation (e.g. wheat and sunflower): in this case, we have a phase difference within each cycle and, considering one level of the repeated factor year, the treatment model should contain both the rotation and the phase, together with their interaction. When we introduce the year (steps 5 and 6 above), we also introduce the interactions ‘year x rotation’, ‘year x phase’ and ‘year x rotation x phase’, which are all meaningful when studying the behaviour of rotations.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;example-3.-ltes-with-a-fixed-rotation-one-test-crop-per-cycle-and-different-treatments&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 3. LTEs with a fixed rotation (one test crop per cycle) and different treatments&lt;/h2&gt;
&lt;p&gt;Durum wheat (&lt;em&gt;Triticum durum&lt;/em&gt; L.) is grown in a two-year rotation with a spring crop and nine cropping systems, consisting of the factorial combination of three soil tillage methods (CT: conventional 40 cm deep ploughing; M: scarification at 25 cm; S: sod seeding with chemical desiccation and chopping) and three N-fertilisation levels (N0, N90 and N180, corresponding to 0, 90 and 180 kg N &lt;span class=&#34;math inline&#34;&gt;\(ha^{-1}\)&lt;/span&gt;). The two possible rotation sequences (wheat-spring crop and spring crop-wheat) are arranged in two adjacent fields, which therefore host the two different crops of the rotation in the same year. Within the two fields, there are two independent randomisations, each with two blocks, tillage levels randomised to main-plots (1500 &lt;span class=&#34;math inline&#34;&gt;\(m^2\)&lt;/span&gt;) and N levels randomised to sub-plots (500 &lt;span class=&#34;math inline&#34;&gt;\(m^2\)&lt;/span&gt;), according to a split-plot design with two replicates. The design is taken from Seddaiu et al. (2016), while the data have been simulated by using Monte Carlo methods.&lt;/p&gt;
&lt;p&gt;This type of LTE is very similar to the previous one, though we have a different experimental layout:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;there are two experimental treatments, laid out in a split-plot design;&lt;/li&gt;
&lt;li&gt;the two sequences are accommodated in two fields.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The experimental design for Dataset 3, for each of two fields in one year is reported in the figure below. The position of wheat and spring crop is exchanged in the following year (CT: conventional ploughing; M: scarification; S: sod seeding; 0: no nitrogen fertilisation; 1: 90 kg N &lt;span class=&#34;math inline&#34;&gt;\(ha^{-1}\)&lt;/span&gt;; 2: 180 kg N &lt;span class=&#34;math inline&#34;&gt;\(ha^{-1}\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/_Figures/Stat_lte_ModelBuildingFigure3.jpg&#34; width=&#34;90%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Before proceeding to model building for Example 3, we need to discuss whether valid analyses are possible at each single level of the repeated factor. Indeed, this is clearly true if we take the year as the repeated factor and consider only one of the two crops in the rotation (wheat, in this case). However, if we intended to consider both crops and compare e.g. their yields, the crop effect would be confounded with the field effect within a single year and, therefore, valid within-year analyses would not be possible. In this case, we should resort to taking the rotation cycle as the repeated factor.&lt;/p&gt;
&lt;p&gt;Dealing only with wheat, we can therefore take the YEAR as the repeated factor and consider that, in one year, the randomised treatment factors are tillage (T) and nitrogen fertilisation (N) and the treatment model is T + N + T:N.&lt;/p&gt;
&lt;p&gt;The block factors are the FIELDS, the BLOCKS within fields, the MAIN plots within blocks and the subplots (SUB) within main plots. The block model (for one year) is FIELD + FIELD:BLOCK + FIELD:BLOCK:MAIN + FIELD:BLOCK:MAIN:SUB.&lt;/p&gt;
&lt;p&gt;The treatment and repeated model can be combined as: (T + N + T:N)*YEAR = T + N + T:N + YEAR + T:YEAR + N:YEAR + T:N:YEAR.&lt;/p&gt;
&lt;p&gt;At this stage, the FIELD main effect needs to be removed, as it is totally confounded with the years. We assign a random effect to the other randomisation units, i.e. FIELD:BLOCK, FIELD:BLOCK:MAIN and FIELD:BLOCK:MAIN:SUB and combine these random terms with the repeated factor YEAR, by using the colon operator, which leads us to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;YIELD ~ T + N + T:N + YEAR + T:YEAR + N:YEAR + T:N:YEAR
RANDOM: FIELD:BLOCK + FIELD:BLOCK:MAIN + FIELD:BLOCK:MAIN:SUB + FIELD:BLOCK:YEAR + FIELD:BLOCK:MAIN:YEAR + FIELD:BLOCK:MAIN:SUB:YEAR&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As usual, the last term (residual) does not need to be explicitly included when implementing the model, but it can be used, together with the two previous ones (FIELD:BLOCK:YEAR + FIELD:BLOCK:MAIN:YEAR) to accommodate possible serial correlation structures into the model, by allowing year-specifity of all design effects and the residuals. For this types of models with several crossed random effects, the coding of ‘lme()’ is not straightforward and it does not always lead to a flexible implementation of correlation structures.&lt;/p&gt;
&lt;p&gt;In the code below we need to build dummy variables for all random effects (five variables, excluding the residual error term, which is not needed). Afterwards, we have to code the random effects as a list; R expects that the element of such list are nested and, therefore, we need to work around this by coding an additional variable, which takes the value of ‘1’ for all subjects, so that the nesting structure is only artificial. We use the ‘pdIdent’ construct to say that each random effect is homoscedastic and uncorrelated.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls()) 
dataset &amp;lt;- read_csv(&amp;quot;https://www.casaonofri.it/_datasets/LTE3.csv&amp;quot;)
dataset &amp;lt;- dataset %&amp;gt;% 
  mutate(across(c(1:9), factor)) %&amp;gt;% 
  mutate(FB = factor(Block:Field),
         FBM = factor(FB:Main),
         FBMS = factor(FBM:Sub),
         FBY = factor(FB:Year),
         FBMY = factor(FBM:Year),
         one = 1L)

mod &amp;lt;- lme(Yield ~ T + N + N:T + 
                 Year + Year:T + Year:N + Year:N:T,
                 random = list(one = pdIdent(~FB - 1),
                               one = pdIdent(~FBM - 1),
                               one = pdIdent(~FBMS - 1),
                               one = pdIdent(~FBY - 1),
                               one = pdIdent(~FBMY - 1)),
               data = dataset, na.action = na.omit)

# Fixed effects tested by using LRT
library(car)
Anova(mod)
## Analysis of Deviance Table (Type II tests)
## 
## Response: Yield
##             Chisq Df Pr(&amp;gt;Chisq)    
## T          5.1169  2    0.07743 .  
## N        804.1717  2  &amp;lt; 2.2e-16 ***
## Year     446.6794 17  &amp;lt; 2.2e-16 ***
## T:N        6.2105  4    0.18397    
## T:Year   142.5132 34  3.065e-15 ***
## N:Year   246.5584 34  &amp;lt; 2.2e-16 ***
## T:N:Year 159.3230 68  2.705e-09 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The fit takes a long time and it is not easy to manipulate the model to introduce correlation structures for the random effects. However, it is not difficult to introduce the correlation of residuals, by using the ‘correlation’ argument (see above).&lt;/p&gt;
&lt;p&gt;Coding the same model with ‘asreml()’ is easier and so is to introduce patterned correlations structures. However, the design has to be balanced and, therefore, we need to introduce NAs for missing observations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Asreml fit (not run)
# datasetS &amp;lt;- dataset %&amp;gt;% 
#  arrange(Sub, Year)
# mod2 &amp;lt;- asreml(Yield ~ T + N + N:T + 
#                 Year + Year:T + Year:N + Year:N:T,
#                 random = ~FB + FB:Main + FB:Main:Sub + 
#                 FB:Year + FB:Main:Year,
#               residual = ~ Sub:Year,
#               data = datasetS)
# summary(mod2)$varcomp&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-4.-lte-with-a-fixed-rotation-different-treatments-and-more-than-one-phase-per-crop-and-cycle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 4. LTE with a fixed rotation, different treatments and more than one phase per crop and cycle&lt;/h2&gt;
&lt;p&gt;Wheat is grown in a three-year rotation maize-wheat-wheat, under two types of management of crop residues (burial and removal), which are randomised to main plots, while the three possible rotation sequences are randomised to subplots. This experiment has 18 plots (three sequences x two treatment levels x three blocks) and, in every year, 12 of those are cropped with wheat and six with maize.&lt;/p&gt;
&lt;p&gt;Also in this case, the response variable is wheat yield from 1983 to 2012, i.e. twelve observations per year and 360 observations in total. Data obtained in the same plot in different years belong to two different phases (wheat after maize and wheat after wheat; the experimental design for one block is shown in the figure below).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/_Figures/Stat_lte_ModelBuildingFigure4.png&#34; width=&#34;80%&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;With respect to Example 3, the situation becomes more complex, because we have two distinct phases in each rotation cycle (phase difference: wheat after maize and wheat after wheat). As usual, we start by regarding the YEAR as the repeated factor. In one year, the treatment factors are the management of soil residues (RES, that is randomly allocated to main-plots) and the phases (P; randomly allocated to subplots); the treatment model is indeed: RES*P.&lt;/p&gt;
&lt;p&gt;In one year, the block model is: BLOCK/MAIN/SUB = BLOCK + BLOCK:MAIN + BLOCK:MAIN:SUB. Introducing the YEAR as repeated factor, we can combine the treatment model with the repeated model as: RES + P + &lt;a href=&#34;RES:P&#34; class=&#34;uri&#34;&gt;RES:P&lt;/a&gt; + YEAR + &lt;a href=&#34;RES:YEAR&#34; class=&#34;uri&#34;&gt;RES:YEAR&lt;/a&gt; + P:YEAR + &lt;a href=&#34;RES:P:YEAR&#34; class=&#34;uri&#34;&gt;RES:P:YEAR&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The terms BLOCK:MAIN and BLOCK:MAIN:SUB reference randomisation units and should receive random effects. The blocks may interact with the years (BLOCK:YEAR), while the random effects for randomisation units can be made year-specific by adding BLOCK:MAIN:YEAR and the residual term BLOCK:MAIN:SUB:YEAR. The final model is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;YIELD ~ RES + P + RES:P + YEAR + RES:YEAR + P:YEAR + RES:P:YEAR + BLOCK + BLOCK:YEAR
RANDOM: BLOCK:MAIN + BLOCK:MAIN:SUB + BLOCK:MAIN:YEAR + BLOCK:MAIN:SUB:YEAR&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls()) 
dataset &amp;lt;- read_csv(&amp;quot;https://www.casaonofri.it/_datasets/LTE4.csv&amp;quot;)
dataset &amp;lt;- dataset %&amp;gt;% 
  mutate(across(c(1:7), factor)) %&amp;gt;% 
  mutate(Main = factor(Block:Res),
         Sub = factor(Main:Sub))

mod &amp;lt;- lme(Yield ~ Block + Res*P + 
              Year + Year:Res + Year:P + Year:Res:P +
              Block:Year, 
           random = list(Main = pdIdent(~1),
                         Main = pdIdent(~Sub - 1),
                         Main = pdIdent(~Year - 1)),
           data = dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;example-5-ltes-with-several-rotations-of-different-lengths-and-different-number-of-phases-per-crop-and-rotation-cycle&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Example 5: LTEs with several rotations of different lengths and different number of phases per crop and rotation cycle&lt;/h2&gt;
&lt;p&gt;Wheat is grown in five maize (M) - wheat (W) rotations of different lengths, i.e. M-W, M-W-W, M-W-W-W, M-W-W-W-W, M-W-W-W-W-W. For all rotations, all phases are contemporarily present in each year, for a total of 20 plots (one for each of the possible sequences, i.e. 2 + 3 + 4 + 5 + 6 = 20) in each of three blocks. Considering wheat yield as the response variable, we find that only 15 observations are obtained in each year, for a total of 1350 data, from 1983 to 2012.&lt;/p&gt;
&lt;p&gt;Experiments of this type represent a high degree of complexity. Indeed, in contrast to all other examples, after 30 years there are plots with: (i) a different number of observations for the same test crop; (ii) a different number of cycles (in some cases the last cycle is also incomplete); (iii) a different number of phases for wheat.&lt;/p&gt;
&lt;p&gt;In some cases, it is necessary to compare several rotations with different characteristics (e.g. a different duration and/or a different number of tests crops and /or a different number of phases per crop), which may create a complex design with some degree of non-orthogonality.&lt;/p&gt;
&lt;p&gt;The repeated factor is again the YEAR. In one year, the treatment factors are the rotation system (ROT) and the rotation phase (P), which are randomly allocated to plots. As there is a different number of phases for each rotation, we nest the phase within the rotation, leading to the following treatment model: ROT/P = ROT + P:ROT.&lt;/p&gt;
&lt;p&gt;In one year, the block model is BLOCK/PLOT = BLOCK + BLOCK:PLOT. The repeated factor is included and combined with the treatment model, by introducing YEAR + ROT:YEAR + ROT:P:YEAR.&lt;/p&gt;
&lt;p&gt;The term BLOCK:PLOT references randomisation units and needs to receive a random effect, while the term YEAR:BLOCK can be added to the model, together with the residual term BLOCK:PLOT:YEAR. The final model is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;YIELD ~ ROT + P:ROT + YEAR + ROT:YEAR + ROT:P:YEAR
RANDOM: BLOCK:PLOT + BLOCK:PLOT:YEAR&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the implementation below we did not succeed reaching convergence with ‘lme()’, but we were successful ‘with asreml()’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls()) 
dataset &amp;lt;- read_csv(&amp;quot;https://www.casaonofri.it/_datasets/LTE5.csv&amp;quot;)

dataset &amp;lt;- dataset %&amp;gt;% 
  mutate(across(c(1:7), factor))

# mod &amp;lt;- asreml(Yield ~ Block + Rot + Rot:P + 
#                 Year + Year:Rot + Year:Rot:P + Block:Year,
#               random = ~Plot,
#               data = dataset)

# mod &amp;lt;- lme(Yield ~ Block + Rot + Rot:P + 
#                Year + Year:Rot + Year:Rot:P + Block:Year, 
#                random=~1|Plot,
#              data = dataset)&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;warning&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Warning!&lt;/h1&gt;
&lt;p&gt;Models 1 to 5 are fairly similar and they are very closely related to those used for multi-environment experiments. However, there are some peculiar aspects which needs to be taken under consideration.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Apart from Dataset 1, there is always a certain degree of unbalance, as plots do not produce data every year. Testing for fixed effects requires great care.&lt;/li&gt;
&lt;li&gt;In all cases, the model formulations shown above induce a compound symmetry correlation structure for observations taken in the same plot over time (‘split-plot in time’). This is seldom appropriate and, thus, more complex correlations structures should be considered.&lt;/li&gt;
&lt;li&gt;In the above formulations, only randomisation units have been given a random effect, while all the other effects have been regarded as fixed. Obviously, depending on the aims of the analyses, it might be convenient and appropriate to regard some of these effects (e.g., the year main effect and interactions) as random.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It’s all, thanks for reading this far. If you have any comments, please, drop me a note at &lt;a href=&#34;mailto:andrea.onofri@unipg.it&#34;&gt;andrea.onofri@unipg.it&lt;/a&gt;. Best wishes,&lt;/p&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Brien, C.J., Demetrio, C.G.B., 2009. Formulating mixed models for experiments, including longitudinal experiments. Journal of Agricultural, Biological and Environmental Statistics 14, 253–280.&lt;/li&gt;
&lt;li&gt;David Butler (2019). asreml: Fits the Linear Mixed Model. R package version 4.1.0.110. www.vsni.co.uk&lt;/li&gt;
&lt;li&gt;Cochran, W.G., 1939. Long-Term Agricultural Experiments. Supplement to the Journal of the Royal Statistical Society 6, 104–148.&lt;/li&gt;
&lt;li&gt;Onofri, A., Seddaiu, G., Piepho, H.-P., 2016. Long-Term Experiments with cropping systems: Case studies on data analysis. European Journal of Agronomy 77, 223–235.&lt;/li&gt;
&lt;li&gt;Patterson, H.D., 1964. Theory of Cyclic Rotation Experiments. Journal of the Royal Statistical Society. Series B (Methodological) 26, 1–45.&lt;/li&gt;
&lt;li&gt;Payne, R.W., 2015. The design and analysis of long-term rotation experiments. Agronomy Journal 107, 772–785.&lt;/li&gt;
&lt;li&gt;Piepho, H.-P., Büchse, A., Emrich, K., 2003. A Hitchhiker’s Guide to Mixed Models for Randomized Experiments. Journal of Agronomy and Crop Science 189, 310–322.&lt;/li&gt;
&lt;li&gt;Piepho, H.-P., Büchse, A., Richter, C., 2004. A Mixed Modelling Approach for Randomized Experiments with Repeated Measures. Journal of Agronomy and Crop Science 190, 230–247.&lt;/li&gt;
&lt;li&gt;Pinheiro J, Bates D, DebRoy S, Sarkar D, R Core Team (2019). &lt;em&gt;nlme: Linear and Nonlinear Mixed Effects Models&lt;/em&gt;. R package version 3.1-142, &amp;lt;URL: &lt;a href=&#34;https://CRAN.R-project.org/package=nlme&#34; class=&#34;uri&#34;&gt;https://CRAN.R-project.org/package=nlme&lt;/a&gt;&amp;gt;.&lt;/li&gt;
&lt;li&gt;Seddaiu, G., Iocola, I., Farina, R., Orsini, R., Iezzi, G., Roggero, P.P., 2016. Long term effects of tillage practices and N fertilization in rainfed Mediterranean cropping systems: durum wheat, sunflower and maize grain yield. European Journal of Agronomy 77, 166–178. &lt;a href=&#34;https://doi.org/10.1016/j.eja.2016.02.008&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1016/j.eja.2016.02.008&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686, &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34; class=&#34;uri&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fitting complex mixed models with nlme. Example #5</title>
      <link>https://www.statforbiology.com/2020/stat_met_jointreg/</link>
      <pubDate>Fri, 05 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2020/stat_met_jointreg/</guid>
      <description>


&lt;div id=&#34;a-joint-regression-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A Joint Regression model&lt;/h1&gt;
&lt;p&gt;Let’s talk about a very old, but, nonetheless, useful technique. It is widely known that the yield of a genotype in different environments depends on environmental covariates, such as the amount of rainfall in some critical periods of time. Apart from rain, also temperature, wind, solar radiation, air humidity and soil characteristics may concur to characterise a certain environment as good or bad and, ultimately, to determine yield potential.&lt;/p&gt;
&lt;p&gt;Early in the 60s, several authors proposed that the yield of genotypes is expressed as a function of an environmental index &lt;span class=&#34;math inline&#34;&gt;\(e_j\)&lt;/span&gt;, measuring the yield potential of each environment &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; (Finlay and Wilkinson, 1963; Eberhart and Russel, 1966; Perkins and Jinks, 1968). For example, for a genotype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, we could write:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ij} = \mu_i + \beta_i e_j\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the yield &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; in a certain environment &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is expressed as a linear function of the environmental index &lt;span class=&#34;math inline&#34;&gt;\(e_j\)&lt;/span&gt;; &lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt; is the intercept and &lt;span class=&#34;math inline&#34;&gt;\(\beta_i\)&lt;/span&gt; is the slope, which expresses how the genotype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; responds to the environment.&lt;/p&gt;
&lt;p&gt;A graphical example may be useful; in the figure below we have two genotypes tested in 10 environments. The yield of the first genotype (red) increases as the environmental index increases, with slope &lt;span class=&#34;math inline&#34;&gt;\(\beta_1 = 0.81\)&lt;/span&gt;. On the other hand, the yield of the second genotype (blue) does not change much with the environment (&lt;span class=&#34;math inline&#34;&gt;\(\beta_2 = -0.08)\)&lt;/span&gt;. Clearly, a high value of &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; demonstrates that the genotype is responsive to the environment and makes profit of favorable conditions. Otherwise, a low &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; value (close to 0) demonstrates that the genotype is not responsive and tends to give more or less the same yield in all environments (static stability; Wood, 1976).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/post/Stat_met_JointReg_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;By now, it should be clear that &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; is a relevant measure of stability. Now, the problem is: how do we determine such value from a multi-environment genotype experiment? As usual, let’s start from a meaningful example.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-multi-environment-experiment&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A multi-environment experiment&lt;/h1&gt;
&lt;p&gt;Let’s take the data in Sharma (2006; Statistical And Biometrical Techniques In Plant Breeding, New Age International ltd. New Delhi, India). They refer to a multi-environment experiment with 7 genotypes, 6 environments and 3 blocks; let’s load the data in the dataframe ‘dataFull’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rm(list=ls())
library(nlme)
library(emmeans)
## Welcome to emmeans.
## NOTE -- Important change from versions &amp;lt;= 1.41:
##     Indicator predictors are now treated as 2-level factors by default.
##     To revert to old behavior, use emm_options(cov.keep = character(0))
Block &amp;lt;- factor(rep(c(1:3), 42))
Var &amp;lt;- factor(rep(LETTERS[1:7],each=18))
Loc &amp;lt;- factor(rep(rep(letters[1:6], each=3), 7))
P1 &amp;lt;- factor(Loc:Block)
Yield &amp;lt;- c(60,65,60,80,65,75,70,75,70,72,82,90,48,45,50,50,40,40,
           80,90,83,70,60,60,85,90,90,70,85,80,40,40,40,38,40,50,
           25,28,30,40,35,35,35,30,30,40,35,35,35,25,20,35,30,30,
           50,65,50,40,40,40,48,50,52,45,45,50,50,50,45,40,48,40,
           52,50,55,55,54,50,40,40,60,48,38,45,38,30,40,35,40,35,
           22,25,25,30,28,32,28,25,30,26,28,28,45,50,45,50,50,50,
           30,30,25,28,34,35,40,45,35,30,32,35,45,35,38,44,45,40)
dataFull &amp;lt;- data.frame(Block, Var, Loc, Yield)
rm(Block, Var, Loc, P1, Yield)
head(dataFull)
##   Block Var Loc Yield
## 1     1   A   a    60
## 2     2   A   a    65
## 3     3   A   a    60
## 4     1   A   b    80
## 5     2   A   b    65
## 6     3   A   b    75&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-an-environmental-index&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is an environmental index?&lt;/h1&gt;
&lt;p&gt;First of all, we need to define an environmental index, which can describe the yield potential in each of the seven environments. Yates and Cochran (1937) proposed that we use the mean of all observations in each environment, expressed as the difference between the environmental mean yield &lt;span class=&#34;math inline&#34;&gt;\(\mu_j\)&lt;/span&gt; and the overall mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; (i.e. &lt;span class=&#34;math inline&#34;&gt;\(e_j = \mu_j - \mu\)&lt;/span&gt;). Let’s do it; in the box below we use the package ‘dplyr’ to augment the dataset with a new variable, representing the environmental indices.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
dataFull &amp;lt;- dataFull %&amp;gt;%
  group_by(Loc) %&amp;gt;% 
  mutate(ej = mean(Yield) - mean(dataFull$Yield))
head(dataFull)
## # A tibble: 6 x 5
## # Groups:   Loc [2]
##   Block Var   Loc   Yield    ej
##   &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 1     A     a        60 1.45 
## 2 2     A     a        65 1.45 
## 3 3     A     a        60 1.45 
## 4 1     A     b        80 0.786
## 5 2     A     b        65 0.786
## 6 3     A     b        75 0.786&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This step is ok with balanced data and it is clear that a high environmental index identifies the favorable environments, while a low (negative) environmental index identifies unfavorable environments. It is necessary to keep in mind that we have unwillingly put a constraint on &lt;span class=&#34;math inline&#34;&gt;\(e_j\)&lt;/span&gt; values, that have to sum up to zero.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;full-model-definition-equation-1&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Full model definition (Equation 1)&lt;/h1&gt;
&lt;p&gt;Now, it is possible to regress the yield data for each genotype against the environmental indices, according to the following joint regression model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ijk} = \gamma_{jk} + \mu_i + \beta_i e_j + d_{ij} + \varepsilon_{ijk} \quad\quad\quad \textrm{(Equation 1)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where: &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk}\)&lt;/span&gt; is the yield for the genotype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in the environment &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and block &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of blocks within environments and &lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt; is the average yield for the genotype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. As we have seen in the figure above, the average yield of a genotype in each environment cannot be exactly described by the regression against the environmental indices (in other words: the observed means do not lie along the regression line). As the consequence, we need the random term &lt;span class=&#34;math inline&#34;&gt;\(d_{ij}\)&lt;/span&gt; to represent the deviation from the regression line for the genotype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in the environment &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;. Finally, the random elements &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon_{ijk}\)&lt;/span&gt; represent the deviations between the replicates for the genotype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; in the environment &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; (within-trial errors). As I said, &lt;span class=&#34;math inline&#34;&gt;\(d_{ij}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon_{ijk}\)&lt;/span&gt; are random, with variances equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_d\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;, respectively.&lt;/p&gt;
&lt;p&gt;According to Finlay-Wilkinson, &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_d\)&lt;/span&gt; is assumed to be equal for all genotypes. Otherwise, according to Eberarth-Russel, &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{d}\)&lt;/span&gt; may assume a different value for each genotype (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{d(i)}\)&lt;/span&gt;) and may become a further measure of stability: if this is small, a genotype does not show relevant variability of yield, apart from that due to the regression against the environmental indices.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;model-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Model fitting&lt;/h1&gt;
&lt;p&gt;We can start the analyses by fitting a traditional ANOVA model, to keep as a reference.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod.aov &amp;lt;- lm(Yield ~ Loc/Block + Var*Loc, data = dataFull)
anova(mod.aov)
## Analysis of Variance Table
## 
## Response: Yield
##           Df  Sum Sq Mean Sq  F value    Pr(&amp;gt;F)    
## Loc        5  1856.0   371.2  17.9749 1.575e-11 ***
## Var        6 20599.2  3433.2 166.2504 &amp;lt; 2.2e-16 ***
## Loc:Block 12   309.8    25.8   1.2502    0.2673    
## Loc:Var   30 12063.6   402.1  19.4724 &amp;lt; 2.2e-16 ***
## Residuals 72  1486.9    20.7                       
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we said, Equation 1 is a mixed model, which calls for the use of the ‘lme()’ function. For better understanding, it is useful to start by augmenting the previous ANOVA model with the regression term (‘Var/ej’). We use the nesting operator, to have different regression lines for each level of ‘Var’.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Augmented ANOVA model
mod.aov2 &amp;lt;- lm(Yield ~ Loc/Block + Var/ej + Loc:Var, data=dataFull)
anova(mod.aov2)
## Analysis of Variance Table
## 
## Response: Yield
##           Df  Sum Sq Mean Sq  F value    Pr(&amp;gt;F)    
## Loc        5  1856.0   371.2  17.9749 1.575e-11 ***
## Var        6 20599.2  3433.2 166.2504 &amp;lt; 2.2e-16 ***
## Loc:Block 12   309.8    25.8   1.2502    0.2673    
## Var:ej     6  9181.2  1530.2  74.0985 &amp;lt; 2.2e-16 ***
## Loc:Var   24  2882.5   120.1   5.8159 2.960e-09 ***
## Residuals 72  1486.9    20.7                       
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the GE interaction in the ANOVA model has been decomposed into two parts: the regression term (‘Var/ej’) and the deviation from regression (‘Loc:Var’), with 6 and 24 degrees of freedom, respectively. This second term corresponds to &lt;span class=&#34;math inline&#34;&gt;\(d_{ij}\)&lt;/span&gt; in Equation 1 (please, note that the two terms ‘Var/ej’ and ‘Loc:Var’ are partly confounded).&lt;/p&gt;
&lt;p&gt;The above analysis is only useful for teaching purposes, but it is unsatisfactory, because the &lt;span class=&#34;math inline&#34;&gt;\(d_{ij}\)&lt;/span&gt; terms have been regarded as fixed, which is pretty illogical. Therefore, we change the fixed effect model into a mixed model, where we include the random ‘genotype by environment’ interaction. We also change the fixed block effect into a random effect and remove the intercept, to more strictly adhere to the parameterisation of Equation 1. The two random effects ‘Loc:Block’ and ‘Loc:Var’ are not nested into each other and we need to code them by using ‘pdMat’ constructs, which are not straightforward. You can use the code in the box below as a guidance to fit a Finlay-Wilkinson model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Finlay-Wilkinson model
modFull1 &amp;lt;- lme(Yield ~ Var/ej - 1, 
                random = list(Loc = pdIdent(~ Var - 1),
                              Loc = pdIdent(~ Block - 1)), 
                data=dataFull)
summary(modFull1)$tTable
##              Value Std.Error  DF    t-value      p-value
## VarA    63.1666667 2.4017164 107 26.3006350 1.624334e-48
## VarB    66.1666667 2.4017164 107 27.5497417 2.135264e-50
## VarC    31.8333333 2.4017164 107 13.2544097 2.599693e-24
## VarD    47.1111111 2.4017164 107 19.6156012 3.170228e-37
## VarE    44.7222222 2.4017164 107 18.6209421 2.378452e-35
## VarF    34.2777778 2.4017164 107 14.2722004 1.614127e-26
## VarG    35.8888889 2.4017164 107 14.9430169 6.028635e-28
## VarA:ej  3.2249875 0.6257787 107  5.1535588 1.176645e-06
## VarB:ej  4.7936139 0.6257787 107  7.6602379 8.827229e-12
## VarC:ej  0.4771074 0.6257787 107  0.7624219 4.474857e-01
## VarD:ej  0.3653064 0.6257787 107  0.5837629 5.606084e-01
## VarE:ej  1.2369950 0.6257787 107  1.9767291 5.064533e-02
## VarF:ej -2.4316943 0.6257787 107 -3.8858692 1.770611e-04
## VarG:ej -0.6663160 0.6257787 107 -1.0647790 2.893729e-01
VarCorr(modFull1)
##          Variance           StdDev   
## Loc =    pdIdent(Var - 1)            
## VarA     27.5007919         5.2441197
## VarB     27.5007919         5.2441197
## VarC     27.5007919         5.2441197
## VarD     27.5007919         5.2441197
## VarE     27.5007919         5.2441197
## VarF     27.5007919         5.2441197
## VarG     27.5007919         5.2441197
## Loc =    pdIdent(Block - 1)          
## Block1    0.4478291         0.6692003
## Block2    0.4478291         0.6692003
## Block3    0.4478291         0.6692003
## Residual 20.8781458         4.5692610&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the output, we see that the variance component &lt;span class=&#34;math inline&#34;&gt;\(\sigma_d\)&lt;/span&gt; (27.50) is the same for all genotypes; if we want to let a different value for each genotype (Eberarth-Russel model), we need to change the ‘pdMat’ construct for the ‘Loc:Var’ effect, turning from ‘pdIdent’ to ‘pdDiag’, as shown in the box below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Eberhart-Russel model
modFull2 &amp;lt;- lme(Yield ~ Var/ej - 1, 
                random = list(Loc = pdDiag(~ Var - 1),
                              Loc = pdIdent(~ Block - 1)), 
                data=dataFull)
summary(modFull2)$tTable
##              Value Std.Error  DF    t-value      p-value
## VarA    63.1666667 3.0507629 107 20.7052032 3.221930e-39
## VarB    66.1666667 2.7818326 107 23.7852798 1.604422e-44
## VarC    31.8333333 1.7240721 107 18.4640387 4.753742e-35
## VarD    47.1111111 2.3526521 107 20.0246824 5.564350e-38
## VarE    44.7222222 2.4054296 107 18.5921974 2.699536e-35
## VarF    34.2777778 1.9814442 107 17.2993906 8.947485e-33
## VarG    35.8888889 2.2617501 107 15.8677515 7.076551e-30
## VarA:ej  3.2249875 0.7948909 107  4.0571447 9.466174e-05
## VarB:ej  4.7936139 0.7248198 107  6.6135249 1.522848e-09
## VarC:ej  0.4771074 0.4492152 107  1.0620909 2.905857e-01
## VarD:ej  0.3653064 0.6129948 107  0.5959372 5.524757e-01
## VarE:ej  1.2369950 0.6267462 107  1.9736777 5.099652e-02
## VarF:ej -2.4316943 0.5162748 107 -4.7100774 7.473942e-06
## VarG:ej -0.6663160 0.5893098 107 -1.1306718 2.607213e-01
VarCorr(modFull2)
##          Variance           StdDev   
## Loc =    pdDiag(Var - 1)             
## VarA     48.7341240         6.9809830
## VarB     39.3227526         6.2707856
## VarC     10.7257438         3.2750181
## VarD     26.1010286         5.1089166
## VarE     27.6077467         5.2543074
## VarF     16.4479246         4.0556041
## VarG     23.5842788         4.8563648
## Loc =    pdIdent(Block - 1)          
## Block1    0.4520678         0.6723599
## Block2    0.4520678         0.6723599
## Block3    0.4520678         0.6723599
## Residual 20.8743411         4.5688446&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From the regression slopes we see that the genotypes A and B are the most responsive to the environment (&lt;span class=&#34;math inline&#34;&gt;\(\beta_A = 3.22\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_B = 4.79\)&lt;/span&gt;, respectively), while the genotypes C and D are stable in a static sense, although their average yield is pretty low.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-a-joint-regression-model-in-two-steps-equation-2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fitting a joint regression model in two-steps (Equation 2)&lt;/h1&gt;
&lt;p&gt;In the previous analyses we used the plot data to fit a joint regression model. In order to reduce the computational burden, it may be useful to split the analyses in two-steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;we analyse the plot data, to retrieve the means for the ‘genotype by environment’ combinations;&lt;/li&gt;
&lt;li&gt;we fit the joint regression model to those means.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The results of the two approaches are not necessarily the same, as some information in the first step is lost in the second. Several weighing schemes have been proposed to make two-steps fitting more reliable (Möhring and Piepho, 2009); in this example, I will show an unweighted two-steps analyses, which is simple, but not necessarily the best way to go.&lt;/p&gt;
&lt;p&gt;A model for the second step is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ij} = \mu_i + \beta_i e_j + f_{ij} \quad\quad\quad \textrm{(Equation 2)}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the residual random component &lt;span class=&#34;math inline&#34;&gt;\(f_{ij}\)&lt;/span&gt; is assumed as normally distributed, with mean equal to zero and variance equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f\)&lt;/span&gt;. In general, &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_f &amp;gt; \sigma^2_d\)&lt;/span&gt;, as the residual sum of squares from Model 2 also contains a component for within trial errors. Indeed, for a balanced experiment, it is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma^2_{f} = \sigma^2_d + \frac{\sigma^2}{k}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; is the within-trial error, which needs to be obtained from the first step. In the previous analyses we have already fitted an anova model to the whole dataset (‘mod.aov’). In the box below, we make use of the ‘emmeans’ package to retrieve the least squares means for the seven genotypes in all locations. Subsequently, the environmental means are calculated and centered, by subtracting the overall mean.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(emmeans)
muGE &amp;lt;- as.data.frame( emmeans(mod.aov, ~Var:Loc) )[,1:3]
names(muGE) &amp;lt;- c(&amp;quot;Var&amp;quot;, &amp;quot;Loc&amp;quot;, &amp;quot;Yield&amp;quot;)
muGE &amp;lt;- muGE %&amp;gt;% 
  group_by(Loc) %&amp;gt;% 
  mutate(ej = mean(Yield) - mean(muGE$Yield))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we fit Equation 2 to the means. In the code below we assume homoscedasticity and, thus, we are fitting the Finlay-Wilkinson model. The variance component &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_d\)&lt;/span&gt; is obtained by subtracting a fraction of the residual variance from the first step.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Finlay-Wilkinson model
modFinlay &amp;lt;- lm(Yield ~ Var/ej - 1, data=muGE)
summary(modFinlay)
## 
## Call:
## lm(formula = Yield ~ Var/ej - 1, data = muGE)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -7.3981 -3.5314 -0.8864  3.7791 11.2045 
## 
## Coefficients:
##         Estimate Std. Error t value Pr(&amp;gt;|t|)    
## VarA     63.1667     2.3915  26.413  &amp;lt; 2e-16 ***
## VarB     66.1667     2.3915  27.668  &amp;lt; 2e-16 ***
## VarC     31.8333     2.3915  13.311 1.24e-13 ***
## VarD     47.1111     2.3915  19.699  &amp;lt; 2e-16 ***
## VarE     44.7222     2.3915  18.701  &amp;lt; 2e-16 ***
## VarF     34.2778     2.3915  14.333 2.02e-14 ***
## VarG     35.8889     2.3915  15.007 6.45e-15 ***
## VarA:ej   3.2250     0.6231   5.176 1.72e-05 ***
## VarB:ej   4.7936     0.6231   7.693 2.22e-08 ***
## VarC:ej   0.4771     0.6231   0.766 0.450272    
## VarD:ej   0.3653     0.6231   0.586 0.562398    
## VarE:ej   1.2370     0.6231   1.985 0.056998 .  
## VarF:ej  -2.4317     0.6231  -3.902 0.000545 ***
## VarG:ej  -0.6663     0.6231  -1.069 0.294052    
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## Residual standard error: 5.858 on 28 degrees of freedom
## Multiple R-squared:  0.9905, Adjusted R-squared:  0.9857 
## F-statistic: 208.3 on 14 and 28 DF,  p-value: &amp;lt; 2.2e-16
sigmaf &amp;lt;- summary(modFinlay)$sigma^2 
sigma2 &amp;lt;- summary(mod.aov)$sigma^2 
sigmaf - sigma2/3 #sigma2_d
## [1] 27.43169&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the box below, we allow for different variances for each genotype and, therefore, we fit the Eberarth-Russel model. As before, we can retrieve the variance components &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{d(i)}\)&lt;/span&gt; from the fitted model object, by subtracting the within-trial error obtained in the first step.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Eberarth-Russel model
modEberarth &amp;lt;- gls(Yield ~ Var/ej - 1, 
              weights=varIdent(form=~1|Var), data=muGE)
coefs &amp;lt;- summary(modEberarth)$tTable
coefs
##              Value Std.Error    t-value      p-value
## VarA    63.1666667 3.0434527 20.7549360 1.531581e-18
## VarB    66.1666667 2.7653537 23.9270177 3.508778e-20
## VarC    31.8333333 1.7165377 18.5450822 2.912238e-17
## VarD    47.1111111 2.3344802 20.1805574 3.204306e-18
## VarE    44.7222222 2.3899219 18.7128381 2.304763e-17
## VarF    34.2777778 1.9783684 17.3262868 1.685683e-16
## VarG    35.8888889 2.2589244 15.8876005 1.537133e-15
## VarA:ej  3.2249875 0.7929862  4.0668898 3.511248e-04
## VarB:ej  4.7936139 0.7205262  6.6529352 3.218756e-07
## VarC:ej  0.4771074 0.4472521  1.0667527 2.951955e-01
## VarD:ej  0.3653064 0.6082600  0.6005761 5.529531e-01
## VarE:ej  1.2369950 0.6227056  1.9864844 5.684599e-02
## VarF:ej -2.4316943 0.5154734 -4.7174004 6.004832e-05
## VarG:ej -0.6663160 0.5885736 -1.1320862 2.672006e-01
sigma &amp;lt;- summary(modEberarth)$sigma
sigma2fi &amp;lt;- (c(1, coef(modEberarth$modelStruct$varStruct, uncons = FALSE)) * sigma)^2
names(sigma2fi)[1] &amp;lt;- &amp;quot;A&amp;quot;
sigma2fi - sigma2/3 #sigma2_di
##        A        B        C        D        E        F        G 
## 48.69203 38.99949 10.79541 25.81519 27.38676 16.60005 23.73284&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fitting in two steps we obtain the very same result as with fitting in one step, but it ain’t necessarily so.&lt;/p&gt;
&lt;p&gt;I would like to conclude by saying that a joint regression model, the way I have fitted it here, is simple and intuitively appealing, although it has been criticized for a number of reasons. In particular, it has been noted that the environmental indices &lt;span class=&#34;math inline&#34;&gt;\(e_j\)&lt;/span&gt; are estimated from the observed data and, therefore, they are not precisely known. On the contrary, linear regression makes the assumption that the levels of explanatory variables are precisely known and not sampled. As the consequence, our estimates of the slopes &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; may be biased. Furthermore, in our construction we have put some arbitrary constraints on the environmental indices (&lt;span class=&#34;math inline&#34;&gt;\(\sum{e_j} = 0\)&lt;/span&gt;) and on the regression slopes (&lt;span class=&#34;math inline&#34;&gt;\(\sum({\beta_i})/G = 1\)&lt;/span&gt;; where G is the number of genotypes), which are not necessarily reasonable.&lt;/p&gt;
&lt;p&gt;Alternative methods of fitting joint regression models have been proposed (see Piepho, 1998), but they are slightly more complex and I will deal with them in a future post.&lt;/p&gt;
&lt;p&gt;Happy coding!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Eberhart, S.A., Russel, W.A., 1966. Stability parameters for comparing verieties. Crop Science 6, 36–40.&lt;/li&gt;
&lt;li&gt;Finlay, K.W., Wilkinson, G.N., 1963. The analysis of adaptation in a plant-breeding programme. Australian Journal of Agricultural Research 14, 742–754.&lt;/li&gt;
&lt;li&gt;Möhring, J., Piepho, H.-P., 2009. Comparison of Weighting in Two-Stage Analysis of Plant Breeding Trials. Crop Science 49, 1977–1988.&lt;/li&gt;
&lt;li&gt;Perkins, J.M., Jinks, J.L., 1968. Environmental gentype-environmental components of variability. III. Multiple lines and crosses. Heredity 23, 339–356.&lt;/li&gt;
&lt;li&gt;Piepho, H.-P., 1998. Methods for comparing the yield stability of cropping systems - A review. Journal of Agronomy and Crop Science 180, 193–213.&lt;/li&gt;
&lt;li&gt;Wood, J., 1976. The use of environmental variables in the interpretation of genotype-environment interaction. Heredity 37, 1–7.&lt;/li&gt;
&lt;li&gt;Yates, F., and Cochran G., 1938. The analysis of groups of experiments. Journal of Agricultural Sciences, 28, 556—580.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>AMMI analyses for GE interactions</title>
      <link>https://www.statforbiology.com/2020/stat_met_ammi/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2020/stat_met_ammi/</guid>
      <description>


&lt;p&gt;The CoViD-19 situation in Italy is little by little improving and I feel a bit more optimistic. It’s time for a new post! I will go back to a subject that is rather important for most agronomists, i.e. the selection of crop varieties.&lt;/p&gt;
&lt;p&gt;All farmers are perfectly aware that crop performances are affected both by the genotype and by the environment. These two effects are not purely additive and they often show a significant interaction. By this word, we mean that a genotype can give particularly good/bad performances in some specific environmental situations, which we may not expect, considering its average behaviour in other environmental conditions. The Genotype by Environment (GE) interaction may cause changes in the ranking of genotypes, depending on the environment and may play a key role in varietal recommendation, for a given mega-environment.&lt;/p&gt;
&lt;p&gt;GE interactions are usually studied by way of Multi-Environment Trials (MET), where experiments are repeated across several years, locations or any combinations of those. Traditional techniques of data analyses, such as two-way ANOVA, give very little insight on the stability/reliability of genotypes across environments and, thus, other specialised techniques are necessary to shed light on interaction effects. I have already talked about stability analyses in other posts, such as &lt;a href=&#34;https://www.statforbiology.com/2019/stat_lmm_stabilityvariance/&#34;&gt;in this post about the stability variance&lt;/a&gt; or in this &lt;a href=&#34;https://www.statforbiology.com/2019/stat_lmm_environmentalvariance/&#34;&gt;other post about the environmental variance&lt;/a&gt;. Now, I would like to propose some simple explanations about AMMI analysis. AMMI stands for: &lt;strong&gt;Additive Main effect Multiplicative Interaction&lt;/strong&gt; and it has become very much in fashion in the last 20-25 years.&lt;/p&gt;
&lt;p&gt;Let’s start with a real MET example.&lt;/p&gt;
&lt;div id=&#34;a-met-with-faba-bean&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A MET with faba bean&lt;/h1&gt;
&lt;p&gt;This experiment consists of 12 faba bean genotypes (well, it was, indeed, 6 genotypes in two sowing dates; but, let’s disregard this detail from now on) in four blocks, two locations and three years (six environments, in all). The dataset is online available as ‘fabaBean.csv’. It has been published by Stagnari et al. (2007).&lt;/p&gt;
&lt;p&gt;First of all, let’s load the dataset and transform the block variable into a factor. Let’s also inspect the two-way table of means, together with the marginal means for genotypes and environments, which will be useful later. In this post, we will make use of the packages ‘dplyr’ (Wickham &lt;em&gt;et al&lt;/em&gt;., 2020), ‘emmeans’ (Lenth, 2020) and ‘aomisc’; this latter is the companion package for this website and must have been installed as detailed in this &lt;a href=&#34;https://www.statforbiology.com/rpackages/&#34;&gt;page here&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# options(width = 70)

rm(list=ls())
# library(devtools)
# install_github(&amp;quot;OnofriAndreaPG/aomisc&amp;quot;)
library(reshape)
library(emmeans)
library(aomisc)

fileName &amp;lt;- &amp;quot;https://www.casaonofri.it/_datasets/fabaBean.csv&amp;quot;
dataset &amp;lt;- read.csv(fileName, header=T)
dataset &amp;lt;- transform(dataset, Block = factor(Block),
                     Genotype = factor(Genotype),
                     Environment = factor(Environment))
head(dataset)
##      Genotype Block Environment Yield
## 1    Chiaro_A     1       bad_1  4.36
## 2    Chiaro_P     1       bad_1  2.76
## 3 Collameno_A     1       bad_1  3.01
## 4 Collameno_P     1       bad_1  2.50
## 5    Palomb_A     1       bad_1  3.85
## 6    Palomb_P     1       bad_1  2.21
#
# Two-ways table of means
GEmedie &amp;lt;- cast(Genotype ~ Environment, data = dataset,
                value = &amp;quot;Yield&amp;quot;, fun=mean)
GEmedie
##       Genotype  bad_1  bad_2  bad_3  pap_1  pap_2  pap_3
## 1     Chiaro_A 4.1050 2.3400 4.1250 4.6325 2.4100 3.8500
## 2     Chiaro_P 2.5075 1.3325 4.2025 3.3225 1.4050 4.3175
## 3  Collameno_A 3.2500 2.1150 4.3825 3.8475 2.2325 4.0700
## 4  Collameno_P 1.9075 0.8475 3.8650 2.5200 0.9850 4.0525
## 5     Palomb_A 3.8400 2.0750 4.2050 5.0525 2.6850 4.6675
## 6     Palomb_P 2.2500 0.9725 3.2575 3.2700 0.8825 4.0125
## 7      Scuro_A 4.3700 2.1050 4.1525 4.8625 2.1275 4.2050
## 8      Scuro_P 3.0500 1.6375 3.9300 3.7200 1.7475 4.5125
## 9    Sicania_A 3.8300 1.9450 4.5050 3.9550 2.2350 4.2350
## 10   Sicania_P 3.2700 0.9900 3.7300 4.0475 0.8225 3.8950
## 11   Vesuvio_A 4.1375 2.0175 4.0275 4.5025 2.2650 4.3225
## 12   Vesuvio_P 2.1225 1.1800 3.5250 3.0950 0.9375 3.6275
#
# Marginal means for genotypes
apply(GEmedie, 1, mean)
##    Chiaro_A    Chiaro_P Collameno_A Collameno_P    Palomb_A 
##    3.577083    2.847917    3.316250    2.362917    3.754167 
##    Palomb_P     Scuro_A     Scuro_P   Sicania_A   Sicania_P 
##    2.440833    3.637083    3.099583    3.450833    2.792500 
##   Vesuvio_A   Vesuvio_P 
##    3.545417    2.414583
#
# Marginal means for environments
apply(GEmedie, 2, mean)
##    bad_1    bad_2    bad_3    pap_1    pap_2    pap_3 
## 3.220000 1.629792 3.992292 3.902292 1.727917 4.147292
#
# Overall mean
mean(as.matrix(GEmedie))
## [1] 3.103264&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What model could we possibly fit to the above data? The basic two-way ANOVA model is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y_{ijk} = \mu + \gamma_{jk} + g_i + e_j + ge_{ij} + \varepsilon_{ijk} \quad \quad (1)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the yield &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for given block &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;, environment &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; and genotype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is described as a function of the effects of blocks within environments (&lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt;), genotypes (&lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt;), environments (&lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt;) and GE interaction (&lt;span class=&#34;math inline&#34;&gt;\(ge\)&lt;/span&gt;). The residual error term &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon\)&lt;/span&gt; is assumed to be normal and homoscedastic, with standard deviation equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Let’s also assume that both the genotype and environment effects are fixed: this is useful for teaching purposes and it is reasonable, as we intend to study the behaviour of specific genotypes in several specific environments.&lt;/p&gt;
&lt;p&gt;The interaction effect &lt;span class=&#34;math inline&#34;&gt;\(ge\)&lt;/span&gt;, under some important assumptions (i.e. balanced data, no missing cells and homoscedastic errors), is given by:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ge_{ij} = Y_{ij.} - \left( \mu + g_i + e_j \right) = Y_{ij.} - Y_{i..} - Y_{.j.} + \mu \quad \quad (2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(Y_{ij.}\)&lt;/span&gt; is the mean of the combination between the genotype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and the environment &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(Y_{i..}\)&lt;/span&gt; is the mean for the genotype &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y_{.j.}\)&lt;/span&gt; is the mean for the environment &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;. For example, for the genotype ‘Chiaro_A’ in the environment ‘bad_1’, the interaction effect was:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;4.1050 - 3.577 - 3.22 + 3.103
## [1] 0.411&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the interaction was positive, in the sense that ‘Chiaro_A’, gave 0.411 tons per hectare more than we could have expected, considering its average performances across environments and the average performances of all genotypes in ‘bad_1’.&lt;/p&gt;
&lt;p&gt;More generally, the two-way table of interaction effects can be obtained by doubly centring the matrix of means, as shown in the following box.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GE &amp;lt;- as.data.frame(t(scale( t(scale(GEmedie, center=T,
 scale=F)), center=T, scale=F)))
print(round(GE, 3))
##              bad_1  bad_2  bad_3  pap_1  pap_2  pap_3
## Chiaro_A     0.411  0.236 -0.341  0.256  0.208 -0.771
## Chiaro_P    -0.457 -0.042  0.466 -0.324 -0.068  0.426
## Collameno_A -0.183  0.272  0.177 -0.268  0.292 -0.290
## Collameno_P -0.572 -0.042  0.613 -0.642 -0.003  0.646
## Palomb_A    -0.031 -0.206 -0.438  0.499  0.306 -0.131
## Palomb_P    -0.308  0.005 -0.072  0.030 -0.183  0.528
## Scuro_A      0.616 -0.059 -0.374  0.426 -0.134 -0.476
## Scuro_P     -0.166  0.011 -0.059 -0.179  0.023  0.369
## Sicania_A    0.262 -0.032  0.165 -0.295  0.160 -0.260
## Sicania_P    0.361 -0.329  0.048  0.456 -0.595  0.058
## Vesuvio_A    0.475 -0.054 -0.407  0.158  0.095 -0.267
## Vesuvio_P   -0.409  0.239  0.221 -0.119 -0.102  0.169&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please, note that the overall mean for all elements in ‘GE’ is zero and the sum of squares is equal to a fraction of the interaction sum of squares in ANOVA (that is &lt;span class=&#34;math inline&#34;&gt;\(RMSE/r\)&lt;/span&gt;; where &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt; is the number of blocks).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(unlist(GE))
## [1] 6.914424e-18
sum(GE^2)
## [1] 7.742996
mod &amp;lt;- lm(Yield ~ Environment/Block + Genotype*Environment, data = dataset)
anova(mod)
## Analysis of Variance Table
## 
## Response: Yield
##                       Df Sum Sq Mean Sq  F value    Pr(&amp;gt;F)    
## Environment            5 316.57  63.313 580.9181 &amp;lt; 2.2e-16 ***
## Genotype              11  70.03   6.366  58.4111 &amp;lt; 2.2e-16 ***
## Environment:Block     18   6.76   0.375   3.4450 8.724e-06 ***
## Environment:Genotype  55  30.97   0.563   5.1669 &amp;lt; 2.2e-16 ***
## Residuals            198  21.58   0.109                       
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
30.97/4
## [1] 7.7425&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;decomposing-the-ge-matrix&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Decomposing the GE matrix&lt;/h1&gt;
&lt;p&gt;It would be nice to be able to give a graphical summary of the GE matrix; in this regard, we could think of using Principal Component Analysis (PCA) via Singular Value Decomposition (SVD). This has been shown by Zobel &lt;em&gt;et al&lt;/em&gt;. (1988) and, formerly, by Gollob (1968). May I just remind you a few things about PCA and SVD? No overwhelming math detail, I promise!&lt;/p&gt;
&lt;p&gt;Most matrices (and our GE matrix) can be decomposed as the product of three matrices, according to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X = U D V^T \quad \quad (3)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is the matrix to be decomposed, &lt;span class=&#34;math inline&#34;&gt;\(U\)&lt;/span&gt; is the matrix of the first &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; eigenvectors of &lt;span class=&#34;math inline&#34;&gt;\(XX^T\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(V\)&lt;/span&gt; is the matrix of the first &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; eigenvectors of &lt;span class=&#34;math inline&#34;&gt;\(X^T X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(D\)&lt;/span&gt; is the diagonal matrix of the first &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; singular values of &lt;span class=&#34;math inline&#34;&gt;\(XX^T\)&lt;/span&gt; (or &lt;span class=&#34;math inline&#34;&gt;\(X^T X\)&lt;/span&gt;; it does not matter, they are the same).&lt;/p&gt;
&lt;p&gt;Indeed, if we want to decompose our GE matrix, it is more clever (and more useful to our purposes), to write the following matrices:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[S_g = U D^{1/2} \quad \quad (4)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[S_e = V D^{1/2} \quad \quad (5)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;so that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[GE = S_g \, S_e^T \quad \quad (6)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(S_g\)&lt;/span&gt; is the matrix of row-scores (genotype scores) and &lt;span class=&#34;math inline&#34;&gt;\(S_e\)&lt;/span&gt; is the matrix of column scores (environment scores). Let me give you an empirical proof, in the box below. In order to find &lt;span class=&#34;math inline&#34;&gt;\(S_g\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S_e\)&lt;/span&gt;, I will use a mathematical operation that is known as Singular Value Decomposition (SVD):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;U &amp;lt;- svd(GE)$u
V &amp;lt;- svd(GE)$v
D &amp;lt;- diag(svd(GE)$d)
Sg &amp;lt;- U %*% sqrt(D)
Se &amp;lt;- V %*% sqrt(D)
row.names(Sg) &amp;lt;- levels(dataset$Genotype)
row.names(Se) &amp;lt;- levels(dataset$Environment)
colnames(Sg) &amp;lt;- colnames(Se) &amp;lt;- paste(&amp;quot;PC&amp;quot;, 1:6, sep =&amp;quot;&amp;quot;)
round(Sg %*% t(Se), 3)
##              bad_1  bad_2  bad_3  pap_1  pap_2  pap_3
## Chiaro_A     0.411  0.236 -0.341  0.256  0.208 -0.771
## Chiaro_P    -0.457 -0.042  0.466 -0.324 -0.068  0.426
## Collameno_A -0.183  0.272  0.177 -0.268  0.292 -0.290
## Collameno_P -0.572 -0.042  0.613 -0.642 -0.003  0.646
## Palomb_A    -0.031 -0.206 -0.438  0.499  0.306 -0.131
## Palomb_P    -0.308  0.005 -0.072  0.030 -0.183  0.528
## Scuro_A      0.616 -0.059 -0.374  0.426 -0.134 -0.476
## Scuro_P     -0.166  0.011 -0.059 -0.179  0.023  0.369
## Sicania_A    0.262 -0.032  0.165 -0.295  0.160 -0.260
## Sicania_P    0.361 -0.329  0.048  0.456 -0.595  0.058
## Vesuvio_A    0.475 -0.054 -0.407  0.158  0.095 -0.267
## Vesuvio_P   -0.409  0.239  0.221 -0.119 -0.102  0.169&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s have a look at &lt;span class=&#34;math inline&#34;&gt;\(S_g\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S_e\)&lt;/span&gt;: they are two interesting entities. I will round up a little to make them smaller, and less scaring.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;round(Sg, 3)
##                PC1    PC2    PC3    PC4    PC5 PC6
## Chiaro_A    -0.607 -0.384  0.001  0.208 -0.063   0
## Chiaro_P     0.552  0.027 -0.081  0.045  0.164   0
## Collameno_A  0.084 -0.542 -0.006  0.176  0.057   0
## Collameno_P  0.807 -0.066 -0.132 -0.172  0.079   0
## Palomb_A    -0.321  0.110  0.591 -0.083  0.389   0
## Palomb_P     0.281  0.346  0.282  0.042 -0.253   0
## Scuro_A     -0.626  0.139 -0.163  0.017 -0.080   0
## Scuro_P      0.230  0.077  0.182 -0.207 -0.242   0
## Sicania_A   -0.063 -0.324 -0.355 -0.280  0.090   0
## Sicania_P   -0.214  0.683 -0.402  0.148  0.151   0
## Vesuvio_A   -0.438 -0.008  0.020 -0.300 -0.177   0
## Vesuvio_P    0.316 -0.058  0.063  0.405 -0.114   0
round(Se, 3)
##          PC1    PC2    PC3    PC4    PC5 PC6
## bad_1 -0.831  0.095 -0.467 -0.317 -0.151   0
## bad_2  0.044 -0.418  0.070  0.371 -0.403   0
## bad_3  0.670 -0.130 -0.525  0.171  0.298   0
## pap_1 -0.661  0.513  0.289  0.314  0.221   0
## pap_2 -0.069 -0.627  0.420 -0.294  0.208   0
## pap_3  0.846  0.567  0.213 -0.244 -0.173   0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Both matrices have 6 columns. Why six, are you asking? I promised I would not go into math detail; it’s enough to know that the number of columns is always equal to the minimum value between the number of genotypes and the number of environments. The final column is irrelevant (all elements are 0). &lt;span class=&#34;math inline&#34;&gt;\(S_g\)&lt;/span&gt; has 12 rows, one per genotype; these are the so called genotype scores: each genotype has six scores. &lt;span class=&#34;math inline&#34;&gt;\(S_e\)&lt;/span&gt; has six rows, one per environment (environment scores).&lt;/p&gt;
&lt;p&gt;You may have some ‘rusty’ memories about matrix multiplication; however, what we have discovered in the code box above is that the GE interaction for the &lt;span class=&#34;math inline&#34;&gt;\(i^{th}\)&lt;/span&gt; genotype and the &lt;span class=&#34;math inline&#34;&gt;\(j^{th}\)&lt;/span&gt; environment can be obtained as the product of genotype scores and environments scores. Indeed:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ge_{ij} = \sum_{z = 1}^n \left[ S_g(iz) \cdot S_e(jz) \right] \quad \quad (7)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is the number of columns (number of principal components). An example is in order, at this point; again, let’s consider the first genotype and the first environment. The genotype and environments scores are in the first columns of &lt;span class=&#34;math inline&#34;&gt;\(S_g\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S_e\)&lt;/span&gt;; if we multiply the elements in the same positioning (1st with 1st, 2nd with 2nd, and so on) and sum up, we get:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;-0.607 * -0.831 +
-0.384 *  0.095 +
 0.001 * -0.467 +
 0.208 * -0.317 + 
-0.063 * -0.151 +
     0 * 0
## [1] 0.411047&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s done: we have transformed the interaction effect into the sum of multiplicative terms. If we replace Equation 7 into the ANOVA model above (Equation 1), we obtain an &lt;em&gt;Additive Main effects Multiplicative Interaction&lt;/em&gt; model, i.e. an AMMI model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;reducing-the-rank&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Reducing the rank&lt;/h1&gt;
&lt;p&gt;In this case we took all available columns in &lt;span class=&#34;math inline&#34;&gt;\(S_g\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S_e\)&lt;/span&gt;. For the sake of simplicity, we could have taken only a subset of those columns. The Eckart-Young (1936) theorem says that, if we take &lt;span class=&#34;math inline&#34;&gt;\(m &amp;lt; 6\)&lt;/span&gt; columns, we obtain the best possible approximation of GE in reduced rank space. For example, let’s use the first two columns of &lt;span class=&#34;math inline&#34;&gt;\(S_g\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S_e\)&lt;/span&gt; (the first two principal component scores):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;PC &amp;lt;- 2
Sg2 &amp;lt;- Sg[,1:PC]
Se2 &amp;lt;- Se[,1:PC]
GE2 &amp;lt;- Sg2 %*% t(Se2)
print ( round(GE2, 3) )
##              bad_1  bad_2  bad_3  pap_1  pap_2  pap_3
## Chiaro_A     0.468  0.134 -0.357  0.205  0.282 -0.732
## Chiaro_P    -0.456  0.013  0.367 -0.351 -0.055  0.482
## Collameno_A -0.122  0.230  0.127 -0.334  0.334 -0.236
## Collameno_P -0.676  0.063  0.549 -0.567 -0.014  0.645
## Palomb_A     0.277 -0.060 -0.230  0.269 -0.047 -0.209
## Palomb_P    -0.201 -0.132  0.144 -0.009 -0.236  0.434
## Scuro_A      0.534 -0.086 -0.438  0.486 -0.044 -0.451
## Scuro_P     -0.184 -0.022  0.144 -0.113 -0.064  0.238
## Sicania_A    0.022  0.133  0.000 -0.124  0.207 -0.237
## Sicania_P    0.243 -0.295 -0.232  0.492 -0.414  0.206
## Vesuvio_A    0.363 -0.016 -0.293  0.286  0.035 -0.375
## Vesuvio_P   -0.268  0.038  0.219 -0.239  0.015  0.234&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;GE2 is not equal to GE, but it is a close approximation. A close approximation in what sense?… you may wonder. Well, the sum of squared elements in GE2 is as close as possible (with &lt;span class=&#34;math inline&#34;&gt;\(n = 2\)&lt;/span&gt;) to the sum of squared elements in GE:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(GE2^2)
## [1] 6.678985&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that the sum of squares in GE2 is 86% of the sum of squares in GE. A very good approximation, isn’t it? It means that the variability of yield across environments is described well enough by using a relatively low number of parameters (scores). However, the multiplicative part of our AMMI model needs to be modified:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ge_{ij} = \sum_{z = 1}^m \left[ s_{g(iz)} \cdot s_{e(jz)} \right] + \xi_{ij}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Indeed, a residual term &lt;span class=&#34;math inline&#34;&gt;\(\xi_{ij}\)&lt;/span&gt; is necessary, to account for the fact that the sum of multiplicative terms is not able to fully recover the original matrix GE. Another example? For the first genotype and the first environment the multiplicative interaction is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;-0.607 * -0.831 + -0.384 * 0.095
## [1] 0.467937&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the residual term &lt;span class=&#34;math inline&#34;&gt;\(\xi_{11}\)&lt;/span&gt; is&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;0.41118056 -0.607 * -0.831 + -0.384 * 0.095
## [1] 0.8791176&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Clearly, the residual terms need to be small enough to be negligible, otherwise the approximation in reduced rank space is not good enough.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-is-this-useful&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Why is this useful?&lt;/h1&gt;
&lt;p&gt;Did you get lost? Hope you didn’t, but let’s make a stop and see where we are standing now. We started from the interaction matrix GE and found a way to decompose it as the product of two matrices, i.e. &lt;span class=&#34;math inline&#34;&gt;\(S_g\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S_e\)&lt;/span&gt;, a matrix of genotype scores and a matrix of environment scores. We discovered that we could obtain a good approximation of GE by working in reduced rank space and we only used two genotypic scores and two environment scores, in place of the available six.&lt;/p&gt;
&lt;p&gt;This is great! Now we have the ability of drawing a biplot, i.e. we can plot both genotypic scores and environmental scores in a dispersion graph (biplot: two plots in one), as we see below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;biplot(Sg[,1:2], Se[,1:2], xlim = c(-1, 1), ylim = c(-1, 1),
       xlab = &amp;quot;PC 1&amp;quot;, ylab = &amp;quot;PC 2&amp;quot;)
abline(h = 0, lty = 2)
abline(v = 0, lty = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://www.statforbiology.com/post/Stat_met_AMMI_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This graph provides a very effective description of GE interaction effects. I will not go into detail, here. Just a few simple comments:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;genotypes and environments lying close to the origin of the axes do not interact with each other (the product of scores would be close to 0)&lt;/li&gt;
&lt;li&gt;genotype and environments lying far away from the origin of axes show very big interaction and, therefore, high yield instability. Someone says that the euclidean distance from the origin should be taken as a measure of instability&lt;/li&gt;
&lt;li&gt;the interaction is positive, when genotypes and environments are close to each other. If two objects are close, their scores (co-ordinates) will have the same signs and thus their product will be positive.&lt;/li&gt;
&lt;li&gt;the interaction is negative, when genotypes and environments are far away from each other. If two objects are distant, their scores (co-ordinates) will have opposte signs and thus their product will be negative.&lt;/li&gt;
&lt;li&gt;For instance, ‘Palomb_P’, ‘Scuro_P’, ‘Chiaro_P’ and ‘Collameno_P’ gave particularly good yields in the environments ‘pap_3’ and ‘bad_3’, while ‘Scuro_A’, ‘Palomb_A’ and ‘Vesuvio_A’ gave particularly good yields (compared to their average) in the environments ‘pap_1’ and ‘bad_1’. ‘Sicania_A’ and ‘Collameno_A’ gave good yields in ‘bad_2’ and ‘pap_2’.&lt;/li&gt;
&lt;/ol&gt;
&lt;div id=&#34;how-many-components&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How many components?&lt;/h2&gt;
&lt;p&gt;In my opinion, AMMI analysis is mainly a visualisation method. Therefore, we should select as many components (columns in &lt;span class=&#34;math inline&#34;&gt;\(S_g\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(S_e\)&lt;/span&gt;) as necessary to describe a main part of the interaction sum of squares. In our example, two components are enough, as they represent 86% of the interaction sum of squares.&lt;/p&gt;
&lt;p&gt;However, many people (and reviewers) are still very concerned with formal hypothesis testing. Therefore, we could proceed in a sequential fashion, and introduce the components one by one.&lt;/p&gt;
&lt;p&gt;The first component has a sum of squares equal to:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;PC &amp;lt;- 1
Sg2 &amp;lt;- Sg[,1:PC]
Se2 &amp;lt;- Se[,1:PC]
GE2 &amp;lt;- Sg2 %*% t(Se2)
sum(GE2^2)
## [1] 5.290174&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have seen that the second component has an additional sum of squares equal to:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;6.678985 - 5.290174
## [1] 1.388811&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can go further ahead and get the sum of squares for all components. According to Zobel (1988), the degrees of freedom for each component are equal to:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ df_n = i + j - 1 - 2m \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is the number of genotypes, &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is the number of environments, and &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; is the number of the selected components. In our case, the first PC has 15 DF, the second one has 13 DF and so on.&lt;/p&gt;
&lt;p&gt;If we can have a reliable estimate of the pure error variance &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt; (see above), we can test the significance of each component by using F tests (although some authors argue that this is too a liberal approach; see Cornelius, 1993).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simple-ammi-analysis-with-r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Simple AMMI analysis with R&lt;/h1&gt;
&lt;p&gt;We have seen that AMMI analysis, under the hood, is a sort of PCA. Therefore, it could be performed, in R by using one of the available packages for PCA. For the sake of simplicity, I have coded a couple of functions, i.e. ‘AMMI()’ and ‘AMMImeans()’ and they are both available in the ‘aomisc’ package. I have described the first one a few years ago in an R news paper (&lt;a href=&#34;https://www.researchgate.net/publication/289419258_Using_R_to_perform_the_AMMI_analysis_on_agriculture_variety_trials&#34;&gt;Onofri and Ciriciofolo, 2007&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Here, I will describe the second one, which permits to handle a small degree of unbalance (a few plots, missing at random). The analysis proceeds in two steps.&lt;/p&gt;
&lt;div id=&#34;first-step-on-raw-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;First step on raw data&lt;/h2&gt;
&lt;p&gt;During the first step we need to obtain a reliable matrix of means for the ‘genotype x environment’ combinations. If the environment is fixed, we can use least squares means, which are unbiased, also when some observations are missing. If the environment effect is random, we could use the BLUPs, but we will not consider such an option here.&lt;/p&gt;
&lt;p&gt;In the box below we take the ‘mod’ object from a two way ANOVA fit and derive the residual mean square (RMSE), which we divide by the number of blocks. This will be our error term to test the significance of components. Later, we pass the ‘mod’ object to the ‘emmeans()’ function, to retrieve the expected marginal means for the ‘genotype by environment’ combinations and proceed to the second step.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;RMSE &amp;lt;- summary(mod)$sigma^2 / 4
dfr &amp;lt;- mod$df.residual
ge.lsm &amp;lt;- emmeans(mod, ~Genotype:Environment)
ge.lsm &amp;lt;- data.frame(ge.lsm)[,1:3]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;second-step-on-least-square-means&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Second step on least square means&lt;/h2&gt;
&lt;p&gt;This second step assumes that the residual variances for all environments are homogeneous. If so (we’d better check this), we can take the expected marginal means (‘ge.lsm’) and submit them to AMMI analysis, by using the ‘AMMImeans()’ function. The syntax is fairly obvious; we also pass to it the RMSE and its degrees of freedom. The resulting object can be explored, by using the appropriate slots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AMMIobj &amp;lt;- AMMImeans(yield = ge.lsm$emmean, 
                     genotype = ge.lsm$Genotype, 
                     environment = ge.lsm$Environment, 
                     MSE = RMSE, dfr = dfr)
#
AMMIobj$genotype_scores
##                     PC1          PC2
## Chiaro_A    -0.60710888 -0.383732821
## Chiaro_P     0.55192742  0.026531045
## Collameno_A  0.08444877 -0.542185666
## Collameno_P  0.80677055 -0.065752971
## Palomb_A    -0.32130513  0.110117240
## Palomb_P     0.28104959  0.345909298
## Scuro_A     -0.62638795  0.139185954
## Scuro_P      0.22961347  0.076555540
## Sicania_A   -0.06286803 -0.323857285
## Sicania_P   -0.21433211  0.683296898
## Vesuvio_A   -0.43786742 -0.007914342
## Vesuvio_P    0.31605973 -0.058152890
#
AMMIobj$environment_scores
##               PC1         PC2
## bad_1 -0.83078550  0.09477362
## bad_2  0.04401963 -0.41801637
## bad_3  0.67043214 -0.12977423
## pap_1 -0.66137357  0.51268429
## pap_2 -0.06863235 -0.62703224
## pap_3  0.84633965  0.56736492
#
round(AMMIobj$summary, 4)
##   PC Singular_value  PC_SS Perc_of_Total_SS cum_perc
## 1  1         2.3000 5.2902          68.3220  68.3220
## 2  2         1.1785 1.3888          17.9364  86.2584
## 3  3         0.8035 0.6456           8.3375  94.5959
## 4  4         0.5119 0.2621           3.3846  97.9806
## 5  5         0.3954 0.1564           2.0194 100.0000
## 6  6         0.0000 0.0000           0.0000 100.0000
#
round(AMMIobj$anova, 4)
##   PC     SS DF     MS       F P.value
## 1  1 5.2902 15 0.3527 12.9437  0.0000
## 2  2 1.3888 13 0.1068  3.9208  0.0000
## 3  3 0.6456 11 0.0587  2.1539  0.0184
## 4  4 0.2621  9 0.0291  1.0687  0.3876
## 5  5 0.1564  7 0.0223  0.8198  0.5718
## 6  6 0.0000  5 0.0000  0.0000  1.0000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In detail, we can retrieve the genotype and environment scores, the proportion of the GE variance explained by each component and the significance of PCs.&lt;/p&gt;
&lt;p&gt;Just to show you, the box below reports the code for AMMI analysis on raw data. Please, note that this only works with balanced data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AMMIobj2 &amp;lt;- AMMI(yield = dataset$Yield, 
                 genotype = dataset$Genotype,
                 environment = dataset$Environment, 
                 block = dataset$Block)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I agree, these functions are not very ambitious. However, they are simple enough to be usable and give reliable results, as long as the basic assumptions for the method are respected. You may also consider to explore other more comprehensive R packages, such as ‘agricolae’ (de Mendiburu, 2020).&lt;/p&gt;
&lt;p&gt;Thank you for reading, so far, and… happy coding!&lt;/p&gt;
&lt;p&gt;Prof. Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;br /&gt;
Borgo XX Giugno 74&lt;br /&gt;
I-06121 - PERUGIA&lt;/p&gt;
&lt;hr /&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;literature-references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Literature references&lt;/h1&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Annichiarico, P. (1997). Additive main effects and multiplicative interaction (AMMI) analysis of genotype-location interaction in variety trials repeated over years. Theoretical applied genetics, 94, 1072-1077.&lt;/li&gt;
&lt;li&gt;Ariyo, O. J. (1998). Use of additive main effects and multiplicative interaction model to analyse multilocation soybean varietal trials. J. Genet. and Breed, 129-134.&lt;/li&gt;
&lt;li&gt;Cornelius, P. L. (1993). Statistical tests and retention of terms in the Additive Main Effects and Multiplicative interaction model for cultivar trials. Crop Science, 33,1186-1193.&lt;/li&gt;
&lt;li&gt;Crossa, J. (1990). Statistical Analyses of multilocation trials. Advances in Agronomy, 44, 55-85.&lt;/li&gt;
&lt;li&gt;Gollob, H. F. (1968). A statistical model which combines features of factor analytic and analysis of variance techniques. Psychometrika, 33, 73-114.&lt;/li&gt;
&lt;li&gt;Lenth R., 2020. emmeans: Estimated Marginal Means, aka Least-Squares Means. R package version 1.4.6. &lt;a href=&#34;https://github.com/rvlenth/emmeans&#34; class=&#34;uri&#34;&gt;https://github.com/rvlenth/emmeans&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;de Mendiburu F., 2020. agricolae: Statistical Procedures for Agricultural Research. R package version 1.3-2. &lt;a href=&#34;https://CRAN.R-project.org/package=agricolae&#34; class=&#34;uri&#34;&gt;https://CRAN.R-project.org/package=agricolae&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Onofri, A., Ciriciofolo, E., 2007. Using R to perform the AMMI analysis on agriculture variety trials. R NEWS 7, 14–19.&lt;/li&gt;
&lt;li&gt;Stagnari F., Onofri A., Jemison J., Monotti M. (2006). Multivariate analyses to discriminate the behaviour of faba bean (Vicia faba L. var. minor) varieties as affected by sowing time in cool, low rainfall Mediterranean environments. Agronomy For Sustainable Development, 27, 387–397.&lt;/li&gt;
&lt;li&gt;Hadley Wickham, Romain François, Lionel Henry and Kirill Müller, 2020. dplyr: A Grammar of Data Manipulation. R package version 0.8.5. &lt;a href=&#34;https://CRAN.R-project.org/package=dplyr&#34; class=&#34;uri&#34;&gt;https://CRAN.R-project.org/package=dplyr&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Zobel, R. W., Wright, M.J., and Gauch, H. G. (1988). Statistical analysis of a yield trial. Agronomy Journal, 388-393.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Fitting &#39;complex&#39; mixed models with &#39;nlme&#39;. Example #1</title>
      <link>https://www.statforbiology.com/2019/stat_lmm_environmentalvariance/</link>
      <pubDate>Tue, 20 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2019/stat_lmm_environmentalvariance/</guid>
      <description>


&lt;div id=&#34;the-environmental-variance-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The environmental variance model&lt;/h1&gt;
&lt;p&gt;Fitting mixed models has become very common in biology and recent developments involve the manipulation of the variance-covariance matrix for random effects and residuals. To the best of my knowledge, within the frame of frequentist methods, the only freeware solution in R should be based on the ‘nlme’ package, as the ‘lmer’ package does not easily permit such manipulations. The ‘nlme’ package is fully described in Pinheiro and Bates (2000). Of course, the ‘asreml’ package can be used, but, unfortunately, this is not freeware.&lt;/p&gt;
&lt;p&gt;Coding mixed models in ‘nlme’ is not always easy, especially when we have crossed random effects, which is very common with agricultural experiments. I have been struggling with this issue very often in the last years and I thought it might be useful to publish a few examples in this blog, to save collegues from a few headaches. Please, note that I have already published other posts dealing with the use of the ‘lme()’ function in the ‘nlme’ package, for example &lt;a href=&#34;https://www.statforbiology.com/2019/stat_general_correlationindependence2/&#34;&gt;this post here&lt;/a&gt; about the correlation in designed experiments and &lt;a href=&#34;https://www.statforbiology.com/2019/stat_lmm_stabilityvariance/&#34;&gt;this other post here&lt;/a&gt;, about heteroscedastic multienvironment experiments.&lt;/p&gt;
&lt;p&gt;The first example in this series relates to a randomised complete block design with three replicates, comparing winter wheat genotypes. The experiment was repeated in seven years in the same location. The dataset (‘WinterWheat’) is available in the ‘aomisc’ package, which is the companion package for this blog and it is available on gitHub. Information on how to download and install the ‘aomisc’ package are given in &lt;a href=&#34;https://www.statforbiology.com/rpackages/&#34;&gt;this page&lt;/a&gt;. Please, note that this dataset shows the data for eight genotypes, but the model that we want to fit requires that the number of environments is higher than the number of genotypes. Therefore, we have to make a subset, at the beginning, removing a couple of genotypes.&lt;/p&gt;
&lt;p&gt;The first code snippet loads the ‘aomisc’ package and other necessary packages. Afterwards, it loads the ‘WinterWheat’ dataset, subsets it and turns the ‘Genotype’, ‘Year’ and ‘Block’ variables into factors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(plyr)
library(nlme)
library(aomisc)
data(WinterWheat)
WinterWheat &amp;lt;- WinterWheat[WinterWheat$Genotype != &amp;quot;SIMETO&amp;quot; &amp;amp; WinterWheat$Genotype != &amp;quot;SOLEX&amp;quot;,]
WinterWheat$Genotype &amp;lt;- factor(WinterWheat$Genotype)
WinterWheat$Year &amp;lt;- factor(WinterWheat$Year)
WinterWheat$Block &amp;lt;- factor(WinterWheat$Block)
head(WinterWheat, 10)
##    Plot Block Genotype Yield Year
## 1     2     1 COLOSSEO  6.73 1996
## 2     1     1    CRESO  6.02 1996
## 3    50     1   DUILIO  6.06 1996
## 4    49     1   GRAZIA  6.24 1996
## 5    63     1    IRIDE  6.23 1996
## 6    32     1 SANCARLO  5.45 1996
## 9   110     2 COLOSSEO  6.96 1996
## 10  137     2    CRESO  5.34 1996
## 11   91     2   DUILIO  5.57 1996
## 12  138     2   GRAZIA  6.09 1996&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Dealing with the above dataset, a good candidate model for data analyses is the so-called ‘environmental variance model’. This model is often used in stability analyses for multi-environment experiments and I will closely follow the coding proposed in Piepho (1999):&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ijk} = \mu + g_i + r_{jk}  +  h_{ij} + \varepsilon_{ijk}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_{ijk}\)&lt;/span&gt; is yield (or other trait) for the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th block, &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th genotype and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th environment, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the intercept, &lt;span class=&#34;math inline&#34;&gt;\(g_i\)&lt;/span&gt; is the effect for the i-th genotype, &lt;span class=&#34;math inline&#34;&gt;\(r_{jk}\)&lt;/span&gt; is the effect for the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th block in the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th environment, &lt;span class=&#34;math inline&#34;&gt;\(h_{ij}\)&lt;/span&gt; is a random deviation from the expected yield for the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th genotype in the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th environment and &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon_{ijk}\)&lt;/span&gt; is the residual variability of yield between plots, within each environment and block.&lt;/p&gt;
&lt;p&gt;We usually assume that &lt;span class=&#34;math inline&#34;&gt;\(r_{jk}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon_{ijk}\)&lt;/span&gt; are independent and normally distributed, with variances equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_r\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_e\)&lt;/span&gt;, respectively. Such an assumption may be questioned, but we will not do it now, for the sake of simplicity.&lt;/p&gt;
&lt;p&gt;Let’s concentrate on &lt;span class=&#34;math inline&#34;&gt;\(h_{ij}\)&lt;/span&gt;, which we will assume as normally distributed with variance-covariance matrix equal to &lt;span class=&#34;math inline&#34;&gt;\(\Omega\)&lt;/span&gt;. In particular, it is reasonable to expect that the genotypes will have different variances across environments (heteroscedasticity), which can be interpreted as static stability measures (‘environmental variances’; hence the name ‘environmental variance model’). Furthermore, it is reasonable that, if an environment is good for one genotype, it may also be good for other genotypes, so that yields in each environment are correlated, although the correlations can be different for each couple of genotypes. To reflect our expectations, the &lt;span class=&#34;math inline&#34;&gt;\(\Omega\)&lt;/span&gt; matrix needs to be totally unstructured, with the only constraint that it is positive definite.&lt;/p&gt;
&lt;p&gt;Piepho (1999) has shown how the above model can be coded by using SAS and I translated his code into R.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;EnvVarMod &amp;lt;- lme(Yield ~ Genotype, 
  random = list(Year = pdSymm(~Genotype - 1), 
              Year = pdIdent(~Block - 1)),
  control = list(opt = &amp;quot;optim&amp;quot;, maxIter = 100),
  data=WinterWheat)
VarCorr(EnvVarMod)
##                  Variance             StdDev    Corr                
## Year =           pdSymm(Genotype - 1)                               
## GenotypeCOLOSSEO 0.48876512           0.6991174 GCOLOS GCRESO GDUILI
## GenotypeCRESO    0.70949309           0.8423141 0.969               
## GenotypeDUILIO   2.37438440           1.5409038 0.840  0.840        
## GenotypeGRAZIA   1.18078525           1.0866394 0.844  0.763  0.942 
## GenotypeIRIDE    1.23555204           1.1115539 0.857  0.885  0.970 
## GenotypeSANCARLO 0.93335518           0.9661031 0.928  0.941  0.962 
## Year =           pdIdent(Block - 1)                                 
## Block1           0.02748257           0.1657787                     
## Block2           0.02748257           0.1657787                     
## Block3           0.02748257           0.1657787                     
## Residual         0.12990355           0.3604214                     
##                               
## Year =                        
## GenotypeCOLOSSEO GGRAZI GIRIDE
## GenotypeCRESO                 
## GenotypeDUILIO                
## GenotypeGRAZIA                
## GenotypeIRIDE    0.896        
## GenotypeSANCARLO 0.884  0.942 
## Year =                        
## Block1                        
## Block2                        
## Block3                        
## Residual&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I coded the random effects as a list, by using the ‘Year’ as the nesting factor (Galecki and Burzykowski, 2013). In order to specify a totally unstructured variance-covariance matrix for the genotypes within years, I used the ‘pdMat’ construct ‘pdSymm()’. This model is rather complex and may take long to converge.&lt;/p&gt;
&lt;p&gt;The environmental variances are retrieved by the following code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;envVar &amp;lt;- as.numeric ( VarCorr(EnvVarMod)[2:7,1] )
envVar
## [1] 0.4887651 0.7094931 2.3743844 1.1807853 1.2355520 0.9333552&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;while the correlations are given by:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;VarCorr(EnvVarMod)[2:7,3:7]
##                  Corr                                        
## GenotypeCOLOSSEO &amp;quot;GCOLOS&amp;quot; &amp;quot;GCRESO&amp;quot; &amp;quot;GDUILI&amp;quot; &amp;quot;GGRAZI&amp;quot; &amp;quot;GIRIDE&amp;quot;
## GenotypeCRESO    &amp;quot;0.969&amp;quot;  &amp;quot;&amp;quot;       &amp;quot;&amp;quot;       &amp;quot;&amp;quot;       &amp;quot;&amp;quot;      
## GenotypeDUILIO   &amp;quot;0.840&amp;quot;  &amp;quot;0.840&amp;quot;  &amp;quot;&amp;quot;       &amp;quot;&amp;quot;       &amp;quot;&amp;quot;      
## GenotypeGRAZIA   &amp;quot;0.844&amp;quot;  &amp;quot;0.763&amp;quot;  &amp;quot;0.942&amp;quot;  &amp;quot;&amp;quot;       &amp;quot;&amp;quot;      
## GenotypeIRIDE    &amp;quot;0.857&amp;quot;  &amp;quot;0.885&amp;quot;  &amp;quot;0.970&amp;quot;  &amp;quot;0.896&amp;quot;  &amp;quot;&amp;quot;      
## GenotypeSANCARLO &amp;quot;0.928&amp;quot;  &amp;quot;0.941&amp;quot;  &amp;quot;0.962&amp;quot;  &amp;quot;0.884&amp;quot;  &amp;quot;0.942&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;unweighted-two-stage-fitting&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Unweighted two-stage fitting&lt;/h1&gt;
&lt;p&gt;In his original paper, Piepho (1999) also gave SAS code to analyse the means of the ‘genotype x environment’ combinations. Indeed, agronomists and plant breeders often adopt a two-steps fitting procedure: in the first step, the means across blocks are calculated for all genotypes in all environments. In the second step, these means are used to fit an environmental variance model. This two-step process is less demanding in terms of computer resources and it is correct whenever the experiments are equireplicated, with no missing ‘genotype x environment’ combinations. Furthermore, we need to be able to assume similar variances within all experiments.&lt;/p&gt;
&lt;p&gt;I would also like to give an example of this two-step analysis method. In the first step, we can use the ‘ddply()’ function in the package ‘plyr’:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#First step
WinterWheatM &amp;lt;- ddply(WinterWheat, c(&amp;quot;Genotype&amp;quot;, &amp;quot;Year&amp;quot;), 
      function(df) c(Yield = mean(df$Yield)) )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have retrieved the means for genotypes in all years, we can fit the following model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ij} = \mu + g_i + a_{ij}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_{ij}\)&lt;/span&gt; is the mean yield for the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th genotype in the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th environment and &lt;span class=&#34;math inline&#34;&gt;\(a_{ij}\)&lt;/span&gt; is the residual term, which includes the genotype x environment random interaction, the block x environment random interaction and the residual error term.&lt;/p&gt;
&lt;p&gt;In this model we have only one random effect (&lt;span class=&#34;math inline&#34;&gt;\(a_{ij}\)&lt;/span&gt;) and, therefore, this is a fixed linear model. However, we need to model the variance-covariance matrix of residuals (&lt;span class=&#34;math inline&#34;&gt;\(R\)&lt;/span&gt;), by adopting a totally unstructured form. Please, note that, when working with raw data, we have modelled &lt;span class=&#34;math inline&#34;&gt;\(\Omega\)&lt;/span&gt;, i.e. the variance-covariance matrix for the random effects. I have used the ‘gls()’ function, together with the ‘weights’ and ‘correlation’ arguments. See the code below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Second step
envVarModM &amp;lt;- gls(Yield ~ Genotype, 
  data = WinterWheatM,
  weights = varIdent(form=~1|Genotype),
  correlation = corSymm(form=~1|Year))
summary(envVarModM)
## Generalized least squares fit by REML
##   Model: Yield ~ Genotype 
##   Data: WinterWheatM 
##       AIC      BIC   logLik
##   80.6022 123.3572 -13.3011
## 
## Correlation Structure: General
##  Formula: ~1 | Year 
##  Parameter estimate(s):
##  Correlation: 
##   1     2     3     4     5    
## 2 0.947                        
## 3 0.809 0.815                  
## 4 0.816 0.736 0.921            
## 5 0.817 0.866 0.952 0.869      
## 6 0.888 0.925 0.949 0.856 0.907
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | Genotype 
##  Parameter estimates:
## COLOSSEO    CRESO   DUILIO   GRAZIA    IRIDE SANCARLO 
## 1.000000 1.189653 2.143713 1.528848 1.560620 1.356423 
## 
## Coefficients:
##                      Value Std.Error   t-value p-value
## (Intercept)       6.413333 0.2742314 23.386574  0.0000
## GenotypeCRESO    -0.439524 0.1107463 -3.968746  0.0003
## GenotypeDUILIO    0.178571 0.3999797  0.446451  0.6579
## GenotypeGRAZIA   -0.330952 0.2518270 -1.314205  0.1971
## GenotypeIRIDE     0.281905 0.2580726  1.092347  0.2819
## GenotypeSANCARLO -0.192857 0.1802547 -1.069915  0.2918
## 
##  Correlation: 
##                  (Intr) GCRESO GDUILI GGRAZI GIRIDE
## GenotypeCRESO     0.312                            
## GenotypeDUILIO    0.503  0.371                     
## GenotypeGRAZIA    0.269 -0.095  0.774              
## GenotypeIRIDE     0.292  0.545  0.857  0.638       
## GenotypeSANCARLO  0.310  0.612  0.856  0.537  0.713
## 
## Standardized residuals:
##        Min         Q1        Med         Q3        Max 
## -2.0949678 -0.5680656  0.1735444  0.7599596  1.3395000 
## 
## Residual standard error: 0.7255481 
## Degrees of freedom: 42 total; 36 residual&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variance-covariance matrix for residuals can be obtained using the ‘getVarCov()’ function in the ‘nlme’ package, although I had to discover that there is a small buglet there, which causes problems in some instances (such as here). Please, &lt;a href=&#34;https://www.jepusto.com/bug-in-nlme-getvarcov/&#34;&gt;see this link&lt;/a&gt;; I have included the correct code in the ‘getVarCov.gls()’ function in the ‘aomisc’ package, that is the companion package for this blog.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;R &amp;lt;- getVarCov.gls(envVarModM)
R
## Marginal variance covariance matrix
##         [,1]    [,2]    [,3]    [,4]    [,5]    [,6]
## [1,] 0.52642 0.59280 0.91285 0.65647 0.67116 0.63376
## [2,] 0.59280 0.74503 1.09440 0.70422 0.84652 0.78560
## [3,] 0.91285 1.09440 2.41920 1.58850 1.67700 1.45230
## [4,] 0.65647 0.70422 1.58850 1.23040 1.09160 0.93442
## [5,] 0.67116 0.84652 1.67700 1.09160 1.28210 1.01070
## [6,] 0.63376 0.78560 1.45230 0.93442 1.01070 0.96855
##   Standard Deviations: 0.72555 0.86315 1.5554 1.1093 1.1323 0.98415&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As the design is perfectly balanced, the diagonal elements of the above matrix correspond to the variances of genotypes across environments:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tapply(WinterWheatM$Yield, WinterWheatM$Genotype, var)
##  COLOSSEO     CRESO    DUILIO    GRAZIA     IRIDE  SANCARLO 
## 0.5264185 0.7450275 2.4191624 1.2304397 1.2821143 0.9685497&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which can also be retreived by the ‘stability’ package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(stability)
## Registered S3 methods overwritten by &amp;#39;lme4&amp;#39;:
##   method                          from
##   cooks.distance.influence.merMod car 
##   influence.merMod                car 
##   dfbeta.influence.merMod         car 
##   dfbetas.influence.merMod        car
envVarStab &amp;lt;-
  stab_measures(
    .data = WinterWheatM,
    .y = Yield,
    .gen = Genotype,
    .env = Year
  )

envVarStab$StabMeasures
## # A tibble: 6 x 7
##   Genotype  Mean GenSS   Var    CV  Ecov ShuklaVar
##   &amp;lt;fct&amp;gt;    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 COLOSSEO  6.41  3.16 0.526  11.3 1.25     0.258 
## 2 CRESO     5.97  4.47 0.745  14.4 1.01     0.198 
## 3 DUILIO    6.59 14.5  2.42   23.6 2.31     0.522 
## 4 GRAZIA    6.08  7.38 1.23   18.2 1.05     0.208 
## 5 IRIDE     6.70  7.69 1.28   16.9 0.614    0.0989
## 6 SANCARLO  6.22  5.81 0.969  15.8 0.320    0.0254&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Strictly speaking, those variances are not the environmental variances, as they also contain the within-experiment and within block random variability, which needs to be separately estimated during the first step.&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;Andrea Onofri&lt;br /&gt;
Department of Agricultural, Food and Environmental Sciences&lt;br /&gt;
University of Perugia (Italy)&lt;/p&gt;
&lt;p&gt;#References&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gałecki, A., Burzykowski, T., 2013. Linear mixed-effects models using R: a step-by-step approach. Springer, Berlin.&lt;/li&gt;
&lt;li&gt;Muhammad Yaseen, Kent M. Eskridge and Ghulam Murtaza (2018). stability: Stability Analysis of Genotype by Environment Interaction (GEI). R package version 0.5.0. &lt;a href=&#34;https://CRAN.R-project.org/package=stability&#34; class=&#34;uri&#34;&gt;https://CRAN.R-project.org/package=stability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Piepho, H.-P., 1999. Stability Analysis Using the SAS System. Agronomy Journal 91, 154–160.&lt;/li&gt;
&lt;li&gt;Pinheiro, J.C., Bates, D.M., 2000. Mixed-Effects Models in S and S-Plus, Springer-Verlag Inc. ed. Springer-Verlag Inc., New York.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Genotype experiments: fitting a stability variance model with R</title>
      <link>https://www.statforbiology.com/2019/stat_lmm_stabilityvariance/</link>
      <pubDate>Thu, 06 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>https://www.statforbiology.com/2019/stat_lmm_stabilityvariance/</guid>
      <description>


&lt;p&gt;Yield stability is a fundamental aspect for the selection of crop genotypes. The definition of stability is rather complex (see, for example, Annichiarico, 2002); in simple terms, the yield is stable when it does not change much from one environment to the other. It is an important trait, that helps farmers to maintain a good income in most years.&lt;/p&gt;
&lt;p&gt;Agronomists and plant breeders are continuosly concerned with the assessment of genotype stability; this is accomplished by planning genotype experiments, where a number of genotypes is compared on randomised complete block designs, with three to five replicates. These experiments are repeated in several years and/or several locations, in order to measure how the environment influences yield level and the ranking of genotypes.&lt;/p&gt;
&lt;p&gt;I would like to show an exemplary dataset, referring to a multienvironment experiment with winter wheat. Eight genotypes were compared in seven years in central Italy, on randomised complete block designs with three replicates. The ‘WinterWheat’ dataset is available in the ‘aomisc’ package, which is the accompanying package for this blog and it is available on gitHub. Information on how to download and install the ‘aomisc’ package are given in &lt;a href=&#34;https://www.statforbiology.com/rpackages/&#34;&gt;this page&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The first code snippet loads the ‘aomisc’ package and other necessary packages. Afterwards, it loads the ‘WinterWheat’ dataset and turns the ‘Year’ and ‘Block’ variables into factors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(plyr)
library(nlme)
library(aomisc)
## Loading required package: drc
## Loading required package: MASS
## Loading required package: drcData
## 
## &amp;#39;drc&amp;#39; has been loaded.
## Please cite R and &amp;#39;drc&amp;#39; if used for a publication,
## for references type &amp;#39;citation()&amp;#39; and &amp;#39;citation(&amp;#39;drc&amp;#39;)&amp;#39;.
## 
## Attaching package: &amp;#39;drc&amp;#39;
## The following objects are masked from &amp;#39;package:stats&amp;#39;:
## 
##     gaussian, getInitial
data(WinterWheat)
WinterWheat$Year &amp;lt;- factor(WinterWheat$Year)
WinterWheat$Block &amp;lt;- factor(WinterWheat$Block)
head(WinterWheat, 10)
##    Plot Block Genotype Yield Year
## 1     2     1 COLOSSEO  6.73 1996
## 2     1     1    CRESO  6.02 1996
## 3    50     1   DUILIO  6.06 1996
## 4    49     1   GRAZIA  6.24 1996
## 5    63     1    IRIDE  6.23 1996
## 6    32     1 SANCARLO  5.45 1996
## 7    35     1   SIMETO  4.99 1996
## 8    33     1    SOLEX  6.08 1996
## 9   110     2 COLOSSEO  6.96 1996
## 10  137     2    CRESO  5.34 1996&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please, note that this is a multienvironment experiment as it is repeated in several years: each year is an ‘environment’ in itself. Furthermore, please note that the year effect (i.e. the environment effect) is of random nature: we select the years, but we cannot control the weather conditions.&lt;/p&gt;
&lt;div id=&#34;defining-a-linear-mixed-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Defining a linear mixed model&lt;/h1&gt;
&lt;p&gt;Dealing with the above dataset, a good candidate model for data analyses is the following linear model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_{ijk} = \mu + \gamma_{kj} + g_i + e_j +  ge_{ij} + \varepsilon_{ijk}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is yield (or other trait) for the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th block, &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th genotype and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th environment, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the intercept, &lt;span class=&#34;math inline&#34;&gt;\(\gamma\)&lt;/span&gt; is the effect of the &lt;span class=&#34;math inline&#34;&gt;\(k\)&lt;/span&gt;-th block in the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th environment, &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; is the effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th genotype, &lt;span class=&#34;math inline&#34;&gt;\(e\)&lt;/span&gt; is the effect of the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th environment, &lt;span class=&#34;math inline&#34;&gt;\(ge\)&lt;/span&gt; is the interaction effect of the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th genotype and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;-th environment, while &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon\)&lt;/span&gt; is the residual random term, which is assumed as normally distributed with variance equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;As I said before, the block effect, the environment effect and the ‘genotype x environment’ interaction are usually regarded as random. Therefore, they are assumed as normally distributed, with means equal to 0 and variances respectively equal to &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{\gamma}\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{e}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{ge}\)&lt;/span&gt;. Indeed, the above model is a Linear Mixed Model (LMM).&lt;/p&gt;
&lt;p&gt;Let’s concentrate on &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{ge}\)&lt;/span&gt;. It is clear that this value is a measure of instability: if it is high, genotypes may respond differently to different environments. In this way, each genotype can be favored in some specific environments and disfavored in some others. Shukla (1974) has suggested that we should allow &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2_{ge}\)&lt;/span&gt; assume a different value for each genotype and use these components as a measure of stability (stability variances). According to Shukla, a genotype is considered stable when its stability variance is lower than &lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Piepho (1999) has shown that stability variances can be obtained within the mixed model framework, by appropriately coding the variance-covariance matrix for random effects. He gave SAS code to accomplish this task and, to me, it was not straightforward to transport his code into R. I finally succeeded and I though I should better share my code, just in case it helps someone save a few headaches.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fitting-a-stability-variance-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fitting a stability variance model&lt;/h1&gt;
&lt;p&gt;As we have to model the variance-covariance of random effects, we need to use the ‘lme’ function in the ‘nlme’ package (Pinheiro and Bates, 2000). The problem is that random effects are crossed and they are not easily coded with this package. After an extensive literature search, I could find the solution in the aforementioned book (at pag. 162-163) and in Galecki and Burzykowski (2013). The trick is made by appropriately using the ‘pdMat’ construct (‘pdBlocked’ and ‘pdIdent’). In the code below, I have built a block-diagonal variance-covariance matrix for random effects, where blocks and genotypes are nested within years:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model.mix &amp;lt;- lme(Yield ~ Genotype, 
  random=list(Year = pdBlocked(list(pdIdent(~1),
                                    pdIdent(~Block - 1),
                                    pdIdent(~Genotype - 1)))),
  data=WinterWheat)
VarCorr(model.mix)
## Year = pdIdent(1), pdIdent(Block - 1), pdIdent(Genotype - 1) 
##                  Variance   StdDev   
## (Intercept)      1.07314201 1.0359257
## Block1           0.01641744 0.1281306
## Block2           0.01641744 0.1281306
## Block3           0.01641744 0.1281306
## GenotypeCOLOSSEO 0.17034091 0.4127238
## GenotypeCRESO    0.17034091 0.4127238
## GenotypeDUILIO   0.17034091 0.4127238
## GenotypeGRAZIA   0.17034091 0.4127238
## GenotypeIRIDE    0.17034091 0.4127238
## GenotypeSANCARLO 0.17034091 0.4127238
## GenotypeSIMETO   0.17034091 0.4127238
## GenotypeSOLEX    0.17034091 0.4127238
## Residual         0.14880400 0.3857512&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Wee see that the variance component for the ‘genotype x environment’ interaction is the same for all genotypes and equal to 0.170.&lt;/p&gt;
&lt;p&gt;Allowing for a different variance component per genotype is relatively easy, by replacing ‘pdIdent()’ with ‘pdDiag()’, as shown below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model.mix2 &amp;lt;- lme(Yield ~ Genotype, 
  random=list(Year = pdBlocked(list(pdIdent(~1),
                                    pdIdent(~Block - 1),
                                    pdDiag(~Genotype - 1)))),
  data=WinterWheat)
VarCorr(model.mix2)
## Year = pdIdent(1), pdIdent(Block - 1), pdDiag(Genotype - 1) 
##                  Variance   StdDev   
## (Intercept)      0.86592829 0.9305527
## Block1           0.01641744 0.1281305
## Block2           0.01641744 0.1281305
## Block3           0.01641744 0.1281305
## GenotypeCOLOSSEO 0.10427267 0.3229128
## GenotypeCRESO    0.09588553 0.3096539
## GenotypeDUILIO   0.47612340 0.6900170
## GenotypeGRAZIA   0.15286445 0.3909788
## GenotypeIRIDE    0.11860160 0.3443858
## GenotypeSANCARLO 0.02575029 0.1604690
## GenotypeSIMETO   0.42998504 0.6557324
## GenotypeSOLEX    0.06713590 0.2591060
## Residual         0.14880439 0.3857517&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that we have now different variance components and we can classify some genotypes as stable (e.g. Sancarlo, Solex and Creso) and some others as unstable (e.g. Duilio and Simeto).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;working-with-the-means&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Working with the means&lt;/h1&gt;
&lt;p&gt;In his original paper, Piepho (1999) also gave SAS code to analyse the means of the ‘genotype x environment’ combinations. Indeed, agronomists and plant breeders often adopt a two-steps fitting procedure: in the first step, the means across blocks are calculated for all genotypes in all environments. In the second step, these means are used to fit a stability variance model. This two-step process is less demanding in terms of computer resources and it is correct whenever the experiments are equireplicated, with no missing ‘genotype x environment’ combinations. Furthermore, we need to be able to assume similar variances within all experiments.&lt;/p&gt;
&lt;p&gt;I would also like to give an example of this two-step analysis method. In the first step, we can use the ‘ddply()’ function in the package ‘plyr’:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#First step
WinterWheatM &amp;lt;- ddply(WinterWheat, c(&amp;quot;Genotype&amp;quot;, &amp;quot;Year&amp;quot;), 
      function(df) c(Yield = mean(df$Yield)) )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have retreived the means for genotypes in all years, we can fit a stability variance model, although we have to use a different approach, with respect to the one we used with the whole dataset. In this case, we need to model the variance of residuals, introducing within-group (within-year) heteroscedasticity. The ‘weights’ argument can be used, together with the ‘pdIdent()’ variance function, to allow for a different variance for each genotype. See the code below.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#Second step
model.mixM &amp;lt;- lme(Yield ~ Genotype, random = ~ 1|Year, data = WinterWheatM,
                 weights = varIdent(form=~1|Genotype))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code to retrieve the within-year variances is not obvious, unfortunately. However, you can use the folllowing snippet as a guidance.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vF &amp;lt;- model.mixM$modelStruct$varStruct
sdRatios &amp;lt;- c(1, coef(vF, unconstrained = F))
names(sdRatios)[1] &amp;lt;- &amp;quot;COLOSSEO&amp;quot;
scalePar &amp;lt;- model.mixM$sigma
sigma2i &amp;lt;- (scalePar * sdRatios)^2
sigma2i
##   COLOSSEO      CRESO     DUILIO     GRAZIA      IRIDE   SANCARLO 
## 0.15387857 0.14548985 0.52571780 0.20246664 0.16820264 0.07535112 
##     SIMETO      SOLEX 
## 0.47958756 0.11673900&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code outputs ‘sigma2i’, which does not contain the stability variances. Indeed, we should remove the within-experiment error (&lt;span class=&#34;math inline&#34;&gt;\(\sigma^2\)&lt;/span&gt;), which can only be estimated from the whole dataset. Indeed, if we take the estimate of 0.1488 (see code above), divide by three (the number of blocks) and subtract from ‘sigma2i’, we get:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sigma2i - model.mix2$sigma^2/3
##   COLOSSEO      CRESO     DUILIO     GRAZIA      IRIDE   SANCARLO 
## 0.10427711 0.09588839 0.47611634 0.15286517 0.11860118 0.02574966 
##     SIMETO      SOLEX 
## 0.42998610 0.06713754&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which are the stability variances, as obtained with the analyses of the whole dataset.&lt;/p&gt;
&lt;p&gt;Thanks for reading!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;References&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Annichiarico, P., 2002. Genotype x Environment Interactions - Challenges and Opportunities for Plant Breeding and Cultivar Recommendations. Plant Production and protection paper, Food &amp;amp; Agriculture Organization of the United Nations (FAO), Roma.&lt;/li&gt;
&lt;li&gt;Gałecki, A., Burzykowski, T., 2013. Linear mixed-effects models using R: a step-by-step approach. Springer, Berlin.&lt;/li&gt;
&lt;li&gt;Piepho, H.-P., 1999. Stability Analysis Using the SAS System. Agronomy Journal 91, 154–160.&lt;/li&gt;
&lt;li&gt;Pinheiro, J.C., Bates, D.M., 2000. Mixed-Effects Models in S and S-Plus, Springer-Verlag Inc. ed. Springer-Verlag Inc., New York.&lt;/li&gt;
&lt;li&gt;Shukla, G.K., 1972. Some statistical aspects of partitioning genotype-environmental components of variability. Heredity 29, 237–245.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>