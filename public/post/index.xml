<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on The broken bridge between biologists and statisticians</title>
    <link>/post/</link>
    <description>Recent content in Posts on The broken bridge between biologists and statisticians</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>Copyright © 2018, @AndreaOnofri</copyright>
    <lastBuildDate>Tue, 19 Feb 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Drowning in a glass of water: variance-covariance and correlation matrices</title>
      <link>/2019/stat_general_correlationcovariance/</link>
      <pubDate>Tue, 19 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/stat_general_correlationcovariance/</guid>
      <description>One of the easiest tasks in R is to get correlations between each pair of variables in a dataset. As an example, let’s take the first four columns in the ‘mtcars’ dataset, that is available within R. Getting the variances-covariances and the correlations is straightforward.
data(mtcars) matr &amp;lt;- mtcars[,1:4] #Covariances cov(matr) ## mpg cyl disp hp ## mpg 36.324103 -9.172379 -633.0972 -320.7321 ## cyl -9.172379 3.189516 199.6603 101.9315 ## disp -633.</description>
    </item>
    
    <item>
      <title>Going back to the basics: the correlation coefficient</title>
      <link>/2019/stat_general_correlation_alookat/</link>
      <pubDate>Thu, 07 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/stat_general_correlation_alookat/</guid>
      <description>A measure of joint variability In statistics, dependence or association is any statistical relationship, whether causal or not, between two random variables or bivariate data. It is often measured by the Pearson correlation coefficient:
\[\rho _{X,Y} =\textrm{corr} (X,Y) = \frac {\textrm{cov}(X,Y) }{ \sigma_X \sigma_Y } = \frac{ \sum_{1 = 1}^n [(X - \mu_X)(Y - \mu_Y)] }{ \sigma_X \sigma_Y }\]
Other measures of correlation can be thought of, such as the Spearman \(\rho\) rank correlation coefficient or Kendall \(\tau\) rank correlation coefficient.</description>
    </item>
    
    <item>
      <title>My first experience with blogdown</title>
      <link>/2018/2018-11_15-first-day-with-blogdown/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/2018-11_15-first-day-with-blogdown/</guid>
      <description>This is my first day at work with blogdown. I must admit it is pretty overwhelming at the beginning &amp;hellip;
I thought that it might be useful to write down a few notes, to summarise my steps ahead, during the learning process. I do not work with blogdown everyday and I tend to forget things quite easily. Therefore, these notes may help me recap how far I have come. And they might also help other beginners, to speed up their initial steps with such a powerful blogging platform.</description>
    </item>
    
    <item>
      <title>Sample variance and population variance: which of the two?</title>
      <link>/2018/stat_general_variancesamplepop/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/stat_general_variancesamplepop/</guid>
      <description>Teaching experimental methodology in agriculture related master courses poses some peculiar problems. One of these is to explain the difference between sample variance and population variance. For the students it is usually easy to grasp the idea that, being the mean the ‘center’ of the dataset, it is relevant to measure the average distance to the mean for all individuals in the dataset. Of course, we need to take the sum of squared distances, otherwise negative and positive residuals cancel each other out.</description>
    </item>
    
    <item>
      <title>Is R dangerous? Side effects of free software for biologists</title>
      <link>/2014/2014-06-08-the-danger-of-r/</link>
      <pubDate>Sun, 08 Jun 2014 00:00:00 +0000</pubDate>
      
      <guid>/2014/2014-06-08-the-danger-of-r/</guid>
      <description>When I started my career in the biological field (it’s already 25 years ago), only the luckiest of us had access to very advanced statistical software. Licenses were very expensive and it was not easy to convince the boss that they were really necessary: “Why do you need to spend so much money to perform an ANOVA?”. Indeed, simple one-way or two-ways ANOVAs were quite easy to perform and one of the people in my group had already built the appropriate routines for several designs, by using the GW-BASIC language.</description>
    </item>
    
  </channel>
</rss>